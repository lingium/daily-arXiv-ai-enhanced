{"id": "2601.05151", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05151", "abs": "https://arxiv.org/abs/2601.05151", "authors": ["Anastasiia Bakhmach", "Paul Dufossé", "Andrea Vaglio", "Florence Monville", "Laurent Greillier", "Fabrice Barlési", "Sébastien Benzekry"], "title": "ROOFS: RObust biOmarker Feature Selection", "comment": null, "summary": "Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models."}
{"id": "2601.05227", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.05227", "abs": "https://arxiv.org/abs/2601.05227", "authors": ["James Rice"], "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data", "comment": "20 pages, 6330 words", "summary": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.\n  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning."}
{"id": "2601.04625", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.04625", "abs": "https://arxiv.org/abs/2601.04625", "authors": ["Santiago Marin", "Bronwyn Loong", "Anton H. Westveld"], "title": "Bayesian nonparametric modeling of dynamic pollution clusters through an autoregressive logistic-beta Stirling-gamma process", "comment": "24 pages, 10 figures", "summary": "Fine suspended particulates (FSP), commonly known as PM2.5, are among the most harmful air pollutants, posing serious risks to population health and environmental integrity. As such, accurately identifying latent clusters of FSP is essential for effective air quality and public health management. This task, however, is notably nontrivial as FSP clusters may depend on various regional and temporal factors, which should be incorporated in the modeling process. Thus, we capitalize on Bayesian nonparametric dynamic clustering ideas, in which clustering structures may be influenced by complex dependencies. Existing implementations of dynamic clustering, however, rely on copula-based dependent Dirichlet processes (DPs), presenting considerable computational challenges for real-world deployment. With this in mind, we propose a more efficient alternative for dynamic clustering by incorporating the novel ideas of logistic-beta dependent DPs. We also adopt a Stirling-gamma prior, a novel distribution family, on the concentration parameter of our underlying DP, easing the process of incorporating prior knowledge into the model. Efficient computational strategies for posterior inference are also presented. We apply our proposed method to identify dynamic FSP clusters across Chile and demonstrate its superior performance over existing approaches."}
{"id": "2601.05227", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.05227", "abs": "https://arxiv.org/abs/2601.05227", "authors": ["James Rice"], "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data", "comment": "20 pages, 6330 words", "summary": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.\n  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning."}
{"id": "2601.04625", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.04625", "abs": "https://arxiv.org/abs/2601.04625", "authors": ["Santiago Marin", "Bronwyn Loong", "Anton H. Westveld"], "title": "Bayesian nonparametric modeling of dynamic pollution clusters through an autoregressive logistic-beta Stirling-gamma process", "comment": "24 pages, 10 figures", "summary": "Fine suspended particulates (FSP), commonly known as PM2.5, are among the most harmful air pollutants, posing serious risks to population health and environmental integrity. As such, accurately identifying latent clusters of FSP is essential for effective air quality and public health management. This task, however, is notably nontrivial as FSP clusters may depend on various regional and temporal factors, which should be incorporated in the modeling process. Thus, we capitalize on Bayesian nonparametric dynamic clustering ideas, in which clustering structures may be influenced by complex dependencies. Existing implementations of dynamic clustering, however, rely on copula-based dependent Dirichlet processes (DPs), presenting considerable computational challenges for real-world deployment. With this in mind, we propose a more efficient alternative for dynamic clustering by incorporating the novel ideas of logistic-beta dependent DPs. We also adopt a Stirling-gamma prior, a novel distribution family, on the concentration parameter of our underlying DP, easing the process of incorporating prior knowledge into the model. Efficient computational strategies for posterior inference are also presented. We apply our proposed method to identify dynamic FSP clusters across Chile and demonstrate its superior performance over existing approaches."}
{"id": "2601.04663", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2601.04663", "abs": "https://arxiv.org/abs/2601.04663", "authors": ["Tomohiro Ando", "Tadao Hoshino", "Ruey Tsay"], "title": "Quantile Vector Autoregression without Crossing", "comment": null, "summary": "This paper considers estimation and model selection of quantile vector autoregression (QVAR). Conventional quantile regression often yields undesirable crossing quantile curves, violating the monotonicity of quantiles. To address this issue, we propose a simplex quantile vector autoregression (SQVAR) framework, which transforms the autoregressive (AR) structure of the original QVAR model into a simplex, ensuring that the estimated quantile curves remain monotonic across all quantile levels. In addition, we impose the smoothly clipped absolute deviation (SCAD) penalty on the SQVAR model to mitigate the explosive nature of the parameter space. We further develop a Bayesian information criterion (BIC)-based procedure for selecting the optimal penalty parameter and introduce new frameworks for impulse response analysis of QVAR models. Finally, we establish asymptotic properties of the proposed method, including the convergence rate and asymptotic normality of the estimator, the consistency of AR order selection, and the validity of the BIC-based penalty selection. For illustration, we apply the proposed method to U.S. financial market data, highlighting the usefulness of our SQVAR method."}
{"id": "2601.05128", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05128", "abs": "https://arxiv.org/abs/2601.05128", "authors": ["Alex Ocampo", "Enrico Giudice", "Zachary R. McCaw", "Tim P. Morris"], "title": "Revealing the Truth: Calculating True Values in Causal Inference Simulation Studies via Gaussian Quadrature", "comment": null, "summary": "Simulation studies are used to understand the properties of statistical methods. A key luxury in many simulation studies is knowledge of the true value (i.e. the estimand) being targeted. With this oracle knowledge in-hand, the researcher conducting the simulation study can assess across repeated realizations of the data how well a given method recovers the truth. In causal inference simulation studies, the truth is rarely a simple parameter of the statistical model chosen to generate the data. Instead, the estimand is often an average treatment effect, marginalized over the distribution of confounders and/or mediators. Luckily, these variables are often generated from common distributions such as the normal, uniform, exponential, or gamma. For all these distributions, Gaussian quadratures provide efficient and accurate calculation for integrands with integral kernels that stem from known probability density functions. We demonstrate through four applications how to use Gaussian quadrature to accurately and efficiently compute the true causal estimand. We also compare the pros and cons of Gauss-Hermite quadrature to Monte Carlo integration approaches, which we use as benchmarks. Overall, we demonstrate that the Gaussian quadrature is an accurate tool with negligible computation time, yet is underused for calculating the true causal estimands in simulation studies."}
{"id": "2601.04644", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.04644", "abs": "https://arxiv.org/abs/2601.04644", "authors": ["Nayana Mukherjee", "Chitradipa Chakraborty"], "title": "Cluster-Based Bayesian SIRD Modeling of Chickenpox Epidemiology in India", "comment": "28 pages, 5 figures", "summary": "This study presents a cluster-based Bayesian SIRD model to analyze the epidemiology of chickenpox (varicella) in India, utilizing data from 1990 to 2021. We employed an age-structured approach, dividing the population into juvenile, adult, and elderly groups, to capture the disease's transmission dynamics across diverse demographic groups. The model incorporates a Holling-type incidence function, which accounts for the saturation effect of transmission at high prevalence levels, and applies Bayesian inference to estimate key epidemiological parameters, including transmission rates, recovery rates, and mortality rates. The study further explores cluster analysis to identify regional clusters within India based on the similarities in chickenpox transmission dynamics, using criteria like incidence, prevalence, and mortality rates. We perform K-means clustering to uncover three distinct epidemiological regimes, which vary in terms of outbreak potential and age-specific dynamics. The findings highlight juveniles as the primary drivers of transmission, while the elderly face a disproportionately high mortality burden. Our results underscore the importance of age-targeted interventions and suggest that regional heterogeneity should be considered in public health strategies for disease control. The model offers a transparent, reproducible framework for understanding long-term transmission dynamics and supports evidence-based planning for chickenpox control in India. The practical utility of the model is further validated through a simulation study."}
