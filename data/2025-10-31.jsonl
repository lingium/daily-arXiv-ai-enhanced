{"id": "2510.25811", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25811", "abs": "https://arxiv.org/abs/2510.25811", "authors": ["William Réveillard", "Richard Combes"], "title": "Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms", "comment": "31 pages; NeurIPS 2025", "summary": "We consider a stochastic multi-armed bandit problem with i.i.d. rewards where\nthe expected reward function is multimodal with at most m modes. We propose the\nfirst known computationally tractable algorithm for computing the solution to\nthe Graves-Lai optimization problem, which in turn enables the implementation\nof asymptotically optimal algorithms for this bandit problem. The code for the\nproposed algorithms is publicly available at\nhttps://github.com/wilrev/MultimodalBandits"}
{"id": "2510.26723", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26723", "abs": "https://arxiv.org/abs/2510.26723", "authors": ["Masahiro Kato"], "title": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "comment": null, "summary": "The goal of policy learning is to train a policy function that recommends a\ntreatment given covariates to maximize population welfare. There are two major\napproaches in policy learning: the empirical welfare maximization (EWM)\napproach and the plug-in approach. The EWM approach is analogous to a\nclassification problem, where one first builds an estimator of the population\nwelfare, which is a functional of policy functions, and then trains a policy by\nmaximizing the estimated welfare. In contrast, the plug-in approach is based on\nregression, where one first estimates the conditional average treatment effect\n(CATE) and then recommends the treatment with the highest estimated outcome.\nThis study bridges the gap between the two approaches by showing that both are\nbased on essentially the same optimization problem. In particular, we prove an\nexact equivalence between EWM and least squares over a reparameterization of\nthe policy class. As a consequence, the two approaches are interchangeable in\nseveral respects and share the same theoretical guarantees under common\nconditions. Leveraging this equivalence, we propose a novel regularization\nmethod for policy learning. Our findings yield a convex and computationally\nefficient training procedure that avoids the NP-hard combinatorial step\ntypically required in EWM."}
{"id": "2510.26783", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26783", "abs": "https://arxiv.org/abs/2510.26783", "authors": ["Masahiro Kato"], "title": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression", "comment": null, "summary": "This note introduces a unified theory for causal inference that integrates\nRiesz regression, covariate balancing, density-ratio estimation (DRE), targeted\nmaximum likelihood estimation (TMLE), and the matching estimator in average\ntreatment effect (ATE) estimation. In ATE estimation, the balancing weights and\nthe regression functions of the outcome play important roles, where the\nbalancing weights are referred to as the Riesz representer, bias-correction\nterm, and clever covariates, depending on the context. Riesz regression,\ncovariate balancing, DRE, and the matching estimator are methods for estimating\nthe balancing weights, where Riesz regression is essentially equivalent to DRE\nin the ATE context, the matching estimator is a special case of DRE, and DRE is\nin a dual relationship with covariate balancing. TMLE is a method for\nconstructing regression function estimators such that the leading bias term\nbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density\nRatio Estimation and Riesz Regression."}
{"id": "2510.25811", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25811", "abs": "https://arxiv.org/abs/2510.25811", "authors": ["William Réveillard", "Richard Combes"], "title": "Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms", "comment": "31 pages; NeurIPS 2025", "summary": "We consider a stochastic multi-armed bandit problem with i.i.d. rewards where\nthe expected reward function is multimodal with at most m modes. We propose the\nfirst known computationally tractable algorithm for computing the solution to\nthe Graves-Lai optimization problem, which in turn enables the implementation\nof asymptotically optimal algorithms for this bandit problem. The code for the\nproposed algorithms is publicly available at\nhttps://github.com/wilrev/MultimodalBandits"}
{"id": "2510.26053", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26053", "abs": "https://arxiv.org/abs/2510.26053", "authors": ["Le Wang", "Xin Xing", "Youhui Ye"], "title": "A L-infinity Norm Synthetic Control Approach", "comment": null, "summary": "This paper reinterprets the Synthetic Control (SC) framework through the lens\nof weighting philosophy, arguing that the contrast between traditional SC and\nDifference-in-Differences (DID) reflects two distinct modeling mindsets: sparse\nversus dense weighting schemes. Rather than viewing sparsity as inherently\nsuperior, we treat it as a modeling choice simple but potentially fragile. We\npropose an L-infinity-regularized SC method that combines the strengths of both\napproaches. Like DID, it employs a denser weighting scheme that distributes\nweights more evenly across control units, enhancing robustness and reducing\noverreliance on a few control units. Like traditional SC, it remains flexible\nand data-driven, increasing the likelihood of satisfying the parallel trends\nassumption while preserving interpretability. We develop an interior point\nalgorithm for efficient computation, derive asymptotic theory under weak\ndependence, and demonstrate strong finite-sample performance through\nsimulations and real-world applications."}
{"id": "2510.26026", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26026", "abs": "https://arxiv.org/abs/2510.26026", "authors": ["Feichen Gan", "Youcun Lu", "Yingying Zhang", "Yukun Liu"], "title": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation", "comment": null, "summary": "Reliable uncertainty quantification is crucial for reinforcement learning\n(RL) in high-stakes settings. We propose a unified conformal prediction\nframework for infinite-horizon policy evaluation that constructs\ndistribution-free prediction intervals {for returns} in both on-policy and\noff-policy settings. Our method integrates distributional RL with conformal\ncalibration, addressing challenges such as unobserved returns, temporal\ndependencies, and distributional shifts. We propose a modular pseudo-return\nconstruction based on truncated rollouts and a time-aware calibration strategy\nusing experience replay and weighted subsampling. These innovations mitigate\nmodel bias and restore approximate exchangeability, enabling uncertainty\nquantification even under policy shifts. Our theoretical analysis provides\ncoverage guarantees that account for model misspecification and importance\nweight estimation. Empirical results, including experiments in synthetic and\nbenchmark environments like Mountain Car, show that our method significantly\nimproves coverage and reliability over standard distributional RL baselines."}
{"id": "2510.26090", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26090", "abs": "https://arxiv.org/abs/2510.26090", "authors": ["Alessandro Zito", "Giovanni Parmigiani", "Jeffrey W. Miller"], "title": "Poisson process factorization for mutational signature analysis with genomic covariates", "comment": null, "summary": "Mutational signatures are powerful summaries of the mutational processes\naltering the DNA of cancer cells and are increasingly relevant as biomarkers in\npersonalized treatments. The widespread approach to mutational signature\nanalysis consists of decomposing the matrix of mutation counts from a sample of\npatients via non-negative matrix factorization (NMF) algorithms. However, by\nworking with aggregate counts, this procedure ignores the non-homogeneous\npatterns of occurrence of somatic mutations along the genome, as well as the\ntissue-specific characteristics that notoriously influence their rate of\nappearance. This gap is primarily due to a lack of adequate methodologies to\nleverage locus-specific covariates directly in the factorization. In this\npaper, we address these limitations by introducing a model based on Poisson\npoint processes to infer mutational signatures and their activities as they\nvary across genomic regions. Using covariate-dependent factorized intensity\nfunctions, our Poisson process factorization (PPF) generalizes the baseline NMF\nmodel to include regression coefficients that capture the effect of commonly\nknown genomic features on the mutation rates from each latent process.\nFurthermore, our method relies on sparsity-inducing hierarchical priors to\nautomatically infer the number of active latent factors in the data, avoiding\nthe need to fit multiple models for a range of plausible ranks. We present\nalgorithms to obtain maximum a posteriori estimates and uncertainty\nquantification via Markov chain Monte Carlo. We test the method on simulated\ndata and on real data from breast cancer, using covariates on alterations in\nchromosomal copies, histone modifications, cell replication timing, nucleosome\npositioning, and DNA methylation. Our results shed light on the joint effect\nthat epigenetic marks have on the latent processes at high resolution."}
{"id": "2510.26177", "categories": ["stat.ME", "stat.OT"], "pdf": "https://arxiv.org/pdf/2510.26177", "abs": "https://arxiv.org/abs/2510.26177", "authors": ["Sagar Pandhare", "Divya Kappara", "Siuli Mukhopadhyay"], "title": "Variable selection in spatial lag models using the focussed information criterion", "comment": "20 pages, 2 figures, 3 tables", "summary": "Spatial regression models have a variety of applications in several fields\nranging from economics to public health. Typically, it is of interest to select\nimportant exogenous predictors of the spatially autocorrelated response\nvariable. In this paper, we propose variable selection in linear spatial lag\nmodels by means of the focussed information criterion (FIC). The FIC-based\nvariable selection involves the minimization of the asymptotic risk in the\nestimation of a certain parametric focus function of interest under potential\nmodel misspecification. We systematically investigate the key asymptotics of\nthe maximum likelihood estimators under the sequence of locally perturbed\nmutually contiguous probability models. Using these results, we obtain the\nexpressions for the bias and the variance of the estimated focus leading to the\ndesired FIC formula. We provide practically useful focus functions that account\nfor various spatial characteristics such as mean response, variability in the\nestimation and spatial spillover effects. Furthermore, we develop an averaged\nversion of the FIC that incorporates varying covariate levels while evaluating\nthe models. The empirical performance of the proposed methodology is\ndemonstrated through simulations and real data analysis."}
{"id": "2510.26726", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2510.26726", "abs": "https://arxiv.org/abs/2510.26726", "authors": ["Daniel O'Hanlon"], "title": "Phantom types for robust hierarchical models with typegeist", "comment": null, "summary": "In Bayesian hierarchical models, group-level parameter arrays must be mapped\nto the observation axis, often using explicit indexing. In complex models with\nnumerous incompatible data and parameter sets, this introduces the potential\nfor bugs, as indexing with the incorrect indices typically fails silently. Here\nwe present typegeist, a type system for Python that uses static type analysis\nto enable specification and enforcement of data-parameter-index\ncorrespondences. We show how this can be used with common probabilistic\nprogramming frameworks to help guarantee model correctness with minimal\nrun-time overhead."}
{"id": "2510.25961", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.25961", "abs": "https://arxiv.org/abs/2510.25961", "authors": ["Amanda Glazer"], "title": "Tractable Algorithms for Changepoint Detection in Player Performance Metrics", "comment": null, "summary": "We present tractable methods for detecting changes in player performance\nmetrics and apply these methods to Major League Baseball (MLB) batting and\npitching data from the 2023 and 2024 seasons. First, we derive principled\nbenchmarks for when performance metrics can be considered statistically\nreliable, assuming no underlying change, using distributional assumptions and\nstandard concentration inequalities. We then propose a changepoint detection\nalgorithm that combines a likelihood-based approach with split-sample inference\nto control false positives, using either nonparametric tests or tests\nappropriate to the underlying data distribution. These tests incorporate a\nshift parameter, allowing users to specify the minimum magnitude of change to\ndetect. We demonstrate the utility of this approach across several baseball\napplications: detecting changes in batter plate discipline metrics (e.g., chase\nand whiff rate), identifying velocity changes in pitcher fastballs, and\nvalidating velocity changepoints against a curated ground-truth dataset of\npitchers who transitioned from relief to starting roles. Our method flags\nmeaningful changes in 91% of these `ground-truth' cases and reveals that, for\nsome metrics, more than 60% of detected changes occur in-season. While\ndeveloped for baseball, the proposed framework is broadly applicable to any\nsetting involving monitoring of individual performance over time."}
{"id": "2510.26043", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26043", "abs": "https://arxiv.org/abs/2510.26043", "authors": ["Shaoxin Wang", "Hanjing Yao"], "title": "$L_1$-norm Regularized Indefinite Kernel Logistic Regression", "comment": "17 pages, 1 figure", "summary": "Kernel logistic regression (KLR) is a powerful classification method widely\napplied across diverse domains. In many real-world scenarios, indefinite\nkernels capture more domain-specific structural information than positive\ndefinite kernels. This paper proposes a novel $L_1$-norm regularized indefinite\nkernel logistic regression (RIKLR) model, which extends the existing IKLR\nframework by introducing sparsity via an $L_1$-norm penalty. The introduction\nof this regularization enhances interpretability and generalization while\nintroducing nonsmoothness and nonconvexity into the optimization landscape. To\naddress these challenges, a theoretically grounded and computationally\nefficient proximal linearized algorithm is developed. Experimental results on\nmultiple benchmark datasets demonstrate the superior performance of the\nproposed method in terms of both accuracy and sparsity."}
{"id": "2510.26177", "categories": ["stat.ME", "stat.OT"], "pdf": "https://arxiv.org/pdf/2510.26177", "abs": "https://arxiv.org/abs/2510.26177", "authors": ["Sagar Pandhare", "Divya Kappara", "Siuli Mukhopadhyay"], "title": "Variable selection in spatial lag models using the focussed information criterion", "comment": "20 pages, 2 figures, 3 tables", "summary": "Spatial regression models have a variety of applications in several fields\nranging from economics to public health. Typically, it is of interest to select\nimportant exogenous predictors of the spatially autocorrelated response\nvariable. In this paper, we propose variable selection in linear spatial lag\nmodels by means of the focussed information criterion (FIC). The FIC-based\nvariable selection involves the minimization of the asymptotic risk in the\nestimation of a certain parametric focus function of interest under potential\nmodel misspecification. We systematically investigate the key asymptotics of\nthe maximum likelihood estimators under the sequence of locally perturbed\nmutually contiguous probability models. Using these results, we obtain the\nexpressions for the bias and the variance of the estimated focus leading to the\ndesired FIC formula. We provide practically useful focus functions that account\nfor various spatial characteristics such as mean response, variability in the\nestimation and spatial spillover effects. Furthermore, we develop an averaged\nversion of the FIC that incorporates varying covariate levels while evaluating\nthe models. The empirical performance of the proposed methodology is\ndemonstrated through simulations and real data analysis."}
{"id": "2510.26496", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.26496", "abs": "https://arxiv.org/abs/2510.26496", "authors": ["Dimas Abreu Archanjo Dutra"], "title": "Variational System Identification of Aircraft", "comment": "AIAA Paper number AIAA 2025-1253. Presented at the AIAA SciTech 2025\n  Forum", "summary": "Variational system identification is a new formulation of maximum likelihood\nfor estimation of parameters of dynamical systems subject to process and\nmeasurement noise, such as aircraft flying in turbulence. This formulation is\nan alternative to the filter-error method that circumvents the solution of a\nRiccati equation and does not have problems with unstable predictors. In this\npaper, variational system identification is demonstrated for estimating\naircraft parameters from real flight-test data. The results show that, in real\napplications of practical interest, it has better convergence properties than\nthe filter-error method, reaching the optimum even when null initial guesses\nare used for all parameters and decision variables. This paper also presents\nthe theory behind the method and practical recommendations for its use."}
{"id": "2510.26046", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26046", "abs": "https://arxiv.org/abs/2510.26046", "authors": ["Pengfei Lyu", "Zhengchi Ma", "Linjun Zhang", "Anru R. Zhang"], "title": "Bias-Corrected Data Synthesis for Imbalanced Learning", "comment": "41 pages, 4 figures, includes proofs and appendix", "summary": "Imbalanced data, where the positive samples represent only a small proportion\ncompared to the negative samples, makes it challenging for classification\nproblems to balance the false positive and false negative rates. A common\napproach to addressing the challenge involves generating synthetic data for the\nminority group and then training classification models with both observed and\nsynthetic data. However, since the synthetic data depends on the observed data\nand fails to replicate the original data distribution accurately, prediction\naccuracy is reduced when the synthetic data is naively treated as the true\ndata. In this paper, we address the bias introduced by synthetic data and\nprovide consistent estimators for this bias by borrowing information from the\nmajority group. We propose a bias correction procedure to mitigate the adverse\neffects of synthetic data, enhancing prediction accuracy while avoiding\noverfitting. This procedure is extended to broader scenarios with imbalanced\ndata, such as imbalanced multi-task learning and causal inference. Theoretical\nproperties, including bounds on bias estimation errors and improvements in\nprediction accuracy, are provided. Simulation results and data analysis on\nhandwritten digit datasets demonstrate the effectiveness of our method."}
{"id": "2510.26226", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26226", "abs": "https://arxiv.org/abs/2510.26226", "authors": ["Do Hyun Kim", "Hua Zhou", "Brendon Chau", "Aubrey Jensen", "Judong Shen", "Devan Mehrotra", "Gang Li", "Jin J. Zhou"], "title": "Estimating heritability of survival traits using censored multiple variance component model", "comment": null, "summary": "Characterizing the genetic basis of survival traits, such as age at disease\nonset, is critical for risk stratification, early intervention, and elucidating\nbiological mechanisms that can inform therapeutic development. However,\ntime-to-event outcomes in human cohorts are frequently right-censored,\ncomplicating both the estimation and partitioning of total heritability. Modern\nbiobanks linked to electronic health records offer the unprecedented power to\ndissect the genetic basis of age-at-diagnosis traits at large scale. Yet, few\nmethods exist for estimating and partitioning the total heritability of\ncensored survival traits. Existing methods impose restrictive distributional\nassumptions on genetic and environmental effects and are not scalable to large\nbiobanks with a million subjects. We introduce a censored multiple variance\ncomponent model to robustly estimate the total heritability of survival traits\nunder right-censoring. We demonstrate through extensive simulations that the\nmethod provides accurate total heritability estimates of right-censored traits\nat censoring rates up to 80% given sufficient sample size. The method is\ncomputationally efficient in estimating one hundred genetic variance components\nof a survival trait using large-scale biobank genotype data consisting of a\nmillion subjects and a million SNPs in under nine hours, including uncertainty\nquantification. We apply our method to estimate the total heritability of four\nage-at-diagnosis traits from the UK Biobank study. Our results establish a\nscalable and robust framework for heritability analysis of right-censored\nsurvival traits in large-scale genetic studies."}
{"id": "2510.26061", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.26061", "abs": "https://arxiv.org/abs/2510.26061", "authors": ["Tomoharu Iwata", "Futoshi Futami"], "title": "Data-driven Projection Generation for Efficiently Solving Heterogeneous Quadratic Programming Problems", "comment": null, "summary": "We propose a data-driven framework for efficiently solving quadratic\nprogramming (QP) problems by reducing the number of variables in\nhigh-dimensional QPs using instance-specific projection. A graph neural\nnetwork-based model is designed to generate projections tailored to each QP\ninstance, enabling us to produce high-quality solutions even for previously\nunseen problems. The model is trained on heterogeneous QPs to minimize the\nexpected objective value evaluated on the projected solutions. This is\nformulated as a bilevel optimization problem; the inner optimization solves the\nQP under a given projection using a QP solver, while the outer optimization\nupdates the model parameters. We develop an efficient algorithm to solve this\nbilevel optimization problem, which computes parameter gradients without\nbackpropagating through the solver. We provide a theoretical analysis of the\ngeneralization ability of solving QPs with projection matrices generated by\nneural networks. Experimental results demonstrate that our method produces\nhigh-quality feasible solutions with reduced computation time, outperforming\nexisting methods."}
{"id": "2510.26447", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26447", "abs": "https://arxiv.org/abs/2510.26447", "authors": ["Saïd Maanan", "Azzouz Dermoune", "Ahmed El Ghini"], "title": "Smoothed Quantile Estimation via Interpolation to the Mean", "comment": null, "summary": "This paper introduces a unified family of smoothed quantile estimators that\ncontinuously interpolate between classical empirical quantiles and the sample\nmean. The estimators q(z, h) are defined as minimizers of a regularized\nobjective function depending on two parameters: a smoothing parameter h $\\ge$ 0\nand a location parameter z $\\in$ R. When h = 0 and z $\\in$ (-1, 1), the\nestimator reduces to the empirical quantile of order $\\tau$ = (1z)/2; as h\n$\\rightarrow$ $\\infty$, it converges to the sample mean for any fixed z. We\nestablish consistency, asymptotic normality, and an explicit variance\nexpression characterizing the efficiency-robustness trade-off induced by h. A\nkey geometric insight shows that for each fixed quantile level $\\tau$ , the\nadmissible parameter pairs (z, h) lie on a straight line in the parameter\nspace, along which the population quantile remains constant while asymptotic\nefficiency varies. The analysis reveals two regimes: under light-tailed\ndistributions (e.g., Gaussian), smoothing yields a monotonic but asymptotic\nvariance reduction with no finite optimum; under heavy-tailed distributions\n(e.g., Laplace), a finite smoothing level h * ($\\tau$ ) > 0 achieves strict\nefficiency improvement over the classical empirical quantile. Numerical\nillustrations confirm these theoretical predictions and highlight how smoothing\nbalances robustness and efficiency across quantile levels."}
{"id": "2510.26121", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26121", "abs": "https://arxiv.org/abs/2510.26121", "authors": ["Mara Daniels", "Liam Hodgkinson", "Michael Mahoney"], "title": "Uncertainty-Aware Diagnostics for Physics-Informed Machine Learning", "comment": null, "summary": "Physics-informed machine learning (PIML) integrates prior physical\ninformation, often in the form of differential equation constraints, into the\nprocess of fitting machine learning models to physical data. Popular PIML\napproaches, including neural operators, physics-informed neural networks,\nneural ordinary differential equations, and neural discrete equilibria, are\ntypically fit to objectives that simultaneously include both data and physical\nconstraints. However, the multi-objective nature of this approach creates\nambiguity in the measurement of model quality. This is related to a poor\nunderstanding of epistemic uncertainty, and it can lead to surprising failure\nmodes, even when existing statistical metrics suggest strong fits. Working\nwithin a Gaussian process regression framework, we introduce the\nPhysics-Informed Log Evidence (PILE) score. Bypassing the ambiguities of test\nlosses, the PILE score is a single, uncertainty-aware metric that provides a\nselection principle for hyperparameters of a PIML model. We show that PILE\nminimization yields excellent choices for a wide variety of model parameters,\nincluding kernel bandwidth, least squares regularization weights, and even\nkernel function selection. We also show that, even prior to data acquisition, a\nspecial 'data-free' case of the PILE score identifies a priori kernel choices\nthat are 'well-adapted' to a given PDE. Beyond the kernel setting, we\nanticipate that the PILE score can be extended to PIML at large, and we outline\napproaches to do so."}
{"id": "2510.26470", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2510.26470", "abs": "https://arxiv.org/abs/2510.26470", "authors": ["Jonas M. Mikhaeil", "Christopher Harshaw"], "title": "In Defense of the Pre-Test: Valid Inference when Testing Violations of Parallel Trends for Difference-in-Differences", "comment": null, "summary": "The difference-in-differences (DID) research design is a key identification\nstrategy which allows researchers to estimate causal effects under the parallel\ntrends assumption. While the parallel trends assumption is counterfactual and\ncannot be tested directly, researchers often examine pre-treatment periods to\ncheck whether the time trends are parallel before treatment is administered.\nRecently, researchers have been cautioned against using preliminary tests which\naim to detect violations of parallel trends in the pre-treatment period. In\nthis paper, we argue that preliminary testing can -- and should -- play an\nimportant role within the DID research design. We propose a new and more\nsubstantively appropriate conditional extrapolation assumption, which requires\nan analyst to conduct a preliminary test to determine whether the severity of\npre-treatment parallel trend violations falls below an acceptable level before\nextrapolation to the post-treatment period is justified. This stands in\ncontrast to prior work which can be interpreted as either setting the\nacceptable level to be exactly zero (in which case preliminary tests lack\npower) or assuming that extrapolation is always justified (in which case\npreliminary tests are not required). Under mild assumptions on how close the\nactual violation is to the acceptable level, we provide a consistent\npreliminary test as well confidence intervals which are valid when conditioned\non the result of the test. The conditional coverage of these intervals\novercomes a common critique made against the use of preliminary testing within\nthe DID research design. We use real data as well as numerical simulations to\nillustrate the performance of the proposed methods."}
{"id": "2510.26401", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26401", "abs": "https://arxiv.org/abs/2510.26401", "authors": ["Joshua Rooijakkers", "Leiv Rønneberg", "François-Xavier Briol", "Jeremias Knoblauch", "Matias Altamirano"], "title": "Multi-Output Robust and Conjugate Gaussian Processes", "comment": null, "summary": "Multi-output Gaussian process (MOGP) regression allows modelling dependencies\namong multiple correlated response variables. Similarly to standard Gaussian\nprocesses, MOGPs are sensitive to model misspecification and outliers, which\ncan distort predictions within individual outputs. This situation can be\nfurther exacerbated by multiple anomalous response variables whose errors\npropagate due to correlations between outputs. To handle this situation, we\nextend and generalise the robust and conjugate Gaussian process (RCGP)\nframework introduced by Altamirano et al. (2024). This results in the\nmulti-output RCGP (MO-RCGP): a provably robust MOGP that is conjugate, and\njointly captures correlations across outputs. We thoroughly evaluate our\napproach through applications in finance and cancer research."}
{"id": "2510.26478", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.26478", "abs": "https://arxiv.org/abs/2510.26478", "authors": ["Congyuan Duan", "Wanteng Ma", "Dong Xia", "Kan Xu"], "title": "Statistical Inference for Matching Decisions via Matrix Completion under Dependent Missingness", "comment": null, "summary": "This paper studies decision-making and statistical inference for two-sided\nmatching markets via matrix completion. In contrast to the independent sampling\nassumed in classical matrix completion literature, the observed entries, which\narise from past matching data, are constrained by matching capacity. This\nmatching-induced dependence poses new challenges for both estimation and\ninference in the matrix completion framework. We propose a non-convex algorithm\nbased on Grassmannian gradient descent and establish near-optimal entrywise\nconvergence rates for three canonical mechanisms, i.e., one-to-one matching,\none-to-many matching with one-sided random arrival, and two-sided random\narrival. To facilitate valid uncertainty quantification and hypothesis testing\non matching decisions, we further develop a general debiasing and projection\nframework for arbitrary linear forms of the reward matrix, deriving asymptotic\nnormality with finite-sample guarantees under matching-induced dependent\nsampling. Our empirical experiments demonstrate that the proposed approach\nprovides accurate estimation, valid confidence intervals, and efficient\nevaluation of matching policies."}
{"id": "2510.26672", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26672", "abs": "https://arxiv.org/abs/2510.26672", "authors": ["Ruimin He", "Shaowei Lin"], "title": "Action-Driven Processes for Continuous-Time Control", "comment": null, "summary": "At the heart of reinforcement learning are actions - decisions made in\nresponse to observations of the environment. Actions are equally fundamental in\nthe modeling of stochastic processes, as they trigger discontinuous state\ntransitions and enable the flow of information through large, complex systems.\nIn this paper, we unify the perspectives of stochastic processes and\nreinforcement learning through action- driven processes, and illustrate their\napplication to spiking neural networks. Leveraging ideas from\ncontrol-as-inference, we show that minimizing the Kullback-Leibler divergence\nbetween a policy-driven true distribution and a reward-driven model\ndistribution for a suitably defined action-driven process is equivalent to\nmaximum entropy reinforcement learning."}
{"id": "2510.26485", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26485", "abs": "https://arxiv.org/abs/2510.26485", "authors": ["Rebecca F. Supple", "Hannah Worthington", "Ben Swallow"], "title": "Discovering Causal Relationships Between Time Series With Spatial Structure", "comment": "14 pages, 1 figure", "summary": "Causal discovery is the subfield of causal inference concerned with\nestimating the structure of cause-and-effect relationships in a system of\ninterrelated variables, as opposed to quantifying the strength of causal\neffects. As interest in causal discovery builds in fields such as ecology,\npublic health, and environmental sciences where data is regularly collected\nwith spatial and temporal structures, approaches must evolve to manage\nautocorrelation and complex confounding. As it stands, the few proposed causal\ndiscovery algorithms for spatiotemporal data require summarizing across\nlocations, ignore spatial autocorrelation, and/or scale poorly to high\ndimensions. Here, we introduce our developing framework that extends\ntime-series causal discovery to systems with spatial structure, building upon\nwork on causal discovery across contexts and methods for handling spatial\nconfounding in causal effect estimation. We close by outlining remaining gaps\nin the literature and directions for future research."}
{"id": "2510.26700", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26700", "abs": "https://arxiv.org/abs/2510.26700", "authors": ["Gerard T. Portela", "Jason B. Gibbons", "Sebastian Schneeweiss", "Rishi J. Desai"], "title": "Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study", "comment": null, "summary": "Observational studies developing causal machine learning (ML) models for the\nprediction of individualized treatment effects (ITEs) seldom conduct empirical\nevaluations to assess the conditional exchangeability assumption. We aimed to\nevaluate the performance of these models under conditional exchangeability\nviolations and the utility of negative control outcomes (NCOs) as a diagnostic.\nWe conducted a simulation study to examine confounding bias in ITE estimates\ngenerated by causal forest and X-learner models under varying conditions,\nincluding the presence or absence of true heterogeneity. We simulated data to\nreflect real-world scenarios with differing levels of confounding, sample size,\nand NCO confounding structures. We then estimated and compared subgroup-level\ntreatment effects on the primary outcome and NCOs across settings with and\nwithout unmeasured confounding. When conditional exchangeability was violated,\ncausal forest and X-learner models failed to recover true treatment effect\nheterogeneity and, in some cases, falsely indicated heterogeneity when there\nwas none. NCOs successfully identified subgroups affected by unmeasured\nconfounding. Even when NCOs did not perfectly satisfy its ideal assumptions, it\nremained informative, flagging potential bias in subgroup level estimates,\nthough not always pinpointing the subgroup with the largest confounding.\nViolations of conditional exchangeability substantially limit the validity of\nITE estimates from causal ML models in routinely collected observational data.\nNCOs serve a useful empirical diagnostic tool for detecting subgroup-specific\nunmeasured confounding and should be incorporated into causal ML workflows to\nsupport the credibility of individualized inference."}
{"id": "2510.26775", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26775", "abs": "https://arxiv.org/abs/2510.26775", "authors": ["Yin Tang", "Yanyuan Ma", "Bing Li"], "title": "A KL-divergence based test for elliptical distribution", "comment": null, "summary": "We conduct a KL-divergence based procedure for testing elliptical\ndistributions. The procedure simultaneously takes into account the two defining\nproperties of an elliptically distributed random vector: independence between\nlength and direction, and uniform distribution of the direction. The test\nstatistic is constructed based on the $k$ nearest neighbors ($k$NN) method, and\ntwo cases are considered where the mean vector and covariance matrix are known\nand unknown. First-order asymptotic properties of the test statistic are\nrigorously established by creatively utilizing sample splitting, truncation and\ntransformation between Euclidean space and unit sphere, while avoiding assuming\nFr\\'echet differentiability of any functionals. Debiasing and variance\ninflation are further proposed to treat the degeneration of the influence\nfunction. Numerical implementations suggest better size and power performance\nthan the state of the art procedures."}
{"id": "2510.26723", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26723", "abs": "https://arxiv.org/abs/2510.26723", "authors": ["Masahiro Kato"], "title": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "comment": null, "summary": "The goal of policy learning is to train a policy function that recommends a\ntreatment given covariates to maximize population welfare. There are two major\napproaches in policy learning: the empirical welfare maximization (EWM)\napproach and the plug-in approach. The EWM approach is analogous to a\nclassification problem, where one first builds an estimator of the population\nwelfare, which is a functional of policy functions, and then trains a policy by\nmaximizing the estimated welfare. In contrast, the plug-in approach is based on\nregression, where one first estimates the conditional average treatment effect\n(CATE) and then recommends the treatment with the highest estimated outcome.\nThis study bridges the gap between the two approaches by showing that both are\nbased on essentially the same optimization problem. In particular, we prove an\nexact equivalence between EWM and least squares over a reparameterization of\nthe policy class. As a consequence, the two approaches are interchangeable in\nseveral respects and share the same theoretical guarantees under common\nconditions. Leveraging this equivalence, we propose a novel regularization\nmethod for policy learning. Our findings yield a convex and computationally\nefficient training procedure that avoids the NP-hard combinatorial step\ntypically required in EWM."}
{"id": "2510.26046", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.26046", "abs": "https://arxiv.org/abs/2510.26046", "authors": ["Pengfei Lyu", "Zhengchi Ma", "Linjun Zhang", "Anru R. Zhang"], "title": "Bias-Corrected Data Synthesis for Imbalanced Learning", "comment": "41 pages, 4 figures, includes proofs and appendix", "summary": "Imbalanced data, where the positive samples represent only a small proportion\ncompared to the negative samples, makes it challenging for classification\nproblems to balance the false positive and false negative rates. A common\napproach to addressing the challenge involves generating synthetic data for the\nminority group and then training classification models with both observed and\nsynthetic data. However, since the synthetic data depends on the observed data\nand fails to replicate the original data distribution accurately, prediction\naccuracy is reduced when the synthetic data is naively treated as the true\ndata. In this paper, we address the bias introduced by synthetic data and\nprovide consistent estimators for this bias by borrowing information from the\nmajority group. We propose a bias correction procedure to mitigate the adverse\neffects of synthetic data, enhancing prediction accuracy while avoiding\noverfitting. This procedure is extended to broader scenarios with imbalanced\ndata, such as imbalanced multi-task learning and causal inference. Theoretical\nproperties, including bounds on bias estimation errors and improvements in\nprediction accuracy, are provided. Simulation results and data analysis on\nhandwritten digit datasets demonstrate the effectiveness of our method."}
{"id": "2510.26783", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26783", "abs": "https://arxiv.org/abs/2510.26783", "authors": ["Masahiro Kato"], "title": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression", "comment": null, "summary": "This note introduces a unified theory for causal inference that integrates\nRiesz regression, covariate balancing, density-ratio estimation (DRE), targeted\nmaximum likelihood estimation (TMLE), and the matching estimator in average\ntreatment effect (ATE) estimation. In ATE estimation, the balancing weights and\nthe regression functions of the outcome play important roles, where the\nbalancing weights are referred to as the Riesz representer, bias-correction\nterm, and clever covariates, depending on the context. Riesz regression,\ncovariate balancing, DRE, and the matching estimator are methods for estimating\nthe balancing weights, where Riesz regression is essentially equivalent to DRE\nin the ATE context, the matching estimator is a special case of DRE, and DRE is\nin a dual relationship with covariate balancing. TMLE is a method for\nconstructing regression function estimators such that the leading bias term\nbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density\nRatio Estimation and Riesz Regression."}
{"id": "2510.26723", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26723", "abs": "https://arxiv.org/abs/2510.26723", "authors": ["Masahiro Kato"], "title": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "comment": null, "summary": "The goal of policy learning is to train a policy function that recommends a\ntreatment given covariates to maximize population welfare. There are two major\napproaches in policy learning: the empirical welfare maximization (EWM)\napproach and the plug-in approach. The EWM approach is analogous to a\nclassification problem, where one first builds an estimator of the population\nwelfare, which is a functional of policy functions, and then trains a policy by\nmaximizing the estimated welfare. In contrast, the plug-in approach is based on\nregression, where one first estimates the conditional average treatment effect\n(CATE) and then recommends the treatment with the highest estimated outcome.\nThis study bridges the gap between the two approaches by showing that both are\nbased on essentially the same optimization problem. In particular, we prove an\nexact equivalence between EWM and least squares over a reparameterization of\nthe policy class. As a consequence, the two approaches are interchangeable in\nseveral respects and share the same theoretical guarantees under common\nconditions. Leveraging this equivalence, we propose a novel regularization\nmethod for policy learning. Our findings yield a convex and computationally\nefficient training procedure that avoids the NP-hard combinatorial step\ntypically required in EWM."}
{"id": "2510.26478", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.26478", "abs": "https://arxiv.org/abs/2510.26478", "authors": ["Congyuan Duan", "Wanteng Ma", "Dong Xia", "Kan Xu"], "title": "Statistical Inference for Matching Decisions via Matrix Completion under Dependent Missingness", "comment": null, "summary": "This paper studies decision-making and statistical inference for two-sided\nmatching markets via matrix completion. In contrast to the independent sampling\nassumed in classical matrix completion literature, the observed entries, which\narise from past matching data, are constrained by matching capacity. This\nmatching-induced dependence poses new challenges for both estimation and\ninference in the matrix completion framework. We propose a non-convex algorithm\nbased on Grassmannian gradient descent and establish near-optimal entrywise\nconvergence rates for three canonical mechanisms, i.e., one-to-one matching,\none-to-many matching with one-sided random arrival, and two-sided random\narrival. To facilitate valid uncertainty quantification and hypothesis testing\non matching decisions, we further develop a general debiasing and projection\nframework for arbitrary linear forms of the reward matrix, deriving asymptotic\nnormality with finite-sample guarantees under matching-induced dependent\nsampling. Our empirical experiments demonstrate that the proposed approach\nprovides accurate estimation, valid confidence intervals, and efficient\nevaluation of matching policies."}
{"id": "2510.26783", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.26783", "abs": "https://arxiv.org/abs/2510.26783", "authors": ["Masahiro Kato"], "title": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression", "comment": null, "summary": "This note introduces a unified theory for causal inference that integrates\nRiesz regression, covariate balancing, density-ratio estimation (DRE), targeted\nmaximum likelihood estimation (TMLE), and the matching estimator in average\ntreatment effect (ATE) estimation. In ATE estimation, the balancing weights and\nthe regression functions of the outcome play important roles, where the\nbalancing weights are referred to as the Riesz representer, bias-correction\nterm, and clever covariates, depending on the context. Riesz regression,\ncovariate balancing, DRE, and the matching estimator are methods for estimating\nthe balancing weights, where Riesz regression is essentially equivalent to DRE\nin the ATE context, the matching estimator is a special case of DRE, and DRE is\nin a dual relationship with covariate balancing. TMLE is a method for\nconstructing regression function estimators such that the leading bias term\nbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density\nRatio Estimation and Riesz Regression."}
