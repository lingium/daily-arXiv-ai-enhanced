{"id": "2511.08081", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08081", "abs": "https://arxiv.org/abs/2511.08081", "authors": ["Merle Mendel", "Roland Fried"], "title": "Parameter Estimation and Seasonal Modification of the Fractional Poisson Process with Application to Vorticity Extremes over the North Atlantic", "comment": null, "summary": "The fractional Poisson process (FPP) generalizes the standard Poisson process by replacing exponentially distributed return times with Mittag-Leffler distributed ones with an extra tail parameter, allowing for greater flexibility. The FPP has been applied in various fields, such as modeling occurrences of extratropical cyclones in meteorology and solar flares in physics. We propose a new estimation method for the parameters of the FPP, based on minimizing the distance between the empirical and the theoretical distribution at selected quantiles. We conduct an extensive simulation study to evaluate the advantages and limitations of the new estimation method and to compare it with several competing estimators, some of which have not yet been examined in the Mittag-Leffler setting. To enhance the applicability of the FPP in real-world scenarios, particularly in meteorology, we propose a method for incorporating seasonality into the FPP through distance-based weighting. We then analyze the return times of relative vorticity extremes in the North Atlantic-European region using our seasonal modeling approach."}
{"id": "2511.08262", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08262", "abs": "https://arxiv.org/abs/2511.08262", "authors": ["Ezra Gayawan", "Osafu Augustine Egbon", "Edson Utazi", "Jamila Abubakar Umar", "Caroline Trotter"], "title": "The impact of Women's empowerment on childhood vaccination coverage in Nigeria: a spatio-temporal analysis", "comment": null, "summary": "Immunization remains one of the most effective public health interventions, substantially reducing childhood morbidity and mortality worldwide. Yet, gender disparity and women's disempowerment continue to hinder access to vaccination services in low- and middle-income countries. In Nigeria, variations in social norms and cultural values shape gender roles, limiting women's autonomy in healthcare decisions and household participation. These constraints contribute to spatial differences in immunization uptake. Using data from four waves of the Nigeria Demographic and Health Survey, we developed two empowerment indices capturing women's participation in household decision-making and their ability to decide on personal healthcare needs. A structured spatiotemporal statistical model was applied to assess how much of the observed vaccination disparities could be attributed to women's empowerment and to predict vaccination outcomes at the third administrative level. We examined five indicators: Bacillus Calmette-Guerin (BCG), zero-dose, complete DPT, MCV-1 (first dose of measles-containing vaccine), and all-basic vaccination coverage. Model validation involved comparing empirical estimates with projections at the second administrative level. Results indicate that empowerment related to household participation and healthcare autonomy generally increases vaccination uptake, though the magnitude of effects varies geographically, particularly among highly empowered women. Despite ongoing national efforts to close immunization gaps, the study highlights the need for context-specific strategies that enhance women's decision-making power and community engagement to reduce regional disparities and improve overall vaccination coverage."}
{"id": "2511.08070", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08070", "abs": "https://arxiv.org/abs/2511.08070", "authors": ["Yuichi Goto", "Hiroko Kato Solvang", "Masanobu Taniguchi", "Tone Falkenhaug"], "title": "ANOVATS: A subsampling-based test to detect differences among short time series in marine studies", "comment": "23 pages, 12 figures", "summary": "Assessing marine ecosystems is important for understanding the impacts of climate change and human activity, as well as for maintaining healthy oceans and ecosystems. In marine science, it is common for biologists and geologists to identify regional differences based on expert knowledge, frequently through data visualization. However, time series data collected through surveys in marine studies typically span only a few decades, limiting the applicability of classical time series methods. Additionally, without expert knowledge, detecting significant differences becomes challenging. To address these issues, we introduce ANOVATS (ANOVA for small-sample time series data), a subsampling-based method to detect regional differences in small-sample time series data with a fixed number of groups. This method bypasses the need for spectral density estimation, which requires a large number of time points in the data. Furthermore, after detecting differences in homogeneity across all areas using the ANOVATS procedure, we devised a simple ANOVATS post hoc procedure to group the areas. Finally, we demonstrate the effectiveness of our method by analyzing zooplankton biomass data collected in different strata of the North Sea, showing its ability to quantify differences in species between geographical areas without relying on prior biological or geographical knowledge."}
{"id": "2511.08124", "categories": ["stat.CO", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08124", "abs": "https://arxiv.org/abs/2511.08124", "authors": ["Alin Morariu", "Jess Bridgen", "Chris Jewell"], "title": "gemlib: Probabilistic programming for epidemic models", "comment": null, "summary": "gemlib is a Python library for defining, simulating, and calibrating Markov state-transition models. Stochastic models are often computationally intensive, making them impractical to use in pandemic response efforts despite their favourable interpretations compared to their deterministic counterparts. gemlib decomposes state-transition models into three key ingredients which succinctly encapsulate the model and are sufficient for executing the subsequent computational routines. Simulation is performed using implementations of Gillespie's algorithm for continuous-time models and a generic Tau-leaping algorithm for discrete time models. gemlib models integrate seamlessly with Markov Chain Monte Carlo samplers as they provide a target distribution for the inference algorithm. Algorithms are implemented using the machine learning computational frameworks JAX and TensorFlow Probability, thus taking advantage of modern hardware to accelerate computation. This abstracts away computational concerns from modellers, allowing them to focus on developing and testing different model structures or assumptions. The gemlib library enables users to rapidly implement and calibrate stochastic epidemic models with the flexibility and robustness required to support decision during an emerging outbreak."}
{"id": "2511.07504", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07504", "abs": "https://arxiv.org/abs/2511.07504", "authors": ["Raymond Zhang", "Hédi Hadiji", "Richard Combes"], "title": "Tractable Instances of Bilinear Maximization: Implementing LinUCB on Ellipsoids", "comment": "27 pages, 8 figures, 4 algos", "summary": "We consider the maximization of $x^\\top θ$ over $(x,θ) \\in \\mathcal{X} \\times Θ$, with $\\mathcal{X} \\subset \\mathbb{R}^d$ convex and $Θ\\subset \\mathbb{R}^d$ an ellipsoid. This problem is fundamental in linear bandits, as the learner must solve it at every time step using optimistic algorithms. We first show that for some sets $\\mathcal{X}$ e.g. $\\ell_p$ balls with $p>2$, no efficient algorithms exist unless $\\mathcal{P} = \\mathcal{NP}$. We then provide two novel algorithms solving this problem efficiently when $\\mathcal{X}$ is a centered ellipsoid. Our findings provide the first known method to implement optimistic algorithms for linear bandits in high dimensions."}
{"id": "2511.07588", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.07588", "abs": "https://arxiv.org/abs/2511.07588", "authors": ["Soumyabrata Bose", "Jay Bartroff"], "title": "Weighted Asymptotically Optimal Sequential Testing", "comment": null, "summary": "This paper develops a framework for incorporating prior information into sequential multiple testing procedures while maintaining asymptotic optimality. We define a weighted log-likelihood ratio (WLLR) as an additive modification of the standard LLR and use it to construct two new sequential tests: the Weighted Gap and Weighted Gap-Intersection procedures. We prove that both procedures provide strong control of the family-wise error rate. Our main theoretical contribution is to show that these weighted procedures are asymptotically optimal; their expected stopping times achieve the theoretical lower bound as the error probabilities vanish. This first-order optimality is shown to be robust, holding in high-dimensional regimes where the number of null hypotheses grows and in settings with random weights, provided that mild, interpretable conditions on the weight distribution are met."}
{"id": "2511.07959", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.07959", "abs": "https://arxiv.org/abs/2511.07959", "authors": ["Pulong Ma"], "title": "Asymmetric Space-Time Covariance Functions via Hierarchical Mixtures", "comment": "32 pages, 4 figures", "summary": "This work is focused on constructing space-time covariance functions through a hierarchical mixture approach that can serve as building blocks for capturing complex dependency structures. This hierarchical mixture approach provides a unified modeling framework that not only constructs a new class of asymmetric space-time covariance functions with closed-form expressions, but also provides corresponding space-time process representations, which further unify constructions for many existing space-time covariance models. This hierarchical mixture framework decomposes the complexity of model specification at different levels of hierarchy, for which parsimonious covariance models can be specified with simple mixing measures to yield flexible properties and closed-form derivation. A characterization theorem is provided for the hierarchical mixture approach on how the mixing measures determine the statistical properties of covariance functions. Several new covariance models resulting from this hierarchical mixture approach are discussed in terms of their practical usefulness. A theorem is also provided to construct a general class of valid asymmetric space-time covariance functions with arbitrary and possibly different degrees of smoothness in space and in time and flexible long-range dependence. The proposed covariance class also bridges a theoretical gap in using the Lagrangian reference framework. The superior performance of several new parsimonious covariance models over existing models is verified with the well-known Irish wind data and the U.S. air temperature data."}
{"id": "2511.07736", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2511.07736", "abs": "https://arxiv.org/abs/2511.07736", "authors": ["Joseph Mathews", "Scott C. Schmidler"], "title": "Improved Bounds for Context-Dependent Evolutionary Models Using Sequential Monte Carlo", "comment": null, "summary": "Statistical inference in evolutionary models with site-dependence is a long-standing challenge in phylogenetics and computational biology. We consider the problem of approximating marginal sequence likelihoods under dependent-site models of biological sequence evolution. We prove a polynomial mixing time bound for a Markov chain Monte Carlo algorithm that samples the conditional distribution over latent sample paths, when the chain is initialized with a warm start. We then introduce a sequential Monte Carlo (SMC) algorithm for approximating the marginal likelihood, and show that our mixing time bound can be combined with recent importance sampling and finite-sample SMC results to obtain bounds on the finite sample approximation error of the resulting estimator. Our results show that the proposed SMC algorithm yields an efficient randomized approximation scheme for many practical problems of interest, and offers a significant improvement over a recently developed importance sampler for this problem. Our approach combines recent innovations in obtaining bounds for MCMC and SMC samplers, and may prove applicable to other problems of approximating marginal likelihoods and Bayes factors."}
{"id": "2511.07604", "categories": ["stat.ML", "cs.LG", "math.FA"], "pdf": "https://arxiv.org/pdf/2511.07604", "abs": "https://arxiv.org/abs/2511.07604", "authors": ["Halyun Jeong", "Palle E. T. Jorgensen", "Hyun-Kyoung Kwon", "Myung-Sin Song"], "title": "Infinite-Dimensional Operator/Block Kaczmarz Algorithms: Regret Bounds and $λ$-Effectiveness", "comment": "Submitted to a journal", "summary": "We present a variety of projection-based linear regression algorithms with a focus on modern machine-learning models and their algorithmic performance. We study the role of the relaxation parameter in generalized Kaczmarz algorithms and establish a priori regret bounds with explicit $λ$-dependence to quantify how much an algorithm's performance deviates from its optimal performance. A detailed analysis of relaxation parameter is also provided. Applications include: explicit regret bounds for the framework of Kaczmarz algorithm models, non-orthogonal Fourier expansions, and the use of regret estimates in modern machine learning models, including for noisy data, i.e., regret bounds for the noisy Kaczmarz algorithms. Motivated by machine-learning practice, our wider framework treats bounded operators (on infinite-dimensional Hilbert spaces), with updates realized as (block) Kaczmarz algorithms, leading to new and versatile results."}
{"id": "2511.07959", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.07959", "abs": "https://arxiv.org/abs/2511.07959", "authors": ["Pulong Ma"], "title": "Asymmetric Space-Time Covariance Functions via Hierarchical Mixtures", "comment": "32 pages, 4 figures", "summary": "This work is focused on constructing space-time covariance functions through a hierarchical mixture approach that can serve as building blocks for capturing complex dependency structures. This hierarchical mixture approach provides a unified modeling framework that not only constructs a new class of asymmetric space-time covariance functions with closed-form expressions, but also provides corresponding space-time process representations, which further unify constructions for many existing space-time covariance models. This hierarchical mixture framework decomposes the complexity of model specification at different levels of hierarchy, for which parsimonious covariance models can be specified with simple mixing measures to yield flexible properties and closed-form derivation. A characterization theorem is provided for the hierarchical mixture approach on how the mixing measures determine the statistical properties of covariance functions. Several new covariance models resulting from this hierarchical mixture approach are discussed in terms of their practical usefulness. A theorem is also provided to construct a general class of valid asymmetric space-time covariance functions with arbitrary and possibly different degrees of smoothness in space and in time and flexible long-range dependence. The proposed covariance class also bridges a theoretical gap in using the Lagrangian reference framework. The superior performance of several new parsimonious covariance models over existing models is verified with the well-known Irish wind data and the U.S. air temperature data."}
{"id": "2511.08303", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08303", "abs": "https://arxiv.org/abs/2511.08303", "authors": ["Masahiro Kato"], "title": "Semi-Supervised Treatment Effect Estimation with Unlabeled Covariates via Generalized Riesz Regression", "comment": null, "summary": "This study investigates treatment effect estimation in the semi-supervised setting, where we can use not only the standard triple of covariates, treatment indicator, and outcome, but also unlabeled auxiliary covariates. For this problem, we develop efficiency bounds and efficient estimators whose asymptotic variance aligns with the efficiency bound. In the analysis, we introduce two different data-generating processes: the one-sample setting and the two-sample setting. The one-sample setting considers the case where we can observe treatment indicators and outcomes for a part of the dataset, which is also called the censoring setting. In contrast, the two-sample setting considers two independent datasets with labeled and unlabeled data, which is also called the case-control setting or the stratified setting. In both settings, we find that by incorporating auxiliary covariates, we can lower the efficiency bound and obtain an estimator with an asymptotic variance smaller than that without such auxiliary covariates."}
{"id": "2511.07786", "categories": ["stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.07786", "abs": "https://arxiv.org/abs/2511.07786", "authors": ["Hanwen Huang"], "title": "A Closed-Form Diffusion Model for Learnring Dynamics from Marginal Observations", "comment": "35 pages, 3 figures", "summary": "Score-based generative models learn transformations from a simple Gaussian to complex data distributions. To generalize these transformations between arbitrary distributions, recent work has focused on the Schrödinger Bridge (SB) problem. However, SB solutions are rarely available in closed form, and existing methods rely on iterative stochastic simulations that are often unstable and costly. We introduce a closed-form framework for learning SB dynamics that unifies and extends previously known closed-form solutions, including the Schrödinger Föllmer process and the Gaussian SB. Notably, the classical Gaussian SB solution arises as an immediate corollary of our formulation. Based on this result, we develop a simulation-free algorithm that directly infers SB dynamics from samples of the source and target distributions. We demonstrate the approach in modeling single-cell developmental trajectories and in image restoration tasks such as inpainting and deblurring."}
{"id": "2511.07671", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07671", "abs": "https://arxiv.org/abs/2511.07671", "authors": ["Yasir Zubayr Barlas", "Sabina J. Sloman", "Samuel Kaski"], "title": "Robust Experimental Design via Generalised Bayesian Inference", "comment": "12 main pages, 43 pages in total", "summary": "Bayesian optimal experimental design is a principled framework for conducting experiments that leverages Bayesian inference to quantify how much information one can expect to gain from selecting a certain design. However, accurate Bayesian inference relies on the assumption that one's statistical model of the data-generating process is correctly specified. If this assumption is violated, Bayesian methods can lead to poor inference and estimates of information gain. Generalised Bayesian (or Gibbs) inference is a more robust probabilistic inference framework that replaces the likelihood in the Bayesian update by a suitable loss function. In this work, we present Generalised Bayesian Optimal Experimental Design (GBOED), an extension of Gibbs inference to the experimental design setting which achieves robustness in both design and inference. Using an extended information-theoretic framework, we derive a new acquisition function, the Gibbs expected information gain (Gibbs EIG). Our empirical results demonstrate that GBOED enhances robustness to outliers and incorrect assumptions about the outcome noise distribution."}
{"id": "2511.07999", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.07999", "abs": "https://arxiv.org/abs/2511.07999", "authors": ["Riccardo De Santis", "Anna Vesely", "Angela Andreella"], "title": "Inference on multiple quantiles in regression models by a rank-score approach", "comment": null, "summary": "This paper tackles the challenge of performing multiple quantile regressions across different quantile levels and the associated problem of controlling the familywise error rate, an issue that is generally overlooked in practice. We propose a multivariate extension of the rank-score test and embed it within a closed-testing procedure to efficiently account for multiple testing. Theoretical foundations and simulation studies demonstrate that our method effectively controls the familywise error rate while achieving higher power than traditional corrections, such as Bonferroni."}
{"id": "2511.08401", "categories": ["stat.ML", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.08401", "abs": "https://arxiv.org/abs/2511.08401", "authors": ["C. Evans Hedges"], "title": "Source-Optimal Training is Transfer-Suboptimal", "comment": null, "summary": "We prove a fundamental misalignment in transfer learning: the source regularization that minimizes source risk almost never coincides with the regularization maximizing transfer benefit. Through sharp phase boundaries for L2-SP ridge regression, we characterize the transfer-optimal source penalty $τ_0^*$ and show it diverges predictably from task-optimal values, requiring stronger regularization in high-SNR regimes and weaker regularization in low-SNR regimes. Additionally, in isotropic settings the decision to transfer is remarkably independent of target sample size and noise, depending only on task alignment and source characteristics. CIFAR-10 and MNIST experiments confirm this counterintuitive pattern persists in non-linear networks."}
{"id": "2511.08124", "categories": ["stat.CO", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08124", "abs": "https://arxiv.org/abs/2511.08124", "authors": ["Alin Morariu", "Jess Bridgen", "Chris Jewell"], "title": "gemlib: Probabilistic programming for epidemic models", "comment": null, "summary": "gemlib is a Python library for defining, simulating, and calibrating Markov state-transition models. Stochastic models are often computationally intensive, making them impractical to use in pandemic response efforts despite their favourable interpretations compared to their deterministic counterparts. gemlib decomposes state-transition models into three key ingredients which succinctly encapsulate the model and are sufficient for executing the subsequent computational routines. Simulation is performed using implementations of Gillespie's algorithm for continuous-time models and a generic Tau-leaping algorithm for discrete time models. gemlib models integrate seamlessly with Markov Chain Monte Carlo samplers as they provide a target distribution for the inference algorithm. Algorithms are implemented using the machine learning computational frameworks JAX and TensorFlow Probability, thus taking advantage of modern hardware to accelerate computation. This abstracts away computational concerns from modellers, allowing them to focus on developing and testing different model structures or assumptions. The gemlib library enables users to rapidly implement and calibrate stochastic epidemic models with the flexibility and robustness required to support decision during an emerging outbreak."}
{"id": "2511.07831", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07831", "abs": "https://arxiv.org/abs/2511.07831", "authors": ["Zewu Zheng", "Yuanyuan Lin"], "title": "Distributionally Robust Online Markov Game with Linear Function Approximation", "comment": "To be published in the Proceedings of AAAI 2026", "summary": "The sim-to-real gap, where agents trained in a simulator face significant performance degradation during testing, is a fundamental challenge in reinforcement learning. Extansive works adopt the framework of distributionally robust RL, to learn a policy that acts robustly under worst case environment shift. Within this framework, our objective is to devise algorithms that are sample efficient with interactive data collection and large state spaces. By assuming d-rectangularity of environment dynamic shift, we identify a fundamental hardness result for learning in online Markov game, and address it by adopting minimum value assumption. Then, a novel least square value iteration type algorithm, DR-CCE-LSI, with exploration bonus devised specifically for multiple agents, is proposed to find an \\episilon-approximate robust Coarse Correlated Equilibrium(CCE). To obtain sample efficient learning, we find that: when the feature mapping function satisfies certain properties, our algorithm, DR-CCE-LSI, is able to achieve ε-approximate CCE with a regret bound of O{dHmin{H,1/min{σ_i}}\\sqrt{K}}, where K is the number of interacting episodes, H is the horizon length, d is the feature dimension, and \\simga_i represents the uncertainty level of player i. Our work introduces the first sample-efficient algorithm for this setting, matches the best result so far in single agent setting, and achieves minimax optimalsample complexity in terms of the feature dimension d. Meanwhile, we also conduct simulation study to validate the efficacy of our algorithm in learning a robust equilibrium."}
{"id": "2511.08070", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08070", "abs": "https://arxiv.org/abs/2511.08070", "authors": ["Yuichi Goto", "Hiroko Kato Solvang", "Masanobu Taniguchi", "Tone Falkenhaug"], "title": "ANOVATS: A subsampling-based test to detect differences among short time series in marine studies", "comment": "23 pages, 12 figures", "summary": "Assessing marine ecosystems is important for understanding the impacts of climate change and human activity, as well as for maintaining healthy oceans and ecosystems. In marine science, it is common for biologists and geologists to identify regional differences based on expert knowledge, frequently through data visualization. However, time series data collected through surveys in marine studies typically span only a few decades, limiting the applicability of classical time series methods. Additionally, without expert knowledge, detecting significant differences becomes challenging. To address these issues, we introduce ANOVATS (ANOVA for small-sample time series data), a subsampling-based method to detect regional differences in small-sample time series data with a fixed number of groups. This method bypasses the need for spectral density estimation, which requires a large number of time points in the data. Furthermore, after detecting differences in homogeneity across all areas using the ANOVATS procedure, we devised a simple ANOVATS post hoc procedure to group the areas. Finally, we demonstrate the effectiveness of our method by analyzing zooplankton biomass data collected in different strata of the North Sea, showing its ability to quantify differences in species between geographical areas without relying on prior biological or geographical knowledge."}
{"id": "2511.08223", "categories": ["stat.CO", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.08223", "abs": "https://arxiv.org/abs/2511.08223", "authors": ["Felix Reichel"], "title": "A Fast and Accurate Approach for Covariance Matrix Construction", "comment": "12 pages, 7 figures", "summary": "Reichel (2025) defined the Bariance as $\\mathrm{Bariance}(x)=\\frac{1}{n(n-1)}\\sum_{i<j}(x_i-x_j)^2$, which admits an $O(n)$ reformulation using scalar sums. We extend this to the covariance matrix by showing that $\\mathrm{Cov}(X)=\\frac{1}{n-1}\\!\\left(X^\\top X-\\frac{1}{n}\\,s\\,s^\\top\\right)$ with $s=X^\\top \\mathbf{1}_n$ is algebraically identical to the pairwise-difference form yet avoids explicit centering. Computation reduces to a single $p\\times p$ outer matrix product and one subtraction. Empirical benchmarks in Python show clear runtime gains over numpy.cov in non-BLAS-tuned settings. Faster Gram routines such as RXTX (Rybin et. al) for $XX^\\top$ further reduce total cost."}
{"id": "2511.07997", "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.07997", "abs": "https://arxiv.org/abs/2511.07997", "authors": ["Ke Jia", "Yuheng Ma", "Yang Li", "Feifei Wang"], "title": "PrAda-GAN: A Private Adaptive Generative Adversarial Network with Bayes Network Structure", "comment": null, "summary": "We revisit the problem of generating synthetic data under differential privacy. To address the core limitations of marginal-based methods, we propose the Private Adaptive Generative Adversarial Network with Bayes Network Structure (PrAda-GAN), which integrates the strengths of both GAN-based and marginal-based approaches. Our method adopts a sequential generator architecture to capture complex dependencies among variables, while adaptively regularizing the learned structure to promote sparsity in the underlying Bayes network. Theoretically, we establish diminishing bounds on the parameter distance, variable selection error, and Wasserstein distance. Our analysis shows that leveraging dependency sparsity leads to significant improvements in convergence rates. Empirically, experiments on both synthetic and real-world datasets demonstrate that PrAda-GAN outperforms existing tabular data synthesis methods in terms of the privacy-utility trade-off."}
{"id": "2511.08088", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08088", "abs": "https://arxiv.org/abs/2511.08088", "authors": ["Linda M. Haines"], "title": "Who's Afraid of the Wallenius Distribution?", "comment": null, "summary": "This paper is about the use of the Wallenius noncentral hypergeometric distribution for analysing contingency tables with two or more groups and two categories and with row margins and sample size, that is both margins, fixed. The parameters of the distribution are taken to be weights which are positive and sum to one and are thus defined on a regular simplex. The approach to analysis is presented for likelihood-based and Bayesian inference and is illustrated by example, with datasets taken from the literature and, in one case, used to generate semi-synthetic data. The analysis of two-by-two contingency tables using the univariate Wallenius distribution is shown to be straightforward, with the parameter a single weight which translates immediately to the requisite odds and the odds ratio. The analysis of contingency tables with more than two groups based on the multivariate Wallenius distribution was however more nuanced than that of the two-group tables. Specifically, some numerical subtleties were required in order to implement the necessary calculations. In particular, optimisation with respect to the weights was performed by transforming the weights to yield an unconstrained optimisation problem and likelihoods which are extremely small were scaled by an appropriate multiplying factor without compromising the elements of inference. Furthermore, a novel Markov chain Monte Carlo algorithm for Bayesian inference, termed the sphere walk Metropolis, was constructed. The proposal is implemented in Cartesian coordinates on the reference simplex and the Metropolis filter in barycentric coordinates on the regular simplex, with the transition between barycentric and Cartesian coordinates effected seamlessly."}
{"id": "2511.08180", "categories": ["stat.ME", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.08180", "abs": "https://arxiv.org/abs/2511.08180", "authors": ["Guido Masarotto"], "title": "Simulation-Based Fitting of Intractable Models via Sequential Sampling and Local Smoothing", "comment": "23 pages, 5 figures, 5 tables", "summary": "This paper presents a comprehensive algorithm for fitting generative models whose likelihood, moments, and other quantities typically used for inference are not analytically or numerically tractable. The proposed method aims to provide a general solution that requires only limited prior information on the model parameters. The algorithm combines a global search phase, aimed at identifying the region of the solution, with a local search phase that mimics a trust region version of the Fisher scoring algorithm for computing a quasi-likelihood estimator. Comparisons with alternative methods demonstrate the strong performance of the proposed approach. An R package implementing the algorithm is available on CRAN."}
{"id": "2511.08303", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08303", "abs": "https://arxiv.org/abs/2511.08303", "authors": ["Masahiro Kato"], "title": "Semi-Supervised Treatment Effect Estimation with Unlabeled Covariates via Generalized Riesz Regression", "comment": null, "summary": "This study investigates treatment effect estimation in the semi-supervised setting, where we can use not only the standard triple of covariates, treatment indicator, and outcome, but also unlabeled auxiliary covariates. For this problem, we develop efficiency bounds and efficient estimators whose asymptotic variance aligns with the efficiency bound. In the analysis, we introduce two different data-generating processes: the one-sample setting and the two-sample setting. The one-sample setting considers the case where we can observe treatment indicators and outcomes for a part of the dataset, which is also called the censoring setting. In contrast, the two-sample setting considers two independent datasets with labeled and unlabeled data, which is also called the case-control setting or the stratified setting. In both settings, we find that by incorporating auxiliary covariates, we can lower the efficiency bound and obtain an estimator with an asymptotic variance smaller than that without such auxiliary covariates."}
{"id": "2511.08180", "categories": ["stat.ME", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.08180", "abs": "https://arxiv.org/abs/2511.08180", "authors": ["Guido Masarotto"], "title": "Simulation-Based Fitting of Intractable Models via Sequential Sampling and Local Smoothing", "comment": "23 pages, 5 figures, 5 tables", "summary": "This paper presents a comprehensive algorithm for fitting generative models whose likelihood, moments, and other quantities typically used for inference are not analytically or numerically tractable. The proposed method aims to provide a general solution that requires only limited prior information on the model parameters. The algorithm combines a global search phase, aimed at identifying the region of the solution, with a local search phase that mimics a trust region version of the Fisher scoring algorithm for computing a quasi-likelihood estimator. Comparisons with alternative methods demonstrate the strong performance of the proposed approach. An R package implementing the algorithm is available on CRAN."}
{"id": "2511.08307", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08307", "abs": "https://arxiv.org/abs/2511.08307", "authors": ["Aranyak Acharyya", "Joshua Agterberg", "Youngser Park", "Carey E. Priebe"], "title": "Concentration bounds on response-based vector embeddings of black-box generative models", "comment": null, "summary": "Generative models, such as large language models or text-to-image diffusion models, can generate relevant responses to user-given queries. Response-based vector embeddings of generative models facilitate statistical analysis and inference on a given collection of black-box generative models. The Data Kernel Perspective Space embedding is one particular method of obtaining response-based vector embeddings for a given set of generative models, already discussed in the literature. In this paper, under appropriate regularity conditions, we establish high probability concentration bounds on the sample vector embeddings for a given set of generative models, obtained through the method of Data Kernel Perspective Space embedding. Our results tell us the required number of sample responses needed in order to approximate the population-level vector embeddings with a desired level of accuracy. The algebraic tools used to establish our results can be used further for establishing concentration bounds on Classical Multidimensional Scaling embeddings in general, when the dissimilarities are observed with noise."}
{"id": "2511.08184", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08184", "abs": "https://arxiv.org/abs/2511.08184", "authors": ["Kentaro Fukumoto"], "title": "Reclustering: A New Method to Test the Appropriate Level of Clustering", "comment": null, "summary": "When scholars suspect units are dependent on each other within clusters but independent of each other across clusters, they employ cluster-robust standard errors (CRSEs). Nevertheless, what to cluster over is sometimes unknown. For instance, in the case of cross-sectional survey samples, clusters may be households, municipalities, counties, or states. A few approaches have been proposed, although they are based on asymptotics. I propose a new method to address this issue that works in a finite sample: reclustering. That is, we randomly and repeatedly group fine clusters into new gross clusters and calculate a statistic such as CRSEs. Under the null hypothesis that fine clusters are independent of each other, how they are grouped into gross clusters should not matter for any cluster-sensitive statistic. Thus, if the statistic based on the original clustering is a significant outlier against the distributions of the statistics induced by reclustering, it is reasonable to reject the null hypothesis and employ gross clusters. I compare the performance of reclustering with that of a few previous tests using Monte Carlo simulation and application."}
{"id": "2511.08401", "categories": ["stat.ML", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.08401", "abs": "https://arxiv.org/abs/2511.08401", "authors": ["C. Evans Hedges"], "title": "Source-Optimal Training is Transfer-Suboptimal", "comment": null, "summary": "We prove a fundamental misalignment in transfer learning: the source regularization that minimizes source risk almost never coincides with the regularization maximizing transfer benefit. Through sharp phase boundaries for L2-SP ridge regression, we characterize the transfer-optimal source penalty $τ_0^*$ and show it diverges predictably from task-optimal values, requiring stronger regularization in high-SNR regimes and weaker regularization in low-SNR regimes. Additionally, in isotropic settings the decision to transfer is remarkably independent of target sample size and noise, depending only on task alignment and source characteristics. CIFAR-10 and MNIST experiments confirm this counterintuitive pattern persists in non-linear networks."}
{"id": "2511.08192", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08192", "abs": "https://arxiv.org/abs/2511.08192", "authors": ["Lydia Kakampakou", "Jennifer L. Wadsworth"], "title": "Geometric modelling of spatial extremes", "comment": "34 pages, 9 figures", "summary": "Recent developments in extreme value statistics have established the so-called geometric approach as a powerful modelling tool for multivariate extremes. We tailor these methods to the case of spatial modelling and examine their efficacy at inferring extremal dependence and performing extrapolation. The geometric approach is based around a limit set described by a gauge function, which is a key target for inference. We consider a variety of spatially-parameterised gauge functions and perform inference on them by building on the framework of Wadsworth and Campbell (2024), where extreme radii are modelled via a truncated gamma distribution. We also consider spatial modelling of the angular distribution, for which we propose two candidate models. Estimation of extreme event probabilities is possible by combining draws from the radial and angular models respectively. We compare our method with two other established frameworks for spatial extreme value analysis and show that our approach generally allows for unbiased, albeit more uncertain, inference compared to the more classical models. We apply the methodology to a space weather dataset of daily geomagnetic field fluctuations."}
{"id": "2511.07786", "categories": ["stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.07786", "abs": "https://arxiv.org/abs/2511.07786", "authors": ["Hanwen Huang"], "title": "A Closed-Form Diffusion Model for Learnring Dynamics from Marginal Observations", "comment": "35 pages, 3 figures", "summary": "Score-based generative models learn transformations from a simple Gaussian to complex data distributions. To generalize these transformations between arbitrary distributions, recent work has focused on the Schrödinger Bridge (SB) problem. However, SB solutions are rarely available in closed form, and existing methods rely on iterative stochastic simulations that are often unstable and costly. We introduce a closed-form framework for learning SB dynamics that unifies and extends previously known closed-form solutions, including the Schrödinger Föllmer process and the Gaussian SB. Notably, the classical Gaussian SB solution arises as an immediate corollary of our formulation. Based on this result, we develop a simulation-free algorithm that directly infers SB dynamics from samples of the source and target distributions. We demonstrate the approach in modeling single-cell developmental trajectories and in image restoration tasks such as inpainting and deblurring."}
{"id": "2511.08332", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08332", "abs": "https://arxiv.org/abs/2511.08332", "authors": ["Victor Pacifique Rwandarwacu"], "title": "Clinicians' Interpretation and Preferences for Survival Data Visualisation: A Pre-Post Study Comparing Kaplan-Meier and Mean Residual Life Plots", "comment": "19 pages, 3 tables, 13 figures. PDF generated from R Markdown. Code available at https://github.com/rwandarwacu1/Msc_thesis_survival", "summary": "Effective visualization of survival data is essential for clinician interpretation and patient communication. While Kaplan-Meier (KM) plots are widely used, Mean Residual Life (MRL) plots may offer a more intuitive display of prognosis over time. However, little is known about clinicians' knowledge and preferences regarding these alternatives. This pre-post pilot cross-sectional survey assessed 32 medical students and doctors who interpreted four survival plot types (KM, survival difference, MRL, and MRL difference) before and after a brief learning section. Interpretation accuracy, learning gain, and ranking preferences were analyzed. Overall accuracy improved from 50.0 percent pre-learning to 81.2 percent post-learning (p = 0.002), with the largest improvement for MRL plots (+37.5 percentage points). KM plots remained the most preferred for ease of clinical use (59 percent), while MRL plots were valued for patient communication (9 percent). Participants with lower self-rated survival knowledge showed the greatest learning gains. These findings suggest that with minimal instruction, clinicians can interpret MRL plots as effectively as KM plots. Incorporating MRL visualizations into clinical dashboards and medical education could improve understanding of survival outcomes and patient-centered communication."}
{"id": "2511.08180", "categories": ["stat.ME", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.08180", "abs": "https://arxiv.org/abs/2511.08180", "authors": ["Guido Masarotto"], "title": "Simulation-Based Fitting of Intractable Models via Sequential Sampling and Local Smoothing", "comment": "23 pages, 5 figures, 5 tables", "summary": "This paper presents a comprehensive algorithm for fitting generative models whose likelihood, moments, and other quantities typically used for inference are not analytically or numerically tractable. The proposed method aims to provide a general solution that requires only limited prior information on the model parameters. The algorithm combines a global search phase, aimed at identifying the region of the solution, with a local search phase that mimics a trust region version of the Fisher scoring algorithm for computing a quasi-likelihood estimator. Comparisons with alternative methods demonstrate the strong performance of the proposed approach. An R package implementing the algorithm is available on CRAN."}
{"id": "2511.08398", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08398", "abs": "https://arxiv.org/abs/2511.08398", "authors": ["Mymuna Monem", "Ian L. Dryden", "Florence George"], "title": "Principal nested spheres for high-dimensional data", "comment": "23 pages, 8 figures, 3 tables", "summary": "The method of Principal Nested Spheres (PNS) is a non-linear dimension reduction technique for spherical data. The method is a backwards fitting procedure, starting with fitting a high-dimensional sphere and then successively reducing dimension at each stage. After reviewing the PNS method in detail, we introduce some new methods for model selection at each stage between great and small subspheres, based on the Kolmogorov-Smirnov test, a variance test and a likelihood ratio test. The current PNS fitting method is slow for high-dimensional spherical data, and so we introduce a fast PNS method which involves an initial principal components analysis decomposition to select a basis for lower dimensional PNS. A new visual method called the PNS biplot is introduced for examining the effects of the original variables on the PNS, and this involves procedures for back-fitting from the PNS scores back to the original variables. The methodology is illustrated with two high-dimensional datasets from cancer research: Melanoma proteomics data with 500 variables and 205 patients, and a Pan Cancer dataset with 12,478 genes and 300 patients. In both applications the PNS biplot is used to select variables for effective classification."}
{"id": "2511.08532", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08532", "abs": "https://arxiv.org/abs/2511.08532", "authors": ["Yinjun Zhao", "Nicholas Tatonetti", "Yuanjia Wang"], "title": "Multi-level Latent Variable Models for Coheritability Analysis in Electronic Health Records", "comment": "21 pages, 5 figures", "summary": "Electronic health records (EHRs) linked with familial relationship data offer a unique opportunity to investigate the genetic architecture of complex phenotypes at scale. However, existing heritability and coheritability estimation methods often fail to account for the intricacies of familial correlation structures, heterogeneity across phenotype types, and computational scalability. We propose a robust and flexible statistical framework for jointly estimating heritability and genetic correlation among continuous and binary phenotypes in EHR-based family studies. Our approach builds on multi-level latent variable models to decompose phenotypic covariance into interpretable genetic and environmental components, incorporating both within- and between-family variations. We derive iteration algorithms based on generalized equation estimations (GEE) for estimation. Simulation studies under various parameter configurations demonstrate that our estimators are consistent and yield valid inference across a range of realistic settings. Applying our methods to real-world EHR data from a large, urban health system, we identify significant genetic correlations between mental health conditions and endocrine/metabolic phenotypes, supporting hypotheses of shared etiology. This work provides a scalable and rigorous framework for coheritability analysis in high-dimensional EHR data and facilitates the identification of shared genetic influences in complex disease networks."}
{"id": "2511.08559", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08559", "abs": "https://arxiv.org/abs/2511.08559", "authors": ["Eun Jeong Oh", "Min Qian"], "title": "Reluctant Transfer Learning in Penalized Regressions for Individualized Treatment Rules under Effect Heterogeneity", "comment": null, "summary": "Estimating individualized treatment rules (ITRs) is fundamental to precision medicine, where the goal is to tailor treatment decisions to individual patient characteristics. While numerous methods have been developed for ITR estimation, there is limited research on model updating that accounts for shifted treatment-covariate relationships in the ITR setting. In real-world practice, models trained on source data must be updated for new (target) datasets that exhibit shifts in treatment effects. To address this challenge, we propose a Reluctant Transfer Learning (RTL) framework that enables efficient model adaptation by selectively transferring essential model components (e.g., regression coefficients) from source to target data, without requiring access to individual-level source data. Leveraging the principle of reluctant modeling, the RTL approach incorporates model adjustments only when they improve performance on the target dataset, thereby controlling complexity and enhancing generalizability. Our method supports multi-armed treatment settings, performs variable selection for interpretability, and provides theoretical guarantees for the value convergence. Through simulation studies and an application to a real data example from the Best Apnea Interventions for Research (BestAIR) trial, we demonstrate that RTL outperforms existing alternatives. The proposed framework offers an efficient, practically feasible approach to adaptive treatment decision-making under evolving treatment effect conditions."}
{"id": "2511.07997", "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.07997", "abs": "https://arxiv.org/abs/2511.07997", "authors": ["Ke Jia", "Yuheng Ma", "Yang Li", "Feifei Wang"], "title": "PrAda-GAN: A Private Adaptive Generative Adversarial Network with Bayes Network Structure", "comment": null, "summary": "We revisit the problem of generating synthetic data under differential privacy. To address the core limitations of marginal-based methods, we propose the Private Adaptive Generative Adversarial Network with Bayes Network Structure (PrAda-GAN), which integrates the strengths of both GAN-based and marginal-based approaches. Our method adopts a sequential generator architecture to capture complex dependencies among variables, while adaptively regularizing the learned structure to promote sparsity in the underlying Bayes network. Theoretically, we establish diminishing bounds on the parameter distance, variable selection error, and Wasserstein distance. Our analysis shows that leveraging dependency sparsity leads to significant improvements in convergence rates. Empirically, experiments on both synthetic and real-world datasets demonstrate that PrAda-GAN outperforms existing tabular data synthesis methods in terms of the privacy-utility trade-off."}
{"id": "2511.08081", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08081", "abs": "https://arxiv.org/abs/2511.08081", "authors": ["Merle Mendel", "Roland Fried"], "title": "Parameter Estimation and Seasonal Modification of the Fractional Poisson Process with Application to Vorticity Extremes over the North Atlantic", "comment": null, "summary": "The fractional Poisson process (FPP) generalizes the standard Poisson process by replacing exponentially distributed return times with Mittag-Leffler distributed ones with an extra tail parameter, allowing for greater flexibility. The FPP has been applied in various fields, such as modeling occurrences of extratropical cyclones in meteorology and solar flares in physics. We propose a new estimation method for the parameters of the FPP, based on minimizing the distance between the empirical and the theoretical distribution at selected quantiles. We conduct an extensive simulation study to evaluate the advantages and limitations of the new estimation method and to compare it with several competing estimators, some of which have not yet been examined in the Mittag-Leffler setting. To enhance the applicability of the FPP in real-world scenarios, particularly in meteorology, we propose a method for incorporating seasonality into the FPP through distance-based weighting. We then analyze the return times of relative vorticity extremes in the North Atlantic-European region using our seasonal modeling approach."}
{"id": "2511.08303", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.08303", "abs": "https://arxiv.org/abs/2511.08303", "authors": ["Masahiro Kato"], "title": "Semi-Supervised Treatment Effect Estimation with Unlabeled Covariates via Generalized Riesz Regression", "comment": null, "summary": "This study investigates treatment effect estimation in the semi-supervised setting, where we can use not only the standard triple of covariates, treatment indicator, and outcome, but also unlabeled auxiliary covariates. For this problem, we develop efficiency bounds and efficient estimators whose asymptotic variance aligns with the efficiency bound. In the analysis, we introduce two different data-generating processes: the one-sample setting and the two-sample setting. The one-sample setting considers the case where we can observe treatment indicators and outcomes for a part of the dataset, which is also called the censoring setting. In contrast, the two-sample setting considers two independent datasets with labeled and unlabeled data, which is also called the case-control setting or the stratified setting. In both settings, we find that by incorporating auxiliary covariates, we can lower the efficiency bound and obtain an estimator with an asymptotic variance smaller than that without such auxiliary covariates."}
