{"id": "2602.21356", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21356", "abs": "https://arxiv.org/abs/2602.21356", "authors": ["Alexander Valencia-Sanchez", "Jeffrey S. Rosenthal", "Yasuhiro Watanabe", "Hirotaka Tamura", "Ali Sheikholeslami"], "title": "Adaptive Importance Tempering: A flexible approach to improve computational efficiency of Metropolis Coupled Markov Chain Monte Carlo algorithms on binary spaces", "comment": "25 pages, 8 figures", "summary": "Based on the algorithm Informed Importance Tempering (IIT) proposed by Li et al. (2023) we propose an algorithm that uses an adaptive bounded balancing function. We argue why implementing parallel tempering where each replica uses a rejection free MCMC algorithm can be inefficient in high dimensional spaces and show how the proposed adaptive algorithm can overcome these computational inefficiencies. We present two equivalent versions of the adaptive algorithm (A-IIT and SS-IIT) and establish that both have the same limiting distribution, making either suitable for use within a parallel tempering framework. To evaluate performance, we benchmark the adaptive algorithm against several MCMC methods: IIT, Rejection free Metropolis-Hastings (RF-MH) and RF-MH using a multiplicity list. Simulation results demonstrate that Adaptive IIT identifies high-probability states more efficiently than these competing algorithms in high-dimensional binary spaces with multiple modes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eIIT\u7684\u81ea\u9002\u5e94\u6709\u754c\u5e73\u8861\u51fd\u6570\u7b97\u6cd5\uff0c\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5e76\u884c\u56de\u706b\u7ed3\u5408\u62d2\u7edd\u81ea\u7531MCMC\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u5177\u6709\u591a\u6a21\u6001\u7684\u9ad8\u7ef4\u4e8c\u5143\u7a7a\u95f4\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u5730\u8bc6\u522b\u9ad8\u6982\u7387\u72b6\u6001\u3002", "motivation": "\u5728Li\u7b49\u4eba(2023)\u63d0\u51fa\u7684IIT\u7b97\u6cd5\u57fa\u7840\u4e0a\uff0c\u9488\u5bf9\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5e76\u884c\u56de\u706b\u7ed3\u5408\u62d2\u7edd\u81ea\u7531MCMC\u7b97\u6cd5\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u81ea\u9002\u5e94\u7b97\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u6709\u754c\u5e73\u8861\u51fd\u6570\u7b97\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u7b49\u6548\u7248\u672c(A-IIT\u548cSS-IIT)\uff0c\u4e24\u8005\u5177\u6709\u76f8\u540c\u7684\u6781\u9650\u5206\u5e03\uff0c\u90fd\u9002\u7528\u4e8e\u5e76\u884c\u56de\u706b\u6846\u67b6\u3002\u7b97\u6cd5\u57fa\u4e8eIIT\u7b97\u6cd5\u6539\u8fdb\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u8fb9\u754c\u5e73\u8861\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c06\u81ea\u9002\u5e94IIT\u4e0eIIT\u3001\u62d2\u7edd\u81ea\u7531Metropolis-Hastings(RF-MH)\u4ee5\u53ca\u4f7f\u7528\u591a\u91cd\u5217\u8868\u7684RF-MH\u8fdb\u884c\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\u5728\u5177\u6709\u591a\u6a21\u6001\u7684\u9ad8\u7ef4\u4e8c\u5143\u7a7a\u95f4\u4e2d\uff0c\u81ea\u9002\u5e94IIT\u6bd4\u8fd9\u4e9b\u7ade\u4e89\u7b97\u6cd5\u66f4\u9ad8\u6548\u5730\u8bc6\u522b\u9ad8\u6982\u7387\u72b6\u6001\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94IIT\u7b97\u6cd5\u89e3\u51b3\u4e86\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5e76\u884c\u56de\u706b\u7ed3\u5408\u62d2\u7edd\u81ea\u7531MCMC\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u590d\u6742\u9ad8\u7ef4\u4e8c\u5143\u7a7a\u95f4\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u5206\u5e03\u91c7\u6837\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21272", "categories": ["stat.ML", "cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21272", "abs": "https://arxiv.org/abs/2602.21272", "authors": ["Reuben Cohn-Gordon", "Uro\u0161 Seljak", "Dries Sels"], "title": "Counterdiabatic Hamiltonian Monte Carlo", "comment": null, "summary": "Hamiltonian Monte Carlo (HMC) is a state of the art method for sampling from distributions with differentiable densities, but can converge slowly when applied to challenging multimodal problems. Running HMC with a time varying Hamiltonian, in order to interpolate from an initial tractable distribution to the target of interest, can address this problem. In conjunction with a weighting scheme to eliminate bias, this can be viewed as a special case of Sequential Monte Carlo (SMC) sampling \\cite{doucet2001introduction}. However, this approach can be inefficient, since it requires slow change between the initial and final distribution. Inspired by \\cite{sels2017minimizing}, where a learned \\emph{counterdiabatic} term added to the Hamiltonian allows for efficient quantum state preparation, we propose \\emph{Counterdiabatic Hamiltonian Monte Carlo} (CHMC), which can be viewed as an SMC sampler with a more efficient kernel. We establish its relationship to recent proposals for accelerating gradient-based sampling with learned drift terms, and demonstrate on simple benchmark problems.", "AI": {"tldr": "\u63d0\u51faCounterdiabatic Hamiltonian Monte Carlo (CHMC)\uff0c\u901a\u8fc7\u6dfb\u52a0\u53cd\u7edd\u70ed\u9879\u6539\u8fdbHMC\u5728\u590d\u6742\u591a\u6a21\u6001\u5206\u5e03\u4e2d\u7684\u91c7\u6837\u6548\u7387", "motivation": "\u4f20\u7edfHamiltonian Monte Carlo (HMC)\u5728\u5904\u7406\u591a\u6a21\u6001\u5206\u5e03\u65f6\u6536\u655b\u7f13\u6162\uff0c\u73b0\u6709\u57fa\u4e8e\u65f6\u95f4\u53d8\u5316\u54c8\u5bc6\u987f\u91cf\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u89e3\u51b3\u6b64\u95ee\u9898\u4f46\u6548\u7387\u4f4e\u4e0b", "method": "\u53d7\u91cf\u5b50\u8ba1\u7b97\u4e2d\u53cd\u7edd\u70ed\u9879\u542f\u53d1\uff0c\u63d0\u51faCHMC\u65b9\u6cd5\uff0c\u5728\u54c8\u5bc6\u987f\u91cf\u4e2d\u6dfb\u52a0\u5b66\u4e60\u7684\u53cd\u7edd\u70ed\u9879\uff0c\u53ef\u89c6\u4e3a\u66f4\u9ad8\u6548\u7684Sequential Monte Carlo\u91c7\u6837\u5668", "result": "\u5efa\u7acb\u4e86CHMC\u4e0e\u73b0\u6709\u52a0\u901f\u68af\u5ea6\u91c7\u6837\u7684\u5b66\u4e60\u6f02\u79fb\u9879\u65b9\u6cd5\u7684\u8054\u7cfb\uff0c\u5e76\u5728\u7b80\u5355\u57fa\u51c6\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1", "conclusion": "CHMC\u901a\u8fc7\u53cd\u7edd\u70ed\u9879\u663e\u8457\u63d0\u9ad8\u4e86HMC\u5728\u591a\u6a21\u6001\u5206\u5e03\u91c7\u6837\u4e2d\u7684\u6548\u7387\uff0c\u662fSMC\u91c7\u6837\u5668\u7684\u4e00\u79cd\u9ad8\u6548\u5b9e\u73b0"}}
{"id": "2602.21403", "categories": ["stat.ME", "cs.CE", "eess.SP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21403", "abs": "https://arxiv.org/abs/2602.21403", "authors": ["Luca Martino", "Eduardo Morgado", "Roberto San Mill\u00e1n-Castillo"], "title": "An index of effective number of variables for uncertainty and reliability analysis in model selection problems", "comment": null, "summary": "An index of an effective number of variables (ENV) is introduced for model selection in nested models. This is the case, for instance, when we have to decide the order of a polynomial function or the number of bases in a nonlinear regression, choose the number of clusters in a clustering problem, or the number of features in a variable selection application (to name few examples). It is inspired by the idea of the maximum area under the curve (AUC). The interpretation of the ENV index is identical to the effective sample size (ESS) indices concerning a set of samples. The ENV index improves {drawbacks of} the elbow detectors described in the literature and introduces different confidence measures of the proposed solution. These novel measures can be also employed jointly with the use of different information criteria, such as the well-known AIC and BIC, or any other model selection procedures. Comparisons with classical and recent schemes are provided in different experiments involving real datasets. Related Matlab code is given.", "AI": {"tldr": "\u63d0\u51faENV\u6307\u6570\u7528\u4e8e\u5d4c\u5957\u6a21\u578b\u9009\u62e9\uff0c\u57fa\u4e8e\u6700\u5927AUC\u601d\u60f3\uff0c\u6539\u8fdb\u73b0\u6709\u8098\u90e8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u4f9b\u7f6e\u4fe1\u5ea6\u5ea6\u91cf\uff0c\u53ef\u4e0eAIC/BIC\u7b49\u51c6\u5219\u7ed3\u5408\u4f7f\u7528\u3002", "motivation": "\u5728\u591a\u9879\u5f0f\u9636\u6570\u9009\u62e9\u3001\u805a\u7c7b\u6570\u91cf\u786e\u5b9a\u3001\u7279\u5f81\u9009\u62e9\u7b49\u5d4c\u5957\u6a21\u578b\u9009\u62e9\u95ee\u9898\u4e2d\uff0c\u73b0\u6709\u8098\u90e8\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u9009\u62e9\u6307\u6807\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u6709\u6548\u53d8\u91cf\u6570(ENV)\u6307\u6570\uff0c\u57fa\u4e8e\u6700\u5927\u66f2\u7ebf\u4e0b\u9762\u79ef(AUC)\u601d\u60f3\uff0c\u63d0\u4f9b\u4e0d\u540c\u7f6e\u4fe1\u5ea6\u5ea6\u91cf\uff0c\u53ef\u4e0eAIC\u3001BIC\u7b49\u4fe1\u606f\u51c6\u5219\u7ed3\u5408\u4f7f\u7528\u3002", "result": "ENV\u6307\u6570\u6539\u8fdb\u4e86\u73b0\u6709\u8098\u90e8\u68c0\u6d4b\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u4e0e\u7ecf\u5178\u548c\u6700\u65b0\u65b9\u6848\u6bd4\u8f83\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u5e76\u63d0\u4f9b\u76f8\u5173Matlab\u4ee3\u7801\u3002", "conclusion": "ENV\u6307\u6570\u4e3a\u5d4c\u5957\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6539\u8fdb\u4e86\u8098\u90e8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u4f9b\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\uff0c\u53ef\u4e0e\u73b0\u6709\u4fe1\u606f\u51c6\u5219\u7ed3\u5408\u4f7f\u7528\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.21711", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21711", "abs": "https://arxiv.org/abs/2602.21711", "authors": ["Yuyao Wang", "Yu Lu", "Tianni Zhang", "Mengfei Ran"], "title": "Adaptive Penalized Doubly Robust Regression for Longitudinal Data", "comment": null, "summary": "Longitudinal data often involve heterogeneity, sparse signals, and contamination from response outliers or high-leverage observations especially in biomedical science. Existing methods usually address only part of this problem, either emphasizing penalized mixed effects modeling without robustness or robust mixed effects estimation without high-dimensional variable selection. We propose a doubly adaptive robust regression (DAR-R) framework for longitudinal linear mixed effects models. It combines a robust pilot fit, doubly adaptive observation weights for residual outliers and leverage points, and folded concave penalization for fixed effect selection, together with weighted updates of random effects and variance components. We develop an iterative reweighting algorithm and establish estimation and prediction error bounds, support recovery consistency, and oracle-type asymptotic normality. Simulations show that DAR-R improves estimation accuracy, false-positive control, and covariance estimation under both vertical outliers and bad leverage contamination. In the TADPOLE/ADNI Alzheimer's disease application, DAR-R achieves accurate and stable prediction of ADAS13 while selecting clinically meaningful predictors with strong resampling stability.", "AI": {"tldr": "\u63d0\u51faDAR-R\u65b9\u6cd5\uff0c\u7528\u4e8e\u7eb5\u5411\u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b\uff0c\u7ed3\u5408\u7a33\u5065\u6027\u3001\u81ea\u9002\u5e94\u6743\u91cd\u548c\u9ad8\u7ef4\u53d8\u91cf\u9009\u62e9\uff0c\u5904\u7406\u5f02\u8d28\u6027\u3001\u7a00\u758f\u4fe1\u53f7\u548c\u5f02\u5e38\u503c\u95ee\u9898\u3002", "motivation": "\u7eb5\u5411\u6570\u636e\u5e38\u5b58\u5728\u5f02\u8d28\u6027\u3001\u7a00\u758f\u4fe1\u53f7\u3001\u54cd\u5e94\u5f02\u5e38\u503c\u548c\u9ad8\u6760\u6746\u89c2\u6d4b\u6c61\u67d3\u7b49\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u53ea\u5173\u6ce8\u60e9\u7f5a\u6df7\u5408\u6548\u5e94\u5efa\u6a21\u800c\u7f3a\u4e4f\u7a33\u5065\u6027\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u7a33\u5065\u6df7\u5408\u6548\u5e94\u4f30\u8ba1\u800c\u7f3a\u4e4f\u9ad8\u7ef4\u53d8\u91cf\u9009\u62e9\uff0c\u65e0\u6cd5\u5168\u9762\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cc\u91cd\u81ea\u9002\u5e94\u7a33\u5065\u56de\u5f52(DAR-R)\u6846\u67b6\uff1a1) \u7a33\u5065\u521d\u59cb\u62df\u5408\uff1b2) \u5bf9\u6b8b\u5dee\u5f02\u5e38\u503c\u548c\u9ad8\u6760\u6746\u70b9\u7684\u53cc\u91cd\u81ea\u9002\u5e94\u89c2\u6d4b\u6743\u91cd\uff1b3) \u56fa\u5b9a\u6548\u5e94\u9009\u62e9\u7684\u6298\u53e0\u51f9\u60e9\u7f5a\uff1b4) \u968f\u673a\u6548\u5e94\u548c\u65b9\u5dee\u5206\u91cf\u7684\u52a0\u6743\u66f4\u65b0\u3002\u5f00\u53d1\u8fed\u4ee3\u91cd\u52a0\u6743\u7b97\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u4f30\u8ba1\u548c\u9884\u6d4b\u8bef\u5dee\u754c\u3001\u652f\u6301\u6062\u590d\u4e00\u81f4\u6027\u3001oracle\u578b\u6e10\u8fd1\u6b63\u6001\u6027\u3002\u6a21\u62df\u663e\u793aDAR-R\u5728\u5782\u76f4\u5f02\u5e38\u503c\u548c\u574f\u6760\u6746\u6c61\u67d3\u4e0b\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3001\u5047\u9633\u6027\u63a7\u5236\u548c\u534f\u65b9\u5dee\u4f30\u8ba1\u3002\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5e94\u7528\u4e2d\uff0cDAR-R\u5b9e\u73b0\u4e86ADAS13\u7684\u51c6\u786e\u7a33\u5b9a\u9884\u6d4b\uff0c\u9009\u62e9\u4e86\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u9884\u6d4b\u56e0\u5b50\uff0c\u5177\u6709\u5f3a\u91cd\u91c7\u6837\u7a33\u5b9a\u6027\u3002", "conclusion": "DAR-R\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7eb5\u5411\u6570\u636e\u4e2d\u7684\u5f02\u8d28\u6027\u3001\u7a00\u758f\u4fe1\u53f7\u548c\u6c61\u67d3\u95ee\u9898\uff0c\u7ed3\u5408\u4e86\u7a33\u5065\u6027\u3001\u81ea\u9002\u5e94\u6743\u91cd\u548c\u9ad8\u7ef4\u53d8\u91cf\u9009\u62e9\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.21792", "categories": ["stat.OT"], "pdf": "https://arxiv.org/pdf/2602.21792", "abs": "https://arxiv.org/abs/2602.21792", "authors": ["Mark Rubin"], "title": "p-Hacking Inflates Type I Error Rates in the Error Statistical Approach but not in the Formal Inference Approach", "comment": null, "summary": "p-hacking occurs when researchers conduct multiple significance tests (e.g., p1;H0,1 and p2;H0,2) and then selectively report tests that yield desirable (usually significant) results (e.g., p2 < 0.05;H0,2) without correcting for multiple testing (e.g., 0.05/2 = 0.025). In the present article, I consider p-hacking in the context of two philosophies of significance testing - the error statistical approach and the formal inference approach. I argue that although p-hacking inflates Type I error rates in the error statistical approach, it does not inflate them in the formal inference approach. Specifically, in the error statistical approach, the \"actual\" familywise error rate (e.g., 1 - [1 - 0.05]2 = 0.098 for two tests) is relevant because it covers both the selectively reported and unreported tests in the \"actual\" test procedure (i.e., p1;H0,1 and p2;H0,2). In this approach, Type I error rate inflation occurs because the \"actual\" error rate (0.098) is higher than the nominal error rate (0.05). In contrast, in the formal inference approach, the \"actual\" familywise error rate is irrelevant because (a) the researcher does not report a statistical inference about the corresponding intersection null hypothesis (i.e., H0,1 intersect H0,2), and (b) the \"actual\" familywise error rate does not license inferences about the reported individual hypotheses (i.e., H0,2). Instead, in the formal inference approach, only the nominal error rate is relevant, and a comparison with the \"actual\" error rate is inappropriate. Implications for conceptualizing, demonstrating, and reducing p-hacking are discussed.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8p-hacking\u5728\u4e24\u79cd\u663e\u8457\u6027\u68c0\u9a8c\u54f2\u5b66\u4e2d\u7684\u4e0d\u540c\u5f71\u54cd\uff1a\u5728\u9519\u8bef\u7edf\u8ba1\u65b9\u6cd5\u4e2d\u4f1a\u81a8\u80c0I\u7c7b\u9519\u8bef\u7387\uff0c\u4f46\u5728\u5f62\u5f0f\u63a8\u65ad\u65b9\u6cd5\u4e2d\u4e0d\u4f1a\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6f84\u6e05p-hacking\u5728\u4e0d\u540c\u663e\u8457\u6027\u68c0\u9a8c\u54f2\u5b66\u6846\u67b6\u4e0b\u7684\u7406\u8bba\u5f71\u54cd\u3002\u4f5c\u8005\u53d1\u73b0\u73b0\u6709\u6587\u732e\u5bf9p-hacking\u7684\u7406\u89e3\u5b58\u5728\u6df7\u6dc6\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u7edf\u8ba1\u54f2\u5b66\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u533a\u5206\u9519\u8bef\u7edf\u8ba1\u65b9\u6cd5\u548c\u5f62\u5f0f\u63a8\u65ad\u65b9\u6cd5\u5bf9p-hacking\u7684\u4e0d\u540c\u89e3\u8bfb\u3002", "method": "\u91c7\u7528\u54f2\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e24\u79cd\u663e\u8457\u6027\u68c0\u9a8c\u54f2\u5b66\uff1a\u9519\u8bef\u7edf\u8ba1\u65b9\u6cd5\uff08\u5173\u6ce8\u5b9e\u9645\u9519\u8bef\u7387\uff09\u548c\u5f62\u5f0f\u63a8\u65ad\u65b9\u6cd5\uff08\u5173\u6ce8\u540d\u4e49\u9519\u8bef\u7387\uff09\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a2\u8ba8p-hacking\u5728\u8fd9\u4e24\u79cd\u6846\u67b6\u4e0b\u7684\u4e0d\u540c\u542b\u4e49\u548c\u5f71\u54cd\u3002", "result": "\u5206\u6790\u8868\u660e\uff1a\u5728\u9519\u8bef\u7edf\u8ba1\u65b9\u6cd5\u4e2d\uff0cp-hacking\u786e\u5b9e\u4f1a\u81a8\u80c0I\u7c7b\u9519\u8bef\u7387\uff0c\u56e0\u4e3a\u5b9e\u9645\u65cf\u9519\u8bef\u7387\uff08\u5982\u4e24\u4e2a\u68c0\u9a8c\u65f6\u4e3a0.098\uff09\u9ad8\u4e8e\u540d\u4e49\u9519\u8bef\u7387\uff080.05\uff09\u3002\u4f46\u5728\u5f62\u5f0f\u63a8\u65ad\u65b9\u6cd5\u4e2d\uff0cp-hacking\u4e0d\u4f1a\u81a8\u80c0I\u7c7b\u9519\u8bef\u7387\uff0c\u56e0\u4e3a\u7814\u7a76\u8005\u4e0d\u62a5\u544a\u76f8\u5e94\u7684\u4ea4\u96c6\u96f6\u5047\u8bbe\u63a8\u65ad\uff0c\u4e14\u5b9e\u9645\u65cf\u9519\u8bef\u7387\u4e0e\u62a5\u544a\u7684\u5355\u5047\u8bbe\u63a8\u65ad\u65e0\u5173\u3002", "conclusion": "\u7ed3\u8bba\u662fp-hacking\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u6240\u91c7\u7528\u7684\u663e\u8457\u6027\u68c0\u9a8c\u54f2\u5b66\u3002\u8fd9\u4e00\u533a\u5206\u5bf9\u7406\u89e3\u3001\u8bc1\u660e\u548c\u51cf\u5c11p-hacking\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u9700\u8981\u5728\u4e0d\u540c\u7edf\u8ba1\u54f2\u5b66\u6846\u67b6\u4e0b\u91cd\u65b0\u5ba1\u89c6p-hacking\u7684\u6982\u5ff5\u548c\u5e94\u5bf9\u7b56\u7565\u3002"}}
{"id": "2602.21370", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.21370", "abs": "https://arxiv.org/abs/2602.21370", "authors": ["Jane She", "Xiaofei Chen", "Malini Iyengar", "Judy Li"], "title": "Evaluation of Minimal Residual Disease as a Surrogate for Progression-Free Survival in Hematology Oncology Trials: A Meta-Analytic Review", "comment": null, "summary": "Traditional health authority approval for oncology drugs is based on a clinical benefit endpoint, or a valid surrogate. In 1992 the FDA created the Accelerated Approval pathway to allow for earlier approval of therapies in serious conditions with an unmet medical need. This is accomplished typically by granting accelerated approval based on a surrogate endpoint that can be measured earlier than a traditional approval endpoint. Minimal residual disease (MRD) is a sensitive measure of residual cancer cells in hematology oncology after treatment, and is increasingly considered as a secondary or exploratory endpoint due to its prognostic potential for traditional clinical trial endpoints such as progression-free survival (PFS) and overall survival (OS). This work aims to evaluate MRD's surrogacy potential across several hematologic cancer indications while keeping the focus on follicular lymphoma (FL), using data from published studies. We examine individual-level and trial-level correlations extracted from previously published studies to elucidate the potential role of MRD in accelerating the drug approval process in hematology oncology trials.", "AI": {"tldr": "\u8bc4\u4f30\u5fae\u5c0f\u6b8b\u7559\u75c5\uff08MRD\uff09\u4f5c\u4e3a\u8840\u6db2\u80bf\u7624\u836f\u7269\u52a0\u901f\u5ba1\u6279\u66ff\u4ee3\u7ec8\u70b9\u7684\u6f5c\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u6ee4\u6ce1\u6027\u6dcb\u5df4\u7624", "motivation": "FDA\u52a0\u901f\u5ba1\u6279\u9014\u5f84\u5141\u8bb8\u57fa\u4e8e\u66ff\u4ee3\u7ec8\u70b9\u6279\u51c6\u4e25\u91cd\u75be\u75c5\u7597\u6cd5\uff0cMRD\u4f5c\u4e3a\u8840\u6db2\u80bf\u7624\u6cbb\u7597\u540e\u6b8b\u7559\u764c\u7ec6\u80de\u7684\u654f\u611f\u6d4b\u91cf\u6307\u6807\uff0c\u5177\u6709\u4f5c\u4e3a\u66ff\u4ee3\u7ec8\u70b9\u7684\u6f5c\u529b\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u52a0\u901f\u836f\u7269\u5ba1\u6279\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528", "method": "\u4f7f\u7528\u5df2\u53d1\u8868\u7814\u7a76\u6570\u636e\uff0c\u901a\u8fc7\u4e2a\u4f53\u6c34\u5e73\u548c\u8bd5\u9a8c\u6c34\u5e73\u76f8\u5173\u6027\u5206\u6790\uff0c\u8bc4\u4f30MRD\u5728\u591a\u79cd\u8840\u6db2\u80bf\u7624\u9002\u5e94\u75c7\u4e2d\u7684\u66ff\u4ee3\u7ec8\u70b9\u6f5c\u529b\uff0c\u7279\u522b\u5173\u6ce8\u6ee4\u6ce1\u6027\u6dcb\u5df4\u7624", "result": "\u901a\u8fc7\u5206\u6790\u5df2\u53d1\u8868\u7814\u7a76\u7684\u76f8\u5173\u6027\u6570\u636e\uff0c\u9610\u660eMRD\u5728\u8840\u6db2\u80bf\u7624\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u52a0\u901f\u836f\u7269\u5ba1\u6279\u8fc7\u7a0b\u7684\u6f5c\u5728\u4f5c\u7528", "conclusion": "MRD\u4f5c\u4e3a\u8840\u6db2\u80bf\u7624\u6cbb\u7597\u7684\u654f\u611f\u6d4b\u91cf\u6307\u6807\uff0c\u5177\u6709\u4f5c\u4e3a\u52a0\u901f\u5ba1\u6279\u66ff\u4ee3\u7ec8\u70b9\u7684\u6f5c\u529b\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u8bc4\u4f30\u5176\u5728\u836f\u7269\u5ba1\u6279\u6d41\u7a0b\u4e2d\u7684\u4f5c\u7528"}}
{"id": "2602.21314", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21314", "abs": "https://arxiv.org/abs/2602.21314", "authors": ["Eli Ben-Michael", "Avi Feller"], "title": "Discussion of \"Matrix Completion When Missing Is Not at Random and Its Applications in Causal Panel Data Models\"", "comment": "Invited discussion of Choi and Yuan \"Matrix Completion When Missing Is Not at Random and Its Applications in Causal Panel Data Models\" at JSM 2025", "summary": "Choi and Yuan (2025) propose a novel approach to applying matrix completion to the problem of estimating causal effects in panel data. The key insight is that even in the presence of structured patterns of missing data -- i.e. selection into treatment -- matrix completion can be effective if the number of treated observations is small relative to the number of control observations. We applaud the authors for their insightful and interesting paper. We discuss this proposal from two complementary perspectives. First, we situate their proposal as an example of a \"split-apply-combine\" strategy that underlies many modern panel data estimators, including difference-in-differences and synthetic control approaches. Second, we discuss the issue of the statistical \"last mile problem\" -- the gap between theory and practice -- and offer suggestions on how to partially address it. We conclude by considering the challenges of estimating the impacts of public policies using panel data and apply the approach to a study on the effect of right to carry laws on violent crime.", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9Choi\u548cYuan(2025)\u5173\u4e8e\u77e9\u9635\u8865\u5168\u5728\u9762\u677f\u6570\u636e\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u5e94\u7528\u65b9\u6cd5\u7684\u8ba8\u8bba\u6027\u5206\u6790\uff0c\u4ece\"\u5206\u5272-\u5e94\u7528-\u7ec4\u5408\"\u7b56\u7565\u548c\u7edf\u8ba1\"\u6700\u540e\u4e00\u516c\u91cc\u95ee\u9898\"\u4e24\u4e2a\u89d2\u5ea6\u8fdb\u884c\u8bc4\u8ff0\u3002", "motivation": "\u8ba8\u8bbaChoi\u548cYuan(2025)\u63d0\u51fa\u7684\u5c06\u77e9\u9635\u8865\u5168\u5e94\u7528\u4e8e\u9762\u677f\u6570\u636e\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u7684\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u8be5\u65b9\u6cd5\u5728\u5b58\u5728\u7ed3\u6784\u5316\u7f3a\u5931\u6570\u636e\uff08\u5373\u5904\u7406\u9009\u62e9\uff09\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5f53\u5904\u7406\u89c2\u6d4b\u6570\u91cf\u76f8\u5bf9\u4e8e\u63a7\u5236\u89c2\u6d4b\u6570\u91cf\u8f83\u5c0f\u65f6\u3002", "method": "\u4ece\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u8fdb\u884c\u5206\u6790\uff1a1) \u5c06\u8be5\u65b9\u6cd5\u5b9a\u4f4d\u4e3a\u73b0\u4ee3\u9762\u677f\u6570\u636e\u4f30\u8ba1\u5668\u4e2d\u5e38\u89c1\u7684\"\u5206\u5272-\u5e94\u7528-\u7ec4\u5408\"\u7b56\u7565\u7684\u5b9e\u4f8b\uff1b2) \u8ba8\u8bba\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u7edf\u8ba1\"\u6700\u540e\u4e00\u516c\u91cc\u95ee\u9898\"\uff0c\u5e76\u63d0\u51fa\u90e8\u5206\u89e3\u51b3\u65b9\u6848\u5efa\u8bae\u3002", "result": "\u901a\u8fc7\u5c06\u77e9\u9635\u8865\u5168\u65b9\u6cd5\u5e94\u7528\u4e8e\u6301\u67aa\u6743\u6cd5\u5f8b\u5bf9\u66b4\u529b\u72af\u7f6a\u5f71\u54cd\u7684\u7814\u7a76\u6848\u4f8b\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4f30\u8ba1\u516c\u5171\u653f\u7b56\u5f71\u54cd\u65f6\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u9762\u677f\u6570\u636e\u653f\u7b56\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u77e9\u9635\u8865\u5168\u65b9\u6cd5\u4e3a\u9762\u677f\u6570\u636e\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b0\u5de5\u5177\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u95ee\u9898\u3002\u4f5c\u8005\u5efa\u8bae\u901a\u8fc7\u66f4\u7ec6\u81f4\u7684\u5b9e\u8bc1\u7b56\u7565\u6765\u90e8\u5206\u89e3\u51b3\"\u6700\u540e\u4e00\u516c\u91cc\u95ee\u9898\"\uff0c\u5e76\u5f3a\u8c03\u5728\u516c\u5171\u653f\u7b56\u8bc4\u4f30\u4e2d\u8c28\u614e\u5e94\u7528\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.21478", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21478", "abs": "https://arxiv.org/abs/2602.21478", "authors": ["Zikai Shen", "Houssam Zenati", "Nathan Kallus", "Arthur Gretton", "Koulik Khamaru", "Aur\u00e9lien Bibaut"], "title": "Efficient Inference after Directionally Stable Adaptive Experiments", "comment": "34 pages", "summary": "We study inference on scalar-valued pathwise differentiable targets after adaptive data collection, such as a bandit algorithm. We introduce a novel target-specific condition, directional stability, which is strictly weaker than previously imposed target-agnostic stability conditions. Under directional stability, we show that estimators that would have been efficient under i.i.d. data remain asymptotically normal and semiparametrically efficient when computed from adaptively collected trajectories. The canonical gradient has a martingale form, and directional stability guarantees stabilization of its predictable quadratic variation, enabling high-dimensional asymptotic normality. We characterize efficiency using a convolution theorem for the adaptive-data setting, and give a condition under which the one-step estimator attains the efficiency bound. We verify directional stability for LinUCB, yielding the first semiparametric efficiency guarantee for a regular scalar target under LinUCB sampling.", "AI": {"tldr": "\u63d0\u51fa\u65b9\u5411\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u8bc1\u660e\u5728\u81ea\u9002\u5e94\u6570\u636e\u6536\u96c6\u4e0b\uff08\u5982bandit\u7b97\u6cd5\uff09\uff0c\u6ee1\u8db3\u8be5\u6761\u4ef6\u7684\u4f30\u8ba1\u91cf\u4ecd\u80fd\u4fdd\u6301\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u534a\u53c2\u6570\u6548\u7387", "motivation": "\u7814\u7a76\u5728\u81ea\u9002\u5e94\u6570\u636e\u6536\u96c6\uff08\u5982bandit\u7b97\u6cd5\uff09\u540e\uff0c\u5bf9\u8def\u5f84\u53ef\u5fae\u6807\u91cf\u76ee\u6807\u7684\u63a8\u65ad\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u8981\u6c42\u76ee\u6807\u65e0\u5173\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u8fd9\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\u3002", "method": "\u5f15\u5165\u65b0\u7684\u76ee\u6807\u7279\u5b9a\u6761\u4ef6\u2014\u2014\u65b9\u5411\u7a33\u5b9a\u6027\uff0c\u8be5\u6761\u4ef6\u6bd4\u4e4b\u524d\u7684\u76ee\u6807\u65e0\u5173\u7a33\u5b9a\u6027\u6761\u4ef6\u66f4\u5f31\u3002\u5728\u65b9\u5411\u7a33\u5b9a\u6027\u4e0b\uff0c\u8bc1\u660e\u5728i.i.d.\u6570\u636e\u4e0b\u6709\u6548\u7684\u4f30\u8ba1\u91cf\u5728\u81ea\u9002\u5e94\u6536\u96c6\u7684\u8f68\u8ff9\u4e2d\u4ecd\u80fd\u4fdd\u6301\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u534a\u53c2\u6570\u6548\u7387\u3002", "result": "\u65b9\u5411\u7a33\u5b9a\u6027\u4fdd\u8bc1\u4e86\u5178\u578b\u68af\u5ea6\u7684\u53ef\u9884\u6d4b\u4e8c\u6b21\u53d8\u5dee\u7684\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u7ef4\u6e10\u8fd1\u6b63\u6001\u6027\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u6570\u636e\u8bbe\u7f6e\u7684\u5377\u79ef\u5b9a\u7406\u523b\u753b\u6548\u7387\uff0c\u7ed9\u51fa\u4e00\u6b65\u4f30\u8ba1\u91cf\u8fbe\u5230\u6548\u7387\u754c\u7684\u6761\u4ef6\u3002\u9a8c\u8bc1\u4e86LinUCB\u6ee1\u8db3\u65b9\u5411\u7a33\u5b9a\u6027\uff0c\u9996\u6b21\u4e3aLinUCB\u91c7\u6837\u4e0b\u7684\u6b63\u5219\u6807\u91cf\u76ee\u6807\u63d0\u4f9b\u4e86\u534a\u53c2\u6570\u6548\u7387\u4fdd\u8bc1\u3002", "conclusion": "\u65b9\u5411\u7a33\u5b9a\u6027\u4e3a\u81ea\u9002\u5e94\u6570\u636e\u6536\u96c6\u4e0b\u7684\u7edf\u8ba1\u63a8\u65ad\u63d0\u4f9b\u4e86\u66f4\u5f31\u7684\u6761\u4ef6\uff0c\u4f7f\u5f97\u5728bandit\u7b97\u6cd5\u7b49\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e2d\uff0c\u4f20\u7edf\u6709\u6548\u4f30\u8ba1\u91cf\u4ecd\u80fd\u4fdd\u6301\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u6548\u7387\uff0c\u6269\u5c55\u4e86\u81ea\u9002\u5e94\u63a8\u65ad\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.21876", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.21876", "abs": "https://arxiv.org/abs/2602.21876", "authors": ["Peer Schliephacke", "Hannah Schult", "Leon Mizera", "Judith W\u00fcrfel", "Gunter Grieser", "Axel Rahmel", "Carl-Ludwig Fischer-Fr\u00f6hlich", "Antje Jahn-Eimermacher"], "title": "Comparative Evaluation of Machine Learning Models for Predicting Donor Kidney Discard", "comment": null, "summary": "A kidney transplant can improve the life expectancy and quality of life of patients with end-stage renal failure. Even more patients could be helped with a transplant if the rate of kidneys that are discarded and not transplanted could be reduced. Machine learning (ML) can support decision-making in this context by early identification of donor organs at high risk of discard, for instance to enable timely interventions to improve organ utilization such as rescue allocation. Although various ML models have been applied, their results are difficult to compare due to heterogenous datasets and differences in feature engineering and evaluation strategies. This study aims to provide a systematic and reproducible comparison of ML models for donor kidney discard prediction. We trained five commonly used ML models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and Deep Learning along with an ensemble model on data from 4,080 deceased donors (death determined by neurologic criteria) in Germany. A unified benchmarking framework was implemented, including standardized feature engineering and selection, and Bayesian hyperparameter optimization. Model performance was assessed for discrimination (MCC, AUC, F1), calibration (Brier score), and explainability (SHAP). The ensemble achieved the highest discrimination performance (MCC=0.76, AUC=0.87, F1=0.90), while individual models such as Logistic Regression, Random Forest, and Deep Learning performed comparably and better than Decision Trees. Platt scaling improved calibration for tree-and neural network-based models. SHAP consistently identified donor age and renal markers as dominant predictors across models, reflecting clinical plausibility. This study demonstrates that consistent data preprocessing, feature selection, and evaluation can be more decisive for predictive success than the choice of the ML algorithm.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e94\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u4f9b\u4f53\u80be\u810f\u4e22\u5f03\u7387\uff0c\u53d1\u73b0\u7edf\u4e00\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u6bd4\u7b97\u6cd5\u9009\u62e9\u66f4\u91cd\u8981\uff0c\u96c6\u6210\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63d0\u9ad8\u7ec8\u672b\u671f\u80be\u8870\u7aed\u60a3\u8005\u7684\u80be\u810f\u79fb\u690d\u7387\uff0c\u51cf\u5c11\u4f9b\u4f53\u80be\u810f\u4e22\u5f03\u3002\u76ee\u524d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u5b58\u5728\u6570\u636e\u96c6\u5f02\u8d28\u6027\u3001\u7279\u5f81\u5de5\u7a0b\u548c\u8bc4\u4f30\u7b56\u7565\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7ed3\u679c\u96be\u4ee5\u6bd4\u8f83\u3002", "method": "\u5728\u5fb7\u56fd4,080\u4f8b\u8111\u6b7b\u4ea1\u4f9b\u4f53\u6570\u636e\u4e0a\uff0c\u8bad\u7ec3\u4e86\u903b\u8f91\u56de\u5f52\u3001\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u3001\u6df1\u5ea6\u5b66\u4e60\u4e94\u79cd\u5e38\u7528ML\u6a21\u578b\u53ca\u96c6\u6210\u6a21\u578b\u3002\u91c7\u7528\u7edf\u4e00\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u62ec\u6807\u51c6\u5316\u7279\u5f81\u5de5\u7a0b\u4e0e\u9009\u62e9\u3001\u8d1d\u53f6\u65af\u8d85\u53c2\u6570\u4f18\u5316\u3002", "result": "\u96c6\u6210\u6a21\u578b\u83b7\u5f97\u6700\u9ad8\u5224\u522b\u6027\u80fd\uff08MCC=0.76, AUC=0.87, F1=0.90\uff09\u3002\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548c\u6df1\u5ea6\u5b66\u4e60\u8868\u73b0\u76f8\u5f53\u4e14\u4f18\u4e8e\u51b3\u7b56\u6811\u3002Platt\u7f29\u653e\u6539\u5584\u4e86\u6811\u57fa\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u6821\u51c6\u3002SHAP\u5206\u6790\u4e00\u81f4\u663e\u793a\u4f9b\u4f53\u5e74\u9f84\u548c\u80be\u810f\u6807\u5fd7\u7269\u662f\u4e3b\u8981\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u4e00\u81f4\u7684\u6570\u636e\u9884\u5904\u7406\u3001\u7279\u5f81\u9009\u62e9\u548c\u8bc4\u4f30\u7b56\u7565\u5bf9\u9884\u6d4b\u6210\u529f\u7684\u5f71\u54cd\u6bd4ML\u7b97\u6cd5\u9009\u62e9\u66f4\u91cd\u8981\u3002\u7814\u7a76\u4e3a\u80be\u810f\u4e22\u5f03\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6bd4\u8f83\u6846\u67b6\u3002"}}
{"id": "2602.21383", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21383", "abs": "https://arxiv.org/abs/2602.21383", "authors": ["Mengbing Li", "Inbal Nahum-Shani", "Walter Dempsey"], "title": "Evaluating time-varying treatment effects in hybrid SMART-MRT designs", "comment": null, "summary": "Recently a new experimental approach, the hybrid experimental design (HED), was introduced to enable investigators to answer scientific questions about building behavioral interventions in which human-delivered and digital components are integrated and adapted on multiple timescales: slow (e.g., every few weeks) and fast (e.g., every few hours), respectively. An increasingly common HED involves the integration of the sequential, multiple assignment, randomized trial (SMART) with the micro-randomized trial (MRT), allowing investigators to answer scientific questions about potential synergistic effects of digital and human-delivered interventions. Approaches to formalize these questions in terms of causal estimands and associated data analytic methods are limited. In this paper, we formally define and assess these synergistic effects in hybrid SMART-MRTs on both proximal and distal outcomes. Practical utility is shown through the analysis of M-Bridge, a hybrid SMART-MRT aimed at reducing binge drinking among first-year college students.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6df7\u5408SMART-MRT\u8bbe\u8ba1\u4e2d\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u8bc4\u4f30\u6570\u5b57\u4e0e\u4eba\u5de5\u5e72\u9884\u534f\u540c\u6548\u5e94\u7684\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e\u51cf\u5c11\u5927\u5b66\u751f\u9157\u9152\u7684\u5b9e\u9645\u7814\u7a76\u3002", "motivation": "\u6df7\u5408\u5b9e\u9a8c\u8bbe\u8ba1(HED)\u6574\u5408\u4e86\u4eba\u5de5\u5e72\u9884\u548c\u6570\u5b57\u5e72\u9884\uff0c\u4f46\u7f3a\u4e4f\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u8fd9\u4e24\u79cd\u5e72\u9884\u5728\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u534f\u540c\u6548\u5e94\uff0c\u7279\u522b\u662f\u5728\u6df7\u5408SMART-MRT\u8bbe\u8ba1\u4e2d\u3002", "method": "\u5728\u6df7\u5408SMART-MRT\u8bbe\u8ba1\u4e2d\u6b63\u5f0f\u5b9a\u4e49\u548c\u8bc4\u4f30\u534f\u540c\u6548\u5e94\uff0c\u5305\u62ec\u8fd1\u7aef\u548c\u8fdc\u7aef\u7ed3\u679c\uff0c\u5e76\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8eM-Bridge\u7814\u7a76\uff08\u65e8\u5728\u51cf\u5c11\u5927\u4e00\u5b66\u751f\u9157\u9152\u7684\u6df7\u5408SMART-MRT\uff09\u3002", "result": "\u5f00\u53d1\u4e86\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u91cf\u5316\u6570\u5b57\u4e0e\u4eba\u5de5\u5e72\u9884\u7684\u534f\u540c\u6548\u5e94\uff0c\u5e76\u901a\u8fc7M-Bridge\u7814\u7a76\u7684\u5b9e\u9645\u5206\u6790\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u6df7\u5408SMART-MRT\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6570\u5b57\u4e0e\u4eba\u5de5\u5e72\u9884\u534f\u540c\u6548\u5e94\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u65b9\u6cd5\u5b66\u7a7a\u767d\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.21357", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21357", "abs": "https://arxiv.org/abs/2602.21357", "authors": ["Ali Siahkoohi", "Hyunwoo Oh"], "title": "Conditional neural control variates for variance reduction in Bayesian inverse problems", "comment": null, "summary": "Bayesian inference for inverse problems involves computing expectations under posterior distributions -- e.g., posterior means, variances, or predictive quantities -- typically via Monte Carlo (MC) estimation. When the quantity of interest varies significantly under the posterior, accurate estimates demand many samples -- a cost often prohibitive for partial differential equation-constrained problems. To address this challenge, we introduce conditional neural control variates, a modular method that learns amortized control variates from joint model-data samples to reduce the variance of MC estimators. To scale to high-dimensional problems, we leverage Stein's identity to design an architecture based on an ensemble of hierarchical coupling layers with tractable Jacobian trace computation. Training requires: (i) samples from the joint distribution of unknown parameters and observed data; and (ii) the posterior score function, which can be computed from physics-based likelihood evaluations, neural operator surrogates, or learned generative models such as conditional normalizing flows. Once trained, the control variates generalize across observations without retraining. We validate our approach on stylized and partial differential equation-constrained Darcy flow inverse problems, demonstrating substantial variance reduction, even when the analytical score is replaced by a learned surrogate.", "AI": {"tldr": "\u63d0\u51fa\u6761\u4ef6\u795e\u7ecf\u63a7\u5236\u53d8\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u53d8\u91cf\u6765\u964d\u4f4e\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4e2d\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u652f\u6301\u9ad8\u7ef4\u95ee\u9898\u5e76\u5229\u7528Stein\u6052\u7b49\u5f0f\u8bbe\u8ba1\u67b6\u6784\u3002", "motivation": "\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4e2d\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u9700\u8981\u5927\u91cf\u6837\u672c\u624d\u80fd\u83b7\u5f97\u51c6\u786e\u7ed3\u679c\uff0c\u5bf9\u4e8e\u504f\u5fae\u5206\u65b9\u7a0b\u7ea6\u675f\u7684\u95ee\u9898\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u964d\u4f4e\u65b9\u5dee\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6761\u4ef6\u795e\u7ecf\u63a7\u5236\u53d8\u91cf\u65b9\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8eStein\u6052\u7b49\u5f0f\u7684\u5c42\u6b21\u8026\u5408\u5c42\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u6a21\u578b-\u6570\u636e\u6837\u672c\u8bad\u7ec3\u644a\u9500\u63a7\u5236\u53d8\u91cf\uff0c\u652f\u6301\u540e\u9a8c\u8bc4\u5206\u51fd\u6570\u6765\u81ea\u7269\u7406\u6a21\u578b\u3001\u795e\u7ecf\u7b97\u5b50\u6216\u751f\u6210\u6a21\u578b\u3002", "result": "\u5728\u98ce\u683c\u5316\u548cDarcy\u6d41\u504f\u5fae\u5206\u65b9\u7a0b\u7ea6\u675f\u7684\u9006\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u5373\u4f7f\u4f7f\u7528\u5b66\u4e60\u66ff\u4ee3\u8bc4\u5206\u51fd\u6570\u4e5f\u80fd\u5b9e\u73b0\u663e\u8457\u7684\u65b9\u5dee\u964d\u4f4e\u3002", "conclusion": "\u6761\u4ef6\u795e\u7ecf\u63a7\u5236\u53d8\u91cf\u662f\u4e00\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u65b9\u5dee\uff0c\u8bad\u7ec3\u540e\u53ef\u5728\u4e0d\u540c\u89c2\u6d4b\u95f4\u6cdb\u5316\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u9006\u95ee\u9898\u3002"}}
{"id": "2602.21501", "categories": ["stat.ML", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.21501", "abs": "https://arxiv.org/abs/2602.21501", "authors": ["Lars van der Laan"], "title": "A Researcher's Guide to Empirical Risk Minimization", "comment": null, "summary": "This guide develops high-probability regret bounds for empirical risk minimization (ERM). The presentation is modular: we state broadly applicable guarantees under high-level conditions and give tools for verifying them for specific losses and function classes. We emphasize that many ERM rate derivations can be organized around a three-step recipe -- a basic inequality, a uniform local concentration bound, and a fixed-point argument -- which yields regret bounds in terms of a critical radius, defined via localized Rademacher complexity, under a mild Bernstein-type variance--risk condition. To make these bounds concrete, we upper bound the critical radius using local maximal inequalities and metric-entropy integrals, recovering familiar rates for VC-subgraph, Sobolev/H\u00f6lder, and bounded-variation classes.\n  We also review ERM with nuisance components -- including weighted ERM and Neyman-orthogonal losses -- as they arise in causal inference, missing data, and domain adaptation. Following the orthogonal learning framework, we highlight that these problems often admit regret-transfer bounds linking regret under an estimated loss to population regret under the target loss. These bounds typically decompose regret into (i) statistical error under the estimated (optimized) loss and (ii) approximation error due to nuisance estimation. Under sample splitting or cross-fitting, the first term can be controlled using standard fixed-loss ERM regret bounds, while the second term depends only on nuisance-estimation accuracy. We also treat the in-sample regime, where nuisances and the ERM are fit on the same data, deriving regret bounds and giving sufficient conditions for fast rates.", "AI": {"tldr": "\u672c\u6587\u4e3a\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316(ERM)\u5f00\u53d1\u4e86\u9ad8\u6982\u7387\u9057\u61be\u754c\uff0c\u63d0\u51fa\u4e86\u6a21\u5757\u5316\u5206\u6790\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u6b65\u9aa4\u65b9\u6cd5\uff1a\u57fa\u672c\u4e0d\u7b49\u5f0f\u3001\u5c40\u90e8\u4e00\u81f4\u96c6\u4e2d\u754c\u548c\u4e0d\u52a8\u70b9\u8bba\u8bc1\u3002\u540c\u65f6\u5904\u7406\u4e86\u5e26\u5e72\u6270\u5206\u91cf\u7684ERM\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u9057\u61be\u5206\u89e3\u4e3a\u7edf\u8ba1\u8bef\u5dee\u548c\u5e72\u6270\u4f30\u8ba1\u8bef\u5dee\u3002", "motivation": "\u4e3a\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316(ERM)\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u9ad8\u6982\u7387\u9057\u61be\u754c\u5206\u6790\u6846\u67b6\uff0c\u7edf\u4e00\u5904\u7406\u5404\u79cd\u635f\u5931\u51fd\u6570\u548c\u51fd\u6570\u7c7b\uff0c\u5e76\u6269\u5c55\u5230\u5305\u542b\u5e72\u6270\u5206\u91cf\u7684\u590d\u6742\u573a\u666f\uff08\u5982\u56e0\u679c\u63a8\u65ad\u3001\u7f3a\u5931\u6570\u636e\u548c\u9886\u57df\u9002\u5e94\uff09\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u57fa\u672c\u4e0d\u7b49\u5f0f\u3001\u5c40\u90e8\u4e00\u81f4\u96c6\u4e2d\u754c\u548c\u4e0d\u52a8\u70b9\u8bba\u8bc1\u7684\u4e09\u6b65\u9aa4\u6846\u67b6\uff1b2\uff09\u901a\u8fc7\u5c40\u90e8Rademacher\u590d\u6742\u5ea6\u5b9a\u4e49\u4e34\u754c\u534a\u5f84\uff1b3\uff09\u4f7f\u7528\u5c40\u90e8\u6781\u5927\u4e0d\u7b49\u5f0f\u548c\u5ea6\u91cf\u71b5\u79ef\u5206\u4e0a\u754c\u4e34\u754c\u534a\u5f84\uff1b4\uff09\u5bf9\u4e8e\u5e26\u5e72\u6270\u5206\u91cf\u7684ERM\uff0c\u91c7\u7528\u6b63\u4ea4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6837\u672c\u5206\u5272\u6216\u4ea4\u53c9\u62df\u5408\u5206\u79bb\u7edf\u8ba1\u8bef\u5dee\u548c\u5e72\u6270\u4f30\u8ba1\u8bef\u5dee\u3002", "result": "\u5efa\u7acb\u4e86\u7edf\u4e00\u7684ERM\u9057\u61be\u754c\u7406\u8bba\u6846\u67b6\uff0c\u6062\u590d\u4e86VC\u5b50\u56fe\u3001Sobolev/H\u00f6lder\u548c\u6709\u754c\u53d8\u5dee\u51fd\u6570\u7c7b\u7684\u7ecf\u5178\u6536\u655b\u7387\u3002\u5bf9\u4e8e\u5e26\u5e72\u6270\u5206\u91cf\u7684ERM\uff0c\u83b7\u5f97\u4e86\u9057\u61be\u8f6c\u79fb\u754c\uff0c\u5c06\u603b\u9057\u61be\u5206\u89e3\u4e3a\u7edf\u8ba1\u8bef\u5dee\u548c\u5e72\u6270\u4f30\u8ba1\u8bef\u5dee\u4e24\u90e8\u5206\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684ERM\u5206\u6790\u5de5\u5177\u7bb1\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u6846\u67b6\u7edf\u4e00\u4e86\u591a\u79cd\u573a\u666f\u4e0b\u7684\u9057\u61be\u754c\u63a8\u5bfc\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u6b63\u4ea4\u5b66\u4e60\u6846\u67b6\u5728\u5904\u7406\u5e26\u5e72\u6270\u5206\u91cf\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.21509", "categories": ["stat.ML", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.21509", "abs": "https://arxiv.org/abs/2602.21509", "authors": ["Jinwon Park", "Kunwoong Kim", "Jihu Lee", "Yongdai Kim"], "title": "Fair Model-based Clustering", "comment": "Accepted by AAAI 2026 (Main Track, Oral presentation)", "summary": "The goal of fair clustering is to find clusters such that the proportion of sensitive attributes (e.g., gender, race, etc.) in each cluster is similar to that of the entire dataset. Various fair clustering algorithms have been proposed that modify standard K-means clustering to satisfy a given fairness constraint. A critical limitation of several existing fair clustering algorithms is that the number of parameters to be learned is proportional to the sample size because the cluster assignment of each datum should be optimized simultaneously with the cluster center, and thus scaling up the algorithms is difficult. In this paper, we propose a new fair clustering algorithm based on a finite mixture model, called Fair Model-based Clustering (FMC). A main advantage of FMC is that the number of learnable parameters is independent of the sample size and thus can be scaled up easily. In particular, mini-batch learning is possible to obtain clusters that are approximately fair. Moreover, FMC can be applied to non-metric data (e.g., categorical data) as long as the likelihood is well-defined. Theoretical and empirical justifications for the superiority of the proposed algorithm are provided.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6709\u9650\u6df7\u5408\u6a21\u578b\u7684\u516c\u5e73\u805a\u7c7b\u7b97\u6cd5FMC\uff0c\u53c2\u6570\u6570\u91cf\u4e0e\u6837\u672c\u89c4\u6a21\u65e0\u5173\uff0c\u652f\u6301\u5c0f\u6279\u91cf\u5b66\u4e60\u548c\u975e\u5ea6\u91cf\u6570\u636e", "motivation": "\u73b0\u6709\u516c\u5e73\u805a\u7c7b\u7b97\u6cd5\u53c2\u6570\u6570\u91cf\u4e0e\u6837\u672c\u89c4\u6a21\u6210\u6b63\u6bd4\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u516c\u5e73\u805a\u7c7b\u65b9\u6cd5", "method": "\u57fa\u4e8e\u6709\u9650\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u5b9e\u73b0\u516c\u5e73\u805a\u7c7b\uff0c\u53c2\u6570\u6570\u91cf\u56fa\u5b9a\uff0c\u652f\u6301\u5c0f\u6279\u91cf\u5b66\u4e60\uff0c\u53ef\u5904\u7406\u975e\u5ea6\u91cf\u6570\u636e", "result": "FMC\u7b97\u6cd5\u53c2\u6570\u6570\u91cf\u4e0e\u6837\u672c\u89c4\u6a21\u65e0\u5173\uff0c\u53ef\u9ad8\u6548\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u652f\u6301\u8fd1\u4f3c\u516c\u5e73\u805a\u7c7b\uff0c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027", "conclusion": "FMC\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u516c\u5e73\u805a\u7c7b\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u53c2\u6570\u8fc7\u591a\u7684\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u548c\u975e\u5ea6\u91cf\u6570\u636e\u573a\u666f"}}
{"id": "2602.21436", "categories": ["stat.ML", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21436", "abs": "https://arxiv.org/abs/2602.21436", "authors": ["Arnab Maiti", "Claire Jie Zhang", "Kevin Jamieson", "Jamie Heather Morgenstern", "Ioannis Panageas", "Lillian J. Ratliff"], "title": "Efficient Uncoupled Learning Dynamics with $\\tilde{O}\\!\\left(T^{-1/4}\\right)$ Last-Iterate Convergence in Bilinear Saddle-Point Problems over Convex Sets under Bandit Feedback", "comment": "19 pages, Accepted at AISTATS 2026", "summary": "In this paper, we study last-iterate convergence of learning algorithms in bilinear saddle-point problems, a preferable notion of convergence that captures the day-to-day behavior of learning dynamics. We focus on the challenging setting where players select actions from compact convex sets and receive only bandit feedback. Our main contribution is the design of an uncoupled learning algorithm that guarantees last-iterate convergence to the Nash equilibrium with high probability. We establish a convergence rate of $\\tilde{O}(T^{-1/4})$ up to polynomial factors in problem parameters. Crucially, our proposed algorithm is computationally efficient, requiring only an efficient linear optimization oracle over the players' compact action sets. The algorithm is obtained by combining techniques from experimental design and the classic Follow-The-Regularized-Leader (FTRL) framework, with a carefully chosen regularizer function tailored to the geometry of the action set of each learner.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u53cc\u7ebf\u6027\u978d\u70b9\u95ee\u9898\u4e2d\u4fdd\u8bc1\u6700\u7ec8\u8fed\u4ee3\u6536\u655b\u7684\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u7d27\u81f4\u51f8\u96c6\u548c\u5f3a\u76d7\u53cd\u9988\u8bbe\u7f6e\uff0c\u6536\u655b\u7387\u4e3a$\\tilde{O}(T^{-1/4})$\uff0c\u4ec5\u9700\u7ebf\u6027\u4f18\u5316\u9884\u8a00\u673a\u3002", "motivation": "\u7814\u7a76\u53cc\u7ebf\u6027\u978d\u70b9\u95ee\u9898\u4e2d\u5b66\u4e60\u7b97\u6cd5\u7684\u6700\u7ec8\u8fed\u4ee3\u6536\u655b\u6027\uff0c\u8fd9\u79cd\u6536\u655b\u6982\u5ff5\u80fd\u66f4\u597d\u5730\u6355\u6349\u5b66\u4e60\u52a8\u6001\u7684\u65e5\u5e38\u884c\u4e3a\u3002\u5173\u6ce8\u5177\u6709\u6311\u6218\u6027\u7684\u8bbe\u7f6e\uff1a\u73a9\u5bb6\u4ece\u7d27\u81f4\u51f8\u96c6\u4e2d\u9009\u62e9\u52a8\u4f5c\u4e14\u4ec5\u63a5\u6536\u5f3a\u76d7\u53cd\u9988\u3002", "method": "\u7ed3\u5408\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u7ecf\u5178FTRL\u6846\u67b6\u6280\u672f\uff0c\u4e3a\u6bcf\u4e2a\u5b66\u4e60\u8005\u7684\u52a8\u4f5c\u96c6\u51e0\u4f55\u7279\u6027\u7cbe\u5fc3\u8bbe\u8ba1\u6b63\u5219\u5316\u51fd\u6570\uff0c\u6784\u5efa\u65e0\u9700\u8026\u5408\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u4ec5\u9700\u9ad8\u6548\u7684\u7ebf\u6027\u4f18\u5316\u9884\u8a00\u673a\u3002", "result": "\u8bbe\u8ba1\u51fa\u4fdd\u8bc1\u4ee5\u9ad8\u6982\u7387\u6700\u7ec8\u8fed\u4ee3\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u7684\u7b97\u6cd5\uff0c\u6536\u655b\u7387\u4e3a$\\tilde{O}(T^{-1/4})$\uff08\u5ffd\u7565\u95ee\u9898\u53c2\u6570\u7684\u591a\u9879\u5f0f\u56e0\u5b50\uff09\uff0c\u7b97\u6cd5\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u7d27\u81f4\u51f8\u96c6\u548c\u5f3a\u76d7\u53cd\u9988\u8bbe\u7f6e\u4e0b\u7684\u6700\u7ec8\u8fed\u4ee3\u6536\u655b\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bbe\u8ba1\u4e0eFTRL\u6846\u67b6\u7ed3\u5408\uff0c\u4e3a\u6bcf\u4e2a\u73a9\u5bb6\u91cf\u8eab\u5b9a\u5236\u6b63\u5219\u5316\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u6536\u655b\u3002"}}
{"id": "2602.21410", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21410", "abs": "https://arxiv.org/abs/2602.21410", "authors": ["Zhentian Zhang", "Tim Friede", "Tim Mathes"], "title": "Identifying the potential of sample overlap in evidence synthesis of observational studies", "comment": "36 pages,17 figures", "summary": "Sample overlap is a common issue in evidence synthesis in the field of medical research, particularly when integrating findings from observational studies utilizing existing databases such as registries. Due to the general inaccessibility of unique identifiers for each observation, addressing sample overlap has been a complex problem, potentially biasing evidence synthesis outcomes and undermining their credibility. We developed a method to construct indicators for the degree of sample overlap in evidence synthesis of studies based on existing data. Our method is rooted in set theory and is based on the coding of the ranges of several well selected sample characteristics, offers a practical solution by focusing on making inference based on sample characteristics rather than on individual participant data. Useful information, such as the overlap-free sample set with the largest sample size in an evidence synthesis, can be derived from this method. We applied our model to several real-world evidence syntheses, demonstrating its effectiveness and flexibility. Our findings highlight the growing importance of addressing sample overlap in evidence synthesis, especially with the increasing relevance of secondary use of data, an area currently under-explored in research.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u5408\u8bba\u548c\u6837\u672c\u7279\u5f81\u7f16\u7801\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u73b0\u6709\u6570\u636e\u7684\u7814\u7a76\u5728\u8bc1\u636e\u5408\u6210\u4e2d\u7684\u6837\u672c\u91cd\u53e0\u7a0b\u5ea6\uff0c\u65e0\u9700\u4e2a\u4f53\u53c2\u4e0e\u8005\u6570\u636e\u3002", "motivation": "\u533b\u5b66\u7814\u7a76\u4e2d\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u6ce8\u518c\u8868\u7b49\u73b0\u6709\u6570\u636e\u5e93\u7684\u89c2\u5bdf\u6027\u7814\u7a76\u4e2d\uff0c\u6837\u672c\u91cd\u53e0\u662f\u8bc1\u636e\u5408\u6210\u7684\u5e38\u89c1\u95ee\u9898\u3002\u7531\u4e8e\u901a\u5e38\u65e0\u6cd5\u83b7\u53d6\u6bcf\u4e2a\u89c2\u5bdf\u7684\u552f\u4e00\u6807\u8bc6\u7b26\uff0c\u89e3\u51b3\u6837\u672c\u91cd\u53e0\u95ee\u9898\u4e00\u76f4\u5f88\u590d\u6742\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bc1\u636e\u5408\u6210\u7ed3\u679c\u504f\u5dee\u5e76\u524a\u5f31\u5176\u53ef\u4fe1\u5ea6\u3002", "method": "\u57fa\u4e8e\u96c6\u5408\u8bba\u5f00\u53d1\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u7801\u51e0\u4e2a\u7cbe\u5fc3\u9009\u62e9\u7684\u6837\u672c\u7279\u5f81\u8303\u56f4\u6765\u6784\u5efa\u6837\u672c\u91cd\u53e0\u7a0b\u5ea6\u7684\u6307\u6807\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6837\u672c\u7279\u5f81\u8fdb\u884c\u63a8\u65ad\uff0c\u800c\u975e\u4e2a\u4f53\u53c2\u4e0e\u8005\u6570\u636e\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63a8\u5bfc\u51fa\u6709\u7528\u4fe1\u606f\uff0c\u5982\u8bc1\u636e\u5408\u6210\u4e2d\u5177\u6709\u6700\u5927\u6837\u672c\u91cf\u7684\u65e0\u91cd\u53e0\u6837\u672c\u96c6\u3002\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u8bc1\u636e\u5408\u6210\u4e2d\u5e94\u7528\u4e86\u8be5\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u8bc1\u636e\u5408\u6210\u4e2d\u89e3\u51b3\u6837\u672c\u91cd\u53e0\u95ee\u9898\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4e8c\u6b21\u4f7f\u7528\u8d8a\u6765\u8d8a\u76f8\u5173\u7684\u80cc\u666f\u4e0b\uff0c\u8fd9\u662f\u4e00\u4e2a\u76ee\u524d\u7814\u7a76\u4e0d\u8db3\u7684\u9886\u57df\u3002"}}
{"id": "2602.21446", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21446", "abs": "https://arxiv.org/abs/2602.21446", "authors": ["Ziyi Liang", "Hamed Poursiami", "Zhishun Yang", "Keiland Cooper", "Akhilesh Jaiswal", "Maryam Parsa", "Norbert Fortin", "Babak Shahbaba"], "title": "ConformalHDC: Uncertainty-Aware Hyperdimensional Computing with Application to Neural Decoding", "comment": null, "summary": "Hyperdimensional Computing (HDC) offers a computationally efficient paradigm for neuromorphic learning. Yet, it lacks rigorous uncertainty quantification, leading to open decision boundaries and, consequently, vulnerability to outliers, adversarial perturbations, and out-of-distribution inputs. To address these limitations, we introduce ConformalHDC, a unified framework that combines the statistical guarantees of conformal prediction with the computational efficiency of HDC. For this framework, we propose two complementary variations. First, the set-valued formulation provides finite-sample, distribution-free coverage guarantees. Using carefully designed conformity scores, it forms enclosed decision boundaries that improve robustness to non-conforming inputs. Second, the point-valued formulation leverages the same conformity scores to produce a single prediction when desired, potentially improving accuracy over traditional HDC by accounting for class interactions. We demonstrate the broad applicability of the proposed framework through evaluations on multiple real-world datasets. In particular, we apply our method to the challenging problem of decoding non-spatial stimulus information from the spiking activity of hippocampal neurons recorded as subjects performed a sequence memory task. Our results show that ConformalHDC not only accurately decodes the stimulus information represented in the neural activity data, but also provides rigorous uncertainty estimates and correctly abstains when presented with data from other behavioral states. Overall, these capabilities position the framework as a reliable, uncertainty-aware foundation for neuromorphic computing.", "AI": {"tldr": "ConformalHDC\uff1a\u5c06\u4fdd\u5f62\u9884\u6d4b\u7684\u7edf\u8ba1\u4fdd\u8bc1\u4e0e\u8d85\u7ef4\u8ba1\u7b97\u7684\u9ad8\u6548\u6027\u76f8\u7ed3\u5408\uff0c\u4e3a\u795e\u7ecf\u5f62\u6001\u5b66\u4e60\u63d0\u4f9b\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u8d85\u7ef4\u8ba1\u7b97\u867d\u7136\u8ba1\u7b97\u9ad8\u6548\uff0c\u4f46\u7f3a\u4e4f\u4e25\u683c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5bfc\u81f4\u51b3\u7b56\u8fb9\u754c\u5f00\u653e\uff0c\u5bb9\u6613\u53d7\u5230\u5f02\u5e38\u503c\u3001\u5bf9\u6297\u6027\u6270\u52a8\u548c\u5206\u5e03\u5916\u8f93\u5165\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faConformalHDC\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u4e92\u8865\u53d8\u4f53\uff1a1) \u96c6\u5408\u503c\u516c\u5f0f\u5316\u63d0\u4f9b\u6709\u9650\u6837\u672c\u3001\u5206\u5e03\u65e0\u5173\u7684\u8986\u76d6\u4fdd\u8bc1\uff0c\u4f7f\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7b26\u5408\u5ea6\u5206\u6570\u5f62\u6210\u5c01\u95ed\u51b3\u7b56\u8fb9\u754c\uff1b2) \u70b9\u503c\u516c\u5f0f\u5316\u5229\u7528\u76f8\u540c\u7b26\u5408\u5ea6\u5206\u6570\u5728\u9700\u8981\u65f6\u4ea7\u751f\u5355\u4e00\u9884\u6d4b\uff0c\u901a\u8fc7\u8003\u8651\u7c7b\u522b\u4ea4\u4e92\u53ef\u80fd\u63d0\u9ad8\u4f20\u7edfHDC\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u4ece\u6d77\u9a6c\u795e\u7ecf\u5143\u5c16\u5cf0\u6d3b\u52a8\u4e2d\u89e3\u7801\u975e\u7a7a\u95f4\u523a\u6fc0\u4fe1\u606f\u7684\u6311\u6218\u6027\u95ee\u9898\u4e0a\uff0c\u4e0d\u4ec5\u51c6\u786e\u89e3\u7801\u795e\u7ecf\u6d3b\u52a8\u6570\u636e\u4e2d\u7684\u523a\u6fc0\u4fe1\u606f\uff0c\u8fd8\u63d0\u4f9b\u4e25\u683c\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5e76\u5728\u9762\u5bf9\u5176\u4ed6\u884c\u4e3a\u72b6\u6001\u6570\u636e\u65f6\u6b63\u786e\u5f03\u6743\u3002", "conclusion": "ConformalHDC\u4e3a\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9760\u3001\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u57fa\u7840\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7edf\u8ba1\u4fdd\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.21846", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21846", "abs": "https://arxiv.org/abs/2602.21846", "authors": ["Masha Naslidnyk"], "title": "Scalable Kernel-Based Distances for Statistical Inference and Integration", "comment": "PhD thesis", "summary": "Representing, comparing, and measuring the distance between probability distributions is a key task in computational statistics and machine learning. The choice of representation and the associated distance determine properties of the methods in which they are used: for example, certain distances can allow one to encode robustness or smoothness of the problem. Kernel methods offer flexible and rich Hilbert space representations of distributions that allow the modeller to enforce properties through the choice of kernel, and estimate associated distances at efficient nonparametric rates. In particular, the maximum mean discrepancy (MMD), a kernel-based distance constructed by comparing Hilbert space mean functions, has received significant attention due to its computational tractability and is favoured by practitioners.\n  In this thesis, we conduct a thorough study of kernel-based distances with a focus on efficient computation, with core contributions in Chapters 3 to 6. Part I of the thesis is focused on the MMD, specifically on improved MMD estimation. In Chapter 3 we propose a theoretically sound, improved estimator for MMD in simulation-based inference. Then, in Chapter 4, we propose an MMD-based estimator for conditional expectations, a ubiquitous task in statistical computation. Closing Part I, in Chapter 5 we study the problem of calibration when MMD is applied to the task of integration.\n  In Part II, motivated by the recent developments in kernel embeddings beyond the mean, we introduce a family of novel kernel-based discrepancies: kernel quantile discrepancies. These address some of the pitfalls of MMD, and are shown through both theoretical results and an empirical study to offer a competitive alternative to MMD and its fast approximations. We conclude with a discussion on broader lessons and future work emerging from the thesis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u57fa\u4e8e\u6838\u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u91cd\u70b9\u6539\u8fdbMMD\u4f30\u8ba1\u5e76\u5f15\u5165\u65b0\u7684\u6838\u5206\u4f4d\u6570\u5dee\u5f02\u65b9\u6cd5", "motivation": "\u6982\u7387\u5206\u5e03\u7684\u8868\u5f81\u3001\u6bd4\u8f83\u548c\u8ddd\u79bb\u5ea6\u91cf\u662f\u8ba1\u7b97\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u7684\u5173\u952e\u4efb\u52a1\u3002\u6838\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e30\u5bcc\u7684\u5206\u5e03\u8868\u793a\uff0c\u7279\u522b\u662f\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u56e0\u5176\u8ba1\u7b97\u53ef\u5904\u7406\u6027\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u9700\u8981\u6539\u8fdb\u4f30\u8ba1\u65b9\u6cd5\u548c\u89e3\u51b3\u5176\u5c40\u9650\u6027", "method": "\u8bba\u6587\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7b2c\u4e00\u90e8\u5206\u805a\u7126MMD\u6539\u8fdb\u4f30\u8ba1\uff0c\u5305\u62ec\u6a21\u62df\u63a8\u7406\u4e2d\u7684MMD\u4f30\u8ba1\u5668\u3001\u6761\u4ef6\u671f\u671b\u7684MMD\u4f30\u8ba1\u5668\u4ee5\u53ca\u79ef\u5206\u4efb\u52a1\u4e2d\u7684\u6821\u51c6\u95ee\u9898\uff1b\u7b2c\u4e8c\u90e8\u5206\u5f15\u5165\u65b0\u7684\u6838\u5206\u4f4d\u6570\u5dee\u5f02\u65b9\u6cd5\uff0c\u89e3\u51b3MMD\u7684\u7f3a\u9677", "result": "\u63d0\u51fa\u4e86\u7406\u8bba\u4e0a\u53ef\u9760\u7684\u6539\u8fdbMMD\u4f30\u8ba1\u5668\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8eMMD\u7684\u6761\u4ef6\u671f\u671b\u4f30\u8ba1\u5668\uff0c\u7814\u7a76\u4e86MMD\u5728\u79ef\u5206\u4efb\u52a1\u4e2d\u7684\u6821\u51c6\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u6838\u5206\u4f4d\u6570\u5dee\u5f02\u4f5c\u4e3aMMD\u7684\u7ade\u4e89\u6027\u66ff\u4ee3\u65b9\u6848", "conclusion": "\u6838\u57fa\u8ddd\u79bb\u5ea6\u91cf\u5728\u5206\u5e03\u6bd4\u8f83\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u6539\u8fdb\u7684MMD\u4f30\u8ba1\u548c\u65b0\u7684\u6838\u5206\u4f4d\u6570\u5dee\u5f02\u65b9\u6cd5\u4e3a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u7ee7\u7eed\u63a2\u7d22\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6269\u5c55\u548c\u5e94\u7528"}}
{"id": "2602.21490", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21490", "abs": "https://arxiv.org/abs/2602.21490", "authors": ["Dingzi Guo", "Diqing Li", "Jingyi Wang", "Wen-Xin Zhou"], "title": "Connection Probabilities Estimation in Multi-layer Networks via Iterative Neighborhood Smoothing", "comment": null, "summary": "Understanding the structural mechanisms of multi-layer networks is essential for analyzing complex systems characterized by multiple interacting layers. This work studies the problem of estimating connection probabilities in multi-layer networks and introduces a new Multi-layer Iterative Connection Probability Estimation (MICE) method. The proposed approach employs an iterative framework that jointly refines inter-layer and intra-layer similarity sets by dynamically updating distance metrics derived from current probability estimates. By leveraging both layer-level and node-level neighborhood information, MICE improves estimation accuracy while preserving computational efficiency. Theoretical analysis establishes the consistency of the estimator and shows that, under mild regularity conditions, the proposed method achieves an optimal convergence rate comparable to that of an oracle estimator. Extensive simulation studies across diverse graphon structures demonstrate the superior performance of MICE relative to existing methods. Empirical evaluations using brain network data from patients with Attention-Deficit/Hyperactivity Disorder (ADHD) and global food and agricultural trade network data further illustrate the robustness and effectiveness of the method in link prediction tasks. Overall, this work provides a theoretically grounded and practically scalable framework for probabilistic modeling and inference in multi-layer network systems.", "AI": {"tldr": "\u63d0\u51faMICE\u65b9\u6cd5\u7528\u4e8e\u591a\u5c42\u7f51\u7edc\u8fde\u63a5\u6982\u7387\u4f30\u8ba1\uff0c\u901a\u8fc7\u8fed\u4ee3\u6846\u67b6\u8054\u5408\u4f18\u5316\u5c42\u95f4\u548c\u5c42\u5185\u76f8\u4f3c\u6027\uff0c\u7406\u8bba\u8bc1\u660e\u5177\u6709\u4e00\u81f4\u6027\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u591a\u5c42\u7f51\u7edc\u7684\u7ed3\u6784\u673a\u5236\u5206\u6790\u5bf9\u7406\u89e3\u590d\u6742\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u4f30\u8ba1\u591a\u5c42\u7f51\u7edc\u8fde\u63a5\u6982\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u51c6\u786e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMICE\u65b9\u6cd5\uff1a\u91c7\u7528\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u57fa\u4e8e\u5f53\u524d\u6982\u7387\u4f30\u8ba1\u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u8054\u5408\u4f18\u5316\u5c42\u95f4\u548c\u5c42\u5185\u76f8\u4f3c\u6027\u96c6\u5408\uff0c\u5229\u7528\u5c42\u7ea7\u548c\u8282\u70b9\u7ea7\u90bb\u57df\u4fe1\u606f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4f30\u8ba1\u91cf\u5177\u6709\u4e00\u81f4\u6027\uff0c\u5728\u6e29\u548c\u6b63\u5219\u6761\u4ef6\u4e0b\u8fbe\u5230\u4e0eoracle\u4f30\u8ba1\u91cf\u76f8\u5f53\u7684\u6700\u4f18\u6536\u655b\u7387\u3002\u6a21\u62df\u548c\u5b9e\u8bc1\u7814\u7a76\uff08ADHD\u8111\u7f51\u7edc\u3001\u5168\u7403\u98df\u54c1\u8d38\u6613\u7f51\u7edc\uff09\u663e\u793aMICE\u5728\u8fde\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MICE\u4e3a\u591a\u5c42\u7f51\u7edc\u7cfb\u7edf\u7684\u6982\u7387\u5efa\u6a21\u548c\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u53ef\u9760\u3001\u5b9e\u9645\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5728\u590d\u6742\u7f51\u7edc\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.22062", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22062", "abs": "https://arxiv.org/abs/2602.22062", "authors": ["Jiawei Li", "Nguyen Nguyen", "Meng Lai", "Ioannis Ch. Paschalidis", "Jonathan H. Huggins"], "title": "Robust Model Selection for Discovery of Latent Mechanistic Processes", "comment": null, "summary": "When learning interpretable latent structures using model-based approaches, even small deviations from modeling assumptions can lead to inferential results that are not mechanistically meaningful. In this work, we consider latent structures that consist of $K_o$ mechanistic processes, where $K_o$ is unknown. When the model is misspecified, likelihood-based model selection methods can substantially overestimate $K_o$ while more robust nonparametric methods can be overly conservative. Hence, there is a need for approaches that combine the sensitivity of likelihood-based methods with the robustness of nonparametric ones. We formalize this objective in terms of a robust model selection consistency property, which is based on a component-level discrepancy measure that captures the mechanistic structure of the model. We then propose the accumulated cutoff discrepancy criterion (ACDC), which leverages plug-in estimates of component-level discrepancies. To apply ACDC, we develop mechanistically meaningful component-level discrepancies for a general class of latent variable models that includes unsupervised and supervised variants of probabilistic matrix factorization and mixture modeling. We show that ACDC is robustly consistent when applied to unsupervised matrix factorization and mixture models. Numerical results demonstrate that in practice our approach reliably identifies a mechanistically meaningful number of latent processes in numerous illustrative applications, outperforming existing methods.", "AI": {"tldr": "\u63d0\u51faACDC\u51c6\u5219\uff0c\u7ed3\u5408\u4f3c\u7136\u65b9\u6cd5\u7684\u654f\u611f\u6027\u548c\u975e\u53c2\u6570\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u7528\u4e8e\u5728\u6a21\u578b\u8bef\u8bbe\u65f6\u7a33\u5065\u5730\u9009\u62e9\u6709\u673a\u5236\u610f\u4e49\u7684\u6f5c\u5728\u8fc7\u7a0b\u6570\u91cf\u3002", "motivation": "\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u5b66\u4e60\u53ef\u89e3\u91ca\u6f5c\u5728\u7ed3\u6784\u65f6\uff0c\u5373\u4f7f\u4e0e\u5efa\u6a21\u5047\u8bbe\u6709\u5fae\u5c0f\u504f\u5dee\uff0c\u4e5f\u4f1a\u5bfc\u81f4\u63a8\u65ad\u7ed3\u679c\u7f3a\u4e4f\u673a\u5236\u610f\u4e49\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u77db\u76fe\uff1a\u4f3c\u7136\u65b9\u6cd5\u4f1a\u9ad8\u4f30\u6f5c\u5728\u8fc7\u7a0b\u6570\u91cf\uff0c\u800c\u975e\u53c2\u6570\u65b9\u6cd5\u53c8\u8fc7\u4e8e\u4fdd\u5b88\u3002", "method": "\u63d0\u51fa\u7d2f\u79ef\u622a\u65ad\u5dee\u5f02\u51c6\u5219(ACDC)\uff0c\u5229\u7528\u7ec4\u4ef6\u7ea7\u5dee\u5f02\u7684\u63d2\u4ef6\u4f30\u8ba1\uff0c\u57fa\u4e8e\u6355\u83b7\u6a21\u578b\u673a\u5236\u7ed3\u6784\u7684\u7ec4\u4ef6\u7ea7\u5dee\u5f02\u5ea6\u91cf\u3002\u4e3a\u5305\u62ec\u6982\u7387\u77e9\u9635\u5206\u89e3\u548c\u6df7\u5408\u6a21\u578b\u5728\u5185\u7684\u6f5c\u53d8\u91cf\u6a21\u578b\u5f00\u53d1\u4e86\u6709\u673a\u5236\u610f\u4e49\u7684\u7ec4\u4ef6\u7ea7\u5dee\u5f02\u5ea6\u91cf\u3002", "result": "\u7406\u8bba\u8bc1\u660eACDC\u5728\u5e94\u7528\u4e8e\u65e0\u76d1\u7763\u77e9\u9635\u5206\u89e3\u548c\u6df7\u5408\u6a21\u578b\u65f6\u5177\u6709\u9c81\u68d2\u4e00\u81f4\u6027\u3002\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5e94\u7528\u4e2d\u80fd\u53ef\u9760\u8bc6\u522b\u6709\u673a\u5236\u610f\u4e49\u7684\u6f5c\u5728\u8fc7\u7a0b\u6570\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ACDC\u6210\u529f\u7ed3\u5408\u4e86\u4f3c\u7136\u65b9\u6cd5\u7684\u654f\u611f\u6027\u548c\u975e\u53c2\u6570\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u5728\u6a21\u578b\u8bef\u8bbe\u60c5\u51b5\u4e0b\u7a33\u5065\u5730\u9009\u62e9\u6709\u673a\u5236\u610f\u4e49\u7684\u6f5c\u5728\u8fc7\u7a0b\u6570\u91cf\uff0c\u4e3a\u6f5c\u53d8\u91cf\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21579", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21579", "abs": "https://arxiv.org/abs/2602.21579", "authors": ["Shivam", "Bhargab Chattopadhyay", "Nil Kamal Hazra"], "title": "Asymptotically Optimal Sequential Confidence Interval for the Gini Index Under Complex Household Survey Design with Sub-Stratification", "comment": null, "summary": "We examine the optimality properties of the Gini index estimator under complex survey design involving stratification, clustering, and sub-stratification. While Darku et al. (Econometrics, 26, 2020) considered only stratification and clustering and did not provide theoretical guarantees, this study addresses these limitations by proposing two procedures - a purely sequential method and a two-stage method. Under suitable regularity conditions, we establish uniform continuity in probability for the proposed estimator, thereby contributing to the development of random central limit theorems under sequential sampling frameworks. Furthermore, we show that the resulting procedures satisfy both asymptotic first-order efficiency and asymptotic consistency. Simulation results demonstrate that the proposed procedures achieve the desired optimality properties across diverse settings. The practical utility of the methodology is further illustrated through an empirical application using data collected by the National Sample Survey agency of India", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u590d\u6742\u62bd\u6837\u8bbe\u8ba1\u4e0b\u57fa\u5c3c\u7cfb\u6570\u4f30\u8ba1\u91cf\u7684\u6700\u4f18\u6027\uff0c\u63d0\u51fa\u4e86\u7eaf\u5e8f\u8d2f\u548c\u4e24\u9636\u6bb5\u4e24\u79cd\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u4f30\u8ba1\u91cf\u7684\u5747\u5300\u8fde\u7eed\u6027\u548c\u6e10\u8fd1\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u548c\u5370\u5ea6\u56fd\u5bb6\u62bd\u6837\u8c03\u67e5\u6570\u636e\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "Darku\u7b49\u4eba(2020)\u4ec5\u8003\u8651\u4e86\u5206\u5c42\u548c\u6574\u7fa4\u62bd\u6837\uff0c\u4e14\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\uff0c\u5728\u5305\u542b\u5206\u5c42\u3001\u6574\u7fa4\u548c\u5b50\u5206\u5c42\u7684\u590d\u6742\u62bd\u6837\u8bbe\u8ba1\u4e0b\uff0c\u5efa\u7acb\u57fa\u5c3c\u7cfb\u6570\u4f30\u8ba1\u91cf\u7684\u6700\u4f18\u6027\u7406\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u5e8f\u8d2f\u62bd\u6837\u65b9\u6cd5\uff1a\u7eaf\u5e8f\u8d2f\u65b9\u6cd5\u548c\u4e24\u9636\u6bb5\u65b9\u6cd5\u3002\u5728\u9002\u5f53\u7684\u6b63\u5219\u6761\u4ef6\u4e0b\uff0c\u5efa\u7acb\u4e86\u4f30\u8ba1\u91cf\u7684\u5747\u5300\u8fde\u7eed\u6027\u6982\u7387\u6027\u8d28\uff0c\u4e3a\u5e8f\u8d2f\u62bd\u6837\u6846\u67b6\u4e0b\u7684\u968f\u673a\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u53d1\u5c55\u505a\u51fa\u8d21\u732e\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u6ee1\u8db3\u6e10\u8fd1\u4e00\u9636\u6548\u7387\u548c\u6e10\u8fd1\u4e00\u81f4\u6027\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u90fd\u80fd\u8fbe\u5230\u671f\u671b\u7684\u6700\u4f18\u6027\u3002\u901a\u8fc7\u5370\u5ea6\u56fd\u5bb6\u62bd\u6837\u8c03\u67e5\u6570\u636e\u7684\u5b9e\u8bc1\u5e94\u7528\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u590d\u6742\u62bd\u6837\u8bbe\u8ba1\u4e0b\u57fa\u5c3c\u7cfb\u6570\u4f30\u8ba1\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u7684\u5e8f\u8d2f\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u793e\u4f1a\u7ecf\u6d4e\u4e0d\u5e73\u7b49\u6d4b\u91cf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u7edf\u8ba1\u5de5\u5177\u3002"}}
{"id": "2602.21479", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21479", "abs": "https://arxiv.org/abs/2602.21479", "authors": ["Beepul Bharti", "Ambar Pal", "Jeremias Sulam"], "title": "Global Sequential Testing for Multi-Stream Auditing", "comment": null, "summary": "Across many risk-sensitive areas, it is critical to continuously audit the performance of machine learning systems and detect any unusual behavior quickly. This can be modeled as a sequential hypothesis testing problem with $k$ incoming streams of data and a global null hypothesis that asserts that the system is working as expected across all $k$ streams. The standard global test employs a Bonferroni correction and has an expected stopping time bound of $O\\left(\\ln\\frac{k}\u03b1\\right)$ when $k$ is large and the significance level of the test, $\u03b1$, is small. In this work, we construct new sequential tests by using ideas of merging test martingales with different trade-offs in expected stopping times under different, sparse or dense alternative hypotheses. We further derive a new, balanced test that achieves an improved expected stopping time bound that matches Bonferroni's in the sparse setting but that naturally results in $O\\left(\\frac{1}{k}\\ln\\frac{1}\u03b1\\right)$ under a dense alternative. We empirically demonstrate the effectiveness of our proposed tests on synthetic and real-world data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u5e8f\u5217\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u5e76\u4e0d\u540c\u6743\u8861\u7684\u6d4b\u8bd5\u9785\uff0c\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5907\u62e9\u5047\u8bbe\u4e0b\u6539\u8fdb\u671f\u671b\u505c\u6b62\u65f6\u95f4\uff0c\u76f8\u6bd4\u6807\u51c6Bonferroni\u65b9\u6cd5\u6709\u66f4\u597d\u6027\u80fd\u3002", "motivation": "\u5728\u98ce\u9669\u654f\u611f\u9886\u57df\uff0c\u9700\u8981\u6301\u7eed\u5ba1\u8ba1\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6027\u80fd\u5e76\u5feb\u901f\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\u3002\u8fd9\u53ef\u4ee5\u5efa\u6a21\u4e3a\u5177\u6709k\u4e2a\u6570\u636e\u6d41\u7684\u5e8f\u5217\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\uff0c\u5168\u5c40\u96f6\u5047\u8bbe\u65ad\u8a00\u7cfb\u7edf\u5728\u6240\u6709\u6d41\u4e0a\u6b63\u5e38\u5de5\u4f5c\u3002\u6807\u51c6\u5168\u5c40\u6d4b\u8bd5\u4f7f\u7528Bonferroni\u6821\u6b63\uff0c\u5728\u5927k\u548c\u5c0f\u663e\u8457\u6027\u6c34\u5e73\u03b1\u65f6\u671f\u671b\u505c\u6b62\u65f6\u95f4\u4e3aO(ln(k/\u03b1))\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u5408\u5e76\u5177\u6709\u4e0d\u540c\u6743\u8861\u7684\u6d4b\u8bd5\u9785\u6765\u6784\u5efa\u65b0\u7684\u5e8f\u5217\u6d4b\u8bd5\u3002\u63d0\u51fa\u5e73\u8861\u6d4b\u8bd5\uff0c\u5728\u7a00\u758f\u5907\u62e9\u5047\u8bbe\u4e0b\u5339\u914dBonferroni\u6027\u80fd\uff0c\u5728\u5bc6\u96c6\u5907\u62e9\u5047\u8bbe\u4e0b\u5b9e\u73b0O((1/k)ln(1/\u03b1))\u7684\u671f\u671b\u505c\u6b62\u65f6\u95f4\u3002", "result": "\u65b0\u6d4b\u8bd5\u5728\u7a00\u758f\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u4e0eBonferroni\u76f8\u540c\u7684\u671f\u671b\u505c\u6b62\u65f6\u95f4\u754c\u9650\uff0c\u4f46\u5728\u5bc6\u96c6\u5907\u62e9\u5047\u8bbe\u4e0b\u663e\u8457\u6539\u8fdb\u4e3aO((1/k)ln(1/\u03b1))\u3002\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u5e8f\u5217\u6d4b\u8bd5\u65b9\u6cd5\u901a\u8fc7\u5408\u5e76\u4e0d\u540c\u6743\u8861\u7684\u6d4b\u8bd5\u9785\uff0c\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5907\u62e9\u5047\u8bbe\u4e0b\u6539\u8fdb\u4e86\u671f\u671b\u505c\u6b62\u65f6\u95f4\u6027\u80fd\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6027\u80fd\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u5de5\u5177\u3002"}}
{"id": "2602.21663", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21663", "abs": "https://arxiv.org/abs/2602.21663", "authors": ["Steffen Gr\u00f8nneberg", "Gudmund Hermansen", "Nils Lid Hjort"], "title": "Estimation, inference and model selection for jump regression models", "comment": "33 pages, 3 figures; Statistical Research Report, Department of Mathematics, University of Oslo, from June 2014, and arXiv'd February 2026. This paper constituted a part of the doctoral dissertations for respectively Gudmund Hermansen and Steffen Gr\u00f8nneberg. An extended and polished version will be written up for journal publication", "summary": "We consider regression models with data of the type $y_i=m(x_i)+\\varepsilon_i$, where the $m(x)$ curve is taken locally constant, with unknown levels and jump points. We investigate the large-sample properties of the minimum least squares estimators, finding in particular that jump point parameters and level parameters are estimated with respectively $n$-rate precision and $\\sqrt{n}$-rate precision, where $n$ is sample size. Bayes solutions are investigated as well and found to be superior. We then construct jump information criteria, respectively AJIC and BJIC, for selecting the right number of jump points from data. This is done by following the line of arguments that lead to the Akaike and Bayesian information criteria AIC and BIC, but which here lead to different formulae due to the different type of large-sample approximations involved.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5177\u6709\u8df3\u8dc3\u70b9\u7684\u56de\u5f52\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u548c\u8d1d\u53f6\u65af\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u7528\u4e8e\u9009\u62e9\u8df3\u8dc3\u70b9\u6570\u91cf\u7684\u4fe1\u606f\u51c6\u5219AJIC\u548cBJIC\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u672a\u77e5\u8df3\u8dc3\u70b9\u548c\u6c34\u5e73\u7684\u5206\u6bb5\u5e38\u6570\u56de\u5f52\u6a21\u578b\uff0c\u8fd9\u7c7b\u6a21\u578b\u5728\u4fe1\u53f7\u5904\u7406\u3001\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u6709\u6548\u7684\u53c2\u6570\u4f30\u8ba1\u548c\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u548c\u8d1d\u53f6\u65af\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5206\u6790\u5927\u6837\u672c\u6027\u8d28\uff0c\u53d1\u73b0\u8df3\u8dc3\u70b9\u53c2\u6570\u548c\u6c34\u5e73\u53c2\u6570\u5206\u522b\u5177\u6709n-\u901f\u7387\u548c\u221an-\u901f\u7387\u7cbe\u5ea6\u3002\u57fa\u4e8eAIC\u548cBIC\u7684\u601d\u8def\uff0c\u6784\u5efa\u4e86\u9002\u7528\u4e8e\u8df3\u8dc3\u70b9\u6a21\u578b\u7684AJIC\u548cBJIC\u4fe1\u606f\u51c6\u5219\u3002", "result": "\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u4e2d\uff0c\u8df3\u8dc3\u70b9\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u4e3an-\u901f\u7387\uff0c\u6c34\u5e73\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u4e3a\u221an-\u901f\u7387\u3002\u8d1d\u53f6\u65af\u4f30\u8ba1\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002\u6784\u5efa\u7684AJIC\u548cBJIC\u4fe1\u606f\u51c6\u5219\u80fd\u591f\u6709\u6548\u9009\u62e9\u6b63\u786e\u7684\u8df3\u8dc3\u70b9\u6570\u91cf\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5177\u6709\u8df3\u8dc3\u70b9\u7684\u56de\u5f52\u6a21\u578b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u7edf\u8ba1\u63a8\u65ad\u6846\u67b6\uff0c\u5305\u62ec\u53c2\u6570\u4f30\u8ba1\u3001\u5927\u6837\u672c\u7406\u8bba\u548c\u6a21\u578b\u9009\u62e9\u51c6\u5219\uff0c\u5176\u4e2d\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u65b0\u6784\u5efa\u7684\u4fe1\u606f\u51c6\u5219\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.21713", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21713", "abs": "https://arxiv.org/abs/2602.21713", "authors": ["Andreas Markoulidakis", "Matthew Hickman", "Nicky J Welton", "Loukia Meligkotsidou", "Hayley E Jones"], "title": "Multi-Parameter Estimation of Prevalence (MPEP): A Bayesian modelling approach to estimate the prevalence of opioid dependence", "comment": null, "summary": "Estimating the number of the number of people from hidden and/or marginalised populations - such as people dependent on opioids or cocaine - is important to guide policy decisions and provision of harm reduction services. Methods such as capture-recapture are widely used, but rely on assumptions that are often violated and not feasible in specific applications. We describe a Bayesian modelling approach called Multi-Parameter Estimation of Prevalence (MPEP). The MPEP approach leverages routinely collected administrative data, starting from a large baseline cohort of individuals from the population of interest and linked events, to estimate the full size of the target population. When multiple event types are included, the approach enables checking of the consistency of evidence about prevalence from different event types. Additional evidence can be incorporated where inconsistencies are identified. In this article, we summarize the general framework of MPEP, with focus on the most recent version, with improved computational efficiency (implemented in STAN). We also explore several extensions to the model that help us understand the sensitivity of the results to modelling assumptions or identify potential sources of bias. We demonstrate the MPEP approach through a case study estimating the prevalence of opioid dependence in Scotland each year from 2014 to 2022.", "AI": {"tldr": "MPEP\u662f\u4e00\u79cd\u8d1d\u53f6\u65af\u5efa\u6a21\u65b9\u6cd5\uff0c\u5229\u7528\u5e38\u89c4\u6536\u96c6\u7684\u884c\u653f\u6570\u636e\u6765\u4f30\u8ba1\u9690\u85cf\u6216\u8fb9\u7f18\u5316\u4eba\u7fa4\u7684\u89c4\u6a21\uff0c\u901a\u8fc7\u591a\u4e2a\u4e8b\u4ef6\u7c7b\u578b\u9a8c\u8bc1\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u82cf\u683c\u5170\u963f\u7247\u7c7b\u836f\u7269\u4f9d\u8d56\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u5230\u5e94\u7528\u3002", "motivation": "\u51c6\u786e\u4f30\u8ba1\u9690\u85cf\u6216\u8fb9\u7f18\u5316\u4eba\u7fa4\uff08\u5982\u963f\u7247\u7c7b\u6216\u53ef\u5361\u56e0\u4f9d\u8d56\u8005\uff09\u7684\u6570\u91cf\u5bf9\u4e8e\u653f\u7b56\u5236\u5b9a\u548c\u51cf\u5c11\u4f24\u5bb3\u670d\u52a1\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u5982\u6355\u83b7-\u518d\u6355\u83b7\u901a\u5e38\u5047\u8bbe\u6761\u4ef6\u96be\u4ee5\u6ee1\u8db3\uff0c\u5728\u7279\u5b9a\u5e94\u7528\u4e2d\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51fa\u591a\u53c2\u6570\u60a3\u75c5\u7387\u4f30\u8ba1\uff08MPEP\uff09\u8d1d\u53f6\u65af\u5efa\u6a21\u65b9\u6cd5\uff1a\u4ece\u76ee\u6807\u4eba\u7fa4\u7684\u5927\u89c4\u6a21\u57fa\u7ebf\u961f\u5217\u5f00\u59cb\uff0c\u94fe\u63a5\u591a\u4e2a\u4e8b\u4ef6\u7c7b\u578b\u6570\u636e\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u6846\u67b6\u4f30\u8ba1\u603b\u4eba\u53e3\u89c4\u6a21\u3002\u6700\u65b0\u7248\u672c\u4f7f\u7528STAN\u5b9e\u73b0\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u5305\u542b\u591a\u4e2a\u6269\u5c55\u6a21\u578b\u6765\u68c0\u9a8c\u654f\u611f\u6027\u3002", "result": "MPEP\u65b9\u6cd5\u80fd\u591f\u5229\u7528\u5e38\u89c4\u884c\u653f\u6570\u636e\u4f30\u8ba1\u9690\u85cf\u4eba\u7fa4\u89c4\u6a21\uff0c\u901a\u8fc7\u591a\u4e2a\u4e8b\u4ef6\u7c7b\u578b\u9a8c\u8bc1\u7ed3\u679c\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u4e0d\u4e00\u81f4\u65f6\u7eb3\u5165\u989d\u5916\u8bc1\u636e\u3002\u6848\u4f8b\u7814\u7a76\u6210\u529f\u5e94\u7528\u4e8e\u4f30\u8ba1\u82cf\u683c\u51702014-2022\u5e74\u963f\u7247\u7c7b\u836f\u7269\u4f9d\u8d56\u60a3\u75c5\u7387\u3002", "conclusion": "MPEP\u4e3a\u4f30\u8ba1\u9690\u85cf\u4eba\u7fa4\u89c4\u6a21\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u7a33\u5065\u7684\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u7684\u5047\u8bbe\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u591a\u6e90\u6570\u636e\u9a8c\u8bc1\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7684\u53ef\u9760\u6027\uff0c\u5728\u516c\u5171\u536b\u751f\u653f\u7b56\u5236\u5b9a\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.21572", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21572", "abs": "https://arxiv.org/abs/2602.21572", "authors": ["Huan Qing"], "title": "Goodness-of-Fit Tests for Latent Class Models with Ordinal Categorical Data", "comment": "50 pages, 4 tables, 3 figures", "summary": "Ordinal categorical data are widely collected in psychology, education, and other social sciences, appearing commonly in questionnaires, assessments, and surveys. Latent class models provide a flexible framework for uncovering unobserved heterogeneity by grouping individuals into homogeneous classes based on their response patterns. A fundamental challenge in applying these models is determining the number of latent classes, which is unknown and must be inferred from data. In this paper, we propose one test statistic for this problem. The test statistic centers the largest singular value of a normalized residual matrix by a simple sample-size adjustment. Under the null hypothesis that the candidate number of latent classes is correct, its upper bound converges to zero in probability. Under an under-fitted alternative, the statistic itself exceeds a fixed positive constant with probability approaching one. This sharp dichotomous behavior of the test statistic yields two sequential testing algorithms that consistently estimate the true number of latent classes. Extensive experimental studies confirm the theoretical findings and demonstrate their accuracy and reliability in determining the number of latent classes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f52\u4e00\u5316\u6b8b\u5dee\u77e9\u9635\u6700\u5927\u5947\u5f02\u503c\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u7528\u4e8e\u786e\u5b9a\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u7684\u6f5c\u5728\u7c7b\u522b\u6570\uff0c\u8be5\u7edf\u8ba1\u91cf\u5728\u6b63\u786e\u6a21\u578b\u4e0b\u6536\u655b\u4e8e\u96f6\uff0c\u5728\u6b20\u62df\u5408\u6a21\u578b\u4e0b\u8d85\u8fc7\u6b63\u5e38\u6570\uff0c\u4ece\u800c\u6784\u5efa\u4e00\u81f4\u6027\u4f30\u8ba1\u7684\u5e8f\u8d2f\u68c0\u9a8c\u7b97\u6cd5\u3002", "motivation": "\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u5728\u5fc3\u7406\u5b66\u3001\u6559\u80b2\u5b66\u7b49\u793e\u4f1a\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u6f5c\u5728\u7c7b\u522b\u6a21\u578b\u80fd\u6709\u6548\u63ed\u793a\u672a\u89c2\u6d4b\u5f02\u8d28\u6027\uff0c\u4f46\u786e\u5b9a\u6f5c\u5728\u7c7b\u522b\u6570\u91cf\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u7edf\u8ba1\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f52\u4e00\u5316\u6b8b\u5dee\u77e9\u9635\u6700\u5927\u5947\u5f02\u503c\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u6837\u672c\u91cf\u8c03\u6574\u8fdb\u884c\u4e2d\u5fc3\u5316\u5904\u7406\u3002\u5728\u96f6\u5047\u8bbe\uff08\u5019\u9009\u7c7b\u522b\u6570\u6b63\u786e\uff09\u4e0b\uff0c\u7edf\u8ba1\u91cf\u4e0a\u754c\u4ee5\u6982\u7387\u6536\u655b\u4e8e\u96f6\uff1b\u5728\u6b20\u62df\u5408\u5907\u62e9\u5047\u8bbe\u4e0b\uff0c\u7edf\u8ba1\u91cf\u4ee5\u6982\u7387\u8d8b\u8fd1\u4e8e1\u8d85\u8fc7\u56fa\u5b9a\u6b63\u5e38\u6570\u3002\u57fa\u4e8e\u8fd9\u79cd\u4e8c\u5206\u884c\u4e3a\u6784\u5efa\u4e24\u79cd\u5e8f\u8d2f\u68c0\u9a8c\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u68c0\u9a8c\u7edf\u8ba1\u91cf\u5177\u6709\u7406\u60f3\u7684\u6e10\u8fd1\u6027\u8d28\uff0c\u5728\u6b63\u786e\u6a21\u578b\u548c\u6b20\u62df\u5408\u6a21\u578b\u4e0b\u8868\u73b0\u51fa\u622a\u7136\u4e0d\u540c\u7684\u884c\u4e3a\u3002\u5927\u91cf\u5b9e\u9a8c\u7814\u7a76\u8bc1\u5b9e\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u786e\u5b9a\u6f5c\u5728\u7c7b\u522b\u6570\u91cf\u65b9\u9762\u5177\u6709\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\u548c\u5e8f\u8d2f\u68c0\u9a8c\u7b97\u6cd5\u80fd\u591f\u4e00\u81f4\u5730\u4f30\u8ba1\u6f5c\u5728\u7c7b\u522b\u7684\u771f\u5b9e\u6570\u91cf\uff0c\u4e3a\u5e8f\u6570\u5206\u7c7b\u6570\u636e\u7684\u6f5c\u5728\u7c7b\u522b\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2602.21969", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21969", "abs": "https://arxiv.org/abs/2602.21969", "authors": ["Nabaneet Das", "Thorsten Dickhaus"], "title": "Estimation of the complexity of a network under a Gaussian graphical model", "comment": null, "summary": "The proportion of edges in a Gaussian graphical model (GGM) characterizes the complexity of its conditional dependence structure. Since edge presence corresponds to a nonzero entry of the precision matrix, estimation of this proportion can be formulated as a large-scale multiple testing problem. We propose an estimator that combines p-values from simultaneous edge-wise tests, conducted under false discovery rate control, with Storey's estimator of the proportion of true null hypotheses. We establish weak dependence conditions on the precision matrix under which the empirical cumulative distribution function of the p-values converges to its population counterpart. These conditions cover high-dimensional regimes, including those arising in genetic association studies. Under such dependence, we characterize the asymptotic bias of the Schweder--Spj\u00f8tvoll estimator, showing that it is upward biased and thus slightly underestimates the true edge proportion. Simulation studies across a variety of models confirm accurate recovery of graph complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408FDR\u63a7\u5236\u4e0bp\u503c\u548cStorey\u4f30\u8ba1\u5668\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u9ad8\u65af\u56fe\u6a21\u578b\u4e2d\u8fb9\u7684\u6bd4\u4f8b\uff0c\u5efa\u7acb\u4e86\u5f31\u4f9d\u8d56\u6761\u4ef6\u4e0b\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5206\u6790\u4e86Schweder-Spj\u00f8tvoll\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u504f\u5dee\u3002", "motivation": "\u9ad8\u65af\u56fe\u6a21\u578b\uff08GGM\uff09\u4e2d\u8fb9\u7684\u6bd4\u4f8b\u8868\u5f81\u4e86\u5176\u6761\u4ef6\u4f9d\u8d56\u7ed3\u6784\u7684\u590d\u6742\u6027\u3002\u7531\u4e8e\u8fb9\u7684\u5b58\u5728\u5bf9\u5e94\u4e8e\u7cbe\u5ea6\u77e9\u9635\u7684\u975e\u96f6\u9879\uff0c\u4f30\u8ba1\u8fd9\u4e2a\u6bd4\u4f8b\u53ef\u4ee5\u8868\u8ff0\u4e3a\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u91cd\u68c0\u9a8c\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u5728\u5f31\u4f9d\u8d56\u6761\u4ef6\u4e0b\u6709\u6548\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408FDR\u63a7\u5236\u4e0b\u540c\u65f6\u8fb9\u68c0\u9a8c\u7684p\u503c\u548cStorey\u771f\u5b9e\u96f6\u5047\u8bbe\u6bd4\u4f8b\u4f30\u8ba1\u5668\u7684\u4f30\u8ba1\u5668\u3002\u5efa\u7acb\u4e86\u7cbe\u5ea6\u77e9\u9635\u7684\u5f31\u4f9d\u8d56\u6761\u4ef6\uff0c\u4fdd\u8bc1p\u503c\u7684\u7ecf\u9a8c\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u6536\u655b\u5230\u5176\u603b\u4f53\u5bf9\u5e94\u7269\u3002", "result": "\u5728\u5f31\u4f9d\u8d56\u6761\u4ef6\u4e0b\uff0cp\u503c\u7684\u7ecf\u9a8c\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u6536\u655b\u5230\u603b\u4f53\u5206\u5e03\u3002\u5206\u6790\u4e86Schweder-Spj\u00f8tvoll\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u504f\u5dee\uff0c\u663e\u793a\u5b83\u662f\u5411\u4e0a\u504f\u501a\u7684\uff0c\u56e0\u6b64\u4f1a\u8f7b\u5fae\u4f4e\u4f30\u771f\u5b9e\u7684\u8fb9\u6bd4\u4f8b\u3002\u6a21\u62df\u7814\u7a76\u8bc1\u5b9e\u4e86\u56fe\u590d\u6742\u6027\u7684\u51c6\u786e\u6062\u590d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u4f30\u8ba1\u9ad8\u65af\u56fe\u6a21\u578b\u4e2d\u8fb9\u7684\u6bd4\u4f8b\uff0c\u5373\u4f7f\u5728\u5f31\u4f9d\u8d56\u7684\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u4e5f\u6709\u6548\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9057\u4f20\u5173\u8054\u7814\u7a76\u7b49\u573a\u666f\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u73b0\u6709\u4f30\u8ba1\u5668\u7684\u504f\u5dee\u7279\u6027\u3002"}}
{"id": "2602.21998", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21998", "abs": "https://arxiv.org/abs/2602.21998", "authors": ["Xinran Li", "Anqi Zhao"], "title": "Design-based theory for causal inference from adaptive experiments", "comment": null, "summary": "Adaptive designs dynamically update treatment probabilities using information accumulated during the experiment. Existing theory for causal inference from adaptive experiments primarily assumes the superpopulation framework with independent and identically distributed units, and may not apply when the distribution of units evolves over time. This paper makes two contributions. First, we extend the literature to the finite-population framework, which allows for possibly nonexchangeable units, and establish the design-based theory for causal inference under general adaptive designs using inverse-propensity-weighted (IPW) and augmented IPW (AIPW) estimators. Our theory accommodates nonexchangeable units, both nonconverging and vanishing treatment probabilities, and nonconverging outcome estimators, thereby justifying inference using AIPW estimators with black-box outcome models that integrate advances from machine learning methods. To alleviate the conservativeness inherent in variance estimation under finite-population inference, we also introduce a covariance estimator for the AIPW estimator that becomes sharp when the residuals from the adaptive regression of potential outcomes on covariates are additive across units. Our framework encompasses widely used adaptive designs, such as multi-armed bandits, covariate-adaptive randomization, and sequential rerandomization, advancing the design-based theory for causal inference in these specific settings. Second, as a methodological contribution, we propose an adaptive covariate adjustment approach for analyzing even nonadaptive designs. The martingale structure induced by adaptive adjustment enables valid inference with black-box outcome estimators that would otherwise require strong assumptions under standard nonadaptive analysis.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u81ea\u9002\u5e94\u5b9e\u9a8c\u7684\u56e0\u679c\u63a8\u65ad\u7406\u8bba\u81f3\u6709\u9650\u603b\u4f53\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u57fa\u4e8e\u8bbe\u8ba1\u7684\u63a8\u65ad\u7406\u8bba\uff0c\u5e76\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u534f\u53d8\u91cf\u8c03\u6574\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u9002\u5e94\u5b9e\u9a8c\u7684\u56e0\u679c\u63a8\u65ad\u7406\u8bba\u4e3b\u8981\u57fa\u4e8e\u8d85\u603b\u4f53\u6846\u67b6\uff0c\u5047\u8bbe\u72ec\u7acb\u540c\u5206\u5e03\u5355\u4f4d\uff0c\u4e0d\u9002\u7528\u4e8e\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u5355\u4f4d\u5206\u5e03\u3002\u9700\u8981\u6269\u5c55\u5230\u6709\u9650\u603b\u4f53\u6846\u67b6\u4ee5\u5904\u7406\u4e0d\u53ef\u4ea4\u6362\u5355\u4f4d\u3002", "method": "1. \u6269\u5c55\u81f3\u6709\u9650\u603b\u4f53\u6846\u67b6\uff0c\u5efa\u7acb\u57fa\u4e8e\u8bbe\u8ba1\u7684\u63a8\u65ad\u7406\u8bba\uff0c\u4f7f\u7528IPW\u548cAIPW\u4f30\u8ba1\u5668\uff1b2. \u63d0\u51fa\u81ea\u9002\u5e94\u534f\u53d8\u91cf\u8c03\u6574\u65b9\u6cd5\uff0c\u5229\u7528\u9785\u7ed3\u6784\u5b9e\u73b0\u6709\u6548\u63a8\u65ad\u3002", "result": "\u7406\u8bba\u6846\u67b6\u80fd\u5904\u7406\u4e0d\u53ef\u4ea4\u6362\u5355\u4f4d\u3001\u975e\u6536\u655b\u548c\u6d88\u5931\u7684\u5904\u7406\u6982\u7387\u3001\u975e\u6536\u655b\u7ed3\u679c\u4f30\u8ba1\u5668\uff0c\u5e76\u5f15\u5165\u534f\u65b9\u5dee\u4f30\u8ba1\u5668\u7f13\u89e3\u65b9\u5dee\u4f30\u8ba1\u7684\u4fdd\u5b88\u6027\u3002\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u81c2\u8001\u864e\u673a\u3001\u534f\u53d8\u91cf\u81ea\u9002\u5e94\u968f\u673a\u5316\u7b49\u8bbe\u8ba1\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u6709\u9650\u603b\u4f53\u6846\u67b6\u4e0b\u7684\u81ea\u9002\u5e94\u5b9e\u9a8c\u56e0\u679c\u63a8\u65ad\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u534f\u53d8\u91cf\u8c03\u6574\u65b9\u6cd5\uff0c\u4e3a\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u63a8\u8fdb\u4e86\u57fa\u4e8e\u8bbe\u8ba1\u7684\u56e0\u679c\u63a8\u65ad\u7406\u8bba\u3002"}}
{"id": "2602.22122", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22122", "abs": "https://arxiv.org/abs/2602.22122", "authors": ["Elio Moreau", "Florentin Coeurdoux", "Gr\u00e9goire Ferre", "Eric Vanden-Eijnden"], "title": "Probing the Geometry of Diffusion Models with the String Method", "comment": null, "summary": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited. Standard latent-space interpolations fail to respect the structure of the learned distribution, often traversing low-density regions. We introduce a framework based on the string method that computes continuous paths between samples by evolving curves under the learned score function. Operating on pretrained models without retraining, our approach interpolates between three regimes: pure generative transport, which yields continuous sample paths; gradient-dominated dynamics, which recover minimum energy paths (MEPs); and finite-temperature string dynamics, which compute principal curves -- self-consistent paths that balance energy and entropy. We demonstrate that the choice of regime matters in practice. For image diffusion models, MEPs contain high-likelihood but unrealistic ''cartoon'' images, confirming prior observations that likelihood maxima appear unrealistic; principal curves instead yield realistic morphing sequences despite lower likelihood. For protein structure prediction, our method computes transition pathways between metastable conformers directly from models trained on static structures, yielding paths with physically plausible intermediates. Together, these results establish the string method as a principled tool for probing the modal structure of diffusion models -- identifying modes, characterizing barriers, and mapping connectivity in complex learned distributions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5f26\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u6269\u6563\u6a21\u578b\u4e2d\u6837\u672c\u95f4\u7684\u8fde\u7eed\u8def\u5f84\uff0c\u63a2\u7d22\u5b66\u4e60\u5206\u5e03\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5305\u62ec\u7eaf\u751f\u6210\u4f20\u8f93\u3001\u68af\u5ea6\u4e3b\u5bfc\u52a8\u529b\u5b66\u548c\u6709\u9650\u6e29\u5ea6\u5f26\u52a8\u529b\u5b66\u4e09\u79cd\u673a\u5236\u3002", "motivation": "\u7406\u89e3\u5b66\u4e60\u5206\u5e03\u7684\u51e0\u4f55\u7ed3\u6784\u5bf9\u4e8e\u6539\u8fdb\u548c\u89e3\u91ca\u6269\u6563\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u5de5\u5177\u6765\u63a2\u7d22\u5176\u666f\u89c2\u3002\u6807\u51c6\u7684\u6f5c\u5728\u7a7a\u95f4\u63d2\u503c\u65b9\u6cd5\u65e0\u6cd5\u5c0a\u91cd\u5b66\u4e60\u5206\u5e03\u7684\u7ed3\u6784\uff0c\u901a\u5e38\u4f1a\u7a7f\u8d8a\u4f4e\u5bc6\u5ea6\u533a\u57df\u3002", "method": "\u57fa\u4e8e\u5f26\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e0a\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u901a\u8fc7\u6f14\u5316\u66f2\u7ebf\u5728\u5b66\u4e60\u7684\u5f97\u5206\u51fd\u6570\u4e0b\u8ba1\u7b97\u6837\u672c\u95f4\u7684\u8fde\u7eed\u8def\u5f84\u3002\u5305\u62ec\u4e09\u79cd\u673a\u5236\uff1a\u7eaf\u751f\u6210\u4f20\u8f93\u3001\u68af\u5ea6\u4e3b\u5bfc\u52a8\u529b\u5b66\uff08\u6062\u590d\u6700\u5c0f\u80fd\u91cf\u8def\u5f84\uff09\u548c\u6709\u9650\u6e29\u5ea6\u5f26\u52a8\u529b\u5b66\uff08\u8ba1\u7b97\u4e3b\u66f2\u7ebf\uff09\u3002", "result": "\u5728\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u6700\u5c0f\u80fd\u91cf\u8def\u5f84\u5305\u542b\u9ad8\u4f3c\u7136\u4f46\u4e0d\u771f\u5b9e\u7684\"\u5361\u901a\"\u56fe\u50cf\uff0c\u800c\u4e3b\u66f2\u7ebf\u4ea7\u751f\u771f\u5b9e\u7684\u53d8\u5f62\u5e8f\u5217\u5c3d\u7ba1\u4f3c\u7136\u8f83\u4f4e\u3002\u5728\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f4\u63a5\u4ece\u9759\u6001\u7ed3\u6784\u8bad\u7ec3\u7684\u6a21\u578b\u4e2d\u8ba1\u7b97\u4e9a\u7a33\u6001\u6784\u8c61\u95f4\u7684\u8fc7\u6e21\u8def\u5f84\uff0c\u4ea7\u751f\u5177\u6709\u7269\u7406\u5408\u7406\u4e2d\u95f4\u4f53\u7684\u8def\u5f84\u3002", "conclusion": "\u5f26\u65b9\u6cd5\u6210\u4e3a\u63a2\u7d22\u6269\u6563\u6a21\u578b\u6a21\u6001\u7ed3\u6784\u7684\u539f\u5219\u6027\u5de5\u5177\uff0c\u80fd\u591f\u8bc6\u522b\u6a21\u6001\u3001\u8868\u5f81\u969c\u788d\uff0c\u5e76\u5728\u590d\u6742\u5b66\u4e60\u5206\u5e03\u4e2d\u6620\u5c04\u8fde\u901a\u6027\u3002"}}
{"id": "2602.22021", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.22021", "abs": "https://arxiv.org/abs/2602.22021", "authors": ["Jiacan Gao", "Xinyan Su", "Mingyuan Ma", "Yiyan Huang", "Xiao Xu", "Xinrui Wan", "Tianqi Gu", "Enyun Yu", "Jiecheng Guo", "Zhiheng Zhang"], "title": "Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data", "comment": null, "summary": "Estimating heterogeneous treatment effects is central to data-driven decision-making, yet industrial applications often face a fundamental tension between limited randomized controlled trial (RCT) budgets and abundant but biased observational data collected under historical targeting policies. Although observational logs offer the advantage of scale, they inherently suffer from severe policyinduced imbalance and overlap violations, rendering standalone estimation unreliable. We propose a budgeted active experimentation framework that iteratively enhances model training for causal effect estimation via active sampling. By leveraging observational priors, we develop an acquisition function targeting uplift estimation uncertainty, overlap deficits, and domain discrepancy to select the most informative units for randomized experiments. We establish finite-sample deviation bounds, asymptotic normality via martingale Central Limit Theorems (CLTs), and minimax lower bounds to prove information-theoretic optimality. Extensive experiments on industrial datasets demonstrate that our approach significantly outperforms standard randomized baselines in cost-constrained settings.", "AI": {"tldr": "\u63d0\u51fa\u9884\u7b97\u4e3b\u52a8\u5b9e\u9a8c\u6846\u67b6\uff0c\u5229\u7528\u89c2\u5bdf\u6570\u636e\u5148\u9a8c\uff0c\u901a\u8fc7\u4e3b\u52a8\u91c7\u6837\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u5355\u5143\u8fdb\u884c\u968f\u673a\u5b9e\u9a8c\uff0c\u4ee5\u5728\u6709\u9650RCT\u9884\u7b97\u4e0b\u63d0\u5347\u5f02\u8d28\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u6548\u679c", "motivation": "\u5de5\u4e1a\u5e94\u7528\u4e2d\u9762\u4e34\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u9884\u7b97\u6709\u9650\u4e0e\u5927\u91cf\u4f46\u6709\u504f\u7684\u89c2\u5bdf\u6570\u636e\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\u3002\u89c2\u5bdf\u6570\u636e\u867d\u89c4\u6a21\u5927\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u7b56\u7565\u8bf1\u5bfc\u4e0d\u5e73\u8861\u548c\u91cd\u53e0\u8fdd\u53cd\u95ee\u9898\uff0c\u5bfc\u81f4\u72ec\u7acb\u4f30\u8ba1\u4e0d\u53ef\u9760", "method": "\u9884\u7b97\u4e3b\u52a8\u5b9e\u9a8c\u6846\u67b6\uff0c\u8fed\u4ee3\u589e\u5f3a\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u7684\u6a21\u578b\u8bad\u7ec3\u3002\u5229\u7528\u89c2\u5bdf\u5148\u9a8c\uff0c\u5f00\u53d1\u9488\u5bf9\u63d0\u5347\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3001\u91cd\u53e0\u7f3a\u9677\u548c\u9886\u57df\u5dee\u5f02\u7684\u83b7\u53d6\u51fd\u6570\uff0c\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u5355\u5143\u8fdb\u884c\u968f\u673a\u5b9e\u9a8c", "result": "\u5efa\u7acb\u4e86\u6709\u9650\u6837\u672c\u504f\u5dee\u754c\u9650\u3001\u901a\u8fc7\u9785\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u7684\u6e10\u8fd1\u6b63\u6001\u6027\u3001\u6781\u5c0f\u6781\u5927\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u4fe1\u606f\u8bba\u6700\u4f18\u6027\u3002\u5de5\u4e1a\u6570\u636e\u96c6\u5b9e\u9a8c\u663e\u793a\u5728\u6210\u672c\u53d7\u9650\u8bbe\u7f6e\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u968f\u673a\u57fa\u7ebf", "conclusion": "\u63d0\u51fa\u7684\u9884\u7b97\u4e3b\u52a8\u5b9e\u9a8c\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3RCT\u9884\u7b97\u6709\u9650\u4e0e\u89c2\u5bdf\u6570\u636e\u6709\u504f\u7684\u77db\u76fe\uff0c\u901a\u8fc7\u4e3b\u52a8\u91c7\u6837\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u5b9e\u9a8c\u5355\u5143\uff0c\u5728\u6210\u672c\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u5f02\u8d28\u5904\u7406\u6548\u5e94\u4f30\u8ba1"}}
