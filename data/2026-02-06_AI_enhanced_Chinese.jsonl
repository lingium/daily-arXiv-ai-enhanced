{"id": "2602.04092", "categories": ["stat.AP", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04092", "abs": "https://arxiv.org/abs/2602.04092", "authors": ["Oana M. Enache", "Sherri Rose"], "title": "Time-to-Event Estimation with Unreliably Reported Events in Medicare Health Plan Payment", "comment": "36 pages, 9 figures", "summary": "Time-to-event estimation (i.e., survival analysis) is common in health research, most often using methods that assume proportional hazards and no competing risks. Because both assumptions are frequently invalid, estimators more aligned with real-world settings have been proposed. An effect can be estimated as the difference in areas below the cumulative incidence functions of two groups up to a pre-specified time point. This approach, restricted mean time lost (RMTL), can be used in settings with competing risks as well. We extend RMTL estimation for use in an understudied health policy application in Medicare. Medicare currently supports healthcare payment for over 69 million beneficiaries, most of whom are enrolled in Medicare Advantage plans and receive insurance from private insurers. These insurers are prospectively paid by the federal government for each of their beneficiaries' anticipated health needs using an ordinary least squares linear regression algorithm. As all coefficients are positive and predictor variables are largely insurer-submitted health conditions, insurers are incentivized to upcode, or report more diagnoses than may be accurate. Such gaming is projected to cost the federal government $40 billion in 2025 alone without clear benefit to beneficiaries. We propose several novel estimators of coding intensity and possible upcoding in Medicare Advantage, including accounting for unreliable reporting. We demonstrate estimator performance in simulated data leveraging the National Institutes of Health's All of Us study and also develop an open source R package to simulate realistic labeled upcoding data, which were not previously available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u751f\u5b58\u5206\u6790\u4e2d\u7684\u9650\u5236\u5e73\u5747\u635f\u5931\u65f6\u95f4\uff08RMTL\uff09\u65b9\u6cd5\u6269\u5c55\u5230\u533b\u7597\u4fdd\u9669\u4f18\u52bf\u8ba1\u5212\u4e2d\uff0c\u7528\u4e8e\u4f30\u8ba1\u7f16\u7801\u5f3a\u5ea6\u548c\u53ef\u80fd\u7684\u8fc7\u5ea6\u7f16\u7801\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90R\u5305\u6765\u6a21\u62df\u771f\u5b9e\u7684\u6807\u8bb0\u6570\u636e\u3002", "motivation": "\u533b\u7597\u4fdd\u9669\u4f18\u52bf\u8ba1\u5212\u4e2d\uff0c\u7531\u4e8e\u4fdd\u9669\u516c\u53f8\u6309\u63d0\u4ea4\u7684\u5065\u5eb7\u72b6\u51b5\u83b7\u5f97\u524d\u77bb\u6027\u652f\u4ed8\uff0c\u5b58\u5728\u8fc7\u5ea6\u7f16\u7801\uff08upcoding\uff09\u7684\u6fc0\u52b1\uff0c\u8fd9\u5bfc\u81f4\u8054\u90a6\u653f\u5e9c\u6bcf\u5e74\u635f\u5931\u6570\u5341\u4ebf\u7f8e\u5143\uff0c\u4f46\u7f3a\u4e4f\u53ef\u9760\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u5c06\u751f\u5b58\u5206\u6790\u4e2d\u7684\u9650\u5236\u5e73\u5747\u635f\u5931\u65f6\u95f4\uff08RMTL\uff09\u65b9\u6cd5\u6269\u5c55\u5230\u533b\u7597\u4fdd\u9669\u4f18\u52bf\u8ba1\u5212\uff0c\u63d0\u51fa\u591a\u79cd\u65b0\u9896\u7684\u7f16\u7801\u5f3a\u5ea6\u4f30\u8ba1\u5668\uff0c\u5305\u62ec\u8003\u8651\u4e0d\u53ef\u9760\u62a5\u544a\u7684\u60c5\u51b5\uff0c\u5e76\u5728\u6a21\u62df\u6570\u636e\u4e2d\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90R\u5305\u6765\u6a21\u62df\u771f\u5b9e\u7684\u6807\u8bb0\u8fc7\u5ea6\u7f16\u7801\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u4ee5\u524d\u4e0d\u53ef\u7528\uff0c\u5e76\u5728\u5229\u7528NIH All of Us\u7814\u7a76\u7684\u6a21\u62df\u6570\u636e\u4e2d\u5c55\u793a\u4e86\u4f30\u8ba1\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u533b\u7597\u4fdd\u9669\u4f18\u52bf\u8ba1\u5212\u4e2d\u7684\u8fc7\u5ea6\u7f16\u7801\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u4f30\u8ba1\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u548c\u91cf\u5316\u8fd9\u4e00\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4f9d\u636e\u3002"}}
{"id": "2602.04353", "categories": ["stat.OT"], "pdf": "https://arxiv.org/pdf/2602.04353", "abs": "https://arxiv.org/abs/2602.04353", "authors": ["Nils Lid Hjort"], "title": "Anyone for chess? Analysing chess ratings above high thresholds", "comment": "9 pages, 7 figures", "summary": "Suppose some cleverness score parameter is sufficiently\n  interesting to be defined and then measured, perhaps for\n  different strata of specialists or for the broader population.\n  Such phenomena could have Gaussian distributions,\n  when it comes to all players in a stratum, but when interest\n  focuses on the very tails, for the top few percent,\n  those above certain high thresholds,\n  different models are called for, along with the need\n  to analyse such based on the listed top scores only.\n  In this note I develop such models and tools,\n  and apply them to the top-100 and above 2100 points\n  lists for regular chess ratings, for the currently active\n  14671 men and 753 women,\n  as given by the FIDE, January 2026.\n  It is argued that even when two or more distributions have\n  close to identical expected values, or medians,\n  even smaller differences in variance may explain gaps\n  for the few very best ones.", "AI": {"tldr": "\u8bba\u6587\u5f00\u53d1\u4e86\u7528\u4e8e\u5206\u6790\u6781\u7aef\u9ad8\u5206\u5c3e\u90e8\u5206\u5e03\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u8bc4\u7ea7\u6570\u636e\uff0c\u53d1\u73b0\u5373\u4f7f\u5206\u5e03\u5747\u503c\u76f8\u8fd1\uff0c\u65b9\u5dee\u5dee\u5f02\u4e5f\u80fd\u89e3\u91ca\u9876\u5c16\u9009\u624b\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u7814\u7a76\u67d0\u4e9b\"\u806a\u660e\u5ea6\"\u53c2\u6570\u65f6\uff0c\u867d\u7136\u6574\u4f53\u5206\u5e03\u53ef\u80fd\u5448\u9ad8\u65af\u5206\u5e03\uff0c\u4f46\u5f53\u6211\u4eec\u5173\u6ce8\u6781\u7aef\u9ad8\u5206\u5c3e\u90e8\u7684\u9876\u5c16\u5c11\u6570\u4eba\u65f6\uff0c\u9700\u8981\u4e0d\u540c\u7684\u7edf\u8ba1\u6a21\u578b\u3002\u7279\u522b\u662f\u5f53\u53ea\u80fd\u83b7\u5f97\u6700\u9ad8\u5206\u5217\u8868\u6570\u636e\u65f6\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u4e13\u95e8\u7528\u4e8e\u5206\u6790\u6781\u7aef\u9ad8\u5206\u5c3e\u90e8\u5206\u5e03\u7684\u7edf\u8ba1\u6a21\u578b\u548c\u5de5\u5177\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eFIDE 2026\u5e741\u6708\u516c\u5e03\u7684\u6d3b\u8dc3\u68cb\u624b\u6570\u636e\uff0c\u5305\u62ec\u524d100\u540d\u548c2100\u5206\u4ee5\u4e0a\u7684\u7537\u6027\u548c\u5973\u6027\u68cb\u624b\u8bc4\u7ea7\u5217\u8868\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u4e24\u4e2a\u6216\u591a\u4e2a\u5206\u5e03\u7684\u671f\u671b\u503c\u6216\u4e2d\u4f4d\u6570\u975e\u5e38\u63a5\u8fd1\uff0c\u65b9\u5dee\u4e0a\u7684\u5fae\u5c0f\u5dee\u5f02\u4e5f\u80fd\u89e3\u91ca\u9876\u5c16\u9009\u624b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u7406\u89e3\u4e3a\u4ec0\u4e48\u5728\u67d0\u4e9b\u9886\u57df\uff0c\u5373\u4f7f\u6574\u4f53\u5e73\u5747\u6c34\u5e73\u76f8\u4f3c\uff0c\u9876\u5c16\u8868\u73b0\u8005\u4e4b\u95f4\u4ecd\u5b58\u5728\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "\u5bf9\u4e8e\u6781\u7aef\u9ad8\u5206\u5c3e\u90e8\u5206\u5e03\u7684\u5206\u6790\u9700\u8981\u4e13\u95e8\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u65b9\u5dee\u5dee\u5f02\u662f\u89e3\u91ca\u9876\u5c16\u8868\u73b0\u8005\u5dee\u8ddd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5373\u4f7f\u5747\u503c\u76f8\u4f3c\u3002\u8fd9\u4e00\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u5404\u79cd\u9700\u8981\u5206\u6790\u9876\u5c16\u8868\u73b0\u7684\u9886\u57df\u3002"}}
{"id": "2602.04554", "categories": ["stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.04554", "abs": "https://arxiv.org/abs/2602.04554", "authors": ["Zhexuan Yang", "Duchwan Ryu", "Feng Luan"], "title": "mmcmcBayes:An R Package Implementing a Multistage MCMC Framework for Detecting the Differentially Methylated Regions", "comment": "27 pages, 3 figures", "summary": "Identifying differentially methylated regions is an important task in epigenome-wide association studies, where differential signals often arise across groups of neighboring CpG sites. Many existing methods detect differentially methylated regions by aggregating CpG-level test results, which may limit their ability to capture complex regional methylation patterns. In this paper, we introduce the R package mmcmcBayes, which implements a multistage Markov chain Monte Carlo procedure for region-level detection of differentially methylated regions. The method models sample-wise regional methylation summaries using the alpha-skew generalized normal distribution and evaluates evidence for differential methylation between groups through Bayes factors. We use a multistage region-splitting strategy to refine candidate regions based on statistical evidence. We describe the underlying methodology and software implementation, and illustrate its performance through simulation studies and applications to Illumina 450K methylation data. The mmcmcBayes package provides a practical region-level alternative to existing CpG-based differentially methylated regions detection methods and includes supporting functions for summarizing, comparing, and visualizing detected regions.", "AI": {"tldr": "mmcmcBayes\u662f\u4e00\u4e2aR\u5305\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u68c0\u6d4b\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\uff0c\u4f7f\u7528\u03b1-\u504f\u659c\u5e7f\u4e49\u6b63\u6001\u5206\u5e03\u5efa\u6a21\u533a\u57df\u7532\u57fa\u5316\u6458\u8981\uff0c\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u56e0\u5b50\u8bc4\u4f30\u7ec4\u95f4\u5dee\u5f02\u8bc1\u636e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u805a\u5408CpG\u4f4d\u70b9\u6c34\u5e73\u7684\u6d4b\u8bd5\u7ed3\u679c\u6765\u68c0\u6d4b\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u6355\u6349\u590d\u6742\u533a\u57df\u7532\u57fa\u5316\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u533a\u57df\u6c34\u5e73\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u7a0b\u5e8f\uff0c\u4f7f\u7528\u03b1-\u504f\u659c\u5e7f\u4e49\u6b63\u6001\u5206\u5e03\u5bf9\u6837\u672c\u533a\u57df\u7532\u57fa\u5316\u6458\u8981\u8fdb\u884c\u5efa\u6a21\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u56e0\u5b50\u8bc4\u4f30\u7ec4\u95f4\u5dee\u5f02\u7532\u57fa\u5316\u8bc1\u636e\uff0c\u5e76\u4f7f\u7528\u591a\u9636\u6bb5\u533a\u57df\u5206\u5272\u7b56\u7565\u57fa\u4e8e\u7edf\u8ba1\u8bc1\u636e\u7ec6\u5316\u5019\u9009\u533a\u57df\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548cIllumina 450K\u7532\u57fa\u5316\u6570\u636e\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u3002mmcmcBayes\u5305\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u533a\u57df\u6c34\u5e73\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5305\u542b\u7528\u4e8e\u603b\u7ed3\u3001\u6bd4\u8f83\u548c\u53ef\u89c6\u5316\u68c0\u6d4b\u533a\u57df\u7684\u8f85\u52a9\u51fd\u6570\u3002", "conclusion": "mmcmcBayes\u4e3a\u73b0\u6709\u57fa\u4e8eCpG\u7684\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u533a\u57df\u6c34\u5e73\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u590d\u6742\u7684\u533a\u57df\u7532\u57fa\u5316\u6a21\u5f0f\u3002"}}
{"id": "2602.04638", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.04638", "abs": "https://arxiv.org/abs/2602.04638", "authors": ["Irene Garc\u00eda Mu\u00f1oz", "Ian Hall", "Thomas House"], "title": "Inference for Within- and Between-Partnership Transmission Rates for HIV Infection", "comment": "14 pages, 3 figures, 3 tables", "summary": "HIV transmission within serodiscordant couples remains a significant public health challenge, particularly in sub-Saharan Africa. Estimating the rate of such infection, alongside the rates of introduction of infection from outside the partnership, is a special case of the more general epidemiological challenge of inferring intensities of within- and between-group intensities of transmission. This study presents a stochastic susceptible-infected (SI) pair model for estimating key epidemiological parameters governing HIV transmission within and between couples, which we further extend to account for gender-specific differences in infection dynamics. Using a likelihood-based inference approach, we estimate transmission parameters and associated uncertainty from observed data. These values can be used to inform infection prevention strategies for HIV, and the methodology proposed can be generalised to other epidemiological settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u968f\u673aSI\u914d\u5bf9\u6a21\u578b\uff0c\u7528\u4e8e\u4f30\u8ba1HIV\u5728\u8840\u6e05\u4e0d\u4e00\u81f4\u4f34\u4fa3\u4e2d\u7684\u4f20\u64ad\u53c2\u6570\uff0c\u8003\u8651\u4e86\u6027\u522b\u5dee\u5f02\uff0c\u4f7f\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u63a8\u65ad\u65b9\u6cd5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u4f20\u64ad\u53c2\u6570\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "HIV\u5728\u8840\u6e05\u4e0d\u4e00\u81f4\u4f34\u4fa3\u4e2d\u7684\u4f20\u64ad\u4ecd\u7136\u662f\u91cd\u8981\u7684\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u5730\u533a\u3002\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u4f34\u4fa3\u5185\u4f20\u64ad\u7387\u548c\u4f34\u4fa3\u5916\u5f15\u5165\u611f\u67d3\u7387\uff0c\u4ee5\u5236\u5b9a\u6709\u6548\u7684\u9884\u9632\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u968f\u673a\u6613\u611f-\u611f\u67d3(SI)\u914d\u5bf9\u6a21\u578b\uff0c\u7528\u4e8e\u4f30\u8ba1HIV\u5728\u4f34\u4fa3\u5185\u548c\u4f34\u4fa3\u95f4\u7684\u4f20\u64ad\u53c2\u6570\u3002\u6a21\u578b\u6269\u5c55\u4ee5\u8003\u8651\u6027\u522b\u7279\u5f02\u6027\u611f\u67d3\u52a8\u6001\uff0c\u91c7\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u63a8\u65ad\u65b9\u6cd5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u53c2\u6570\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u6210\u529f\u4f30\u8ba1\u4e86HIV\u4f20\u64ad\u7684\u5173\u952e\u6d41\u884c\u75c5\u5b66\u53c2\u6570\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e9b\u53c2\u6570\u53ef\u7528\u4e8e\u6307\u5bfcHIV\u611f\u67d3\u9884\u9632\u7b56\u7565\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u6d41\u884c\u75c5\u5b66\u573a\u666f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u8ba1\u6846\u67b6\u6765\u4f30\u8ba1HIV\u5728\u8840\u6e05\u4e0d\u4e00\u81f4\u4f34\u4fa3\u4e2d\u7684\u4f20\u64ad\u52a8\u6001\uff0c\u8003\u8651\u4e86\u6027\u522b\u5dee\u5f02\uff0c\u4e3a\u5236\u5b9a\u9488\u5bf9\u6027\u9884\u9632\u7b56\u7565\u63d0\u4f9b\u4e86\u79d1\u5b66\u4f9d\u636e\uff0c\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2602.03985", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.03985", "abs": "https://arxiv.org/abs/2602.03985", "authors": ["Augustine Wigle", "Erica E. M. Moodie"], "title": "Doubly-Robust Bayesian Estimation of Optimal Individualized Treatment Rules using Network Meta-Analysis", "comment": null, "summary": "An optimal individualized treatment rule (ITR) is a function that takes a patient's characteristics, such as demographics, biomarkers, and treatment history, and outputs a treatment that is expected to give the best outcome for that patient. Major Depressive Disorder (MDD) is a common and disabling mental health condition for which an optimal ITR is of interest. Unfortunately, the power to detect treatment-covariate interactions in individual studies of MDD treatments is low. Additionally, all treatments of interest are not compared head-to-head in a single study. Network meta-analysis (NMA) is a method of synthesizing data from multiple studies to estimate the relative effects of a set of treatments. Recently, two-stage ITR NMA was proposed as a method to estimate ITRs that has the potential to improve power and simultaneously consider all relevant treatment options. In the first stage, study-specific ITRs are estimated, and in the second stage, they are pooled using a Bayesian NMA model. The existing approach is vulnerable to model misspecification and fails to address missing outcomes, which occur in the MDD data. We overcome these challenges by proposing Bayesian Bootstrap dynamic Weighted Ordinary Least Squares (BBdWOLS), a doubly-robust approach to ITR estimation that accounts for missing at random outcomes and naturally quantifies the uncertainty in estimation. We also propose an improvement to the NMA model that incorporates the full variance-covariance matrix of study-specific estimates. In a simulation study, we show that our fully Bayesian ITR NMA method is more robust and efficient than the existing approach. We apply our method to the motivating dataset consisting of three studies of pharmacological treatments for MDD, and explore how ITR NMA results can support personalized decision making in this context.", "AI": {"tldr": "\u63d0\u51faBBdWOLS\u65b9\u6cd5\u6539\u8fdb\u7f51\u7edc\u835f\u8403\u5206\u6790\u4e2d\u7684\u4e2a\u4f53\u5316\u6cbb\u7597\u89c4\u5219\u4f30\u8ba1\uff0c\u89e3\u51b3\u6a21\u578b\u8bef\u8bbe\u548c\u7f3a\u5931\u6570\u636e\u95ee\u9898\uff0c\u5e94\u7528\u4e8e\u6291\u90c1\u75c7\u6cbb\u7597\u51b3\u7b56", "motivation": "\u6291\u90c1\u75c7\u6cbb\u7597\u4e2d\uff0c\u73b0\u6709\u4e24\u9636\u6bb5ITR-NMA\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u8bef\u8bbe\u8106\u5f31\u6027\u548c\u65e0\u6cd5\u5904\u7406\u7f3a\u5931\u6570\u636e\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u652f\u6301\u4e2a\u6027\u5316\u6cbb\u7597\u51b3\u7b56", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u81ea\u52a9\u52a8\u6001\u52a0\u6743\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff08BBdWOLS\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u53cc\u91cd\u7a33\u5065\u7684ITR\u4f30\u8ba1\u65b9\u6cd5\uff0c\u80fd\u5904\u7406\u968f\u673a\u7f3a\u5931\u7ed3\u679c\u5e76\u91cf\u5316\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff1b\u540c\u65f6\u6539\u8fdbNMA\u6a21\u578b\u4ee5\u7eb3\u5165\u7814\u7a76\u7279\u5b9a\u4f30\u8ba1\u7684\u5b8c\u6574\u65b9\u5dee-\u534f\u65b9\u5dee\u77e9\u9635", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u5b8c\u5168\u8d1d\u53f6\u65afITR-NMA\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7a33\u5065\u548c\u9ad8\u6548\uff1b\u5e94\u7528\u4e8e\u4e09\u4e2a\u6291\u90c1\u75c7\u836f\u7269\u6cbb\u7597\u7814\u7a76\u6570\u636e\u96c6\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u652f\u6301\u4e2a\u6027\u5316\u51b3\u7b56", "conclusion": "BBdWOLS\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709ITR-NMA\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6291\u90c1\u75c7\u7b49\u75be\u75c5\u7684\u4e2a\u6027\u5316\u6cbb\u7597\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5904\u7406\u7f3a\u5931\u6570\u636e\u5e76\u91cf\u5316\u4e0d\u786e\u5b9a\u6027"}}
{"id": "2602.03889", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03889", "abs": "https://arxiv.org/abs/2602.03889", "authors": ["Ernest Fokou\u00e9"], "title": "Transcendental Regularization of Finite Mixtures:Theoretical Guarantees and Practical Limitations", "comment": "24 pages, 6 figures, 2 tables", "summary": "Finite mixture models are widely used for unsupervised learning, but maximum likelihood estimation via EM suffers from degeneracy as components collapse. We introduce transcendental regularization, a penalized likelihood framework with analytic barrier functions that prevent degeneracy while maintaining asymptotic efficiency. The resulting Transcendental Algorithm for Mixtures of Distributions (TAMD) offers strong theoretical guarantees: identifiability, consistency, and robustness. Empirically, TAMD successfully stabilizes estimation and prevents collapse, yet achieves only modest improvements in classification accuracy-highlighting fundamental limits of mixture models for unsupervised learning in high dimensions. Our work provides both a novel theoretical framework and an honest assessment of practical limitations, implemented in an open-source R package.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9632\u6b62\u6709\u9650\u6df7\u5408\u6a21\u578b\u9000\u5316\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u2014\u2014\u8d85\u8d8a\u6b63\u5219\u5316\uff0c\u901a\u8fc7\u89e3\u6790\u5c4f\u969c\u51fd\u6570\u9632\u6b62\u5206\u91cf\u5d29\u6e83\uff0c\u540c\u65f6\u4fdd\u6301\u6e10\u8fd1\u6548\u7387\u3002", "motivation": "\u6709\u9650\u6df7\u5408\u6a21\u578b\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u901a\u8fc7EM\u7b97\u6cd5\u8fdb\u884c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u65f6\u5b58\u5728\u9000\u5316\u95ee\u9898\uff0c\u5373\u5206\u91cf\u4f1a\u5d29\u6e83\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u9632\u6b62\u9000\u5316\u5e76\u4fdd\u6301\u7edf\u8ba1\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u8d85\u8d8a\u6b63\u5219\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u60e9\u7f5a\u4f3c\u7136\u65b9\u6cd5\uff0c\u5305\u542b\u89e3\u6790\u5c4f\u969c\u51fd\u6570\u6765\u9632\u6b62\u9000\u5316\u3002\u5f00\u53d1\u4e86TAMD\u7b97\u6cd5\uff08Transcendental Algorithm for Mixtures of Distributions\uff09\uff0c\u5177\u6709\u53ef\u8bc6\u522b\u6027\u3001\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u7b49\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "TAMD\u6210\u529f\u7a33\u5b9a\u4e86\u4f30\u8ba1\u5e76\u9632\u6b62\u4e86\u5d29\u6e83\uff0c\u4f46\u5728\u9ad8\u7ef4\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u5206\u7c7b\u51c6\u786e\u7387\u7684\u63d0\u5347\u6709\u9650\uff0c\u7a81\u663e\u4e86\u6df7\u5408\u6a21\u578b\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u9650\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5bf9\u6df7\u5408\u6a21\u578b\u5728\u9ad8\u7ef4\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5b9e\u9645\u5c40\u9650\u6027\u8fdb\u884c\u4e86\u8bda\u5b9e\u8bc4\u4f30\uff0c\u5df2\u5b9e\u73b0\u4e3a\u5f00\u6e90R\u5305\u3002"}}
{"id": "2602.04272", "categories": ["stat.CO", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04272", "abs": "https://arxiv.org/abs/2602.04272", "authors": ["Peiwen Jiang", "Takuo Matsubara", "Minh-Ngoc Tran"], "title": "Bures-Wasserstein Importance-Weighted Evidence Lower Bound: Exposition and Applications", "comment": "27 pages, 6 figures. Submitted to Bayesian Analysis", "summary": "The Importance-Weighted Evidence Lower Bound (IW-ELBO) has emerged as an effective objective for variational inference (VI), tightening the standard ELBO and mitigating the mode-seeking behaviour.\n  However, optimizing the IW-ELBO in Euclidean space is often inefficient, as its gradient estimators suffer from a vanishing signal-to-noise ratio (SNR). This paper formulates the optimisation of the IW-ELBO in Bures-Wasserstein space, a manifold of Gaussian distributions equipped with the 2-Wasserstein metric. We derive the Wasserstein gradient of the IW-ELBO and project it onto the Bures-Wasserstein space to yield a tractable algorithm for Gaussian VI.\n  A pivotal contribution of our analysis concerns the stability of the gradient estimator. While the SNR of the standard Euclidean gradient estimator is known to vanish as the number of importance samples $K$ increases, we prove that the SNR of the Wasserstein gradient scales favourably as $\u03a9(\\sqrt{K})$, ensuring optimisation efficiency even for large $K$. We further extend this geometric analysis to the Variational R\u00e9nyi Importance-Weighted Autoencoder bound, establishing analogous stability guarantees. Experiments demonstrate that the proposed framework achieves superior approximation performance compared to other baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5728Bures-Wasserstein\u7a7a\u95f4\u4e2d\u4f18\u5316\u91cd\u8981\u6027\u52a0\u6743\u8bc1\u636e\u4e0b\u754c(IW-ELBO)\uff0c\u901a\u8fc7Wasserstein\u68af\u5ea6\u89e3\u51b3\u4e86\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u68af\u5ea6\u4f30\u8ba1\u5668\u4fe1\u566a\u6bd4\u6d88\u5931\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u65af\u53d8\u5206\u63a8\u65ad\u7684\u6027\u80fd\u3002", "motivation": "\u91cd\u8981\u6027\u52a0\u6743\u8bc1\u636e\u4e0b\u754c(IW-ELBO)\u867d\u7136\u80fd\u6536\u7d27\u6807\u51c6ELBO\u5e76\u7f13\u89e3\u6a21\u5f0f\u5bfb\u6c42\u884c\u4e3a\uff0c\u4f46\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u4f18\u5316\u6548\u7387\u4f4e\u4e0b\uff0c\u5176\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u4fe1\u566a\u6bd4\u4f1a\u6d88\u5931\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5c06IW-ELBO\u4f18\u5316\u95ee\u9898\u8868\u8ff0\u5728Bures-Wasserstein\u7a7a\u95f4\u4e2d\uff0c\u8fd9\u662f\u4e00\u4e2a\u914d\u59072-Wasserstein\u5ea6\u91cf\u7684\u9ad8\u65af\u5206\u5e03\u6d41\u5f62\u3002\u63a8\u5bfcIW-ELBO\u7684Wasserstein\u68af\u5ea6\uff0c\u5e76\u5c06\u5176\u6295\u5f71\u5230Bures-Wasserstein\u7a7a\u95f4\uff0c\u5f97\u5230\u9ad8\u65af\u53d8\u5206\u63a8\u65ad\u7684\u53ef\u884c\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86Wasserstein\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u4fe1\u566a\u6bd4\u4ee5\u03a9(\u221aK)\u7684\u6709\u5229\u65b9\u5f0f\u7f29\u653e\uff0c\u5373\u4f7f\u5bf9\u4e8e\u5927\u7684\u91cd\u8981\u6027\u6837\u672c\u6570K\u4e5f\u80fd\u4fdd\u6301\u4f18\u5316\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8fd1\u4f3c\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5728Bures-Wasserstein\u7a7a\u95f4\u4e2d\u4f18\u5316IW-ELBO\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u9ad8\u6548\u7684\u53d8\u5206\u63a8\u65ad\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u68af\u5ea6\u4f30\u8ba1\u5668\u4fe1\u566a\u6bd4\u6d88\u5931\u7684\u95ee\u9898\uff0c\u4e3a\u9ad8\u65af\u53d8\u5206\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2602.03899", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.03899", "abs": "https://arxiv.org/abs/2602.03899", "authors": ["Gilles Bareilles", "Wassim Bouaziz", "Julien Fageot", "El-Mahdi El-Mhamdi"], "title": "Byzantine Machine Learning: MultiKrum and an optimal notion of robustness", "comment": null, "summary": "Aggregation rules are the cornerstone of distributed (or federated) learning in the presence of adversaries, under the so-called Byzantine threat model. They are also interesting mathematical objects from the point of view of robust mean estimation. The Krum aggregation rule has been extensively studied, and endowed with formal robustness and convergence guarantees. Yet, MultiKrum, a natural extension of Krum, is often preferred in practice for its superior empirical performance, even though no theoretical guarantees were available until now. In this work, we provide the first proof that MultiKrum is a robust aggregation rule, and bound its robustness coefficient. To do so, we introduce $\u03ba^\\star$, the optimal *robustness coefficient* of an aggregation rule, which quantifies the accuracy of mean estimation in the presence of adversaries in a tighter manner compared with previously adopted notions of robustness. We then construct an upper and a lower bound on MultiKrum's robustness coefficient. As a by-product, we also improve on the best-known bounds on Krum's robustness coefficient. We show that MultiKrum's bounds are never worse than Krum's, and better in realistic regimes. We illustrate this analysis by an experimental investigation on the quality of the lower bound.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8bc1\u660e\u4e86MultiKrum\u805a\u5408\u89c4\u5219\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u6700\u4f18\u9c81\u68d2\u7cfb\u6570\u03ba*\u6765\u66f4\u7cbe\u786e\u5730\u91cf\u5316\u5bf9\u6297\u73af\u5883\u4e0b\u7684\u5747\u503c\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u6539\u8fdb\u4e86\u5bf9Krum\u548cMultiKrum\u9c81\u68d2\u7cfb\u6570\u7684\u7406\u8bba\u5206\u6790\u3002", "motivation": "MultiKrum\u4f5c\u4e3aKrum\u7684\u81ea\u7136\u6269\u5c55\uff0c\u5728\u5b9e\u8df5\u4e2d\u56e0\u5176\u4f18\u8d8a\u7684\u5b9e\u8bc1\u6027\u80fd\u800c\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u4e00\u76f4\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3aMultiKrum\u63d0\u4f9b\u9996\u4e2a\u9c81\u68d2\u6027\u8bc1\u660e\u3002", "method": "\u5f15\u5165\u6700\u4f18\u9c81\u68d2\u7cfb\u6570\u03ba*\u4f5c\u4e3a\u65b0\u7684\u9c81\u68d2\u6027\u5ea6\u91cf\u6807\u51c6\uff0c\u7136\u540e\u6784\u5efaMultiKrum\u9c81\u68d2\u7cfb\u6570\u7684\u4e0a\u4e0b\u754c\uff0c\u540c\u65f6\u6539\u8fdb\u4e86Krum\u9c81\u68d2\u7cfb\u6570\u7684\u5df2\u77e5\u6700\u4f73\u754c\u9650\u3002", "result": "\u8bc1\u660e\u4e86MultiKrum\u7684\u9c81\u68d2\u6027\uff0c\u5176\u754c\u9650\u4ece\u4e0d\u5dee\u4e8eKrum\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u597d\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0b\u754c\u7684\u8d28\u91cf\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u4e3aMultiKrum\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u66f4\u7cbe\u786e\u7684\u9c81\u68d2\u7cfb\u6570\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4e3a\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u5bf9\u6297\u6027\u9632\u5fa1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.04178", "categories": ["stat.ME", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.04178", "abs": "https://arxiv.org/abs/2602.04178", "authors": ["Qi Xu", "Jing Lei", "Kathryn Roeder"], "title": "Sparse group principal component analysis via double thresholding with application to multi-cellular programs", "comment": null, "summary": "Multi-cellular programs (MCPs) are coordinated patterns of gene expression across interacting cell types that collectively drive complex biological processes such as tissue development and immune responses. While MCPs are typically estimated from high-dimensional gene expression data using methods like sparse principal component analysis or latent factor models, these approaches often suffer from high computational costs and limited statistical power. In this work, we propose Sparse Group Principal Component Analysis (SGPCA) to estimate MCPs by leveraging their inherent group and individual sparsity. We introduce an efficient double-thresholding algorithm based on power iteration. In each iteration, a group thresholding step first identifies relevant gene groups, followed by an individual thresholding step to select active cell types. This algorithm achieves a linear computational complexity of $O(np)$, making it highly efficient and scalable for large-scale genomic analyses. We establish theoretical guarantees for SGPCA, including statistical consistency and a convergence rate that surpasses competing methods. Through extensive simulations, we demonstrate that SGPCA achieves superior estimation accuracy and improved statistical power for signal detection. Furthermore, We apply SGPCA to a Lupus study, discovering differentially expressed MCPs distinguishing Lupus patients from normal subjects.", "AI": {"tldr": "\u63d0\u51faSGPCA\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u91cd\u9608\u503c\u7b97\u6cd5\u9ad8\u6548\u4f30\u8ba1\u591a\u7ec6\u80de\u7a0b\u5e8f\uff0c\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u6a21\u62df\u548c\u72fc\u75ae\u7814\u7a76\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u4f30\u8ba1\u591a\u7ec6\u80de\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff08\u5982\u7a00\u758f\u4e3b\u6210\u5206\u5206\u6790\u6216\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\uff09\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u7edf\u8ba1\u529f\u6548\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7a00\u758f\u7ec4\u4e3b\u6210\u5206\u5206\u6790\uff08SGPCA\uff09\uff0c\u5229\u7528\u591a\u7ec6\u80de\u7a0b\u5e8f\u7684\u56fa\u6709\u7ec4\u7a00\u758f\u6027\u548c\u4e2a\u4f53\u7a00\u758f\u6027\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u5e42\u8fed\u4ee3\u7684\u9ad8\u6548\u53cc\u91cd\u9608\u503c\u7b97\u6cd5\uff0c\u5305\u62ec\u7ec4\u9608\u503c\u6b65\u9aa4\u548c\u4e2a\u4f53\u9608\u503c\u6b65\u9aa4\u3002", "result": "SGPCA\u5177\u6709O(np)\u7684\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7406\u8bba\u4fdd\u8bc1\u5305\u62ec\u7edf\u8ba1\u4e00\u81f4\u6027\u548c\u4f18\u4e8e\u7ade\u4e89\u65b9\u6cd5\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5728\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u4f30\u8ba1\u7cbe\u5ea6\u548c\u4fe1\u53f7\u68c0\u6d4b\u7edf\u8ba1\u529f\u6548\uff0c\u5728\u72fc\u75ae\u7814\u7a76\u4e2d\u53d1\u73b0\u4e86\u533a\u5206\u60a3\u8005\u4e0e\u6b63\u5e38\u53d7\u8bd5\u8005\u7684\u5dee\u5f02\u8868\u8fbe\u591a\u7ec6\u80de\u7a0b\u5e8f\u3002", "conclusion": "SGPCA\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u591a\u7ec6\u80de\u7a0b\u5e8f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u57fa\u56e0\u7ec4\u5206\u6790\u3002"}}
{"id": "2602.04010", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04010", "abs": "https://arxiv.org/abs/2602.04010", "authors": ["Arijit Pyne"], "title": "Robust Nonparametric Two-Sample Tests via Mutual Information using Extended Bregman Divergence", "comment": null, "summary": "We introduce a generalized formulation of mutual information (MI) based on the extended Bregman divergence, a framework that subsumes the generalized S-Bregman (GSB) divergence family. The GSB divergence unifies two important classes of statistical distances, namely the S-divergence and the Bregman exponential divergence (BED), thereby encompassing several widely used subfamilies, including the power divergence (PD), density power divergence (DPD), and S-Hellinger distance (S-HD). In parametric inference, minimum divergence estimators are well known to balance robustness with high asymptotic efficiency relative to the maximum likelihood estimator. However, nonparametric tests based on such statistical distances have been relatively less explored. In this paper, we construct a class of consistent and robust nonparametric two-sample tests for the equality of two absolutely continuous distributions using the generalized MI. We establish the asymptotic normality of the proposed test statistics under the null and contiguous alternatives. The robustness properties of the generalized MI are rigorously studied through the influence function and the breakdown point, demonstrating that stability of the generalized MI translates into stability of the associated tests. Extensive simulation studies show that divergences beyond the PD family often yield superior robustness under contamination while retaining high asymptotic power. A data-driven scheme for selecting optimal tuning parameters is also proposed. Finally, the methodology is illustrated with applications to real data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u5c55Bregman\u6563\u5ea6\u7684\u5e7f\u4e49\u4e92\u4fe1\u606f\u6846\u67b6\uff0c\u6784\u5efa\u7a33\u5065\u7684\u975e\u53c2\u6570\u4e24\u6837\u672c\u68c0\u9a8c\uff0c\u8bc1\u660e\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u7814\u7a76\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7edf\u8ba1\u8ddd\u79bb\u7684\u6700\u5c0f\u6563\u5ea6\u4f30\u8ba1\u5668\u5728\u53c2\u6570\u63a8\u65ad\u4e2d\u5df2\u8bc1\u660e\u80fd\u5e73\u8861\u9c81\u68d2\u6027\u548c\u6e10\u8fd1\u6548\u7387\uff0c\u4f46\u57fa\u4e8e\u6b64\u7c7b\u8ddd\u79bb\u7684\u975e\u53c2\u6570\u68c0\u9a8c\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002\u9700\u8981\u5f00\u53d1\u65e2\u4e00\u81f4\u53c8\u7a33\u5065\u7684\u975e\u53c2\u6570\u4e24\u6837\u672c\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6269\u5c55Bregman\u6563\u5ea6\u7684\u5e7f\u4e49\u4e92\u4fe1\u606f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u5e7f\u4e49S-Bregman\u6563\u5ea6\u65cf\uff0c\u7edf\u4e00\u4e86S-\u6563\u5ea6\u548cBregman\u6307\u6570\u6563\u5ea6\u3002\u5229\u7528\u5e7f\u4e49\u4e92\u4fe1\u606f\u6784\u5efa\u975e\u53c2\u6570\u4e24\u6837\u672c\u68c0\u9a8c\uff0c\u5efa\u7acb\u68c0\u9a8c\u7edf\u8ba1\u91cf\u5728\u96f6\u5047\u8bbe\u548c\u5c40\u90e8\u5907\u62e9\u4e0b\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u901a\u8fc7\u5f71\u54cd\u51fd\u6570\u548c\u5d29\u6e83\u70b9\u7814\u7a76\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u8c03\u4f18\u53c2\u6570\u9009\u62e9\u65b9\u6848\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u68c0\u9a8c\u7edf\u8ba1\u91cf\u5177\u6709\u6e10\u8fd1\u6b63\u6001\u6027\uff1b\u9c81\u68d2\u6027\u5206\u6790\uff1a\u5e7f\u4e49\u4e92\u4fe1\u606f\u7684\u7a33\u5b9a\u6027\u8f6c\u5316\u4e3a\u68c0\u9a8c\u7684\u7a33\u5b9a\u6027\uff1b\u6a21\u62df\u7814\u7a76\uff1a\u8d85\u8d8a\u5e42\u6563\u5ea6\u65cf\u7684\u6563\u5ea6\u5728\u6c61\u67d3\u4e0b\u5177\u6709\u66f4\u4f18\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6e10\u8fd1\u529f\u6548\uff1b\u5b9e\u9645\u5e94\u7528\uff1a\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e7f\u4e49\u4e92\u4fe1\u606f\u6846\u67b6\u4e3a\u6784\u5efa\u7a33\u5065\u7684\u975e\u53c2\u6570\u4e24\u6837\u672c\u68c0\u9a8c\u63d0\u4f9b\u4e86\u7edf\u4e00\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86S-Bregman\u6563\u5ea6\u65cf\u5728\u975e\u53c2\u6570\u68c0\u9a8c\u4e2d\u7684\u5e94\u7528\uff0c\u5728\u4fdd\u6301\u7edf\u8ba1\u529f\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.03896", "categories": ["stat.ML", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.03896", "abs": "https://arxiv.org/abs/2602.03896", "authors": ["Michael Ibrahim", "Hanqi Zhao", "Eli Sennesh", "Zhi Li", "Anqi Wu", "Jacob L. Yates", "Chengrui Li", "Hadi Vafaii"], "title": "A Hitchhiker's Guide to Poisson Gradient Estimation", "comment": "Code: https://github.com/hadivafaii/PoissonGradientEstimation", "summary": "Poisson-distributed latent variable models are widely used in computational neuroscience, but differentiating through discrete stochastic samples remains challenging. Two approaches address this: Exponential Arrival Time (EAT) simulation and Gumbel-SoftMax (GSM) relaxation. We provide the first systematic comparison of these methods, along with practical guidance for practitioners. Our main technical contribution is a modification to the EAT method that theoretically guarantees an unbiased first moment (exactly matching the firing rate), and reduces second-moment bias. We evaluate these methods on their distributional fidelity, gradient quality, and performance on two tasks: (1) variational autoencoders with Poisson latents, and (2) partially observable generalized linear models, where latent neural connectivity must be inferred from observed spike trains. Across all metrics, our modified EAT method exhibits better overall performance (often comparable to exact gradients), and substantially higher robustness to hyperparameter choices. Together, our results clarify the trade-offs between these methods and offer concrete recommendations for practitioners working with Poisson latent variable models.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u6cca\u677e\u6f5c\u53d8\u91cf\u6a21\u578b\u4e2d\u7684\u4e24\u79cd\u68af\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff08EAT\u548cGSM\uff09\uff0c\u63d0\u51fa\u6539\u8fdb\u7684EAT\u65b9\u6cd5\u4fdd\u8bc1\u4e00\u9636\u77e9\u65e0\u504f\u5e76\u51cf\u5c11\u4e8c\u9636\u77e9\u504f\u5dee\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6cca\u677e\u6f5c\u53d8\u91cf\u6a21\u578b\u5728\u8ba1\u7b97\u795e\u7ecf\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u901a\u8fc7\u79bb\u6563\u968f\u673a\u6837\u672c\u8fdb\u884c\u5fae\u5206\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u73b0\u6709\u7684\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff08EAT\u548cGSM\uff09\uff0c\u5e76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "method": "1. \u7cfb\u7edf\u6bd4\u8f83EAT\uff08\u6307\u6570\u5230\u8fbe\u65f6\u95f4\uff09\u6a21\u62df\u548cGumbel-SoftMax\u677e\u5f1b\u4e24\u79cd\u65b9\u6cd5\uff1b2. \u63d0\u51fa\u6539\u8fdb\u7684EAT\u65b9\u6cd5\uff0c\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e00\u9636\u77e9\u65e0\u504f\uff08\u7cbe\u786e\u5339\u914d\u53d1\u653e\u7387\uff09\u5e76\u51cf\u5c11\u4e8c\u9636\u77e9\u504f\u5dee\uff1b3. \u5728\u5206\u5e03\u4fdd\u771f\u5ea6\u3001\u68af\u5ea6\u8d28\u91cf\u548c\u4e24\u4e2a\u4efb\u52a1\u4e0a\u8bc4\u4f30\u65b9\u6cd5\uff1a\u6cca\u677e\u6f5c\u53d8\u91cf\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u3002", "result": "\u6539\u8fdb\u7684EAT\u65b9\u6cd5\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6574\u4f53\u6027\u80fd\uff08\u901a\u5e38\u4e0e\u7cbe\u786e\u68af\u5ea6\u76f8\u5f53\uff09\uff0c\u5e76\u4e14\u5bf9\u8d85\u53c2\u6570\u9009\u62e9\u5177\u6709\u663e\u8457\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u4fdd\u771f\u5ea6\u548c\u68af\u5ea6\u8d28\u91cf\u65b9\u9762\u4f18\u4e8eGSM\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u9610\u660e\u4e86\u6cca\u677e\u6f5c\u53d8\u91cf\u6a21\u578b\u4e2d\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae\u3002\u6539\u8fdb\u7684EAT\u65b9\u6cd5\u56e0\u5176\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u6210\u4e3a\u63a8\u8350\u9009\u62e9\u3002"}}
{"id": "2602.04679", "categories": ["stat.CO", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04679", "abs": "https://arxiv.org/abs/2602.04679", "authors": ["Eleni Oikonomaki", "Belivanis Dimitris", "Kakderi Christina"], "title": "LID Framework: A new method for geospatial and exploratory data analysis of potential innovation deter-minants at the neighborhood level", "comment": null, "summary": "The geography of innovation offers a framework to understand how territorial characteristics shape innovation, often via spatial and cognitive proximity. Empirical research has focused largely on national and regional scales, while urban and sub-regional geographies receive less attention. Local studies typically rely on limited indicators (e.g., firm-level data, patents, basic socioeconomic measures), with few offering a systematic framework integrating urban form, mobility, amenities, and human-capital proxies at the neighborhood scale. Our study investigates innovation at a finer spatial resolution, going beyond proprietary or static indicators. We develop the Local Innovation Determinants (LID) database and framework to identify key enabling factors across regions, combining traditional government data with publicly available data via APIs for a more granular understanding of spatial dynamics shaping innovation capacity. Using exploratory big and geospatial data analytics and random forest models, we examine neighborhoods in New York and Massachusetts across four dimensions: social factors, economic characteristics, land use and mobility, morphology, and environment. Results show that alternative data sources offer significant yet underexplored potential to enhance insights into innovation dynamics. City policymakers should consider neighborhood-specific determinants and characteristics when designing and implementing local innovation strategies.", "AI": {"tldr": "\u5f00\u53d1\u672c\u5730\u521b\u65b0\u51b3\u5b9a\u56e0\u7d20\uff08LID\uff09\u6570\u636e\u5e93\u548c\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u7edf\u653f\u5e9c\u6570\u636e\u548cAPI\u516c\u5f00\u6570\u636e\uff0c\u5728\u90bb\u91cc\u5c3a\u5ea6\u5206\u6790\u521b\u65b0\u5f71\u54cd\u56e0\u7d20\uff0c\u53d1\u73b0\u66ff\u4ee3\u6570\u636e\u6e90\u5bf9\u7406\u89e3\u521b\u65b0\u52a8\u6001\u6709\u91cd\u8981\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u521b\u65b0\u5730\u7406\u7814\u7a76\u591a\u5173\u6ce8\u56fd\u5bb6\u548c\u533a\u57df\u5c3a\u5ea6\uff0c\u57ce\u5e02\u548c\u6b21\u533a\u57df\u5c3a\u5ea6\u7814\u7a76\u8f83\u5c11\uff0c\u4e14\u901a\u5e38\u4f9d\u8d56\u6709\u9650\u6307\u6807\uff08\u5982\u4f01\u4e1a\u6570\u636e\u3001\u4e13\u5229\u7b49\uff09\uff0c\u7f3a\u4e4f\u6574\u5408\u57ce\u5e02\u5f62\u6001\u3001\u6d41\u52a8\u6027\u3001\u8bbe\u65bd\u548c\u4eba\u529b\u8d44\u672c\u4ee3\u7406\u7684\u7cfb\u7edf\u6846\u67b6\u3002", "method": "\u5f00\u53d1LID\u6570\u636e\u5e93\u548c\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u7edf\u653f\u5e9c\u6570\u636e\u548cAPI\u516c\u5f00\u6570\u636e\uff0c\u4f7f\u7528\u63a2\u7d22\u6027\u5927\u6570\u636e\u548c\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\u4ee5\u53ca\u968f\u673a\u68ee\u6797\u6a21\u578b\uff0c\u5206\u6790\u7ebd\u7ea6\u548c\u9a6c\u8428\u8bf8\u585e\u5dde\u90bb\u91cc\u5728\u56db\u4e2a\u7ef4\u5ea6\uff1a\u793e\u4f1a\u56e0\u7d20\u3001\u7ecf\u6d4e\u7279\u5f81\u3001\u571f\u5730\u5229\u7528\u4e0e\u6d41\u52a8\u6027\u3001\u5f62\u6001\u4e0e\u73af\u5883\u3002", "result": "\u66ff\u4ee3\u6570\u636e\u6e90\u63d0\u4f9b\u4e86\u663e\u8457\u4f46\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u7684\u6f5c\u529b\uff0c\u80fd\u589e\u5f3a\u5bf9\u521b\u65b0\u52a8\u6001\u7684\u7406\u89e3\u3002\u57ce\u5e02\u653f\u7b56\u5236\u5b9a\u8005\u5728\u8bbe\u8ba1\u548c\u5b9e\u65bd\u672c\u5730\u521b\u65b0\u6218\u7565\u65f6\u5e94\u8003\u8651\u90bb\u91cc\u7279\u5b9a\u7684\u51b3\u5b9a\u56e0\u7d20\u548c\u7279\u5f81\u3002", "conclusion": "\u9700\u8981\u5728\u66f4\u7cbe\u7ec6\u7684\u7a7a\u95f4\u5c3a\u5ea6\u4e0a\u7814\u7a76\u521b\u65b0\uff0c\u7ed3\u5408\u591a\u79cd\u6570\u636e\u6e90\u548c\u7ef4\u5ea6\uff0c\u4e3a\u57ce\u5e02\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u521b\u65b0\u5f71\u54cd\u56e0\u7d20\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2602.03948", "categories": ["stat.ML", "cs.CR", "cs.LG", "cs.SI", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.03948", "abs": "https://arxiv.org/abs/2602.03948", "authors": ["Bibhabasu Mandal", "Sagnik Nandy"], "title": "Privacy utility trade offs for parameter estimation in degree heterogeneous higher order networks", "comment": null, "summary": "In sensitive applications involving relational datasets, protecting information about individual links from adversarial queries is of paramount importance. In many such settings, the available data are summarized solely through the degrees of the nodes in the network. We adopt the $\u03b2$ model, which is the prototypical statistical model adopted for this form of aggregated relational information, and study the problem of minimax-optimal parameter estimation under both local and central differential privacy constraints. We establish finite sample minimax lower bounds that characterize the precise dependence of the estimation risk on the network size and the privacy parameters, and we propose simple estimators that achieve these bounds up to constants and logarithmic factors under both local and central differential privacy frameworks. Our results provide the first comprehensive finite sample characterization of privacy utility trade offs for parameter estimation in $\u03b2$ models, addressing the classical graph case and extending the analysis to higher order hypergraph models. We further demonstrate the effectiveness of our methods through experiments on synthetic data and a real world communication network.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5173\u7cfb\u6570\u636e\u96c6\u4e2d\u4fdd\u62a4\u4e2a\u4f53\u94fe\u63a5\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u9488\u5bf9\u4ec5\u901a\u8fc7\u8282\u70b9\u5ea6\u6c47\u603b\u7684\u6570\u636e\uff0c\u91c7\u7528\u03b2\u6a21\u578b\uff0c\u5728\u672c\u5730\u548c\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u5efa\u7acb\u4e86\u53c2\u6570\u4f30\u8ba1\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u6027\u7406\u8bba\u3002", "motivation": "\u5728\u6d89\u53ca\u5173\u7cfb\u6570\u636e\u96c6\u7684\u654f\u611f\u5e94\u7528\u4e2d\uff0c\u4fdd\u62a4\u4e2a\u4f53\u94fe\u63a5\u4fe1\u606f\u514d\u53d7\u5bf9\u6297\u6027\u67e5\u8be2\u81f3\u5173\u91cd\u8981\u3002\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u53ef\u7528\u6570\u636e\u4ec5\u901a\u8fc7\u7f51\u7edc\u4e2d\u7684\u8282\u70b9\u5ea6\u8fdb\u884c\u6c47\u603b\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\u3002", "method": "\u91c7\u7528\u03b2\u6a21\u578b\u4f5c\u4e3a\u805a\u5408\u5173\u7cfb\u4fe1\u606f\u7684\u539f\u578b\u7edf\u8ba1\u6a21\u578b\uff0c\u5728\u672c\u5730\u548c\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\uff0c\u5efa\u7acb\u6709\u9650\u6837\u672c\u6781\u5c0f\u6781\u5927\u4e0b\u754c\uff0c\u5e76\u63d0\u51fa\u7b80\u5355\u4f30\u8ba1\u5668\uff0c\u5728\u4e24\u79cd\u9690\u79c1\u6846\u67b6\u4e0b\u90fd\u80fd\u8fbe\u5230\u8fd9\u4e9b\u754c\uff08\u6700\u591a\u76f8\u5dee\u5e38\u6570\u548c\u5bf9\u6570\u56e0\u5b50\uff09\u3002", "result": "\u5efa\u7acb\u4e86\u7cbe\u786e\u523b\u753b\u4f30\u8ba1\u98ce\u9669\u4e0e\u7f51\u7edc\u89c4\u6a21\u548c\u9690\u79c1\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\u7684\u6709\u9650\u6837\u672c\u6781\u5c0f\u6781\u5927\u4e0b\u754c\uff0c\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5728\u4e24\u79cd\u9690\u79c1\u6846\u67b6\u4e0b\u90fd\u80fd\u8fbe\u5230\u8fd9\u4e9b\u754c\u3002\u8fd9\u662f\u03b2\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u9690\u79c1\u6548\u7528\u6743\u8861\u7684\u7b2c\u4e00\u4e2a\u5168\u9762\u6709\u9650\u6837\u672c\u8868\u5f81\uff0c\u6db5\u76d6\u7ecf\u5178\u56fe\u60c5\u51b5\u5e76\u6269\u5c55\u5230\u9ad8\u9636\u8d85\u56fe\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u03b2\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u9690\u79c1\u6548\u7528\u6743\u8861\u7406\u8bba\u6846\u67b6\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u901a\u4fe1\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2602.04788", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.04788", "abs": "https://arxiv.org/abs/2602.04788", "authors": ["Louise Alamichel", "Julyan Arbel", "Guillaume Kon Kam King", "Igor Pr\u00fcnster"], "title": "Species Sensitivity Distribution revisited: a Bayesian nonparametric approach", "comment": null, "summary": "We present a novel approach to ecological risk assessment by recasting the Species Sensitivity Distribution (SSD) method within a Bayesian nonparametric (BNP) framework. Widely mandated by environmental regulatory bodies globally, SSD has faced criticism due to its historical reliance on parametric assumptions when modeling species variability. By adopting nonparametric mixture models, we address this limitation, establishing a statistically robust foundation for SSD. Our BNP approach offers several advantages, including its efficacy in handling small datasets or censored data, which are common in ecological risk assessment, and its ability to provide principled uncertainty quantification alongside simultaneous density estimation and clustering. We utilize a specific nonparametric prior as the mixing measure, chosen for its robust clustering properties, a crucial consideration given the lack of strong prior beliefs about the number of components. Through simulation studies and analysis of real datasets, we demonstrate the superiority of our BNP-SSD over classical SSD methods. We also provide a BNP-SSD Shiny application, making our methodology available to the Ecotoxicology community. Moreover, we exploit the inherent clustering structure of the mixture model to explore patterns in species sensitivity. Our findings underscore the effectiveness of the proposed approach in improving ecological risk assessment methodologies.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u7269\u79cd\u654f\u611f\u5ea6\u5206\u5e03\u65b9\u6cd5\u7f6e\u4e8e\u8d1d\u53f6\u65af\u975e\u53c2\u6570\u6846\u67b6\u4e2d\uff0c\u89e3\u51b3\u4f20\u7edf\u53c2\u6570\u5047\u8bbe\u9650\u5236\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u5c0f\u6570\u636e\u96c6\u5904\u7406\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u805a\u7c7b\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfSSD\u65b9\u6cd5\u4f9d\u8d56\u53c2\u6570\u5047\u8bbe\u5efa\u6a21\u7269\u79cd\u53d8\u5f02\u6027\uff0c\u53d7\u5230\u6279\u8bc4\u3002\u751f\u6001\u98ce\u9669\u8bc4\u4f30\u4e2d\u5e38\u9047\u5230\u5c0f\u6570\u636e\u96c6\u6216\u622a\u5c3e\u6570\u636e\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u7edf\u8ba1\u57fa\u7840\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u975e\u53c2\u6570\u6df7\u5408\u6a21\u578b\uff0c\u4f7f\u7528\u5177\u6709\u7a33\u5065\u805a\u7c7b\u7279\u6027\u7684\u975e\u53c2\u6570\u5148\u9a8c\u4f5c\u4e3a\u6df7\u5408\u6d4b\u5ea6\uff0c\u5efa\u7acbBNP-SSD\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548c\u771f\u5b9e\u6570\u636e\u5206\u6790\uff0c\u8bc1\u660eBNP-SSD\u4f18\u4e8e\u7ecf\u5178SSD\u65b9\u6cd5\uff0c\u63d0\u4f9bBNP-SSD Shiny\u5e94\u7528\uff0c\u5e76\u5229\u7528\u6df7\u5408\u6a21\u578b\u7684\u805a\u7c7b\u7ed3\u6784\u63a2\u7d22\u7269\u79cd\u654f\u611f\u5ea6\u6a21\u5f0f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8d1d\u53f6\u65af\u975e\u53c2\u6570\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u8fdb\u751f\u6001\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u5b66\uff0c\u4e3a\u751f\u6001\u6bd2\u7406\u5b66\u754c\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2602.04124", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04124", "abs": "https://arxiv.org/abs/2602.04124", "authors": ["Monika Hu", "Matthew R. Williams", "Terrance D. Savitsky"], "title": "Privacy Amplification for Synthetic data using Range Restriction", "comment": "25 pages, 20 figures", "summary": "We introduce a new class of range restricted formal data privacy standards that condition on owner beliefs about sensitive data ranges. By incorporating this additional information, we can provide a stronger privacy guarantee (e.g. an amplification). The range restricted formal privacy standards protect only a subset (or ball) of data values and exclude ranges (or balls) believed to be already publicly known. The privacy standards are designed for the risk-weighted pseudo posterior (model) mechanism (PPM) used to generate synthetic data under an asymptotic Differential (aDP) privacy guarantee. The PPM downweights the likelihood contribution for each record proportionally to its disclosure risk. The PPM is adapted under inclusion of beliefs by adjusting the risk-weighted pseudo likelihood. We introduce two alternative adjustments. The first expresses data owner knowledge of the sensitive range as a probability, $\u03bb$, that a datum value drawn from the underlying generating distribution lies outside the ball or subspace of values that are sensitive. The portion of each datum likelihood contribution deemed sensitive is then $(1-\u03bb) \\leq 1$ and is the only portion of the likelihood subject to risk down-weighting. The second adjustment encodes knowledge as the difference in probability masses $P(R) \\leq 1$ between the edges of the sensitive range, $R$. We use the resulting conditional (pseudo) likelihood for a sensitive record, which boosts its worst case tail values away from 0. We compare privacy and utility properties for the PPM under the aDP and range restricted privacy standards.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u56f4\u9650\u5236\u5f62\u5f0f\u5316\u6570\u636e\u9690\u79c1\u6807\u51c6\uff0c\u901a\u8fc7\u7eb3\u5165\u6570\u636e\u6240\u6709\u8005\u5bf9\u654f\u611f\u6570\u636e\u8303\u56f4\u7684\u5148\u9a8c\u4fe1\u5ff5\uff0c\u63d0\u4f9b\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u969c\uff08\u5982\u9690\u79c1\u653e\u5927\uff09\u3002\u8be5\u6807\u51c6\u4ec5\u4fdd\u62a4\u654f\u611f\u503c\u5b50\u96c6\uff0c\u6392\u9664\u5df2\u516c\u5f00\u7684\u8303\u56f4\uff0c\u9002\u7528\u4e8e\u98ce\u9669\u52a0\u6743\u4f2a\u540e\u9a8c\u673a\u5236\u751f\u6210\u5408\u6210\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u6807\u51c6\u5bf9\u6240\u6709\u6570\u636e\u63d0\u4f9b\u7edf\u4e00\u4fdd\u62a4\uff0c\u4f46\u5b9e\u9645\u4e2d\u6570\u636e\u6240\u6709\u8005\u53ef\u80fd\u5bf9\u654f\u611f\u6570\u636e\u8303\u56f4\u6709\u5148\u9a8c\u4fe1\u5ff5\u3002\u901a\u8fc7\u7eb3\u5165\u8fd9\u4e9b\u4fe1\u5ff5\u4fe1\u606f\uff0c\u53ef\u4ee5\u9488\u5bf9\u6027\u5730\u4fdd\u62a4\u771f\u6b63\u654f\u611f\u7684\u6570\u636e\u8303\u56f4\uff0c\u6392\u9664\u5df2\u516c\u5f00\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u969c\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u8c03\u6574\u98ce\u9669\u52a0\u6743\u4f2a\u4f3c\u7136\u7684\u65b9\u6cd5\uff1a1\uff09\u7528\u6982\u7387\u03bb\u8868\u793a\u6570\u636e\u503c\u843d\u5728\u654f\u611f\u8303\u56f4\u5916\u7684\u4fe1\u5ff5\uff0c\u53ea\u6709(1-\u03bb)\u90e8\u5206\u88ab\u89c6\u4e3a\u654f\u611f\u5e76\u63a5\u53d7\u98ce\u9669\u964d\u6743\uff1b2\uff09\u7528\u6982\u7387\u8d28\u91cf\u5deeP(R)\u7f16\u7801\u654f\u611f\u8303\u56f4\u8fb9\u7f18\u7684\u77e5\u8bc6\u3002\u5c06\u8c03\u6574\u540e\u7684\u6761\u4ef6\u4f2a\u4f3c\u7136\u5e94\u7528\u4e8e\u654f\u611f\u8bb0\u5f55\uff0c\u63d0\u5347\u5176\u6700\u574f\u60c5\u51b5\u5c3e\u90e8\u503c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6e10\u8fdb\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u4e0b\uff0c\u901a\u8fc7\u8303\u56f4\u9650\u5236\u9690\u79c1\u6807\u51c6\u589e\u5f3a\u4e86\u9690\u79c1\u4fdd\u62a4\u5f3a\u5ea6\uff08\u5b9e\u73b0\u9690\u79c1\u653e\u5927\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6570\u636e\u6548\u7528\u3002\u6bd4\u8f83\u4e86PPM\u5728aDP\u548c\u8303\u56f4\u9650\u5236\u9690\u79c1\u6807\u51c6\u4e0b\u7684\u9690\u79c1\u4e0e\u6548\u7528\u7279\u6027\u3002", "conclusion": "\u901a\u8fc7\u7eb3\u5165\u6570\u636e\u6240\u6709\u8005\u5bf9\u654f\u611f\u8303\u56f4\u7684\u4fe1\u5ff5\uff0c\u8303\u56f4\u9650\u5236\u5f62\u5f0f\u5316\u9690\u79c1\u6807\u51c6\u80fd\u591f\u63d0\u4f9b\u6bd4\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u969c\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u6548\u7528\uff0c\u4e3a\u5408\u6210\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\u3002"}}
{"id": "2602.04751", "categories": ["stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04751", "abs": "https://arxiv.org/abs/2602.04751", "authors": ["Enzo Porto Brasil"], "title": "Multiple Imputation Methods under Extreme Values", "comment": "36 pages main text, 20 pages appendix, 12 figures, 28 tables. Submitted to the Austrian Journal of Statistics (under review)", "summary": "Missing data are ubiquitous in empirical databases, yet statistical analyses typically require complete data matrices. Multiple imputation offers a principled solution for filling these gaps. This study evaluates the performance of several multiple imputation methods, both in the presence and absence of extreme values, using the MICE package in R. Through Monte Carlo simulations, we generated incomplete data sets with three variables and assessed each imputation method within regression models. The results indicate that the linear regression based imputation method showed the best overall predictive performance (CV-MSE), whereas the sparse model approach was generally less efficient. Our findings underscore the relevance of extreme values when selecting an imputation strategy and highlight sample size, proportion of missingness, presence of extremes, and the type of fitted model as key determinants of performance. Despite its limitations, the study offers practical recommendations for researchers, stressing the need to examine the missingness mechanism and the occurrence of extreme values before choosing an imputation method.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cd\u591a\u91cd\u63d2\u8865\u65b9\u6cd5\u5728\u6709\u65e0\u6781\u7aef\u503c\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u7ebf\u6027\u56de\u5f52\u7684\u63d2\u8865\u65b9\u6cd5\u6574\u4f53\u9884\u6d4b\u6027\u80fd\u6700\u4f73\uff0c\u800c\u7a00\u758f\u6a21\u578b\u65b9\u6cd5\u6548\u7387\u8f83\u4f4e\u3002", "motivation": "\u5b9e\u8bc1\u6570\u636e\u5e93\u4e2d\u666e\u904d\u5b58\u5728\u7f3a\u5931\u6570\u636e\uff0c\u4f46\u7edf\u8ba1\u5206\u6790\u901a\u5e38\u9700\u8981\u5b8c\u6574\u6570\u636e\u77e9\u9635\u3002\u591a\u91cd\u63d2\u8865\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6848\uff0c\u4f46\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u9700\u8981\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528R\u8bed\u8a00\u4e2d\u7684MICE\u5305\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u751f\u6210\u5305\u542b\u4e09\u4e2a\u53d8\u91cf\u7684\u4e0d\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u5728\u56de\u5f52\u6a21\u578b\u4e2d\u8bc4\u4f30\u5404\u79cd\u591a\u91cd\u63d2\u8865\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u57fa\u4e8e\u7ebf\u6027\u56de\u5f52\u7684\u63d2\u8865\u65b9\u6cd5\u663e\u793a\u51fa\u6700\u4f73\u7684\u6574\u4f53\u9884\u6d4b\u6027\u80fd\uff08CV-MSE\uff09\uff0c\u800c\u7a00\u758f\u6a21\u578b\u65b9\u6cd5\u901a\u5e38\u6548\u7387\u8f83\u4f4e\u3002\u6781\u7aef\u503c\u7684\u5b58\u5728\u3001\u6837\u672c\u5927\u5c0f\u3001\u7f3a\u5931\u6bd4\u4f8b\u3001\u6781\u7aef\u503c\u51fa\u73b0\u4ee5\u53ca\u62df\u5408\u6a21\u578b\u7c7b\u578b\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u9009\u62e9\u63d2\u8865\u7b56\u7565\u65f6\u8003\u8651\u6781\u7aef\u503c\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\uff1a\u5728\u9009\u62e9\u63d2\u8865\u65b9\u6cd5\u524d\uff0c\u9700\u8981\u68c0\u67e5\u7f3a\u5931\u673a\u5236\u548c\u6781\u7aef\u503c\u7684\u51fa\u73b0\u60c5\u51b5\u3002"}}
{"id": "2602.03970", "categories": ["stat.ML", "cs.LG", "cs.NE", "math.MG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.03970", "abs": "https://arxiv.org/abs/2602.03970", "authors": ["Anastasis Kratsios", "Giulia Livieri", "A. Martina Neuman"], "title": "Statistical Guarantees for Reasoning Probes on Looped Boolean Circuits", "comment": null, "summary": "We study the statistical behaviour of reasoning probes in a stylized model of looped reasoning, given by Boolean circuits whose computational graph is a perfect $\u03bd$-ary tree ($\u03bd\\ge 2$) and whose output is appended to the input and fed back iteratively for subsequent computation rounds. A reasoning probe has access to a sampled subset of internal computation nodes, possibly without covering the entire graph, and seeks to infer which $\u03bd$-ary Boolean gate is executed at each queried node, representing uncertainty via a probability distribution over a fixed collection of $\\mathtt{m}$ admissible $\u03bd$-ary gates. This partial observability induces a generalization problem, which we analyze in a realizable, transductive setting.\n  We show that, when the reasoning probe is parameterized by a graph convolutional network (GCN)-based hypothesis class and queries $N$ nodes, the worst-case generalization error attains the optimal rate $\\mathcal{O}(\\sqrt{\\log(2/\u03b4)}/\\sqrt{N})$ with probability at least $1-\u03b4$, for $\u03b4\\in (0,1)$. Our analysis combines snowflake metric embedding techniques with tools from statistical optimal transport. A key insight is that this optimal rate is achievable independently of graph size, owing to the existence of a low-distortion one-dimensional snowflake embedding of the induced graph metric. As a consequence, our results provide a sharp characterization of how structural properties of the computational graph govern the statistical efficiency of reasoning under partial access.", "AI": {"tldr": "\u7814\u7a76\u5faa\u73af\u63a8\u7406\u4e2d\u63a8\u7406\u63a2\u9488\u7684\u7edf\u8ba1\u884c\u4e3a\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\uff0c\u4f7f\u7528GCN\u53c2\u6570\u5316\u7684\u63a8\u7406\u63a2\u9488\u80fd\u591f\u8fbe\u5230\u6700\u4f18\u6cdb\u5316\u8bef\u5dee\u7387\uff0c\u4e14\u4e0e\u56fe\u5927\u5c0f\u65e0\u5173\u3002", "motivation": "\u7814\u7a76\u5728\u5faa\u73af\u63a8\u7406\u6a21\u578b\u4e2d\uff0c\u5f53\u63a8\u7406\u63a2\u9488\u53ea\u80fd\u8bbf\u95ee\u8ba1\u7b97\u56fe\u7684\u90e8\u5206\u8282\u70b9\u65f6\uff0c\u5982\u4f55\u5206\u6790\u5176\u7edf\u8ba1\u6cdb\u5316\u6027\u80fd\u3002\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u5e26\u6765\u4e86\u6cdb\u5316\u95ee\u9898\uff0c\u9700\u8981\u7406\u89e3\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u7279\u6027\u5982\u4f55\u5f71\u54cd\u63a8\u7406\u7684\u7edf\u8ba1\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5e03\u5c14\u7535\u8def\u4f5c\u4e3a\u5faa\u73af\u63a8\u7406\u7684\u6a21\u578b\u5316\u8868\u793a\uff0c\u8ba1\u7b97\u56fe\u4e3a\u5b8c\u7f8e\u7684\u03bd\u5143\u6811\u3002\u63a8\u7406\u63a2\u9488\u901a\u8fc7GCN\u53c2\u6570\u5316\uff0c\u67e5\u8be2N\u4e2a\u8282\u70b9\u6765\u63a8\u65ad\u6bcf\u4e2a\u67e5\u8be2\u8282\u70b9\u6267\u884c\u7684\u5e03\u5c14\u95e8\u7c7b\u578b\u3002\u5206\u6790\u7ed3\u5408\u96ea\u82b1\u5ea6\u91cf\u5d4c\u5165\u6280\u672f\u548c\u7edf\u8ba1\u6700\u4f18\u4f20\u8f93\u5de5\u5177\u3002", "result": "\u5f53\u63a8\u7406\u63a2\u9488\u4f7f\u7528GCN\u53c2\u6570\u5316\u5e76\u67e5\u8be2N\u4e2a\u8282\u70b9\u65f6\uff0c\u6700\u574f\u60c5\u51b5\u6cdb\u5316\u8bef\u5dee\u8fbe\u5230\u6700\u4f18\u901f\u7387O(\u221alog(2/\u03b4)/\u221aN)\uff0c\u6982\u7387\u81f3\u5c11\u4e3a1-\u03b4\u3002\u8fd9\u4e00\u6700\u4f18\u901f\u7387\u4e0e\u56fe\u5927\u5c0f\u65e0\u5173\uff0c\u5f52\u56e0\u4e8e\u8bf1\u5bfc\u56fe\u5ea6\u91cf\u5b58\u5728\u4f4e\u5931\u771f\u7684\u4e00\u7ef4\u96ea\u82b1\u5d4c\u5165\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u7279\u6027\uff08\u7279\u522b\u662f\u5b58\u5728\u4f4e\u5931\u771f\u96ea\u82b1\u5d4c\u5165\uff09\u51b3\u5b9a\u4e86\u90e8\u5206\u8bbf\u95ee\u4e0b\u63a8\u7406\u7684\u7edf\u8ba1\u6548\u7387\u3002\u8fd9\u4e3a\u7406\u89e3\u5faa\u73af\u63a8\u7406\u4e2d\u63a8\u7406\u63a2\u9488\u7684\u7edf\u8ba1\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2602.03954", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.03954", "abs": "https://arxiv.org/abs/2602.03954", "authors": ["Quanjun Lang", "Xiong Wang", "Fei Lu", "Mauro Maggioni"], "title": "Learning Multi-type heterogeneous interacting particle systems", "comment": null, "summary": "We propose a framework for the joint inference of network topology, multi-type interaction kernels, and latent type assignments in heterogeneous interacting particle systems from multi-trajectory data. This learning task is a challenging non-convex mixed-integer optimization problem, which we address through a novel three-stage approach. First, we leverage shared structure across agent interactions to recover a low-rank embedding of the system parameters via matrix sensing. Second, we identify discrete interaction types by clustering within the learned embedding. Third, we recover the network weight matrix and kernel coefficients through matrix factorization and a post-processing refinement. We provide theoretical guarantees with estimation error bounds under a Restricted Isometry Property (RIP) assumption and establish conditions for the exact recovery of interaction types based on cluster separability. Numerical experiments on synthetic datasets, including heterogeneous predator-prey systems, demonstrate that our method yields an accurate reconstruction of the underlying dynamics and is robust to noise.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ece\u591a\u8f68\u8ff9\u6570\u636e\u4e2d\u8054\u5408\u63a8\u65ad\u5f02\u8d28\u4ea4\u4e92\u7c92\u5b50\u7cfb\u7edf\u7684\u7f51\u7edc\u62d3\u6251\u3001\u591a\u7c7b\u578b\u4ea4\u4e92\u6838\u548c\u6f5c\u5728\u7c7b\u578b\u5206\u914d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u65b9\u6cd5\u89e3\u51b3\u975e\u51f8\u6df7\u5408\u6574\u6570\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u5f02\u8d28\u4ea4\u4e92\u7c92\u5b50\u7cfb\u7edf\uff08\u5982\u751f\u7269\u7fa4\u4f53\u3001\u793e\u4ea4\u7f51\u7edc\uff09\u4e2d\uff0c\u4e0d\u540c\u4e2a\u4f53\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u4ea4\u4e92\u7c7b\u578b\u548c\u5f3a\u5ea6\uff0c\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u8054\u5408\u63a8\u65ad\u7f51\u7edc\u7ed3\u6784\u3001\u4ea4\u4e92\u6838\u548c\u7c7b\u578b\u5206\u914d\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u975e\u51f8\u6df7\u5408\u6574\u6570\u4f18\u5316\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5229\u7528\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u5171\u4eab\u7ed3\u6784\uff0c\u901a\u8fc7\u77e9\u9635\u611f\u77e5\u6062\u590d\u7cfb\u7edf\u53c2\u6570\u7684\u4f4e\u79e9\u5d4c\u5165\uff1b2) \u5728\u5b66\u5230\u7684\u5d4c\u5165\u4e2d\u901a\u8fc7\u805a\u7c7b\u8bc6\u522b\u79bb\u6563\u4ea4\u4e92\u7c7b\u578b\uff1b3) \u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u540e\u5904\u7406\u7ec6\u5316\u6062\u590d\u7f51\u7edc\u6743\u91cd\u77e9\u9635\u548c\u6838\u7cfb\u6570\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\uff08\u5305\u62ec\u5f02\u8d28\u6355\u98df\u8005-\u88ab\u6355\u98df\u8005\u7cfb\u7edf\uff09\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u91cd\u5efa\u5e95\u5c42\u52a8\u6001\uff0c\u5e76\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\u3002\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u5728RIP\u5047\u8bbe\u4e0b\u7684\u4f30\u8ba1\u8bef\u5dee\u754c\uff0c\u5e76\u5efa\u7acb\u4e86\u57fa\u4e8e\u805a\u7c7b\u53ef\u5206\u79bb\u6027\u7684\u4ea4\u4e92\u7c7b\u578b\u7cbe\u786e\u6062\u590d\u6761\u4ef6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4ece\u591a\u8f68\u8ff9\u6570\u636e\u4e2d\u5b66\u4e60\u5f02\u8d28\u4ea4\u4e92\u7c92\u5b50\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u9002\u7528\u4e8e\u751f\u7269\u7fa4\u4f53\u52a8\u6001\u5efa\u6a21\u7b49\u573a\u666f\u3002"}}
{"id": "2602.04318", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.04318", "abs": "https://arxiv.org/abs/2602.04318", "authors": ["Yoshiki Kinoshita", "Aya Shinozaki", "Toshinari Kamakura"], "title": "Accurate and Efficient Approximation of the Null Distribution of Rao's Spacing Test", "comment": "10 pages", "summary": "Rao's spacing test is a widely used nonparametric method for assessing uniformity on the circle. However, its broader applicability in practical settings has been limited because the null distribution is not easily calculated. As a result, practitioners have traditionally depended on pre-tabulated critical values computed for a limited set of sample sizes, which restricts the flexibility and generality of the method. In this paper, we address this limitation by recursively computing higher-order moments of the Rao's spacing test statistic and employing the Gram-Charlier expansion to derive an accurate approximation to its null distribution. This approach allows for the efficient and direct computation of p-values for arbitrary sample sizes, thereby eliminating the dependency on existing critical value tables. Moreover, we confirm that our method remains accurate and effective even for large sample sizes that are not represented in current tables, thus overcoming a significant practical limitation. Comparative evaluations with published critical values and saddlepoint approximations demonstrate that our method achieves a high degree of accuracy across a wide range of sample sizes. These findings greatly improve the practicality and usability of Rao's spacing test in both theoretical investigations and applied statistical analyses.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u9636\u77e9\u9012\u5f52\u8ba1\u7b97\u548cGram-Charlier\u5c55\u5f00\u7684\u65b9\u6cd5\uff0c\u8fd1\u4f3cRao\u95f4\u8ddd\u68c0\u9a8c\u7684\u96f6\u5206\u5e03\uff0c\u5b9e\u73b0\u4efb\u610f\u6837\u672c\u91cf\u4e0bp\u503c\u7684\u9ad8\u6548\u8ba1\u7b97\uff0c\u6446\u8131\u4f20\u7edf\u4e34\u754c\u503c\u8868\u7684\u9650\u5236\u3002", "motivation": "Rao\u95f4\u8ddd\u68c0\u9a8c\u4f5c\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5706\u5f62\u5747\u5300\u6027\u975e\u53c2\u6570\u68c0\u9a8c\u65b9\u6cd5\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d7\u5230\u9650\u5236\uff0c\u56e0\u4e3a\u5176\u96f6\u5206\u5e03\u96be\u4ee5\u8ba1\u7b97\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u6837\u672c\u91cf\u7684\u9884\u8ba1\u7b97\u4e34\u754c\u503c\u8868\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u901a\u7528\u6027\u3002", "method": "\u901a\u8fc7\u9012\u5f52\u8ba1\u7b97Rao\u95f4\u8ddd\u68c0\u9a8c\u7edf\u8ba1\u91cf\u7684\u9ad8\u9636\u77e9\uff0c\u5e76\u91c7\u7528Gram-Charlier\u5c55\u5f00\u6765\u63a8\u5bfc\u5176\u96f6\u5206\u5e03\u7684\u7cbe\u786e\u8fd1\u4f3c\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u76f4\u63a5\u5730\u8ba1\u7b97\u4efb\u610f\u6837\u672c\u91cf\u7684p\u503c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u8ba1\u7b97\u4efb\u610f\u6837\u672c\u91cf\u7684p\u503c\uff0c\u5373\u4f7f\u5728\u5f53\u524d\u8868\u4e2d\u672a\u5305\u542b\u7684\u5927\u6837\u672c\u91cf\u60c5\u51b5\u4e0b\u4e5f\u4fdd\u6301\u51c6\u786e\u6709\u6548\u3002\u4e0e\u5df2\u53d1\u8868\u4e34\u754c\u503c\u548c\u978d\u70b9\u8fd1\u4f3c\u7684\u6bd4\u8f83\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5e7f\u6cdb\u7684\u6837\u672c\u91cf\u8303\u56f4\u5185\u5b9e\u73b0\u4e86\u9ad8\u5ea6\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86Rao\u95f4\u8ddd\u68c0\u9a8c\u5728\u7406\u8bba\u7814\u7a76\u548c\u5e94\u7528\u7edf\u8ba1\u5206\u6790\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u7528\u6027\uff0c\u6d88\u9664\u4e86\u5bf9\u73b0\u6709\u4e34\u754c\u503c\u8868\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u7075\u6d3b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2602.04230", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.04230", "abs": "https://arxiv.org/abs/2602.04230", "authors": ["Albert Tan", "Sadegh Shirani", "James Nordlund", "Mohsen Bayati"], "title": "Validating Causal Message Passing Against Network-Aware Methods on Real Experiments", "comment": null, "summary": "Estimating total treatment effects in the presence of network interference typically requires knowledge of the underlying interaction structure. However, in many practical settings, network data is either unavailable, incomplete, or measured with substantial error. We demonstrate that causal message passing, a methodology that leverages temporal structure in outcome data rather than network topology, can recover total treatment effects comparable to network-aware approaches. We apply causal message passing to two large-scale field experiments where a recently developed bipartite graph methodology, which requires network knowledge, serves as a benchmark. Despite having no access to the interaction network, causal message passing produces effect estimates that match the network-aware approach in direction across all metrics and in statistical significance for the primary decision metric. Our findings validate the premise of causal message passing: that temporal variation in outcomes can serve as an effective substitute for network observation when estimating spillover effects. This has important practical implications: practitioners facing settings where network data is costly to collect, proprietary, or unreliable can instead exploit the temporal dynamics of their experimental data.", "AI": {"tldr": "\u56e0\u679c\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\u5229\u7528\u7ed3\u679c\u6570\u636e\u7684\u65f6\u95f4\u7ed3\u6784\u800c\u975e\u7f51\u7edc\u62d3\u6251\u6765\u4f30\u8ba1\u7f51\u7edc\u5e72\u6270\u4e0b\u7684\u603b\u5904\u7406\u6548\u5e94\uff0c\u5728\u7f3a\u4e4f\u7f51\u7edc\u6570\u636e\u65f6\u80fd\u83b7\u5f97\u4e0e\u7f51\u7edc\u611f\u77e5\u65b9\u6cd5\u76f8\u5f53\u7684\u6548\u679c\u4f30\u8ba1\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7f51\u7edc\u6570\u636e\u5e38\u5e38\u4e0d\u53ef\u5f97\u3001\u4e0d\u5b8c\u6574\u6216\u5b58\u5728\u4e25\u91cd\u6d4b\u91cf\u8bef\u5dee\uff0c\u8fd9\u9650\u5236\u4e86\u4f20\u7edf\u9700\u8981\u7f51\u7edc\u62d3\u6251\u4fe1\u606f\u7684\u65b9\u6cd5\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u7f51\u7edc\u89c2\u6d4b\u5c31\u80fd\u4f30\u8ba1\u6ea2\u51fa\u6548\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u56e0\u679c\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u7f51\u7edc\u62d3\u6251\u77e5\u8bc6\uff0c\u800c\u662f\u5229\u7528\u7ed3\u679c\u6570\u636e\u7684\u65f6\u95f4\u7ed3\u6784\u6765\u4f30\u8ba1\u603b\u5904\u7406\u6548\u5e94\u3002\u901a\u8fc7\u4e24\u4e2a\u5927\u89c4\u6a21\u73b0\u573a\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e0e\u9700\u8981\u7f51\u7edc\u77e5\u8bc6\u7684\u4e8c\u5206\u56fe\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u56e0\u679c\u6d88\u606f\u4f20\u9012\u5728\u6ca1\u6709\u8bbf\u95ee\u4ea4\u4e92\u7f51\u7edc\u7684\u60c5\u51b5\u4e0b\uff0c\u4ea7\u751f\u7684\u6548\u5e94\u4f30\u8ba1\u5728\u6240\u6709\u6307\u6807\u65b9\u5411\u4e0a\u4e0e\u7f51\u7edc\u611f\u77e5\u65b9\u6cd5\u4e00\u81f4\uff0c\u5728\u4e3b\u8981\u51b3\u7b56\u6307\u6807\u7684\u7edf\u8ba1\u663e\u8457\u6027\u4e0a\u4e5f\u5339\u914d\u3002\u6548\u679c\u4f30\u8ba1\u4e0e\u7f51\u7edc\u611f\u77e5\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u7ed3\u679c\u9a8c\u8bc1\u4e86\u56e0\u679c\u6d88\u606f\u4f20\u9012\u7684\u524d\u63d0\uff1a\u5728\u4f30\u8ba1\u6ea2\u51fa\u6548\u5e94\u65f6\uff0c\u7ed3\u679c\u7684\u65f6\u95f4\u53d8\u5316\u53ef\u4ee5\u6709\u6548\u5730\u66ff\u4ee3\u7f51\u7edc\u89c2\u6d4b\u3002\u8fd9\u5bf9\u5b9e\u8df5\u6709\u91cd\u8981\u542f\u793a\uff1a\u5f53\u7f51\u7edc\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u3001\u4e13\u6709\u6216\u4e0d\u53ef\u9760\u65f6\uff0c\u53ef\u4ee5\u5229\u7528\u5b9e\u9a8c\u6570\u636e\u7684\u65f6\u95f4\u52a8\u6001\u3002"}}
{"id": "2602.04400", "categories": ["stat.ME", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.04400", "abs": "https://arxiv.org/abs/2602.04400", "authors": ["F. A. Shiha"], "title": "Unit Shiha Distribution and its Applications to Engineering and Medical Data", "comment": null, "summary": "There is a growing need for flexible statistical distributions that can accurately model data defined on the unit interval. This paper introduces a new unit distribution, termed the unit Shiha (USh) distribution, which is derived from the original Shiha (Sh) distribution through an inverse exponential transformation. The probability density function of the USh distribution is sufficiently flexible to model both left- and right-skewed data, while its hazard rate function is capable of capturing various failure-rate patterns, including increasing, bathtub-shaped, and J-shaped forms. Several statistical properties of the proposed distribution are investigated, including moments and related measures, the quantile function, entropy, and stress-strength reliability. Parameter estimation is carried out using the maximum likelihood method, and its performance is evaluated through a simulation study. The practical usefulness of the USh distribution is demonstrated using four real-life data sets, and its performance is compared with several well-known competing unit distributions. The comparative results indicate that the proposed model fits the data better than the competitive models applied in this study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5355\u4f4d\u533a\u95f4\u5206\u5e03\u2014\u2014\u5355\u4f4dShiha(USh)\u5206\u5e03\uff0c\u901a\u8fc7\u9006\u6307\u6570\u53d8\u6362\u4ece\u539f\u59cbShiha\u5206\u5e03\u63a8\u5bfc\u800c\u6765\uff0c\u80fd\u591f\u7075\u6d3b\u5efa\u6a21\u5355\u4f4d\u533a\u95f4\u6570\u636e\uff0c\u5728\u56db\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7ade\u4e89\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u5bf9\u5355\u4f4d\u533a\u95f4\u6570\u636e\u5efa\u6a21\u9700\u6c42\u7684\u589e\u957f\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u7edf\u8ba1\u5206\u5e03\u6765\u51c6\u786e\u63cf\u8ff0\u8fd9\u7c7b\u6570\u636e\u3002\u73b0\u6709\u5355\u4f4d\u5206\u5e03\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6570\u636e\u7684\u5404\u79cd\u504f\u659c\u5f62\u6001\u548c\u5931\u6548\u7387\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u9006\u6307\u6570\u53d8\u6362\u4ece\u539f\u59cbShiha\u5206\u5e03\u63a8\u5bfc\u51fa\u5355\u4f4dShiha(USh)\u5206\u5e03\uff0c\u7814\u7a76\u5176\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u548c\u98ce\u9669\u7387\u51fd\u6570\u7684\u7279\u6027\uff0c\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u6cd5\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc4\u4f30\u6027\u80fd\u3002", "result": "USh\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u80fd\u591f\u7075\u6d3b\u5efa\u6a21\u5de6\u504f\u548c\u53f3\u504f\u6570\u636e\uff0c\u98ce\u9669\u7387\u51fd\u6570\u80fd\u591f\u6355\u6349\u9012\u589e\u3001\u6d74\u76c6\u5f62\u548cJ\u5f62\u7b49\u591a\u79cd\u5931\u6548\u7387\u6a21\u5f0f\u3002\u5728\u56db\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u8868\u660e\uff0cUSh\u5206\u5e03\u6bd4\u73b0\u6709\u7ade\u4e89\u6a21\u578b\u62df\u5408\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u5355\u4f4dShiha\u5206\u5e03\u662f\u4e00\u4e2a\u7075\u6d3b\u7684\u5355\u4f4d\u533a\u95f4\u5206\u5e03\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u5efa\u6a21\u5404\u79cd\u504f\u659c\u5f62\u6001\u548c\u5931\u6548\u7387\u6a21\u5f0f\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u7ade\u4e89\u6a21\u578b\u7684\u62df\u5408\u6027\u80fd\u3002"}}
{"id": "2602.04402", "categories": ["stat.ML", "cs.AI", "cs.CY", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.04402", "abs": "https://arxiv.org/abs/2602.04402", "authors": ["Julian Rodemann", "Unai Fischer-Abaigar", "James Bailie", "Krikamol Muandet"], "title": "Performative Learning Theory", "comment": "52 pages, 2 figures", "summary": "Performative predictions influence the very outcomes they aim to forecast. We study performative predictions that affect a sample (e.g., only existing users of an app) and/or the whole population (e.g., all potential app users). This raises the question of how well models generalize under performativity. For example, how well can we draw insights about new app users based on existing users when both of them react to the app's predictions? We address this question by embedding performative predictions into statistical learning theory. We prove generalization bounds under performative effects on the sample, on the population, and on both. A key intuition behind our proofs is that in the worst case, the population negates predictions, while the sample deceptively fulfills them. We cast such self-negating and self-fulfilling predictions as min-max and min-min risk functionals in Wasserstein space, respectively. Our analysis reveals a fundamental trade-off between performatively changing the world and learning from it: the more a model affects data, the less it can learn from it. Moreover, our analysis results in a surprising insight on how to improve generalization guarantees by retraining on performatively distorted samples. We illustrate our bounds in a case study on prediction-informed assignments of unemployed German residents to job trainings, drawing upon administrative labor market records from 1975 to 2017 in Germany.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728\u9884\u6d4b\u4f1a\u5f71\u54cd\u5b9e\u9645\u7ed3\u679c\uff08performative predictions\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5206\u6790\u4e86\u9884\u6d4b\u5bf9\u6837\u672c\u548c\u603b\u4f53\u4ea7\u751f\u4e0d\u540c\u5f71\u54cd\u65f6\u7684\u6cdb\u5316\u754c\u9650\uff0c\u5e76\u63ed\u793a\u4e86\u6539\u53d8\u4e16\u754c\u4e0e\u4ece\u4e16\u754c\u5b66\u4e60\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u5728\u9884\u6d4b\u4f1a\u5f71\u54cd\u5b9e\u9645\u7ed3\u679c\uff08performative predictions\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5f53\u9884\u6d4b\u4e0d\u4ec5\u5f71\u54cd\u6837\u672c\uff08\u5982\u73b0\u6709\u7528\u6237\uff09\u8fd8\u5f71\u54cd\u603b\u4f53\uff08\u5982\u6f5c\u5728\u7528\u6237\uff09\u65f6\uff0c\u5982\u4f55\u8bc4\u4f30\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff1f\u4f8b\u5982\uff0c\u5f53\u73b0\u6709\u7528\u6237\u548c\u6f5c\u5728\u7528\u6237\u90fd\u4f1a\u5bf9\u5e94\u7528\u7684\u9884\u6d4b\u505a\u51fa\u53cd\u5e94\u65f6\uff0c\u5982\u4f55\u57fa\u4e8e\u73b0\u6709\u7528\u6237\u6d1e\u5bdf\u65b0\u7528\u6237\uff1f", "method": "\u5c06performative predictions\u5d4c\u5165\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5728\u9884\u6d4b\u5f71\u54cd\u6837\u672c\u3001\u603b\u4f53\u6216\u4e24\u8005\u60c5\u51b5\u4e0b\u7684\u6cdb\u5316\u754c\u9650\u3002\u5c06\u81ea\u6211\u5426\u5b9a\u548c\u81ea\u6211\u5b9e\u73b0\u7684\u9884\u6d4b\u5206\u522b\u5efa\u6a21\u4e3aWasserstein\u7a7a\u95f4\u4e2d\u7684min-max\u548cmin-min\u98ce\u9669\u6cdb\u51fd\u3002\u901a\u8fc7\u5fb7\u56fd\u5931\u4e1a\u5c45\u6c11\u5c31\u4e1a\u57f9\u8bad\u5206\u914d\u7684\u6848\u4f8b\u7814\u7a76\uff08\u57fa\u4e8e1975-2017\u5e74\u5fb7\u56fd\u52b3\u52a8\u529b\u5e02\u573a\u884c\u653f\u8bb0\u5f55\uff09\u9a8c\u8bc1\u7406\u8bba\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86\u5728performative effects\u4e0b\u7684\u6cdb\u5316\u754c\u9650\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u6539\u53d8\u6570\u636e\u4e0e\u4ece\u6570\u636e\u5b66\u4e60\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\uff1a\u6a21\u578b\u5bf9\u6570\u636e\u7684\u5f71\u54cd\u8d8a\u5927\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\u8d8a\u5f31\u3002\u540c\u65f6\u53d1\u73b0\u4e86\u4e00\u4e2a\u53cd\u76f4\u89c9\u7684\u89c1\u89e3\uff1a\u901a\u8fc7\u5728performatively\u626d\u66f2\u7684\u6837\u672c\u4e0a\u91cd\u65b0\u8bad\u7ec3\u53ef\u4ee5\u6539\u5584\u6cdb\u5316\u4fdd\u8bc1\u3002", "conclusion": "\u5728performative predictions\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u53d7\u5230\u9884\u6d4b\u5bf9\u6837\u672c\u548c\u603b\u4f53\u5f71\u54cd\u7684\u5236\u7ea6\u3002\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u603b\u4f53\u53ef\u80fd\u5426\u5b9a\u9884\u6d4b\uff0c\u800c\u6837\u672c\u53ef\u80fd\u6b3a\u9a97\u6027\u5730\u5b9e\u73b0\u9884\u6d4b\u3002\u7814\u7a76\u4e3a\u7406\u89e3\u9884\u6d4b\u5f71\u54cd\u73b0\u5b9e\u4e16\u754c\u65f6\u7684\u5b66\u4e60\u7406\u8bba\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584\u6cdb\u5316\u6027\u80fd\u7684\u5b9e\u7528\u7b56\u7565\u3002"}}
{"id": "2602.04322", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04322", "abs": "https://arxiv.org/abs/2602.04322", "authors": ["Vincent Runge", "Anica Kostic", "Alexandre Combeau", "Gaetano Romano"], "title": "Exact Multiple Change-Point Detection Via Smallest Valid Partitioning", "comment": null, "summary": "We introduce smallest valid partitioning (SVP), a segmentation method for multiple change-point detection in time-series. SVP relies on a local notion of segment validity: a candidate segment is retained only if it passes a user-chosen validity test (e.g., a single change-point test). From the collection of valid segments, we propose a coherent aggregation procedure that constructs a global segmentation which is the exact solution of an optimization problem. Our main contribution is the use of a lexicographic order for the optimization problem that prioritizes parsimony. We analyze the computational complexity of the resulting procedure, which ranges from linear to cubic time depending on the chosen cost and validity functions, the data regime and the number of detected changes. Finally, we assess the quality of SVP through comparisons with standard optimal partitioning algorithms, showing that SVP yields competitive segmentations while explicitly enforcing segment validity. The flexibility of SVP makes it applicable to a broad class of problems; as an illustration, we demonstrate robust change-point detection by encoding robustness in the validity criterion.", "AI": {"tldr": "SVP\u662f\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u6709\u6548\u6027\u68c0\u9a8c\u7684\u65f6\u95f4\u5e8f\u5217\u591a\u53d8\u5316\u70b9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bcd\u6c47\u5e8f\u4f18\u5316\u4f18\u5148\u8003\u8651\u7b80\u6d01\u6027\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u7ebf\u6027\u5230\u7acb\u65b9\u4e0d\u7b49\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u5f0f\u786e\u4fdd\u5206\u6bb5\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u53d8\u5316\u70b9\u68c0\u6d4b\u65b9\u6cd5\u53ef\u80fd\u7f3a\u4e4f\u5bf9\u5206\u6bb5\u6709\u6548\u6027\u7684\u663e\u5f0f\u4fdd\u8bc1\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u68c0\u6d4b\u591a\u4e2a\u53d8\u5316\u70b9\u53c8\u80fd\u786e\u4fdd\u6bcf\u4e2a\u68c0\u6d4b\u5230\u7684\u5206\u6bb5\u90fd\u901a\u8fc7\u7edf\u8ba1\u6709\u6548\u6027\u68c0\u9a8c\u7684\u65b9\u6cd5\u3002", "method": "SVP\u57fa\u4e8e\u5c40\u90e8\u6709\u6548\u6027\u6982\u5ff5\uff1a\u5019\u9009\u5206\u6bb5\u4ec5\u5f53\u901a\u8fc7\u7528\u6237\u9009\u62e9\u7684\u6709\u6548\u6027\u68c0\u9a8c\uff08\u5982\u5355\u53d8\u5316\u70b9\u68c0\u9a8c\uff09\u65f6\u624d\u88ab\u4fdd\u7559\u3002\u901a\u8fc7\u6709\u6548\u5206\u6bb5\u7684\u96c6\u5408\uff0c\u91c7\u7528\u8bcd\u6c47\u5e8f\u4f18\u5316\u95ee\u9898\u7684\u805a\u5408\u7a0b\u5e8f\u6784\u5efa\u5168\u5c40\u5206\u5272\uff0c\u4f18\u5148\u8003\u8651\u7b80\u6d01\u6027\u3002", "result": "SVP\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u7ebf\u6027\u5230\u7acb\u65b9\u65f6\u95f4\u4e0d\u7b49\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u6210\u672c\u51fd\u6570\u3001\u6709\u6548\u6027\u51fd\u6570\u3001\u6570\u636e\u673a\u5236\u548c\u68c0\u6d4b\u5230\u7684\u53d8\u5316\u70b9\u6570\u91cf\u3002\u4e0e\u6807\u51c6\u6700\u4f18\u5206\u5272\u7b97\u6cd5\u76f8\u6bd4\uff0cSVP\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u5f0f\u786e\u4fdd\u5206\u6bb5\u6709\u6548\u6027\u3002", "conclusion": "SVP\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u591a\u53d8\u5316\u70b9\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u6709\u6548\u6027\u68c0\u9a8c\u786e\u4fdd\u5206\u6bb5\u8d28\u91cf\uff0c\u8bcd\u6c47\u5e8f\u4f18\u5316\u4f18\u5148\u7b80\u6d01\u6027\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u95ee\u9898\uff0c\u5982\u901a\u8fc7\u6709\u6548\u6027\u51c6\u5219\u7f16\u7801\u5b9e\u73b0\u9c81\u68d2\u53d8\u5316\u70b9\u68c0\u6d4b\u3002"}}
{"id": "2602.03972", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03972", "abs": "https://arxiv.org/abs/2602.03972", "authors": ["Kapilan Balagopalan", "Yinan Li", "Yao Zhao", "Tuan Nguyen", "Anton Daitche", "Houssam Nassif", "Kwang-Sung Jun"], "title": "Fixed Budget is No Harder Than Fixed Confidence in Best-Arm Identification up to Logarithmic Factors", "comment": null, "summary": "The best-arm identification (BAI) problem is one of the most fundamental problems in interactive machine learning, which has two flavors: the fixed-budget setting (FB) and the fixed-confidence setting (FC).\n  For $K$-armed bandits with the unique best arm, the optimal sample complexities for both settings have been settled down, and they match up to logarithmic factors.\n  This prompts an interesting research question about the generic, potentially structured BAI problems: Is FB harder than FC or the other way around?\n  In this paper, we show that FB is no harder than FC up to logarithmic factors.\n  We do this constructively: we propose a novel algorithm called FC2FB (fixed confidence to fixed budget), which is a meta algorithm that takes in an FC algorithm $\\mathcal{A}$ and turn it into an FB algorithm.\n  We prove that this FC2FB enjoys a sample complexity that matches, up to logarithmic factors, that of the sample complexity of $\\mathcal{A}$.\n  This means that the optimal FC sample complexity is an upper bound of the optimal FB sample complexity up to logarithmic factors.\n  Our result not only reveals a fundamental relationship between FB and FC, but also has a significant implication: FC2FB, combined with existing state-of-the-art FC algorithms, leads to improved sample complexity for a number of FB problems.", "AI": {"tldr": "FB\uff08\u56fa\u5b9a\u9884\u7b97\uff09\u4e0d\u6bd4FC\uff08\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\uff09\u96be\uff0c\u4e24\u8005\u6837\u672c\u590d\u6742\u5ea6\u5728log\u56e0\u5b50\u5185\u5339\u914d\u3002\u63d0\u51fa\u4e86FC2FB\u5143\u7b97\u6cd5\uff0c\u53ef\u5c06FC\u7b97\u6cd5\u8f6c\u6362\u4e3aFB\u7b97\u6cd5\uff0c\u4e14\u4fdd\u6301\u6837\u672c\u590d\u6742\u5ea6\u76f8\u8fd1\u3002", "motivation": "\u5728\u6700\u4f73\u81c2\u8bc6\u522b\uff08BAI\uff09\u95ee\u9898\u4e2d\uff0c\u56fa\u5b9a\u9884\u7b97\uff08FB\uff09\u548c\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\uff08FC\uff09\u4e24\u79cd\u8bbe\u7f6e\u7684\u6837\u672c\u590d\u6742\u5ea6\u5df2\u6709\u7814\u7a76\u3002\u5bf9\u4e8eK\u81c2\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u4e24\u8005\u7684\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u5df2\u786e\u5b9a\u4e14\u76f8\u5deelog\u56e0\u5b50\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u5bf9\u4e8e\u66f4\u4e00\u822c\u7684\u7ed3\u6784\u5316BAI\u95ee\u9898\uff0cFB\u548cFC\u54ea\u4e2a\u66f4\u96be\uff1f\u672c\u6587\u65e8\u5728\u63a2\u7a76\u8fd9\u4e24\u79cd\u8bbe\u7f6e\u4e4b\u95f4\u7684\u6839\u672c\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86FC2FB\uff08\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8f6c\u56fa\u5b9a\u9884\u7b97\uff09\u5143\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u4ee5\u4efb\u610fFC\u7b97\u6cd5A\u4f5c\u4e3a\u8f93\u5165\uff0c\u5c06\u5176\u8f6c\u6362\u4e3aFB\u7b97\u6cd5\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\uff0c\u8f6c\u6362\u540e\u7684FB\u7b97\u6cd5\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u539f\u59cbFC\u7b97\u6cd5\u5728log\u56e0\u5b50\u5185\u5339\u914d\u3002", "result": "\u8bc1\u660e\u4e86FB\u4e0d\u6bd4FC\u96be\uff08\u5728log\u56e0\u5b50\u5185\uff09\uff0c\u5373\u6700\u4f18FC\u6837\u672c\u590d\u6742\u5ea6\u662fFB\u6837\u672c\u590d\u6742\u5ea6\u7684\u4e0a\u754c\uff08\u76f8\u5deelog\u56e0\u5b50\uff09\u3002FC2FB\u7b97\u6cd5\u4e0e\u73b0\u6709\u6700\u4f18FC\u7b97\u6cd5\u7ed3\u5408\uff0c\u53ef\u5728\u591a\u4e2aFB\u95ee\u9898\u4e0a\u83b7\u5f97\u6539\u8fdb\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "conclusion": "\u63ed\u793a\u4e86FB\u548cFC\u8bbe\u7f6e\u4e4b\u95f4\u7684\u57fa\u672c\u5173\u7cfb\uff1aFB\u5728log\u56e0\u5b50\u5185\u4e0d\u6bd4FC\u96be\u3002FC2FB\u5143\u7b97\u6cd5\u4e0d\u4ec5\u5efa\u7acb\u4e86\u7406\u8bba\u5173\u7cfb\uff0c\u8fd8\u5177\u6709\u5b9e\u9645\u610f\u4e49\uff0c\u80fd\u591f\u5229\u7528\u73b0\u6709FC\u7b97\u6cd5\u63d0\u5347FB\u95ee\u9898\u7684\u6027\u80fd\u3002"}}
{"id": "2602.04077", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04077", "abs": "https://arxiv.org/abs/2602.04077", "authors": ["Zhongming Xie", "Joseph Giorgio", "Jingshen Wang"], "title": "Efficient Subgroup Analysis via Optimal Trees with Global Parameter Fusion", "comment": null, "summary": "Identifying and making statistical inferences on differential treatment effects (commonly known as subgroup analysis in clinical research) is central to precision health. Subgroup analysis allows practitioners to pinpoint populations for whom a treatment is especially beneficial or protective, thereby advancing targeted interventions. Tree based recursive partitioning methods are widely used for subgroup analysis due to their interpretability. Nevertheless, these approaches encounter significant limitations, including suboptimal partitions induced by greedy heuristics and overfitting from locally estimated splits, especially under limited sample sizes. To address these limitations, we propose a fused optimal causal tree method that leverages mixed integer optimization (MIO) to facilitate precise subgroup identification. Our approach ensures globally optimal partitions and introduces a parameter fusion constraint to facilitate information sharing across related subgroups. This design substantially improves subgroup discovery accuracy and enhances statistical efficiency. We provide theoretical guarantees by rigorously establishing out of sample risk bounds and comparing them with those of classical tree based methods. Empirically, our method consistently outperforms popular baselines in simulations. Finally, we demonstrate its practical utility through a case study on the Health and Aging Brain Study Health Disparities (HABS-HD) dataset, where our approach yields clinically meaningful insights.", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408\u6700\u4f18\u56e0\u679c\u6811\u65b9\u6cd5\uff0c\u4f7f\u7528\u6df7\u5408\u6574\u6570\u4f18\u5316\u8fdb\u884c\u5168\u5c40\u6700\u4f18\u5b50\u7ec4\u8bc6\u522b\uff0c\u901a\u8fc7\u53c2\u6570\u878d\u5408\u7ea6\u675f\u4fc3\u8fdb\u5b50\u7ec4\u95f4\u4fe1\u606f\u5171\u4eab\uff0c\u63d0\u9ad8\u5b50\u7ec4\u53d1\u73b0\u51c6\u786e\u6027\u548c\u7edf\u8ba1\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6811\u7684\u9012\u5f52\u5206\u5272\u65b9\u6cd5\u5b58\u5728\u8d2a\u5a6a\u542f\u53d1\u5f0f\u5bfc\u81f4\u6b21\u4f18\u5206\u5272\u3001\u5c40\u90e8\u4f30\u8ba1\u5206\u5272\u5728\u5c0f\u6837\u672c\u4e0b\u5bb9\u6613\u8fc7\u62df\u5408\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b50\u7ec4\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u878d\u5408\u6700\u4f18\u56e0\u679c\u6811\u65b9\u6cd5\uff0c\u5229\u7528\u6df7\u5408\u6574\u6570\u4f18\u5316\u5b9e\u73b0\u5168\u5c40\u6700\u4f18\u5206\u5272\uff0c\u5f15\u5165\u53c2\u6570\u878d\u5408\u7ea6\u675f\u4fc3\u8fdb\u76f8\u5173\u5b50\u7ec4\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u3002", "result": "\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u6837\u672c\u5916\u98ce\u9669\u754c\u9650\uff0c\u8bc1\u660e\u4f18\u4e8e\u7ecf\u5178\u6811\u65b9\u6cd5\uff1b\u5b9e\u8bc1\u4e0a\u5728\u6a21\u62df\u4e2d\u4f18\u4e8e\u6d41\u884c\u57fa\u7ebf\u65b9\u6cd5\uff1b\u5728HABS-HD\u6570\u636e\u96c6\u6848\u4f8b\u7814\u7a76\u4e2d\u83b7\u5f97\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u89c1\u89e3\u3002", "conclusion": "\u878d\u5408\u6700\u4f18\u56e0\u679c\u6811\u65b9\u6cd5\u901a\u8fc7\u5168\u5c40\u4f18\u5316\u548c\u53c2\u6570\u878d\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b50\u7ec4\u53d1\u73b0\u7684\u51c6\u786e\u6027\u548c\u7edf\u8ba1\u6548\u7387\uff0c\u4e3a\u7cbe\u51c6\u533b\u7597\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b50\u7ec4\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2602.04457", "categories": ["stat.ME", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04457", "abs": "https://arxiv.org/abs/2602.04457", "authors": ["Qianyi Chen", "Anpeng Wu", "Bo Li", "Lu Deng", "Yong Wang"], "title": "Journey to the Centre of Cluster: Harnessing Interior Nodes for A/B Testing under Network Interference", "comment": "ICLR 2026", "summary": "A/B testing on platforms often faces challenges from network interference, where a unit's outcome depends not only on its own treatment but also on the treatments of its network neighbors. To address this, cluster-level randomization has become standard, enabling the use of network-aware estimators. These estimators typically trim the data to retain only a subset of informative units, achieving low bias under suitable conditions but often suffering from high variance. In this paper, we first demonstrate that the interior nodes - units whose neighbors all lie within the same cluster - constitute the vast majority of the post-trimming subpopulation. In light of this, we propose directly averaging over the interior nodes to construct the mean-in-interior (MII) estimator, which circumvents the delicate reweighting required by existing network-aware estimators and substantially reduces variance in classical settings. However, we show that interior nodes are often not representative of the full population, particularly in terms of network-dependent covariates, leading to notable bias. We then augment the MII estimator with a counterfactual predictor trained on the entire network, allowing us to adjust for covariate distribution shifts between the interior nodes and full population. By rearranging the expression, we reveal that our augmented MII estimator embodies an analytical form of the point estimator within prediction-powered inference framework. This insight motivates a semi-supervised lens, wherein interior nodes are treated as labeled data subject to selection bias. Extensive and challenging simulation studies demonstrate the outstanding performance of our augmented MII estimator across various settings.", "AI": {"tldr": "\u63d0\u51faMII\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u76f4\u63a5\u5e73\u5747\u5185\u90e8\u8282\u70b9\u6765\u51cf\u5c11\u65b9\u5dee\uff0c\u518d\u901a\u8fc7\u9884\u6d4b\u5668\u8c03\u6574\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u5728\u5b58\u5728\u7f51\u7edc\u5e72\u6270\u7684A/B\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "A/B\u6d4b\u8bd5\u4e2d\u7684\u7f51\u7edc\u5e72\u6270\u95ee\u9898\uff1a\u4e2a\u4f53\u7684\u7ed3\u679c\u4e0d\u4ec5\u53d7\u81ea\u8eab\u5904\u7406\u5f71\u54cd\uff0c\u8fd8\u53d7\u7f51\u7edc\u90bb\u5c45\u5904\u7406\u7684\u5f71\u54cd\u3002\u73b0\u6709\u7684\u7f51\u7edc\u611f\u77e5\u4f30\u8ba1\u5668\u867d\u7136\u80fd\u964d\u4f4e\u504f\u5dee\uff0c\u4f46\u65b9\u5dee\u5f88\u9ad8\uff0c\u4e14\u9700\u8981\u590d\u6742\u7684\u91cd\u65b0\u52a0\u6743\u3002", "method": "1. \u63d0\u51faMII\u4f30\u8ba1\u5668\uff1a\u76f4\u63a5\u5e73\u5747\u5185\u90e8\u8282\u70b9\uff08\u90bb\u5c45\u90fd\u5728\u540c\u4e00\u96c6\u7fa4\u5185\u7684\u5355\u5143\uff09\uff0c\u907f\u514d\u590d\u6742\u52a0\u6743\uff0c\u964d\u4f4e\u65b9\u5dee\u30022. \u589e\u5f3aMII\u4f30\u8ba1\u5668\uff1a\u4f7f\u7528\u5728\u6574\u4e2a\u7f51\u7edc\u4e0a\u8bad\u7ec3\u7684\u53cd\u4e8b\u5b9e\u9884\u6d4b\u5668\uff0c\u8c03\u6574\u5185\u90e8\u8282\u70b9\u4e0e\u603b\u4f53\u4e4b\u95f4\u7684\u534f\u53d8\u91cf\u5206\u5e03\u504f\u79fb\u30023. \u5c06\u589e\u5f3aMII\u4f30\u8ba1\u5668\u91cd\u65b0\u8868\u8ff0\u4e3a\u9884\u6d4b\u9a71\u52a8\u63a8\u65ad\u6846\u67b6\u4e2d\u7684\u70b9\u4f30\u8ba1\u5668\uff0c\u91c7\u7528\u534a\u76d1\u7763\u89c6\u89d2\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u589e\u5f3aMII\u4f30\u8ba1\u5668\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u65b9\u5dee\uff0c\u540c\u65f6\u901a\u8fc7\u534f\u53d8\u91cf\u8c03\u6574\u51cf\u5c11\u4e86\u504f\u5dee\u3002", "conclusion": "\u589e\u5f3aMII\u4f30\u8ba1\u5668\u901a\u8fc7\u76f4\u63a5\u5229\u7528\u5185\u90e8\u8282\u70b9\u5e76\u8c03\u6574\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u5728\u5b58\u5728\u7f51\u7edc\u5e72\u6270\u7684A/B\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u65b9\u5dee\u548c\u4f4e\u504f\u5dee\u7684\u5e73\u8861\uff0c\u4e3a\u7f51\u7edc\u5e72\u6270\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04125", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04125", "abs": "https://arxiv.org/abs/2602.04125", "authors": ["Qingwen Zhang", "Wenjia Wang"], "title": "Attack-Resistant Uniform Fairness for Linear and Smooth Contextual Bandits", "comment": null, "summary": "Modern systems, such as digital platforms and service systems, increasingly rely on contextual bandits for online decision-making; however, their deployment can inadvertently create unfair exposure among arms, undermining long-term platform sustainability and supplier trust. This paper studies the contextual bandit problem under a uniform $(1-\u03b4)$-fairness constraint, and addresses its unique vulnerabilities to strategic manipulation. The fairness constraint ensures that preferential treatment is strictly justified by an arm's actual reward across all contexts and time horizons, using uniformity to prevent statistical loopholes. We develop novel algorithms that achieve (nearly) minimax-optimal regret for both linear and smooth reward functions, while maintaining strong $(1-\\tilde{O}(1/T))$-fairness guarantees, and further characterize the theoretically inherent yet asymptotically marginal \"price of fairness\". However, we reveal that such merit-based fairness becomes uniquely susceptible to signal manipulation. We show that an adversary with a minimal $\\tilde{O}(1)$ budget can not only degrade overall performance as in traditional attacks, but also selectively induce insidious fairness-specific failures while leaving conspicuous regret measures largely unaffected. To counter this, we design robust variants incorporating corruption-adaptive exploration and error-compensated thresholding. Our approach yields the first minimax-optimal regret bounds under $C$-budgeted attack while preserving $(1-\\tilde{O}(1/T))$-fairness. Numerical experiments and a real-world case demonstrate that our algorithms sustain both fairness and efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5e26\u6709\u516c\u5e73\u6027\u7ea6\u675f\u7684\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u5728\u4fdd\u6301\u516c\u5e73\u6027\u7684\u540c\u65f6\u8fbe\u5230\u6700\u4f18\u9057\u61be\u7684\u7b97\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u6b64\u7c7b\u516c\u5e73\u6027\u5bf9\u7b56\u7565\u6027\u64cd\u7eb5\u7684\u72ec\u7279\u8106\u5f31\u6027\uff0c\u8fdb\u800c\u8bbe\u8ba1\u4e86\u9c81\u68d2\u53d8\u4f53\u6765\u62b5\u5fa1\u653b\u51fb\u3002", "motivation": "\u73b0\u4ee3\u7cfb\u7edf\uff08\u5982\u6570\u5b57\u5e73\u53f0\u548c\u670d\u52a1\u7cfb\u7edf\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u8fdb\u884c\u5728\u7ebf\u51b3\u7b56\uff0c\u4f46\u8fd9\u4e9b\u90e8\u7f72\u53ef\u80fd\u65e0\u610f\u4e2d\u9020\u6210\u4e0d\u540c\u9009\u9879\uff08arms\uff09\u4e4b\u95f4\u7684\u4e0d\u516c\u5e73\u66dd\u5149\uff0c\u635f\u5bb3\u5e73\u53f0\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u548c\u4f9b\u5e94\u5546\u4fe1\u4efb\u3002\u9700\u8981\u7814\u7a76\u5728\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u7279\u522b\u5173\u6ce8\u516c\u5e73\u6027\u7ea6\u675f\u5bf9\u7b56\u7565\u6027\u64cd\u7eb5\u7684\u72ec\u7279\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u7b97\u6cd5\uff0c\u9488\u5bf9\u7ebf\u6027\u548c\u5e73\u6ed1\u5956\u52b1\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u5f3a(1-\u00d5(1/T))-\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u8fbe\u5230\uff08\u8fd1\u4f3c\uff09\u6781\u5c0f\u6781\u5927\u6700\u4f18\u9057\u61be\u3002\u4e3a\u4e86\u62b5\u5fa1\u653b\u51fb\uff0c\u8bbe\u8ba1\u4e86\u9c81\u68d2\u53d8\u4f53\uff0c\u7ed3\u5408\u4e86\u8150\u8d25\u81ea\u9002\u5e94\u63a2\u7d22\u548c\u8bef\u5dee\u8865\u507f\u9608\u503c\u6280\u672f\u3002", "result": "\u7b97\u6cd5\u5728\u4fdd\u6301\u516c\u5e73\u6027\u7684\u540c\u65f6\u8fbe\u5230\u4e86\u6781\u5c0f\u6781\u5927\u6700\u4f18\u9057\u61be\uff0c\u5e76\u63ed\u793a\u4e86\u57fa\u4e8e\u4ef7\u503c\u7684\u516c\u5e73\u6027\u5bf9\u4fe1\u53f7\u64cd\u7eb5\u7684\u72ec\u7279\u8106\u5f31\u6027\uff1a\u5bf9\u624b\u53ea\u9700\u00d5(1)\u7684\u9884\u7b97\u5c31\u80fd\u5bfc\u81f4\u516c\u5e73\u6027\u7279\u5b9a\u7684\u5931\u8d25\uff0c\u800c\u663e\u6027\u7684\u9057\u61be\u5ea6\u91cf\u57fa\u672c\u4e0d\u53d7\u5f71\u54cd\u3002\u9c81\u68d2\u53d8\u4f53\u5728C-\u9884\u7b97\u653b\u51fb\u4e0b\u5b9e\u73b0\u4e86\u9996\u4e2a\u6781\u5c0f\u6781\u5927\u6700\u4f18\u9057\u61be\u754c\uff0c\u540c\u65f6\u4fdd\u6301\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u7684\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u7b97\u6cd5\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u516c\u5e73\u6027\u5bf9\u7b56\u7565\u6027\u64cd\u7eb5\u7684\u72ec\u7279\u8106\u5f31\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9c81\u68d2\u7b97\u6cd5\u6765\u540c\u65f6\u4fdd\u8bc1\u516c\u5e73\u6027\u548c\u6548\u7387\u3002\u6570\u503c\u5b9e\u9a8c\u548c\u771f\u5b9e\u6848\u4f8b\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.04594", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04594", "abs": "https://arxiv.org/abs/2602.04594", "authors": ["Wen Zhang", "Liping Zhu", "Songshan Yang"], "title": "Distributed Convoluted Rank Regression for Non-Shareable Data under Non-Additive Losses", "comment": null, "summary": "We study high-dimensional rank regression when data are distributed across multiple machines and the loss is a non-additive U-statistic, as in convoluted rank regression (CRR). Classical communication-efficient surrogate likelihood (CSL) methods crucially rely on the additivity of the empirical loss and therefore break down for CRR, whose global loss couples all sample pairs across machines. We propose a distributed convoluted rank regression (DCRR) framework that constructs a similar surrogate loss and demonstrate its validity under the non-additive losses. We show that this surrogate shares the same population minimizer as the full-data CRR loss and yields estimators that are statistically equivalent to centralized CRR. Building on this, we develop a two-stage sparse DCRR procedure -- an iterative $\\ell_1$-penalized stage followed by a folded-concave refinement -- and establish non-asymptotic error bounds, a distributed strong oracle property, and a DHBIC-type criterion for consistent model selection. A scaling result shows that the number of machines may diverge as $M = o({N/(s^2\\log p)})$ while achieving centralized oracle rates with only $O(\\log N)$ communication rounds. Simulations and a large-scale real data example demonstrate substantial gains over naive divide-and-conquer, particularly under heavy-tailed errors.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u5377\u79ef\u79e9\u56de\u5f52(DCRR)\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u673a\u73af\u5883\u4e0b\u975e\u53ef\u52a0U\u7edf\u8ba1\u91cf\u635f\u5931\u51fd\u6570\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u96c6\u4e2d\u5f0f\u4f30\u8ba1\u5668\u7edf\u8ba1\u7b49\u4ef7\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u9ad8\u6548\u7684\u66ff\u4ee3\u4f3c\u7136\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7ecf\u9a8c\u635f\u5931\u7684\u53ef\u52a0\u6027\uff0c\u4f46\u5728\u5377\u79ef\u79e9\u56de\u5f52(CRR)\u4e2d\u5931\u6548\uff0c\u56e0\u4e3a\u5176\u5168\u5c40\u635f\u5931\u8026\u5408\u4e86\u6240\u6709\u673a\u5668\u4e0a\u7684\u6837\u672c\u5bf9\u3002\u9700\u8981\u89e3\u51b3\u975e\u53ef\u52a0\u635f\u5931\u4e0b\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51faDCRR\u6846\u67b6\uff0c\u6784\u5efa\u4e0e\u5168\u6570\u636eCRR\u635f\u5931\u5177\u6709\u76f8\u540c\u603b\u4f53\u6700\u5c0f\u5316\u5668\u7684\u66ff\u4ee3\u635f\u5931\u3002\u5f00\u53d1\u4e24\u9636\u6bb5\u7a00\u758fDCRR\u7a0b\u5e8f\uff1a\u8fed\u4ee3\u21131\u60e9\u7f5a\u9636\u6bb5+\u6298\u53e0\u51f9\u7ec6\u5316\u9636\u6bb5\uff0c\u5e76\u5efa\u7acbDHBIC\u578b\u51c6\u5219\u8fdb\u884c\u6a21\u578b\u9009\u62e9\u3002", "result": "\u8bc1\u660e\u66ff\u4ee3\u635f\u5931\u4e0e\u96c6\u4e2d\u5f0fCRR\u7edf\u8ba1\u7b49\u4ef7\uff0c\u5efa\u7acb\u975e\u6e10\u8fd1\u8bef\u5dee\u754c\u3001\u5206\u5e03\u5f0f\u5f3aoracle\u6027\u8d28\u3002\u673a\u5668\u6570\u91cf\u53ef\u53d1\u6563\u81f3M=o(N/(s\u00b2log p))\uff0c\u4ec5\u9700O(log N)\u901a\u4fe1\u8f6e\u6b21\u5373\u53ef\u8fbe\u5230\u96c6\u4e2d\u5f0foracle\u901f\u7387\u3002", "conclusion": "DCRR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u975e\u53ef\u52a0\u635f\u5931\u4e0b\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u91cd\u5c3e\u8bef\u5dee\u4e0b\u76f8\u6bd4\u6734\u7d20\u5206\u6cbb\u65b9\u6cd5\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u6548\u7387\u4e0e\u7edf\u8ba1\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.04155", "categories": ["stat.ML", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04155", "abs": "https://arxiv.org/abs/2602.04155", "authors": ["Jiwoo Han", "Moulinath Banerjee", "Yuekai Sun"], "title": "Maximin Relative Improvement: Fair Learning as a Bargaining Problem", "comment": null, "summary": "When deploying a single predictor across multiple subpopulations, we propose a fundamentally different approach: interpreting group fairness as a bargaining problem among subpopulations. This game-theoretic perspective reveals that existing robust optimization methods such as minimizing worst-group loss or regret correspond to classical bargaining solutions and embody different fairness principles. We propose relative improvement, the ratio of actual risk reduction to potential reduction from a baseline predictor, which recovers the Kalai-Smorodinsky solution. Unlike absolute-scale methods that may not be comparable when groups have different potential predictability, relative improvement provides axiomatic justification including scale invariance and individual monotonicity. We establish finite-sample convergence guarantees under mild conditions.", "AI": {"tldr": "\u5c06\u7fa4\u4f53\u516c\u5e73\u6027\u89c6\u4e3a\u5b50\u7fa4\u4f53\u95f4\u7684\u8ba8\u4ef7\u8fd8\u4ef7\u95ee\u9898\uff0c\u63d0\u51fa\u76f8\u5bf9\u6539\u8fdb\u65b9\u6cd5\u4f5c\u4e3aKalai-Smorodinsky\u89e3\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u6bd4\u6027\u548c\u516c\u7406\u57fa\u7840", "motivation": "\u73b0\u6709\u9c81\u68d2\u4f18\u5316\u65b9\u6cd5\uff08\u5982\u6700\u5c0f\u5316\u6700\u5dee\u7fa4\u4f53\u635f\u5931\uff09\u5728\u90e8\u7f72\u5355\u4e00\u9884\u6d4b\u5668\u5230\u591a\u4e2a\u5b50\u7fa4\u4f53\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4ece\u535a\u5f08\u8bba\u89d2\u5ea6\u91cd\u65b0\u601d\u8003\u7fa4\u4f53\u516c\u5e73\u6027\u95ee\u9898", "method": "\u5c06\u7fa4\u4f53\u516c\u5e73\u6027\u5efa\u6a21\u4e3a\u5b50\u7fa4\u4f53\u95f4\u7684\u8ba8\u4ef7\u8fd8\u4ef7\u95ee\u9898\uff0c\u63d0\u51fa\u76f8\u5bf9\u6539\u8fdb\u65b9\u6cd5\uff08\u5b9e\u9645\u98ce\u9669\u964d\u4f4e\u4e0e\u6f5c\u5728\u964d\u4f4e\u7684\u6bd4\u503c\uff09\uff0c\u5bf9\u5e94Kalai-Smorodinsky\u89e3\uff0c\u5177\u6709\u5c3a\u5ea6\u4e0d\u53d8\u6027\u548c\u4e2a\u4f53\u5355\u8c03\u6027\u7b49\u516c\u7406\u6027\u8d28", "result": "\u5efa\u7acb\u4e86\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u7684\u6709\u9650\u6837\u672c\u6536\u655b\u4fdd\u8bc1\uff0c\u76f8\u5bf9\u6539\u8fdb\u65b9\u6cd5\u5728\u4e0d\u540c\u7fa4\u4f53\u5177\u6709\u4e0d\u540c\u53ef\u9884\u6d4b\u6f5c\u529b\u65f6\u66f4\u5177\u53ef\u6bd4\u6027", "conclusion": "\u535a\u5f08\u8bba\u89c6\u89d2\u4e3a\u7fa4\u4f53\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u76f8\u5bf9\u6539\u8fdb\u65b9\u6cd5\u76f8\u6bd4\u7edd\u5bf9\u5c3a\u5ea6\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u516c\u7406\u57fa\u7840\u548c\u5b9e\u9645\u9002\u7528\u6027"}}
{"id": "2602.04682", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04682", "abs": "https://arxiv.org/abs/2602.04682", "authors": ["Emma G Crenshaw", "Yuhua Zhang", "Jukka-Pekka Onnela"], "title": "Covariate Selection for Joint Latent Space Modeling of Sparse Network Data", "comment": null, "summary": "Network data are increasingly common in the social sciences and infectious disease epidemiology. Analyses often link network structure to node-level covariates, but existing methods falter with sparse networks and high-dimensional node features. We propose a joint latent space modeling framework for sparse networks with high-dimensional binary node covariates that performs covariate selection while accounting for uncertainty in estimated latent positions. Building on joint latent space models that couple edges and node variables through shared latent positions, we introduce a group lasso screening step and incorporate a measurement-error-aware stabilization term to mitigate bias from using estimated latent positions as predictors. We establish prediction error rates for the covariate component both when latent positions are treated as observed and when they are estimated with bounded error; under uniform control across $q$ covariates and $n$ nodes, the rate is of order $O(\\log q / n)$ up to an additional term due to latent position estimation error. Our method addresses three challenges: (1) incorporating information from isolated nodes, which are common in sparse networks but often ignored; (2) selecting relevant covariates from high-dimensional spaces; and (3) accounting for uncertainty in estimated latent positions. Simulations show predictive performance remains stable as covariate sparsity grows, while naive approaches degrade. We illustrate how the method can support efficient study design using household social networks from 75 Indian villages, where an emulated pilot study screens a large covariate battery and substantially reduces required subsequent data collection without sacrificing network predictive accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8054\u5408\u6f5c\u5728\u7a7a\u95f4\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7a00\u758f\u7f51\u7edc\u548c\u9ad8\u7ef4\u4e8c\u5143\u8282\u70b9\u534f\u53d8\u91cf\uff0c\u901a\u8fc7\u534f\u53d8\u91cf\u9009\u62e9\u548c\u8003\u8651\u6f5c\u5728\u4f4d\u7f6e\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6539\u8fdb\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7a00\u758f\u7f51\u7edc\u548c\u9ad8\u7ef4\u8282\u70b9\u7279\u5f81\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u65e0\u6cd5\u6709\u6548\u5229\u7528\u5b64\u7acb\u8282\u70b9\u4fe1\u606f\u3001\u8fdb\u884c\u534f\u53d8\u91cf\u9009\u62e9\u4ee5\u53ca\u5904\u7406\u6f5c\u5728\u4f4d\u7f6e\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u57fa\u4e8e\u8054\u5408\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\uff0c\u5f15\u5165\u7ec4\u5957\u7d22\u7b5b\u9009\u6b65\u9aa4\u548c\u6d4b\u91cf\u8bef\u5dee\u611f\u77e5\u7684\u7a33\u5b9a\u9879\uff0c\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u4f4d\u7f6e\u8026\u5408\u8fb9\u548c\u8282\u70b9\u53d8\u91cf\uff0c\u51cf\u5c11\u4f7f\u7528\u4f30\u8ba1\u6f5c\u5728\u4f4d\u7f6e\u4f5c\u4e3a\u9884\u6d4b\u53d8\u91cf\u65f6\u7684\u504f\u5dee\u3002", "result": "\u5efa\u7acb\u4e86\u534f\u53d8\u91cf\u5206\u91cf\u7684\u9884\u6d4b\u8bef\u5dee\u7387\uff0c\u5f53\u6f5c\u5728\u4f4d\u7f6e\u88ab\u89c6\u4e3a\u89c2\u6d4b\u503c\u65f6\u4e3aO(log q/n)\uff0c\u5f53\u4f30\u8ba1\u6709\u754c\u8bef\u5dee\u65f6\u589e\u52a0\u989d\u5916\u9879\u3002\u6a21\u62df\u663e\u793a\u968f\u7740\u534f\u53d8\u91cf\u7a00\u758f\u6027\u589e\u52a0\uff0c\u9884\u6d4b\u6027\u80fd\u4fdd\u6301\u7a33\u5b9a\uff0c\u800c\u6734\u7d20\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u7a00\u758f\u7f51\u7edc\u4e2d\u7684\u4e09\u4e2a\u6311\u6218\uff1a\u5229\u7528\u5b64\u7acb\u8282\u70b9\u4fe1\u606f\u3001\u9ad8\u7ef4\u534f\u53d8\u91cf\u9009\u62e9\u548c\u6f5c\u5728\u4f4d\u7f6e\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5370\u5ea6\u6751\u5e84\u5bb6\u5ead\u793e\u4ea4\u7f51\u7edc\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u652f\u6301\u9ad8\u6548\u7814\u7a76\u8bbe\u8ba1\u3002"}}
{"id": "2602.04233", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04233", "abs": "https://arxiv.org/abs/2602.04233", "authors": ["Kazuto Fukuchi", "Ryuichiro Hataya", "Kota Matsui"], "title": "Provable Target Sample Complexity Improvements as Pre-Trained Models Scale", "comment": "AISTATS2026", "summary": "Pre-trained models have become indispensable for efficiently building models across a broad spectrum of downstream tasks. The advantages of pre-trained models have been highlighted by empirical studies on scaling laws, which demonstrate that larger pre-trained models can significantly reduce the sample complexity of downstream learning. However, existing theoretical investigations of pre-trained models lack the capability to explain this phenomenon. In this paper, we provide a theoretical investigation by introducing a novel framework, caulking, inspired by parameter-efficient fine-tuning (PEFT) methods such as adapter-based fine-tuning, low-rank adaptation, and partial fine-tuning. Our analysis establishes that improved pre-trained models provably decrease the sample complexity of downstream tasks, thereby offering theoretical justification for the empirically observed scaling laws relating pre-trained model size to downstream performance, a relationship not covered by existing results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3a\"caulking\"\u7684\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u9884\u8bad\u7ec3\u6a21\u578b\u89c4\u6a21\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u4e3a\u7ecf\u9a8c\u89c2\u5bdf\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u7814\u7a76\u65e0\u6cd5\u89e3\u91ca\u9884\u8bad\u7ec3\u6a21\u578b\u89c4\u6a21\u6269\u5927\u80fd\u663e\u8457\u964d\u4f4e\u4e0b\u6e38\u4efb\u52a1\u6837\u672c\u590d\u6742\u5ea6\u7684\u7ecf\u9a8c\u73b0\u8c61\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u540d\u4e3a\"caulking\"\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08\u5982\u9002\u914d\u5668\u5fae\u8c03\u3001\u4f4e\u79e9\u9002\u5e94\u3001\u90e8\u5206\u5fae\u8c03\uff09\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5efa\u7acb\u9884\u8bad\u7ec3\u6a21\u578b\u6539\u8fdb\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6837\u672c\u590d\u6742\u5ea6\u964d\u4f4e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u6539\u8fdb\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u786e\u5b9e\u80fd\u964d\u4f4e\u4e0b\u6e38\u4efb\u52a1\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u89c4\u6a21\u4e0e\u4e0b\u6e38\u6027\u80fd\u4e4b\u95f4\u7684\u7f29\u653e\u5b9a\u5f8b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u73b0\u6709\u7406\u8bba\u65e0\u6cd5\u89e3\u91ca\u9884\u8bad\u7ec3\u6a21\u578b\u7f29\u653e\u5b9a\u5f8b\u7684\u7a7a\u767d\uff0c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4f18\u52bf\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u7684\u7406\u8bba\u8054\u7cfb\u3002"}}
{"id": "2602.04691", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04691", "abs": "https://arxiv.org/abs/2602.04691", "authors": ["Subhodeep Dey", "Gopal K. Basak", "Samarjit Das"], "title": "Linear Regression: Inference Based on Cluster Estimates", "comment": null, "summary": "This article proposes a novel estimator for regression coefficients in clustered data that explicitly accounts for within-cluster dependence. We study the asymptotic properties of the proposed estimator under both finite and infinite cluster sizes. The analysis is then extended to a standard random coefficient model, where we derive asymptotic results for the average (common) parameters and develop a Wald-type test for general linear hypotheses. We also investigate the performance of the conventional pooled ordinary least squares (POLS) estimator within the random coefficients framework and show that it can be unreliable across a wide range of empirically relevant settings. Furthermore, we introduce a new test for parameter stability at a higher (superblock; Tier 2, Tier 3,...) level, assuming that parameters are stable across clusters within that level. Extensive simulation studies demonstrate the effectiveness of the proposed tests, and an empirical application illustrates their practical relevance.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u805a\u7c7b\u6570\u636e\u56de\u5f52\u7cfb\u6570\u7684\u65b0\u4f30\u8ba1\u5668\uff0c\u8003\u8651\u7ec4\u5185\u76f8\u5173\u6027\uff0c\u7814\u7a76\u6709\u9650\u548c\u65e0\u9650\u805a\u7c7b\u89c4\u6a21\u4e0b\u7684\u6e10\u8fd1\u6027\u8d28\uff0c\u6269\u5c55\u81f3\u968f\u673a\u7cfb\u6570\u6a21\u578b\uff0c\u5f00\u53d1\u53c2\u6570\u7a33\u5b9a\u6027\u68c0\u9a8c\uff0c\u8bc1\u660e\u4f20\u7edfPOLS\u4f30\u8ba1\u5668\u4e0d\u53ef\u9760\u3002", "motivation": "\u805a\u7c7b\u6570\u636e\u4e2d\u4f20\u7edf\u4f30\u8ba1\u65b9\u6cd5\uff08\u5982POLS\uff09\u5ffd\u7565\u7ec4\u5185\u76f8\u5173\u6027\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u4f30\u8ba1\u7ed3\u679c\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u660e\u786e\u8003\u8651\u7ec4\u5185\u4f9d\u8d56\u5173\u7cfb\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u76f8\u5e94\u7684\u68c0\u9a8c\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u56de\u5f52\u7cfb\u6570\u4f30\u8ba1\u5668\uff0c\u8003\u8651\u805a\u7c7b\u5185\u76f8\u5173\u6027\uff1b\u7814\u7a76\u6709\u9650\u548c\u65e0\u9650\u805a\u7c7b\u89c4\u6a21\u4e0b\u7684\u6e10\u8fd1\u6027\u8d28\uff1b\u6269\u5c55\u81f3\u968f\u673a\u7cfb\u6570\u6a21\u578b\uff0c\u63a8\u5bfc\u5e73\u5747\u53c2\u6570\u7684\u6e10\u8fd1\u7ed3\u679c\uff1b\u5f00\u53d1Wald\u578b\u68c0\u9a8c\u7528\u4e8e\u4e00\u822c\u7ebf\u6027\u5047\u8bbe\uff1b\u5f15\u5165\u9ad8\u5c42\u7ea7\u53c2\u6570\u7a33\u5b9a\u6027\u68c0\u9a8c\u3002", "result": "\u8bc1\u660e\u4f20\u7edfPOLS\u4f30\u8ba1\u5668\u5728\u968f\u673a\u7cfb\u6570\u6846\u67b6\u4e0b\u4e0d\u53ef\u9760\uff1b\u65b0\u4f30\u8ba1\u5668\u5177\u6709\u826f\u597d\u7684\u6e10\u8fd1\u6027\u8d28\uff1b\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u68c0\u9a8c\u7684\u6709\u6548\u6027\uff1b\u5b9e\u8bc1\u5e94\u7528\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u76f8\u5173\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u548c\u68c0\u9a8c\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u805a\u7c7b\u6570\u636e\u4e2d\u7684\u7ec4\u5185\u76f8\u5173\u6027\uff0c\u4e3a\u968f\u673a\u7cfb\u6570\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u63a8\u65ad\u5de5\u5177\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.04335", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04335", "abs": "https://arxiv.org/abs/2602.04335", "authors": ["Ferdinand Genans", "Olivier Wintenberger"], "title": "Geometry-Aware Optimal Transport: Fast Intrinsic Dimension and Wasserstein Distance Estimation", "comment": null, "summary": "Solving large scale Optimal Transport (OT) in machine learning typically relies on sampling measures to obtain a tractable discrete problem. While the discrete solver's accuracy is controllable, the rate of convergence of the discretization error is governed by the intrinsic dimension of our data. Therefore, the true bottleneck is the knowledge and control of the sampling error. In this work, we tackle this issue by introducing novel estimators for both sampling error and intrinsic dimension. The key finding is a simple, tuning-free estimator of $\\text{OT}_c(\u03c1, \\hat\u03c1)$ that utilizes the semi-dual OT functional and, remarkably, requires no OT solver. Furthermore, we derive a fast intrinsic dimension estimator from the multi-scale decay of our sampling error estimator. This framework unlocks significant computational and statistical advantages in practice, enabling us to (i) quantify the convergence rate of the discretization error, (ii) calibrate the entropic regularization of Sinkhorn divergences to the data's intrinsic geometry, and (iii) introduce a novel, intrinsic-dimension-based Richardson extrapolation estimator that strongly debiases Wasserstein distance estimation. Numerical experiments demonstrate that our geometry-aware pipeline effectively mitigates the discretization error bottleneck while maintaining computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u6700\u4f18\u4f20\u8f93\u6c42\u89e3\u5668\u7684\u91c7\u6837\u8bef\u5dee\u4f30\u8ba1\u5668\u548c\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\u5668\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u79bb\u6563\u5316\u8bef\u5dee\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u6700\u4f18\u4f20\u8f93\u901a\u5e38\u4f9d\u8d56\u91c7\u6837\u83b7\u5f97\u79bb\u6563\u95ee\u9898\uff0c\u4f46\u91c7\u6837\u8bef\u5dee\u6536\u655b\u901f\u5ea6\u53d7\u6570\u636e\u5185\u5728\u7ef4\u5ea6\u63a7\u5236\uff0c\u6210\u4e3a\u5b9e\u9645\u74f6\u9888\u3002\u9700\u8981\u91cf\u5316\u91c7\u6837\u8bef\u5dee\u548c\u63a7\u5236\u5185\u5728\u7ef4\u5ea6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u534a\u5bf9\u5076\u6700\u4f18\u4f20\u8f93\u51fd\u6570\u7684\u65e0\u8c03\u53c2\u91c7\u6837\u8bef\u5dee\u4f30\u8ba1\u5668\uff0c\u65e0\u9700\u6700\u4f18\u4f20\u8f93\u6c42\u89e3\u5668\u3002\u4ece\u91c7\u6837\u8bef\u5dee\u4f30\u8ba1\u5668\u7684\u591a\u5c3a\u5ea6\u8870\u51cf\u63a8\u5bfc\u5feb\u901f\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\u5668\u3002", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u8ba1\u7b97\u548c\u7edf\u8ba1\u4f18\u52bf\uff1a\u91cf\u5316\u79bb\u6563\u5316\u8bef\u5dee\u6536\u655b\u7387\u3001\u6839\u636e\u6570\u636e\u5185\u5728\u51e0\u4f55\u6821\u51c6Sinkhorn\u6563\u5ea6\u7684\u71b5\u6b63\u5219\u5316\u3001\u63d0\u51fa\u57fa\u4e8e\u5185\u5728\u7ef4\u5ea6\u7684Richardson\u5916\u63a8\u4f30\u8ba1\u5668\u663e\u8457\u51cf\u5c11Wasserstein\u8ddd\u79bb\u4f30\u8ba1\u504f\u5dee\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u51e0\u4f55\u611f\u77e5\u7684\u6d41\u7a0b\u6709\u6548\u7f13\u89e3\u79bb\u6563\u5316\u8bef\u5dee\u74f6\u9888\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u6700\u4f18\u4f20\u8f93\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04347", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04347", "abs": "https://arxiv.org/abs/2602.04347", "authors": ["Lukas De Kerpel", "Arthur Thuy", "Dries F. Benoit"], "title": "A Bandit-Based Approach to Educational Recommender Systems: Contextual Thompson Sampling for Learner Skill Gain Optimization", "comment": "Accepted for publication in INFORMS Transactions on Education", "summary": "In recent years, instructional practices in Operations Research (OR), Management Science (MS), and Analytics have increasingly shifted toward digital environments, where large and diverse groups of learners make it difficult to provide practice that adapts to individual needs. This paper introduces a method that generates personalized sequences of exercises by selecting, at each step, the exercise most likely to advance a learner's understanding of a targeted skill. The method uses information about the learner and their past performance to guide these choices, and learning progress is measured as the change in estimated skill level before and after each exercise. Using data from an online mathematics tutoring platform, we find that the approach recommends exercises associated with greater skill improvement and adapts effectively to differences across learners. From an instructional perspective, the framework enables personalized practice at scale, highlights exercises with consistently strong learning value, and helps instructors identify learners who may benefit from additional support.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u8005\u4fe1\u606f\u548c\u5386\u53f2\u8868\u73b0\u751f\u6210\u4e2a\u6027\u5316\u7ec3\u4e60\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u53ef\u80fd\u63d0\u5347\u76ee\u6807\u6280\u80fd\u7684\u7ec3\u4e60\uff0c\u5b9e\u73b0\u5728\u7ebf\u6559\u80b2\u4e2d\u7684\u89c4\u6a21\u5316\u4e2a\u6027\u5316\u6559\u5b66\u3002", "motivation": "\u968f\u7740\u8fd0\u7b79\u5b66\u3001\u7ba1\u7406\u79d1\u5b66\u548c\u5206\u6790\u5b66\u6559\u5b66\u5411\u6570\u5b57\u73af\u5883\u8f6c\u79fb\uff0c\u9762\u5bf9\u5927\u89c4\u6a21\u591a\u6837\u5316\u5b66\u4e60\u8005\u7fa4\u4f53\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u63d0\u4f9b\u9002\u5e94\u4e2a\u4f53\u9700\u6c42\u7684\u4e2a\u6027\u5316\u7ec3\u4e60\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u89c4\u6a21\u5316\u63d0\u4f9b\u4e2a\u6027\u5316\u7ec3\u4e60\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u7ec3\u4e60\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u6bcf\u4e00\u6b65\u9009\u62e9\u6700\u53ef\u80fd\u63d0\u5347\u5b66\u4e60\u8005\u76ee\u6807\u6280\u80fd\u7684\u7ec3\u4e60\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5b66\u4e60\u8005\u4fe1\u606f\u548c\u5386\u53f2\u8868\u73b0\u6307\u5bfc\u9009\u62e9\uff0c\u901a\u8fc7\u6bcf\u6b21\u7ec3\u4e60\u524d\u540e\u4f30\u8ba1\u6280\u80fd\u6c34\u5e73\u7684\u53d8\u5316\u6765\u8861\u91cf\u5b66\u4e60\u8fdb\u5c55\u3002", "result": "\u57fa\u4e8e\u5728\u7ebf\u6570\u5b66\u8f85\u5bfc\u5e73\u53f0\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63a8\u8350\u7684\u7ec3\u4e60\u4e0e\u66f4\u5927\u7684\u6280\u80fd\u63d0\u5347\u76f8\u5173\uff0c\u5e76\u80fd\u6709\u6548\u9002\u5e94\u4e0d\u540c\u5b66\u4e60\u8005\u7684\u5dee\u5f02\u3002\u4ece\u6559\u5b66\u89d2\u5ea6\u770b\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u89c4\u6a21\u5316\u4e2a\u6027\u5316\u7ec3\u4e60\uff0c\u8bc6\u522b\u51fa\u5177\u6709\u6301\u7eed\u5f3a\u5b66\u4e60\u4ef7\u503c\u7684\u7ec3\u4e60\uff0c\u5e76\u5e2e\u52a9\u6559\u5e08\u8bc6\u522b\u9700\u8981\u989d\u5916\u652f\u6301\u7684\u5b66\u4e60\u8005\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u7ebf\u6559\u80b2\u73af\u5883\u4e2d\u7684\u89c4\u6a21\u5316\u4e2a\u6027\u5316\u6559\u5b66\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u80fd\u591f\u6839\u636e\u4e2a\u4f53\u5b66\u4e60\u8005\u9700\u6c42\u52a8\u6001\u8c03\u6574\u7ec3\u4e60\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u679c\u5e76\u652f\u6301\u6559\u5b66\u51b3\u7b56\u3002"}}
{"id": "2602.04798", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.04798", "abs": "https://arxiv.org/abs/2602.04798", "authors": ["Wenbin Zhou", "Liyan Xie", "Shixiang Zhu"], "title": "Score-Based Change-Point Detection and Region Localization for Spatio-Temporal Point Processes", "comment": null, "summary": "We study sequential change-point detection for spatio-temporal point processes, where actionable detection requires not only identifying when a distributional change occurs but also localizing where it manifests in space. While classical quickest change detection methods provide strong guarantees on detection delay and false-alarm rates, existing approaches for point-process data predominantly focus on temporal changes and do not explicitly infer affected spatial regions. We propose a likelihood-free, score-based detection framework that jointly estimates the change time and the change region in continuous space-time without assuming parametric knowledge of the pre- or post-change dynamics. The method leverages a localized and conditionally weighted Hyv\u00e4rinen score to quantify event-level deviations from nominal behavior and aggregates these scores using a spatio-temporal CUSUM-type statistic over a prescribed class of spatial regions. Operating sequentially, the procedure outputs both a stopping time and an estimated change region, enabling real-time detection with spatial interpretability. We establish theoretical guarantees on false-alarm control, detection delay, and spatial localization accuracy, and demonstrate the effectiveness of the proposed approach through simulations and real-world spatio-temporal event data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65f6\u7a7a\u70b9\u8fc7\u7a0b\u7684\u5e8f\u8d2f\u53d8\u70b9\u68c0\u6d4b\u6846\u67b6\uff0c\u4e0d\u4ec5\u80fd\u68c0\u6d4b\u53d8\u5316\u65f6\u95f4\uff0c\u8fd8\u80fd\u5b9a\u4f4d\u53d8\u5316\u53d1\u751f\u7684\u7a7a\u95f4\u533a\u57df\uff0c\u65e0\u9700\u53c2\u6570\u5316\u5047\u8bbe\u3002", "motivation": "\u73b0\u6709\u53d8\u70b9\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u65f6\u95f4\u53d8\u5316\uff0c\u65e0\u6cd5\u660e\u786e\u63a8\u65ad\u53d7\u5f71\u54cd\u7684\u7a7a\u95f4\u533a\u57df\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u540c\u65f6\u8bc6\u522b\u53d8\u5316\u65f6\u95f4\u548c\u7a7a\u95f4\u4f4d\u7f6e\u3002", "method": "\u57fa\u4e8e\u65e0\u4f3c\u7136\u3001\u8bc4\u5206\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5c40\u90e8\u6761\u4ef6\u52a0\u6743Hyv\u00e4rinen\u8bc4\u5206\u91cf\u5316\u4e8b\u4ef6\u7ea7\u504f\u5dee\uff0c\u901a\u8fc7\u65f6\u7a7aCUSUM\u7edf\u8ba1\u91cf\u5728\u7a7a\u95f4\u533a\u57df\u7c7b\u4e0a\u805a\u5408\uff0c\u5e8f\u8d2f\u8f93\u51fa\u505c\u6b62\u65f6\u95f4\u548c\u4f30\u8ba1\u53d8\u5316\u533a\u57df\u3002", "result": "\u5efa\u7acb\u4e86\u8bef\u62a5\u63a7\u5236\u3001\u68c0\u6d4b\u5ef6\u8fdf\u548c\u7a7a\u95f4\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u65f6\u7a7a\u4e8b\u4ef6\u6570\u636e\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u5177\u6709\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u7684\u5b9e\u65f6\u68c0\u6d4b\uff0c\u4e3a\u65f6\u7a7a\u70b9\u8fc7\u7a0b\u7684\u53d8\u70b9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04364", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04364", "abs": "https://arxiv.org/abs/2602.04364", "authors": ["Bror Hultberg", "Dave Zachariah", "Ant\u00f4nio H. Ribeiro"], "title": "Anytime-Valid Conformal Risk Control", "comment": null, "summary": "Prediction sets provide a means of quantifying the uncertainty in predictive tasks. Using held out calibration data, conformal prediction and risk control can produce prediction sets that exhibit statistically valid error control in a computationally efficient manner. However, in the standard formulations, the error is only controlled on average over many possible calibration datasets of fixed size. In this paper, we extend the control to remain valid with high probability over a cumulatively growing calibration dataset at any time point. We derive such guarantees using quantile-based arguments and illustrate the applicability of the proposed framework to settings involving distribution shift. We further establish a matching lower bound and show that our guarantees are asymptotically tight. Finally, we demonstrate the practical performance of our methods through both simulations and real-world numerical examples.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9884\u6d4b\u96c6\u6846\u67b6\uff0c\u80fd\u591f\u5728\u7d2f\u79ef\u589e\u957f\u7684\u6821\u51c6\u6570\u636e\u96c6\u4e0a\u4ee5\u9ad8\u6982\u7387\u4fdd\u6301\u7edf\u8ba1\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u6f02\u79fb\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u548c\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\u4ec5\u5728\u56fa\u5b9a\u5927\u5c0f\u7684\u6821\u51c6\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63a7\u5236\u8bef\u5dee\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5728\u7d2f\u79ef\u589e\u957f\u7684\u6821\u51c6\u6570\u636e\u4e0a\u59cb\u7ec8\u4fdd\u6301\u6709\u6548\u6027\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u5206\u4f4d\u6570\u8bba\u8bc1\u65b9\u6cd5\uff0c\u5efa\u7acb\u80fd\u591f\u5728\u4efb\u610f\u65f6\u95f4\u70b9\u5bf9\u7d2f\u79ef\u589e\u957f\u7684\u6821\u51c6\u6570\u636e\u96c6\u4fdd\u6301\u9ad8\u6982\u7387\u6709\u6548\u6027\u7684\u7edf\u8ba1\u4fdd\u8bc1\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u5339\u914d\u7684\u4e0b\u754c\uff0c\u8bc1\u660e\u6240\u63d0\u4fdd\u8bc1\u662f\u6e10\u8fd1\u7d27\u7684\u3002\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6269\u5c55\u4e86\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u7d2f\u79ef\u589e\u957f\u7684\u6821\u51c6\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u9ad8\u6982\u7387\u6709\u6548\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5b58\u5728\u5206\u5e03\u6f02\u79fb\u7684\u573a\u666f\u3002"}}
{"id": "2602.04855", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04855", "abs": "https://arxiv.org/abs/2602.04855", "authors": ["Suchismita Roy", "Alexander A. Fisher", "Jason Xu"], "title": "Marginal Likelihood Inference for Fitting Dynamical Survival Analysis Models to Epidemic Count Data", "comment": "25 pages, 2 figures and 6 tables", "summary": "Stochastic compartmental models are prevalent tools for describing disease spread, but inference under these models is challenging for many types of surveillance data when the marginal likelihood function becomes intractable due to missing information. To address this, we develop a closed-form likelihood for discretely observed incidence count data under the dynamical survival analysis (DSA) paradigm. The method approximates the stochastic population-level hazard by a large population limit while retaining a count-valued stochastic model, and leads to survival analytic inferential strategies that are both computationally efficient and flexible to model generalizations. Through simulation, we show that parameter estimation is competitive with recent exact but computationally expensive likelihood-based methods in partially observed settings. Previous work has shown that the DSA approximation is generalizable, and we show that the inferential developments here also carry over to models featuring individual heterogeneity, such as frailty models. We consider case studies of both Ebola and COVID-19 data on variants of the model, including a network-based epidemic model and a model with distributions over susceptibility, demonstrating its flexibility and practical utility on real, partially observed datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u751f\u5b58\u5206\u6790\uff08DSA\uff09\u7684\u95ed\u5f0f\u4f3c\u7136\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u79bb\u6563\u89c2\u6d4b\u7684\u53d1\u75c5\u7387\u8ba1\u6570\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u968f\u673a\u533a\u5ba4\u6a21\u578b\u5728\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e0b\u4f3c\u7136\u51fd\u6570\u96be\u4ee5\u8ba1\u7b97\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u673a\u533a\u5ba4\u6a21\u578b\u5e38\u7528\u4e8e\u63cf\u8ff0\u75be\u75c5\u4f20\u64ad\uff0c\u4f46\u5728\u8bb8\u591a\u76d1\u6d4b\u6570\u636e\u4e0b\uff0c\u7531\u4e8e\u4fe1\u606f\u7f3a\u5931\u5bfc\u81f4\u8fb9\u9645\u4f3c\u7136\u51fd\u6570\u96be\u4ee5\u5904\u7406\uff0c\u4f7f\u5f97\u63a8\u65ad\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u91c7\u7528\u52a8\u6001\u751f\u5b58\u5206\u6790\uff08DSA\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u5927\u79cd\u7fa4\u6781\u9650\u8fd1\u4f3c\u968f\u673a\u79cd\u7fa4\u6c34\u5e73\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u7559\u8ba1\u6570\u503c\u7684\u968f\u673a\u6a21\u578b\uff0c\u5f00\u53d1\u51fa\u95ed\u5f0f\u4f3c\u7136\u51fd\u6570\u7528\u4e8e\u79bb\u6563\u89c2\u6d4b\u7684\u53d1\u75c5\u7387\u8ba1\u6570\u6570\u636e\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u5728\u90e8\u5206\u89c2\u6d4b\u8bbe\u7f6e\u4e0b\uff0c\u53c2\u6570\u4f30\u8ba1\u4e0e\u6700\u8fd1\u7cbe\u786e\u4f46\u8ba1\u7b97\u6602\u8d35\u7684\u57fa\u4e8e\u4f3c\u7136\u7684\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u3002\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5177\u6709\u4e2a\u4f53\u5f02\u8d28\u6027\u7684\u6a21\u578b\uff08\u5982\u8106\u5f31\u6a21\u578b\uff09\uff0c\u5e76\u5728\u57c3\u535a\u62c9\u548cCOVID-19\u6570\u636e\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u7075\u6d3b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684DSA\u65b9\u6cd5\u4e3a\u90e8\u5206\u89c2\u6d4b\u7684\u6d41\u884c\u75c5\u6570\u636e\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u63a8\u65ad\u7b56\u7565\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u6a21\u578b\u5982\u7f51\u7edc\u4f20\u64ad\u6a21\u578b\u548c\u5177\u6709\u6613\u611f\u6027\u5206\u5e03\u7684\u6a21\u578b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.04459", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04459", "abs": "https://arxiv.org/abs/2602.04459", "authors": ["Ali Mohammad-Djafari"], "title": "Bayesian PINNs for uncertainty-aware inverse problems (BPINN-IP)", "comment": "submitted to ICIP 2006 conference", "summary": "The main contribution of this paper is to develop a hierarchical Bayesian formulation of PINNs for linear inverse problems, which is called BPINN-IP. The proposed methodology extends PINN to account for prior knowledge on the nature of the expected NN output, as well as its weights. Also, as we can have access to the posterior probability distributions, naturally uncertainties can be quantified. Also, variational inference and Monte Carlo dropout are employed to provide predictive means and variances for reconstructed images. Un example of applications to deconvolution and super-resolution is considered, details of the different steps of implementations are given, and some preliminary results are presented.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BPINN-IP\uff0c\u4e00\u79cd\u7528\u4e8e\u7ebf\u6027\u9006\u95ee\u9898\u7684\u5206\u5c42\u8d1d\u53f6\u65af\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u80fd\u591f\u7ed3\u5408\u5148\u9a8c\u77e5\u8bc6\u5e76\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edfPINNs\u5728\u5904\u7406\u9006\u95ee\u9898\u65f6\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u4e14\u96be\u4ee5\u878d\u5165\u5148\u9a8c\u77e5\u8bc6\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\u6765\u6269\u5c55PINNs\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u7ebf\u6027\u9006\u95ee\u9898\u5e76\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8d1d\u53f6\u65afPINN\u6846\u67b6(BPINN-IP)\uff0c\u5c06\u5148\u9a8c\u77e5\u8bc6\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u548c\u6743\u91cd\u3002\u91c7\u7528\u53d8\u5206\u63a8\u7406\u548c\u8499\u7279\u5361\u6d1bdropout\u65b9\u6cd5\u8ba1\u7b97\u9884\u6d4b\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u53bb\u5377\u79ef\u548c\u8d85\u5206\u8fa8\u7387\u7b49\u7ebf\u6027\u9006\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u5e94\u7528\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5b9e\u73b0\u7ec6\u8282\uff0c\u5e76\u7ed9\u51fa\u4e86\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "BPINN-IP\u6210\u529f\u5c06\u8d1d\u53f6\u65af\u6846\u67b6\u5f15\u5165PINNs\uff0c\u4e3a\u7ebf\u6027\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u5148\u9a8c\u77e5\u8bc6\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u56fe\u50cf\u91cd\u5efa\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2602.04596", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04596", "abs": "https://arxiv.org/abs/2602.04596", "authors": ["Sandra Fortini", "Kenyon Ng", "Sonia Petrone", "Judith Rousseau", "Susan Wei"], "title": "A principled framework for uncertainty decomposition in TabPFN", "comment": "9 pages (+2 reference, +34 appendix). Code in https://github.com/weiyaw/ud4pfn", "summary": "TabPFN is a transformer that achieves state-of-the-art performance on supervised tabular tasks by amortizing Bayesian prediction into a single forward pass. However, there is currently no method for uncertainty decomposition in TabPFN. Because it behaves, in an idealised limit, as a Bayesian in-context learner, we cast the decomposition challenge as a Bayesian predictive inference (BPI) problem. The main computational tool in BPI, predictive Monte Carlo, is challenging to apply here as it requires simulating unmodeled covariates. We therefore pursue the asymptotic alternative, filling a gap in the theory for supervised settings by proving a predictive CLT under quasi-martingale conditions. We derive variance estimators determined by the volatility of predictive updates along the context. The resulting credible bands are fast to compute, target epistemic uncertainty, and achieve near-nominal frequentist coverage. For classification, we further obtain an entropy-based uncertainty decomposition.", "AI": {"tldr": "TabPFN\u4f5c\u4e3a\u8868\u683c\u6570\u636e\u9884\u6d4b\u7684transformer\u6a21\u578b\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u65b9\u6cd5\uff0c\u672c\u6587\u901a\u8fc7\u8d1d\u53f6\u65af\u9884\u6d4b\u63a8\u65ad\u7406\u8bba\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u573a\u666f\u4e0b\u8bc1\u660e\u4e86\u9884\u6d4b\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u9884\u6d4b\u66f4\u65b0\u6ce2\u52a8\u7387\u7684\u65b9\u5dee\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u8ba1\u7b97\u7684\u53ef\u4fe1\u533a\u95f4\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u3002", "motivation": "TabPFN\u5728\u8868\u683c\u76d1\u7763\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u65b9\u6cd5\u3002\u7531\u4e8eTabPFN\u5728\u7406\u60f3\u5316\u6781\u9650\u4e0b\u8868\u73b0\u4e3a\u8d1d\u53f6\u65af\u4e0a\u4e0b\u6587\u5b66\u4e60\u5668\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u5176\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u53ef\u9760\u9884\u6d4b\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u95ee\u9898\u8f6c\u5316\u4e3a\u8d1d\u53f6\u65af\u9884\u6d4b\u63a8\u65ad\u95ee\u9898\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u573a\u666f\u4e0b\u8bc1\u660e\u4e86\u9884\u6d4b\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff08\u57fa\u4e8e\u62df\u9785\u6761\u4ef6\uff09\uff0c\u63a8\u5bfc\u51fa\u7531\u4e0a\u4e0b\u6587\u9884\u6d4b\u66f4\u65b0\u6ce2\u52a8\u7387\u51b3\u5b9a\u7684\u65b9\u5dee\u4f30\u8ba1\u5668\u3002\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u8fdb\u4e00\u6b65\u83b7\u5f97\u57fa\u4e8e\u71b5\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u8ba1\u7b97\u53ef\u4fe1\u533a\u95f4\uff0c\u9488\u5bf9\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u63a5\u8fd1\u540d\u4e49\u9891\u7387\u7684\u8986\u76d6\u5ea6\u3002\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u83b7\u5f97\u4e86\u57fa\u4e8e\u71b5\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\uff0c\u4e3aTabPFN\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86TabPFN\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u9884\u6d4b\u63a8\u65ad\u6846\u67b6\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u573a\u666f\u4e0b\u5efa\u7acb\u4e86\u9884\u6d4b\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u4e3a\u8868\u683c\u6570\u636etransformer\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.04611", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04611", "abs": "https://arxiv.org/abs/2602.04611", "authors": ["Yuxin Wang", "Dennis Frauen", "Emil Javurek", "Konstantin Hess", "Yuchen Ma", "Stefan Feuerriegel"], "title": "Targeted Synthetic Control Method", "comment": null, "summary": "The synthetic control method (SCM) estimates causal effects in panel data with a single-treated unit by constructing a counterfactual outcome as a weighted combination of untreated control units that matches the pre-treatment trajectory. In this paper, we introduce the targeted synthetic control (TSC) method, a new two-stage estimator that directly estimates the counterfactual outcome. Specifically, our TSC method (1) yields a targeted debiasing estimator, in the sense that the targeted updating refines the initial weights to produce more stable weights; and (2) ensures that the final counterfactual estimation is a convex combination of observed control outcomes to enable direct interpretation of the synthetic control weights. TSC is flexible and can be instantiated with arbitrary machine learning models. Methodologically, TSC starts from an initial set of synthetic-control weights via a one-dimensional targeted update through the weight-tilting submodel, which calibrates the weights to reduce bias of weights estimation arising from pre-treatment fit. Furthermore, TSC avoids key shortcomings of existing methods (e.g., the augmented SCM), which can produce unbounded counterfactual estimates. Across extensive synthetic and real-world experiments, TSC consistently improves estimation accuracy over state-of-the-art SCM baselines.", "AI": {"tldr": "\u63d0\u51fa\u76ee\u6807\u5408\u6210\u63a7\u5236(TSC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f30\u8ba1\u76f4\u63a5\u4f30\u8ba1\u53cd\u4e8b\u5b9e\u7ed3\u679c\uff0c\u6539\u8fdb\u4f20\u7edf\u5408\u6210\u63a7\u5236\u65b9\u6cd5\u7684\u6743\u91cd\u7a33\u5b9a\u6027\u548c\u4f30\u8ba1\u51c6\u786e\u6027", "motivation": "\u4f20\u7edf\u5408\u6210\u63a7\u5236\u65b9\u6cd5(SCM)\u5728\u9762\u677f\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u65f6\uff0c\u901a\u8fc7\u672a\u5904\u7406\u63a7\u5236\u5355\u5143\u7684\u52a0\u6743\u7ec4\u5408\u6784\u5efa\u53cd\u4e8b\u5b9e\u7ed3\u679c\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6743\u91cd\u4f30\u8ba1\u4e0d\u7a33\u5b9a\u3001\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u53ef\u80fd\u65e0\u754c\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u65b9\u6cd5", "method": "\u63d0\u51fa\u76ee\u6807\u5408\u6210\u63a7\u5236(TSC)\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u76ee\u6807\u53bb\u504f\u4f30\u8ba1\u5668\uff0c\u4f7f\u7528\u6743\u91cd\u503e\u659c\u5b50\u6a21\u578b\u8fdb\u884c\u4e00\u7ef4\u76ee\u6807\u66f4\u65b0\uff0c\u6821\u51c6\u6743\u91cd\u4ee5\u51cf\u5c11\u9884\u6cbb\u7597\u62df\u5408\u5e26\u6765\u7684\u504f\u5dee\uff1b2) \u786e\u4fdd\u6700\u7ec8\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u662f\u89c2\u6d4b\u63a7\u5236\u7ed3\u679c\u7684\u51f8\u7ec4\u5408\uff0c\u4fbf\u4e8e\u76f4\u63a5\u89e3\u91ca\u5408\u6210\u63a7\u5236\u6743\u91cd\uff1b3) \u65b9\u6cd5\u7075\u6d3b\uff0c\u53ef\u4e0e\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u5408", "result": "\u5728\u5e7f\u6cdb\u7684\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0cTSC\u76f8\u6bd4\u6700\u5148\u8fdb\u7684SCM\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6301\u7eed\u63d0\u9ad8\u4e86\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5(\u5982\u589e\u5f3aSCM)\u53ef\u80fd\u4ea7\u751f\u65e0\u754c\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u7684\u5173\u952e\u7f3a\u9677", "conclusion": "TSC\u65b9\u6cd5\u901a\u8fc7\u76ee\u6807\u66f4\u65b0\u673a\u5236\u6539\u8fdb\u4e86\u5408\u6210\u63a7\u5236\u6743\u91cd\u4f30\u8ba1\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6743\u91cd\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u9762\u677f\u6570\u636e\u4e2d\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u7a33\u5065\u7684\u4f30\u8ba1\u6846\u67b6"}}
{"id": "2602.04667", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04667", "abs": "https://arxiv.org/abs/2602.04667", "authors": ["Philipp Alexander Schwarz", "Johannes Oberpriller", "Sven Klaassen"], "title": "Causal explanations of outliers in systems with lagged time-dependencies", "comment": null, "summary": "Root-cause analysis in controlled time dependent systems poses a major challenge in applications. Especially energy systems are difficult to handle as they exhibit instantaneous as well as delayed effects and if equipped with storage, do have a memory. In this paper we adapt the causal root-cause analysis method of Budhathoki et al. [2022] to general time-dependent systems, as it can be regarded as a strictly causal definition of the term \"root-cause\". Particularly, we discuss two truncation approaches to handle the infinite dependency graphs present in time-dependent systems. While one leaves the causal mechanisms intact, the other approximates the mechanisms at the start nodes. The effectiveness of the different approaches is benchmarked using a challenging data generation process inspired by a problem in factory energy management: the avoidance of peaks in the power consumption. We show that given enough lags our extension is able to localize the root-causes in the feature and time domain. Further the effect of mechanism approximation is discussed.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06Budhathoki\u7b49\u4eba\u7684\u56e0\u679c\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u6269\u5c55\u5230\u65f6\u95f4\u4f9d\u8d56\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e24\u79cd\u622a\u65ad\u65b9\u6cd5\u5904\u7406\u65e0\u9650\u4f9d\u8d56\u56fe\uff0c\u5e76\u5728\u5de5\u5382\u80fd\u6e90\u7ba1\u7406\u7684\u5cf0\u503c\u907f\u514d\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u65f6\u95f4\u4f9d\u8d56\u7cfb\u7edf\uff08\u7279\u522b\u662f\u80fd\u6e90\u7cfb\u7edf\uff09\u7684\u6839\u56e0\u5206\u6790\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u7cfb\u7edf\u540c\u65f6\u5b58\u5728\u77ac\u65f6\u6548\u5e94\u548c\u5ef6\u8fdf\u6548\u5e94\uff0c\u4e14\u5982\u679c\u914d\u5907\u5b58\u50a8\u5219\u5177\u6709\u8bb0\u5fc6\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8fd9\u7c7b\u7cfb\u7edf\u7684\u56e0\u679c\u5206\u6790\u3002", "method": "\u5c06Budhathoki\u7b49\u4eba\u7684\u56e0\u679c\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u6269\u5c55\u5230\u4e00\u822c\u65f6\u95f4\u4f9d\u8d56\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e24\u79cd\u622a\u65ad\u65b9\u6cd5\uff1a\u4e00\u79cd\u4fdd\u6301\u56e0\u679c\u673a\u5236\u5b8c\u6574\uff0c\u53e6\u4e00\u79cd\u5728\u8d77\u59cb\u8282\u70b9\u5904\u8fd1\u4f3c\u56e0\u679c\u673a\u5236\u3002\u4f7f\u7528\u5de5\u5382\u80fd\u6e90\u7ba1\u7406\u4e2d\u907f\u514d\u529f\u7387\u6d88\u8017\u5cf0\u503c\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5f53\u63d0\u4f9b\u8db3\u591f\u7684\u6ede\u540e\u9879\u65f6\uff0c\u6269\u5c55\u65b9\u6cd5\u80fd\u591f\u5728\u7279\u5f81\u57df\u548c\u65f6\u95f4\u57df\u4e2d\u5b9a\u4f4d\u6839\u56e0\u3002\u540c\u65f6\u8ba8\u8bba\u4e86\u673a\u5236\u8fd1\u4f3c\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06\u56e0\u679c\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u6269\u5c55\u5230\u65f6\u95f4\u4f9d\u8d56\u7cfb\u7edf\uff0c\u63d0\u51fa\u7684\u622a\u65ad\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u65e0\u9650\u4f9d\u8d56\u56fe\uff0c\u4e3a\u80fd\u6e90\u7cfb\u7edf\u7b49\u5177\u6709\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6839\u56e0\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2602.04736", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04736", "abs": "https://arxiv.org/abs/2602.04736", "authors": ["Thatchanon Anancharoenkij", "Donlapark Ponnoprat"], "title": "Conditional Counterfactual Mean Embeddings: Doubly Robust Estimation and Learning Rates", "comment": "Code is available at https://github.com/donlap/Conditional-Counterfactual-Mean-Embeddings", "summary": "A complete understanding of heterogeneous treatment effects involves characterizing the full conditional distribution of potential outcomes. To this end, we propose the Conditional Counterfactual Mean Embeddings (CCME), a framework that embeds conditional distributions of counterfactual outcomes into a reproducing kernel Hilbert space (RKHS). Under this framework, we develop a two-stage meta-estimator for CCME that accommodates any RKHS-valued regression in each stage. Based on this meta-estimator, we develop three practical CCME estimators: (1) Ridge Regression estimator, (2) Deep Feature estimator that parameterizes the feature map by a neural network, and (3) Neural-Kernel estimator that performs RKHS-valued regression, with the coefficients parameterized by a neural network. We provide finite-sample convergence rates for all estimators, establishing that they possess the double robustness property. Our experiments demonstrate that our estimators accurately recover distributional features including multimodal structure of conditional counterfactual distributions.", "AI": {"tldr": "\u63d0\u51fa\u6761\u4ef6\u53cd\u4e8b\u5b9e\u5747\u503c\u5d4c\u5165\uff08CCME\uff09\u6846\u67b6\uff0c\u5c06\u53cd\u4e8b\u5b9e\u7ed3\u679c\u7684\u6761\u4ef6\u5206\u5e03\u5d4c\u5165\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u5f00\u53d1\u4e86\u4e09\u79cd\u5177\u6709\u53cc\u91cd\u7a33\u5065\u6027\u7684\u4f30\u8ba1\u5668\uff0c\u80fd\u51c6\u786e\u6062\u590d\u6761\u4ef6\u53cd\u4e8b\u5b9e\u5206\u5e03\u7684\u591a\u6a21\u6001\u7ed3\u6784\u3002", "motivation": "\u4e3a\u4e86\u5168\u9762\u7406\u89e3\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\uff0c\u9700\u8981\u523b\u753b\u6f5c\u5728\u7ed3\u679c\u7684\u5b8c\u6574\u6761\u4ef6\u5206\u5e03\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u6761\u4ef6\u5747\u503c\uff0c\u800c\u5ffd\u7565\u4e86\u5206\u5e03\u7684\u5176\u4ed6\u7279\u5f81\u3002", "method": "\u63d0\u51faCCME\u6846\u67b6\uff0c\u5c06\u6761\u4ef6\u53cd\u4e8b\u5b9e\u5206\u5e03\u5d4c\u5165RKHS\u3002\u5f00\u53d1\u4e24\u9636\u6bb5\u5143\u4f30\u8ba1\u5668\uff0c\u53ef\u5bb9\u7eb3\u4efb\u4f55RKHS\u503c\u56de\u5f52\u3002\u5177\u4f53\u5b9e\u73b0\u4e09\u79cd\u4f30\u8ba1\u5668\uff1a\u5cad\u56de\u5f52\u4f30\u8ba1\u5668\u3001\u6df1\u5ea6\u7279\u5f81\u4f30\u8ba1\u5668\uff08\u7528\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u7279\u5f81\u6620\u5c04\uff09\u3001\u795e\u7ecf\u6838\u4f30\u8ba1\u5668\uff08\u7528\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316RKHS\u503c\u56de\u5f52\u7cfb\u6570\uff09\u3002", "result": "\u4e3a\u6240\u6709\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u6709\u9650\u6837\u672c\u6536\u655b\u7387\uff0c\u8bc1\u660e\u5b83\u4eec\u5177\u6709\u53cc\u91cd\u7a33\u5065\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u4f30\u8ba1\u5668\u80fd\u51c6\u786e\u6062\u590d\u6761\u4ef6\u53cd\u4e8b\u5b9e\u5206\u5e03\u7684\u5206\u5e03\u7279\u5f81\uff0c\u5305\u62ec\u591a\u6a21\u6001\u7ed3\u6784\u3002", "conclusion": "CCME\u6846\u67b6\u4e3a\u5206\u6790\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u6355\u6349\u5b8c\u6574\u7684\u6761\u4ef6\u5206\u5e03\u7279\u5f81\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5747\u503c\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2602.04872", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04872", "abs": "https://arxiv.org/abs/2602.04872", "authors": ["Nicholas Barnfield", "Subhabrata Sen", "Pragya Sur"], "title": "Multi-layer Cross-Attention is Provably Optimal for Multi-modal In-context Learning", "comment": null, "summary": "Recent progress has rapidly advanced our understanding of the mechanisms underlying in-context learning in modern attention-based neural networks. However, existing results focus exclusively on unimodal data; in contrast, the theoretical underpinnings of in-context learning for multi-modal data remain poorly understood. We introduce a mathematically tractable framework for studying multi-modal learning and explore when transformer-like architectures can recover Bayes-optimal performance in-context. To model multi-modal problems, we assume the observed data arises from a latent factor model. Our first result comprises a negative take on expressibility: we prove that single-layer, linear self-attention fails to recover the Bayes-optimal predictor uniformly over the task distribution. To address this limitation, we introduce a novel, linearized cross-attention mechanism, which we study in the regime where both the number of cross-attention layers and the context length are large. We show that this cross-attention mechanism is provably Bayes optimal when optimized using gradient flow. Our results underscore the benefits of depth for in-context learning and establish the provable utility of cross-attention for multi-modal distributions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u6a21\u6001\u6570\u636e\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7406\u8bba\u673a\u5236\uff0c\u8bc1\u660e\u4e86\u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u65e0\u6cd5\u5b9e\u73b0\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\uff0c\u800c\u63d0\u51fa\u7684\u7ebf\u6027\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5728\u6df1\u5ea6\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u8db3\u591f\u5927\u65f6\u80fd\u591f\u5b9e\u73b0\u8d1d\u53f6\u65af\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u7406\u8bba\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u6a21\u6001\u6570\u636e\uff0c\u800c\u591a\u6a21\u6001\u6570\u636e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7406\u8bba\u57fa\u7840\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63a2\u7d22transformer\u67b6\u6784\u4f55\u65f6\u80fd\u6062\u590d\u8d1d\u53f6\u65af\u6700\u4f18\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u6570\u5b66\u53ef\u5904\u7406\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5047\u8bbe\u89c2\u6d4b\u6570\u636e\u6765\u81ea\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u3002\u9996\u5148\u8bc1\u660e\u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u65e0\u6cd5\u5b9e\u73b0\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\uff0c\u7136\u540e\u5f15\u5165\u7ebf\u6027\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7814\u7a76\u5728\u4ea4\u53c9\u6ce8\u610f\u529b\u5c42\u6570\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u90fd\u5f88\u5927\u7684\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002", "result": "1. \u5355\u5c42\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u65e0\u6cd5\u5728\u4efb\u52a1\u5206\u5e03\u4e0a\u4e00\u81f4\u6062\u590d\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\u5668\uff1b2. \u63d0\u51fa\u7684\u7ebf\u6027\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5728\u4f7f\u7528\u68af\u5ea6\u6d41\u4f18\u5316\u65f6\uff0c\u5728\u6df1\u5ea6\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u8db3\u591f\u5927\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u5b9e\u73b0\u8d1d\u53f6\u65af\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u6df1\u5ea6\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u6709\u76ca\uff0c\u4ea4\u53c9\u6ce8\u610f\u529b\u5bf9\u591a\u6a21\u6001\u5206\u5e03\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6548\u7528\u3002\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5f3a\u8c03\u4e86\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5728\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
