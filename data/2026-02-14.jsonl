{"id": "2602.11379", "categories": ["stat.AP", "econ.GN", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11379", "abs": "https://arxiv.org/abs/2602.11379", "authors": ["Han Su", "Xiaojia Guo", "Xiaoke Zhang"], "title": "Regularized Ensemble Forecasting for Learning Weights from Historical and Current Forecasts", "comment": null, "summary": "Combining forecasts from multiple experts often yields more accurate results than relying on a single expert. In this paper, we introduce a novel regularized ensemble method that extends the traditional linear opinion pool by leveraging both current forecasts and historical performances to set the weights. Unlike existing approaches that rely only on either the current forecasts or past accuracy, our method accounts for both sources simultaneously. It learns weights by minimizing the variance of the combined forecast (or its transformed version) while incorporating a regularization term informed by historical performances. We also show that this approach has a Bayesian interpretation. Different distributional assumptions within this Bayesian framework yield different functional forms for the variance component and the regularization term, adapting the method to various scenarios. In empirical studies on Walmart sales and macroeconomic forecasting, our ensemble outperforms leading benchmark models both when experts' full forecasting histories are available and when experts enter and exit over time, resulting in incomplete historical records. Throughout, we provide illustrative examples that show how the optimal weights are determined and, based on the empirical results, we discuss where the framework's strengths lie and when experts' past versus current forecasts are more informative."}
{"id": "2602.12072", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.12072", "abs": "https://arxiv.org/abs/2602.12072", "authors": ["Maxime Turgeon", "Michael Kieser", "Dwight Wolfe", "Bruce MacArthur"], "title": "Enhanced Forest Inventories for Habitat Mapping: A Case Study in the Sierra Nevada Mountains of California", "comment": "11 pages, 6 figures", "summary": "Traditional forest inventory systems, originally designed to quantify merchantable timber volume, often lack the spatial resolution and structural detail required for modern multi-resource ecosystem management. In this manuscript, we present an Enhanced Forest Inventory (EFI) and demonstrate its utility for high-resolution wildlife habitat mapping. The project area covers 270,000 acres of the Eldorado National Forest in California's Sierra Nevada. By integrating 118 ground-truth Forest Inventory and Analysis (FIA) plots with multi-modal remote sensing data (LiDAR, aerial photography, and Sentinel-2 satellite imagery), we developed predictive models for key forest attributes. Our methodology employed a two-tier segmentation approach, partitioning the landscape into approximately 575,000 reporting units with an average size of 0.5 acre to capture forest heterogeneity. We utilized an Elastic-Net Regression framework and automated feature selection to relate remote sensing metrics to ground-measured variables such as basal area, stems per acre, and canopy cover. These physical metrics were translated into functional habitat attributes to evaluate suitability for two focal species: the California Spotted Owl (Strix occidentalis occidentalis) and the Pacific Fisher (Pekania pennanti). Our analysis identified 25,630 acres of nesting and 26,622 acres of foraging habitat for the owl, and 25,636 acres of likely habitat for the fisher based on structural requirements like large-diameter trees and high canopy closure. The results demonstrate that EFIs provide a critical bridge between forestry and conservation ecology, offering forest managers a spatially explicit tool to monitor ecosystem health and manage vulnerable species in complex environments."}
{"id": "2602.11711", "categories": ["stat.ML", "cs.LG", "math.NA", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.11711", "abs": "https://arxiv.org/abs/2602.11711", "authors": ["Jean-François Giovannelli"], "title": "Estimation of instrument and noise parameters for inverse problem based on prior diffusion model", "comment": null, "summary": "This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification."}
{"id": "2602.11403", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11403", "abs": "https://arxiv.org/abs/2602.11403", "authors": ["Kenneth M. Lee", "Xi Fang", "Fan Li", "Michael O. Harhay"], "title": "Who's Winning? Clarifying Estimands Based on Win Statistics in Cluster Randomized Trials", "comment": "13 pages (main manuscript), 5 pages (supplementary appendix), 4 tables (main manuscript), 3 tables (supplementary appendix)", "summary": "Treatment effect estimands based on win statistics, including the win ratio, win odds, and win difference are increasingly popular targets for summarizing endpoints in clinical trials. Such win estimands offer an intuitive approach for prioritizing outcomes by clinical importance. The implementation and interpretation of win estimands is complicated in cluster randomized trials (CRTs), where researchers can target fundamentally different estimands on the individual-level or cluster-level. We numerically demonstrate that individual-pair and cluster-pair win estimands can substantially differ when cluster size is informative: where outcomes and/or treatment effects depend on cluster size. With such informative cluster sizes, individual-pair and cluster-pair win estimands can even yield opposite conclusions regarding treatment benefit. We describe consistent estimators for individual-pair and cluster-pair win estimands and propose a leave-one-cluster-out jackknife variance estimator for inference. Despite being consistent, our simulations highlight that some caution is needed when implementing individual-pair win estimators due to finite-sample bias. In contrast, cluster-pair win estimators are unbiased for their respective targets. Altogether, careful specification of the target estimand is essential when applying win estimators in CRTs. Failure to clearly define whether individual-pair or cluster-pair win estimands are of primary interest may result in answering a dramatically different question than intended."}
{"id": "2602.11496", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11496", "abs": "https://arxiv.org/abs/2602.11496", "authors": ["Youngho Bae", "Chanmin Kim", "Fenglei Wang", "Qi Sun", "Kyu Ha Lee"], "title": "High-Dimensional Mediation Analysis for Generalized Linear Models Using Bayesian Variable Selection Guided by Mediator Correlation", "comment": null, "summary": "High-dimensional mediation analysis aims to identify mediating pathways and to estimate indirect effects linking an exposure to an outcome. In this paper, we propose a Bayesian framework to address key challenges in these analyses, including high dimensionality, complex dependence among omics mediators, and non-continuous outcomes. Furthermore, commonly used approaches assume independent mediators or ignore correlations in the selection stage, which can reduce power when mediators are highly correlated. Addressing these challenges leads to a non-Gaussian likelihood and specialized selection priors, which in turn require efficient and adaptive posterior computation. Our proposed framework selects active pathways under generalized linear models while accounting for mediator dependence. Specifically, the mediators are modeled using a multivariate distribution, exposure-mediator selection is guided by a Markov random field prior on inclusion indicators, and mediator-outcome activation is restricted to mediators supported in the exposure-mediator model through a sequential subsetting Bernoulli prior. Simulation studies show improved operating characteristics in correlated-mediator settings, with appropriate error control under the global null and stable performance under model misspecification. We illustrate the method using real-world metabolomics data to study metabolites that mediate the association between adherence to the Alternate Mediterranean Diet score and two cardiometabolic outcomes."}
{"id": "2602.11325", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11325", "abs": "https://arxiv.org/abs/2602.11325", "authors": ["Ayush Bharti", "Charita Dellaporta", "Yuga Hikida", "François-Xavier Briol"], "title": "Amortised and provably-robust simulation-based inference", "comment": null, "summary": "Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches."}
{"id": "2602.11511", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11511", "abs": "https://arxiv.org/abs/2602.11511", "authors": ["Ziqi Liu", "Ye Tian", "Weijing Tang"], "title": "Representation Learning with Blockwise Missingness and Signal Heterogeneity", "comment": null, "summary": "Unified representation learning for multi-source data integration faces two important challenges: blockwise missingness and blockwise signal heterogeneity. The former arises from sources observing different, yet potentially overlapping, feature sets, while the latter involves varying signal strengths across subject groups and feature sets. While existing methods perform well with fully observed data or uniform signal strength, their performance degenerates when these two challenges coincide, which is common in practice. To address this, we propose Anchor Projected Principal Component Analysis (APPCA), a general framework for representation learning with structured blockwise missingness that is robust to signal heterogeneity. APPCA first recovers robust group-specific column spaces using all observed feature sets, and then aligns them by projecting shared \"anchor\" features onto these subspaces before performing PCA. This projection step induces a significant denoising effect. We establish estimation error bounds for embedding reconstruction through a fine-grained perturbation analysis. In particular, using a novel spectral slicing technique, our bound eliminates the standard dependency on the signal strength of subject embeddings, relying instead solely on the signal strength of integrated feature sets. We validate the proposed method through extensive simulation studies and an application to multimodal single-cell sequencing data."}
{"id": "2602.11511", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11511", "abs": "https://arxiv.org/abs/2602.11511", "authors": ["Ziqi Liu", "Ye Tian", "Weijing Tang"], "title": "Representation Learning with Blockwise Missingness and Signal Heterogeneity", "comment": null, "summary": "Unified representation learning for multi-source data integration faces two important challenges: blockwise missingness and blockwise signal heterogeneity. The former arises from sources observing different, yet potentially overlapping, feature sets, while the latter involves varying signal strengths across subject groups and feature sets. While existing methods perform well with fully observed data or uniform signal strength, their performance degenerates when these two challenges coincide, which is common in practice. To address this, we propose Anchor Projected Principal Component Analysis (APPCA), a general framework for representation learning with structured blockwise missingness that is robust to signal heterogeneity. APPCA first recovers robust group-specific column spaces using all observed feature sets, and then aligns them by projecting shared \"anchor\" features onto these subspaces before performing PCA. This projection step induces a significant denoising effect. We establish estimation error bounds for embedding reconstruction through a fine-grained perturbation analysis. In particular, using a novel spectral slicing technique, our bound eliminates the standard dependency on the signal strength of subject embeddings, relying instead solely on the signal strength of integrated feature sets. We validate the proposed method through extensive simulation studies and an application to multimodal single-cell sequencing data."}
{"id": "2602.11406", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11406", "abs": "https://arxiv.org/abs/2602.11406", "authors": ["Tomer Gafni", "Garud Iyengar", "Assaf Zeevi"], "title": "The Cost of Learning under Multiple Change Points", "comment": null, "summary": "We consider an online learning problem in environments with multiple change points. In contrast to the single change point problem that is widely studied using classical \"high confidence\" detection schemes, the multiple change point environment presents new learning-theoretic and algorithmic challenges. Specifically, we show that classical methods may exhibit catastrophic failure (high regret) due to a phenomenon we refer to as endogenous confounding. To overcome this, we propose a new class of learning algorithms dubbed Anytime Tracking CUSUM (ATC). These are horizon-free online algorithms that implement a selective detection principle, balancing the need to ignore \"small\" (hard-to-detect) shifts, while reacting \"quickly\" to significant ones. We prove that the performance of a properly tuned ATC algorithm is nearly minimax-optimal; its regret is guaranteed to closely match a novel information-theoretic lower bound on the achievable performance of any learning algorithm in the multiple change point problem. Experiments on synthetic as well as real-world data validate the aforementioned theoretical findings."}
{"id": "2602.11610", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11610", "abs": "https://arxiv.org/abs/2602.11610", "authors": ["Aniket Biswas", "Aaditya Ramdas"], "title": "Improving the adjusted Benjamini--Hochberg method using e-values in knockoff-assisted variable selection", "comment": "Main manuscript 18 pages, 4 figures. Appendices 12 pages, 8 figures", "summary": "Considering the knockoff-based multiple testing framework of Barber and Candès [2015], we revisit the method of Sarkar and Tang [2022] and identify it as a specific case of an un-normalized e-value weighted Benjamini-Hochberg procedure. Building on this insight, we extend the method to use bounded p-to-e calibrators that enable more refined and flexible weight assignments. Our approach generalizes the method of Sarkar and Tang [2022], which emerges as a special case corresponding to an extreme calibrator. Within this framework, we propose three procedures: an e-value weighted Benjamini-Hochberg method, its adaptive extension using an estimate of the proportion of true null hypotheses, and an adaptive weighted Benjamini-Hochberg method. We establish control of the false discovery rate (FDR) for the proposed methods. While we do not formally prove that the proposed methods outperform those of Barber and Candès [2015] and Sarkar and Tang [2022], simulation studies and real-data analysis demonstrate large and consistent improvement over the latter in all cases, and better performance than the knockoff method in scenarios with low target FDR, a small number of signals, and weak signal strength. Simulation studies and a real-data application in HIV-1 drug resistance analysis demonstrate strong finite sample FDR control and exhibit improved, or at least competitive, power relative to the aforementioned methods."}
{"id": "2602.11325", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11325", "abs": "https://arxiv.org/abs/2602.11325", "authors": ["Ayush Bharti", "Charita Dellaporta", "Yuga Hikida", "François-Xavier Briol"], "title": "Amortised and provably-robust simulation-based inference", "comment": null, "summary": "Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches."}
{"id": "2602.11520", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.11520", "abs": "https://arxiv.org/abs/2602.11520", "authors": ["Yasin Khadem Charvadeh", "Katherine S. Panageas", "Yuan Chen"], "title": "Locally Interpretable Individualized Treatment Rules for Black-Box Decision Models", "comment": null, "summary": "Individualized treatment rules (ITRs) aim to optimize healthcare by tailoring treatment decisions to patient-specific characteristics. Existing methods typically rely on either interpretable but inflexible models or highly flexible black-box approaches that sacrifice interpretability; moreover, most impose a single global decision rule across patients. We introduce the Locally Interpretable Individualized Treatment Rule (LI-ITR) method, which combines flexible machine learning models to accurately learn complex treatment outcomes with locally interpretable approximations to construct subject-specific treatment rules. LI-ITR employs variational autoencoders to generate realistic local synthetic samples and learns individualized decision rules through a mixture of interpretable experts. Simulation studies show that LI-ITR accurately recovers true subject-specific local coefficients and optimal treatment strategies. An application to precision side-effect management in breast cancer illustrates the necessity of flexible predictive modeling and highlights the practical utility of LI-ITR in estimating optimal treatment rules while providing transparent, clinically interpretable explanations."}
{"id": "2602.11679", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11679", "abs": "https://arxiv.org/abs/2602.11679", "authors": ["Kyungbok Lee", "Angelica Cristello Sarteau", "Michael R. Kosorok"], "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs", "comment": "65 pages, 4 figures. Submitted to JMLR", "summary": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness."}
{"id": "2602.11610", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11610", "abs": "https://arxiv.org/abs/2602.11610", "authors": ["Aniket Biswas", "Aaditya Ramdas"], "title": "Improving the adjusted Benjamini--Hochberg method using e-values in knockoff-assisted variable selection", "comment": "Main manuscript 18 pages, 4 figures. Appendices 12 pages, 8 figures", "summary": "Considering the knockoff-based multiple testing framework of Barber and Candès [2015], we revisit the method of Sarkar and Tang [2022] and identify it as a specific case of an un-normalized e-value weighted Benjamini-Hochberg procedure. Building on this insight, we extend the method to use bounded p-to-e calibrators that enable more refined and flexible weight assignments. Our approach generalizes the method of Sarkar and Tang [2022], which emerges as a special case corresponding to an extreme calibrator. Within this framework, we propose three procedures: an e-value weighted Benjamini-Hochberg method, its adaptive extension using an estimate of the proportion of true null hypotheses, and an adaptive weighted Benjamini-Hochberg method. We establish control of the false discovery rate (FDR) for the proposed methods. While we do not formally prove that the proposed methods outperform those of Barber and Candès [2015] and Sarkar and Tang [2022], simulation studies and real-data analysis demonstrate large and consistent improvement over the latter in all cases, and better performance than the knockoff method in scenarios with low target FDR, a small number of signals, and weak signal strength. Simulation studies and a real-data application in HIV-1 drug resistance analysis demonstrate strong finite sample FDR control and exhibit improved, or at least competitive, power relative to the aforementioned methods."}
{"id": "2602.11711", "categories": ["stat.ML", "cs.LG", "math.NA", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.11711", "abs": "https://arxiv.org/abs/2602.11711", "authors": ["Jean-François Giovannelli"], "title": "Estimation of instrument and noise parameters for inverse problem based on prior diffusion model", "comment": null, "summary": "This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification."}
{"id": "2602.12234", "categories": ["stat.ME", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.12234", "abs": "https://arxiv.org/abs/2602.12234", "authors": ["Sofia Mäkinen", "Andrew B. Duncan", "Tapio Helin"], "title": "Batch-based Bayesian Optimal Experimental Design in Linear Inverse Problems", "comment": "25 pages, 5 figures", "summary": "Experimental design is central to science and engineering. A ubiquitous challenge is how to maximize the value of information obtained from expensive or constrained experimental settings. Bayesian optimal experimental design (OED) provides a principled framework for addressing such questions. In this paper, we study experimental design problems such as the optimization of sensor locations over a continuous domain in the context of linear Bayesian inverse problems. We focus in particular on batch design, that is, the simultaneous optimization of multiple design variables, which leads to a notoriously difficult non-convex optimization problem. We tackle this challenge using a promising strategy recently proposed in the frequentist setting, which relaxes A-optimal design to the space of finite positive measures. Our main contribution is the rigorous identification of the Bayesian inference problem corresponding to this relaxed A-optimal OED formulation. Moreover, building on recent work, we develop a Wasserstein gradient-flow -based optimization algorithm for the expected utility and introduce novel regularization schemes that guarantee convergence to an empirical measure. These theoretical results are supported by numerical experiments demonstrating both convergence and the effectiveness of the proposed regularization strategy."}
{"id": "2602.11722", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11722", "abs": "https://arxiv.org/abs/2602.11722", "authors": ["Julien Bastian", "Benjamin Leblanc", "Pascal Germain", "Amaury Habrard", "Christine Largeron", "Guillaume Metzler", "Emilie Morvant", "Paul Viallard"], "title": "PAC-Bayesian Generalization Guarantees for Fairness on Stochastic and Deterministic Classifiers", "comment": null, "summary": "Classical PAC generalization bounds on the prediction risk of a classifier are insufficient to provide theoretical guarantees on fairness when the goal is to learn models balancing predictive risk and fairness constraints. We propose a PAC-Bayesian framework for deriving generalization bounds for fairness, covering both stochastic and deterministic classifiers. For stochastic classifiers, we derive a fairness bound using standard PAC-Bayes techniques. Whereas for deterministic classifiers, as usual PAC-Bayes arguments do not apply directly, we leverage a recent advance in PAC-Bayes to extend the fairness bound beyond the stochastic setting. Our framework has two advantages: (i) It applies to a broad class of fairness measures that can be expressed as a risk discrepancy, and (ii) it leads to a self-bounding algorithm in which the learning procedure directly optimizes a trade-off between generalization bounds on the prediction risk and on the fairness. We empirically evaluate our framework with three classical fairness measures, demonstrating not only its usefulness but also the tightness of our bounds."}
{"id": "2602.11325", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11325", "abs": "https://arxiv.org/abs/2602.11325", "authors": ["Ayush Bharti", "Charita Dellaporta", "Yuga Hikida", "François-Xavier Briol"], "title": "Amortised and provably-robust simulation-based inference", "comment": null, "summary": "Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches."}
{"id": "2602.11760", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11760", "abs": "https://arxiv.org/abs/2602.11760", "authors": ["Joseph Paillard", "Angel Reyero Lobo", "Denis A. Engemann", "Bertrand Thirion"], "title": "Aggregate Models, Not Explanations: Improving Feature Importance Estimation", "comment": null, "summary": "Feature-importance methods show promise in transforming machine learning models from predictive engines into tools for scientific discovery. However, due to data sampling and algorithmic stochasticity, expressive models can be unstable, leading to inaccurate variable importance estimates and undermining their utility in critical biomedical applications. Although ensembling offers a solution, deciding whether to explain a single ensemble model or aggregate individual model explanations is difficult due to the nonlinearity of importance measures and remains largely understudied. Our theoretical analysis, developed under assumptions accommodating complex state-of-the-art ML models, reveals that this choice is primarily driven by the model's excess risk. In contrast to prior literature, we show that ensembling at the model level provides more accurate variable-importance estimates, particularly for expressive models, by reducing this leading error term. We validate these findings on classical benchmarks and a large-scale proteomic study from the UK Biobank."}
{"id": "2602.11379", "categories": ["stat.AP", "econ.GN", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11379", "abs": "https://arxiv.org/abs/2602.11379", "authors": ["Han Su", "Xiaojia Guo", "Xiaoke Zhang"], "title": "Regularized Ensemble Forecasting for Learning Weights from Historical and Current Forecasts", "comment": null, "summary": "Combining forecasts from multiple experts often yields more accurate results than relying on a single expert. In this paper, we introduce a novel regularized ensemble method that extends the traditional linear opinion pool by leveraging both current forecasts and historical performances to set the weights. Unlike existing approaches that rely only on either the current forecasts or past accuracy, our method accounts for both sources simultaneously. It learns weights by minimizing the variance of the combined forecast (or its transformed version) while incorporating a regularization term informed by historical performances. We also show that this approach has a Bayesian interpretation. Different distributional assumptions within this Bayesian framework yield different functional forms for the variance component and the regularization term, adapting the method to various scenarios. In empirical studies on Walmart sales and macroeconomic forecasting, our ensemble outperforms leading benchmark models both when experts' full forecasting histories are available and when experts enter and exit over time, resulting in incomplete historical records. Throughout, we provide illustrative examples that show how the optimal weights are determined and, based on the empirical results, we discuss where the framework's strengths lie and when experts' past versus current forecasts are more informative."}
{"id": "2602.12039", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12039", "abs": "https://arxiv.org/abs/2602.12039", "authors": ["Alon Beck", "Yohai Bar Sinai", "Noam Levi"], "title": "The Implicit Bias of Logit Regularization", "comment": null, "summary": "Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods."}
{"id": "2602.11679", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11679", "abs": "https://arxiv.org/abs/2602.11679", "authors": ["Kyungbok Lee", "Angelica Cristello Sarteau", "Michael R. Kosorok"], "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs", "comment": "65 pages, 4 figures. Submitted to JMLR", "summary": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness."}
{"id": "2602.11520", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.11520", "abs": "https://arxiv.org/abs/2602.11520", "authors": ["Yasin Khadem Charvadeh", "Katherine S. Panageas", "Yuan Chen"], "title": "Locally Interpretable Individualized Treatment Rules for Black-Box Decision Models", "comment": null, "summary": "Individualized treatment rules (ITRs) aim to optimize healthcare by tailoring treatment decisions to patient-specific characteristics. Existing methods typically rely on either interpretable but inflexible models or highly flexible black-box approaches that sacrifice interpretability; moreover, most impose a single global decision rule across patients. We introduce the Locally Interpretable Individualized Treatment Rule (LI-ITR) method, which combines flexible machine learning models to accurately learn complex treatment outcomes with locally interpretable approximations to construct subject-specific treatment rules. LI-ITR employs variational autoencoders to generate realistic local synthetic samples and learns individualized decision rules through a mixture of interpretable experts. Simulation studies show that LI-ITR accurately recovers true subject-specific local coefficients and optimal treatment strategies. An application to precision side-effect management in breast cancer illustrates the necessity of flexible predictive modeling and highlights the practical utility of LI-ITR in estimating optimal treatment rules while providing transparent, clinically interpretable explanations."}
