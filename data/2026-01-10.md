<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 1]
- [stat.ML](#stat.ML) [Total: 2]
- [stat.ME](#stat.ME) [Total: 3]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Cluster-Based Bayesian SIRD Modeling of Chickenpox Epidemiology in India](https://arxiv.org/abs/2601.04644)
*Nayana Mukherjee,Chitradipa Chakraborty*

Main category: stat.AP

TL;DR: 该研究提出了一个基于聚类的贝叶斯SIRD模型，分析1990-2021年印度水痘流行病学，采用年龄分层方法，结合Holling型发病率函数和贝叶斯推断，识别出三个不同的流行病学区域集群。


<details>
  <summary>Details</summary>
Motivation: 印度水痘流行病学特征复杂，存在年龄和地区差异，需要开发一个能够捕捉长期传播动态、考虑人口结构异质性和区域差异的模型，为制定针对性防控策略提供依据。

Method: 1. 建立年龄分层的贝叶斯SIRD模型（易感者-感染者-康复者-死亡者）；2. 采用Holling型发病率函数考虑高流行水平下的饱和效应；3. 应用贝叶斯推断估计关键流行病学参数；4. 基于发病率、患病率和死亡率进行K-means聚类分析识别区域集群；5. 通过模拟研究验证模型实用性。

Result: 1. 识别出三个不同的流行病学区域集群，具有不同的暴发潜力和年龄特异性动态；2. 青少年是主要传播驱动者；3. 老年人面临不成比例的高死亡率负担；4. 模型提供了透明、可复现的长期传播动态分析框架。

Conclusion: 研究强调了年龄针对性干预的重要性，建议公共卫生策略应考虑区域异质性。该模型为印度水痘控制提供了基于证据的规划支持，并通过模拟研究验证了其实际效用。

Abstract: This study presents a cluster-based Bayesian SIRD model to analyze the epidemiology of chickenpox (varicella) in India, utilizing data from 1990 to 2021. We employed an age-structured approach, dividing the population into juvenile, adult, and elderly groups, to capture the disease's transmission dynamics across diverse demographic groups. The model incorporates a Holling-type incidence function, which accounts for the saturation effect of transmission at high prevalence levels, and applies Bayesian inference to estimate key epidemiological parameters, including transmission rates, recovery rates, and mortality rates. The study further explores cluster analysis to identify regional clusters within India based on the similarities in chickenpox transmission dynamics, using criteria like incidence, prevalence, and mortality rates. We perform K-means clustering to uncover three distinct epidemiological regimes, which vary in terms of outbreak potential and age-specific dynamics. The findings highlight juveniles as the primary drivers of transmission, while the elderly face a disproportionately high mortality burden. Our results underscore the importance of age-targeted interventions and suggest that regional heterogeneity should be considered in public health strategies for disease control. The model offers a transparent, reproducible framework for understanding long-term transmission dynamics and supports evidence-based planning for chickenpox control in India. The practical utility of the model is further validated through a simulation study.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [2] [ROOFS: RObust biOmarker Feature Selection](https://arxiv.org/abs/2601.05151)
*Anastasiia Bakhmach,Paul Dufossé,Andrea Vaglio,Florence Monville,Laurent Greillier,Fabrice Barlési,Sébastien Benzekry*

Main category: stat.ML

TL;DR: Roofs是一个Python包，用于帮助研究人员选择适合其问题的特征选择方法，通过基准测试和生成综合评估报告。


<details>
  <summary>Details</summary>
Motivation: 生物医学数据集的特征选择面临高维特征空间、小样本量、多重共线性和缺失值等挑战，且不同数据集和预测任务中特征选择性能差异很大，需要系统化的评估工具。

Method: 开发了roofs Python包，对用户数据上的多种特征选择方法进行基准测试，生成包含下游预测性能（使用乐观校正估计）、稳定性、特征可靠性、基于半合成数据的真阳性率和假阳性率等综合评估指标的报告。

Result: 在PIONeeR临床试验数据（肺癌抗PD-(L)1免疫治疗耐药性预测）中，评估了23种特征选择方法和11种分类器（共253个模型），发现基于t检验和逻辑回归的Benjamini-Hochberg FDR调整p值联合的过滤方法最优，优于包括LASSO在内的其他方法。

Conclusion: 使用roofs进行综合基准测试可以提高特征选择发现的稳健性和可重复性，并增加临床模型的转化价值。

Abstract: Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.

</details>


### [3] [Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data](https://arxiv.org/abs/2601.05227)
*James Rice*

Main category: stat.ML

TL;DR: 提出SLDI框架，将随机微分方程与深度生成模型结合，通过变分自编码器潜在空间中的Itô SDE改进结构化时序数据的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 改进机器学习中结构化时序数据的不确定性量化，传统方法在处理不规则采样和复杂动态结构时存在局限，需要更灵活、数学基础更严谨的连续时间建模方法。

Method: 在变分自编码器的潜在空间中嵌入Itô SDE，用神经网络参数化SDE的漂移和扩散项；核心创新是伴随状态的协同参数化，通过专用神经网络形成耦合的前向-后向系统，引入路径正则化的伴随损失，并基于随机分析分析方差减少的梯度流。

Result: 提出了一个统一框架，将变分推断、连续时间生成建模和控制理论优化相结合，为深度潜在SDE提供了更稳定的训练工具，能够处理不规则采样和复杂动态结构。

Conclusion: SLDI框架为随机概率机器学习提供了严谨的数学基础，通过SDE与深度生成模型的集成，显著改进了不确定性量化能力，为未来相关研究提供了新的理论工具和方法论。

Abstract: I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.
  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [4] [Bayesian nonparametric modeling of dynamic pollution clusters through an autoregressive logistic-beta Stirling-gamma process](https://arxiv.org/abs/2601.04625)
*Santiago Marin,Bronwyn Loong,Anton H. Westveld*

Main category: stat.ME

TL;DR: 提出了一种基于logistic-beta依赖Dirichlet过程的高效动态聚类方法，用于识别PM2.5的时空聚类，应用于智利空气质量分析。


<details>
  <summary>Details</summary>
Motivation: PM2.5是危害最大的空气污染物之一，准确识别其潜在聚类对空气质量和公共卫生管理至关重要。但现有动态聚类方法基于copula依赖Dirichlet过程，计算复杂度高，难以实际应用。

Method: 提出基于logistic-beta依赖Dirichlet过程的动态聚类方法，采用Stirling-gamma先验分布处理DP的浓度参数，便于融入先验知识，并设计了高效的后验推断计算策略。

Result: 将方法应用于智利PM2.5动态聚类识别，相比现有方法表现出更优越的性能。

Conclusion: 提出的logistic-beta依赖DP动态聚类方法计算效率更高，能够有效识别PM2.5的时空聚类模式，为空气质量管理和公共卫生政策提供支持。

Abstract: Fine suspended particulates (FSP), commonly known as PM2.5, are among the most harmful air pollutants, posing serious risks to population health and environmental integrity. As such, accurately identifying latent clusters of FSP is essential for effective air quality and public health management. This task, however, is notably nontrivial as FSP clusters may depend on various regional and temporal factors, which should be incorporated in the modeling process. Thus, we capitalize on Bayesian nonparametric dynamic clustering ideas, in which clustering structures may be influenced by complex dependencies. Existing implementations of dynamic clustering, however, rely on copula-based dependent Dirichlet processes (DPs), presenting considerable computational challenges for real-world deployment. With this in mind, we propose a more efficient alternative for dynamic clustering by incorporating the novel ideas of logistic-beta dependent DPs. We also adopt a Stirling-gamma prior, a novel distribution family, on the concentration parameter of our underlying DP, easing the process of incorporating prior knowledge into the model. Efficient computational strategies for posterior inference are also presented. We apply our proposed method to identify dynamic FSP clusters across Chile and demonstrate its superior performance over existing approaches.

</details>


### [5] [Quantile Vector Autoregression without Crossing](https://arxiv.org/abs/2601.04663)
*Tomohiro Ando,Tadao Hoshino,Ruey Tsay*

Main category: stat.ME

TL;DR: 提出一种新的分位数向量自回归方法（SQVAR），通过将AR结构转换为单纯形来避免分位数曲线交叉，同时使用SCAD惩罚处理参数空间爆炸问题，并开发了基于BIC的惩罚参数选择方法。


<details>
  <summary>Details</summary>
Motivation: 传统分位数回归经常产生不理想的分位数曲线交叉问题，这违反了分位数的单调性。在向量自回归框架下，这个问题更加复杂，需要一种能够保证分位数曲线单调性的方法。

Method: 提出单纯形分位数向量自回归（SQVAR）框架，将原始QVAR模型的AR结构转换为单纯形，确保估计的分位数曲线在所有分位数水平上保持单调。同时施加SCAD惩罚来缓解参数空间的爆炸性，并开发基于BIC的惩罚参数选择程序。

Result: 建立了所提方法的渐近性质，包括估计量的收敛速度和渐近正态性、AR阶数选择的一致性以及基于BIC的惩罚选择的有效性。将方法应用于美国金融市场数据，展示了SQVAR方法的实用性。

Conclusion: SQVAR方法有效解决了分位数曲线交叉问题，保证了分位数的单调性，同时通过SCAD惩罚和BIC选择机制提高了模型的稳定性和可解释性，为分位数向量自回归分析提供了可靠的理论框架和实用工具。

Abstract: This paper considers estimation and model selection of quantile vector autoregression (QVAR). Conventional quantile regression often yields undesirable crossing quantile curves, violating the monotonicity of quantiles. To address this issue, we propose a simplex quantile vector autoregression (SQVAR) framework, which transforms the autoregressive (AR) structure of the original QVAR model into a simplex, ensuring that the estimated quantile curves remain monotonic across all quantile levels. In addition, we impose the smoothly clipped absolute deviation (SCAD) penalty on the SQVAR model to mitigate the explosive nature of the parameter space. We further develop a Bayesian information criterion (BIC)-based procedure for selecting the optimal penalty parameter and introduce new frameworks for impulse response analysis of QVAR models. Finally, we establish asymptotic properties of the proposed method, including the convergence rate and asymptotic normality of the estimator, the consistency of AR order selection, and the validity of the BIC-based penalty selection. For illustration, we apply the proposed method to U.S. financial market data, highlighting the usefulness of our SQVAR method.

</details>


### [6] [Revealing the Truth: Calculating True Values in Causal Inference Simulation Studies via Gaussian Quadrature](https://arxiv.org/abs/2601.05128)
*Alex Ocampo,Enrico Giudice,Zachary R. McCaw,Tim P. Morris*

Main category: stat.ME

TL;DR: 论文提出使用高斯求积法在因果推断模拟研究中准确高效计算真实因果估计值，相比蒙特卡洛积分具有计算时间可忽略的优势。


<details>
  <summary>Details</summary>
Motivation: 在因果推断模拟研究中，真实估计值（如平均处理效应）通常不是简单的模型参数，而是需要边际化处理混杂变量和中介变量的复杂积分。传统方法计算这些真实因果估计值存在困难，而高斯求积法能够提供高效准确的计算方案。

Method: 使用高斯求积法（特别是Gauss-Hermite求积）来计算因果推断模拟研究中的真实估计值。该方法利用常见分布（正态、均匀、指数、伽马等）的概率密度函数作为积分核，通过高斯求积公式高效计算积分。论文通过四个应用案例展示了该方法的具体实施。

Result: 高斯求积法在计算真实因果估计值时表现出极高的准确性，计算时间可忽略不计。与作为基准的蒙特卡洛积分方法相比，高斯求积法在准确性和效率方面都表现优异。

Conclusion: 高斯求积法是计算因果推断模拟研究中真实估计值的准确高效工具，但目前使用不足。该方法应被更广泛地应用于模拟研究，以提高计算效率和准确性。

Abstract: Simulation studies are used to understand the properties of statistical methods. A key luxury in many simulation studies is knowledge of the true value (i.e. the estimand) being targeted. With this oracle knowledge in-hand, the researcher conducting the simulation study can assess across repeated realizations of the data how well a given method recovers the truth. In causal inference simulation studies, the truth is rarely a simple parameter of the statistical model chosen to generate the data. Instead, the estimand is often an average treatment effect, marginalized over the distribution of confounders and/or mediators. Luckily, these variables are often generated from common distributions such as the normal, uniform, exponential, or gamma. For all these distributions, Gaussian quadratures provide efficient and accurate calculation for integrands with integral kernels that stem from known probability density functions. We demonstrate through four applications how to use Gaussian quadrature to accurately and efficiently compute the true causal estimand. We also compare the pros and cons of Gauss-Hermite quadrature to Monte Carlo integration approaches, which we use as benchmarks. Overall, we demonstrate that the Gaussian quadrature is an accurate tool with negligible computation time, yet is underused for calculating the true causal estimands in simulation studies.

</details>
