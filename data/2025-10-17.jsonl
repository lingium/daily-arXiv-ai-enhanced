{"id": "2510.14415", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.14415", "abs": "https://arxiv.org/abs/2510.14415", "authors": ["Tadao Hoshino"], "title": "Evaluating Policy Effects under Network Interference without Network Information: A Transfer Learning Approach", "comment": null, "summary": "This paper develops a sensitivity analysis framework that transfers the\naverage total treatment effect (ATTE) from source data with a fully observed\nnetwork to target data whose network is completely unknown. The ATTE represents\nthe average social impact of a policy that assigns the treatment to every\nindividual in the dataset. We postulate a covariate-shift type assumption that\nboth source and target datasets share the same conditional mean outcome.\nHowever, because the target network is unobserved, this assumption alone is not\nsufficient to pin down the ATTE for the target data. To address this issue, we\nconsider a sensitivity analysis based on the uncertainty of the target\nnetwork's degree distribution, where the extent of uncertainty is measured by\nthe Wasserstein distance from a given reference degree distribution. We then\nconstruct bounds on the target ATTE using a linear programming-based estimator.\nThe limiting distribution of the bound estimator is derived via the functional\ndelta method, and we develop a wild bootstrap approach to approximate the\ndistribution. As an empirical illustration, we revisit the social network\nexperiment on farmers' weather insurance adoption in China by Cai et al.\n(2015)."}
{"id": "2510.13927", "categories": ["stat.AP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13927", "abs": "https://arxiv.org/abs/2510.13927", "authors": ["Jishu Adhikary", "Raju Maiti"], "title": "Long-Term Spatio-Temporal Forecasting of Monthly Rainfall in West Bengal Using Ensemble Learning Approaches", "comment": "25 pages, 22 figures", "summary": "Rainfall forecasting plays a critical role in climate adaptation,\nagriculture, and water resource management. This study develops long-term\nforecasts of monthly rainfall across 19 districts of West Bengal using a\ncentury-scale dataset spanning 1900-2019. Daily rainfall records are aggregated\ninto monthly series, resulting in 120 years of observations for each district.\nThe forecasting task involves predicting the next 108 months (9 years,\n2011-2019) while accounting for temporal dependencies and spatial interactions\namong districts. To address the nonlinear and complex structure of rainfall\ndynamics, we propose a hierarchical modeling framework that combines\nregression-based forecasting of yearly features with multi-layer perceptrons\n(MLPs) for monthly prediction. Yearly features, such as annual totals,\nquarterly proportions, variability measures, skewness, and extremes, are first\nforecasted using regression models that incorporate both own lags and\nneighboring-district lags. These forecasts are then integrated as auxiliary\ninputs into an MLP model, which captures nonlinear temporal patterns and\nspatial dependencies in the monthly series. The results demonstrate that the\nhierarchical regression-MLP architecture provides robust long-term\nspatio-temporal forecasts, offering valuable insights for agriculture,\nirrigation planning, and water conservation strategies."}
{"id": "2510.14074", "categories": ["stat.ML", "cs.LG", "math.OC", "math.PR", "60H30"], "pdf": "https://arxiv.org/pdf/2510.14074", "abs": "https://arxiv.org/abs/2510.14074", "authors": ["Elizabeth Collins-Woodfin", "Inbar Seroussi"], "title": "Exact Dynamics of Multi-class Stochastic Gradient Descent", "comment": "58 pages, 12 figures", "summary": "We develop a framework for analyzing the training and learning rate dynamics\non a variety of high- dimensional optimization problems trained using one-pass\nstochastic gradient descent (SGD) with data generated from multiple anisotropic\nclasses. We give exact expressions for a large class of functions of the\nlimiting dynamics, including the risk and the overlap with the true signal, in\nterms of a deterministic solution to a system of ODEs. We extend the existing\ntheory of high-dimensional SGD dynamics to Gaussian-mixture data and a large\n(growing with the parameter size) number of classes. We then investigate in\ndetail the effect of the anisotropic structure of the covariance of the data in\nthe problems of binary logistic regression and least square loss. We study\nthree cases: isotropic covariances, data covariance matrices with a large\nfraction of zero eigenvalues (denoted as the zero-one model), and covariance\nmatrices with spectra following a power-law distribution. We show that there\nexists a structural phase transition. In particular, we demonstrate that, for\nthe zero-one model and the power-law model with sufficiently large power, SGD\ntends to align more closely with values of the class mean that are projected\nonto the \"clean directions\" (i.e., directions of smaller variance). This is\nsupported by both numerical simulations and analytical studies, which show the\nexact asymptotic behavior of the loss in the high-dimensional limit."}
{"id": "2510.13930", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13930", "abs": "https://arxiv.org/abs/2510.13930", "authors": ["Ziwen Zhong"], "title": "Earthquake Forecasting with ETAS.inlabru", "comment": null, "summary": "The ETAS models are currently the most popular in the field of earthquake\nforecasting. The MCMC method is time-consuming and limited by parameter\ncorrelation while bringing parameter uncertainty. The INLA-based method\n\"inlabru\" solves these problems and performs better at Bayesian inference.\n  The report introduces the composition of the ETAS model, then provides the\nmodel's log-likelihood and approximates it using Taylor expansion and binning\nstrategies. We also present the general procedure of Bayesian inference in\ninlabru.\n  The report follows three experiments. The first one explores the effect of\nfixing one parameter at its actual or wrong values on the posterior\ndistribution of other parameters. We found that $\\alpha$ and $K$ have an\napparent mutual influence relationship. At the same time, fixing $\\alpha$ or\n$K$ to its actual value can reduce the model fitting time by more than half.\n  The second experiment compares normalised inter-event-time distribution on\nreal data and synthetic catalogues. The distributions of normalised\ninter-event-time of real data and synthetic catalogues are consistent. Compared\nwith Exp(1), they have more short and long inter-event-time, indicating the\nexistence of clustering. Change on $\\mu$ and $p$ will influence the\ninter-event-time distribution.\n  In the last one, we use events before the mainshock to predict events ten\nweeks after the mainshock. We use the number test and Continuous Ranked\nProbability Score (CRPS) to measure the accuracy and precision of the\npredictions. We found that we need at least one mainshock and corresponding\noffspring to make reliable forecasting. And when we have more mainshocks in our\ndata, our forecasting will be better. Besides, we also figure out what is\nneeded to obtain a good posterior distribution for each parameter."}
{"id": "2510.14092", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14092", "abs": "https://arxiv.org/abs/2510.14092", "authors": ["Julio Enrique Castrillon-Candas", "Hanfeng Gu", "Caleb Meredith", "Yulin Li", "Xiaojing Tang", "Pontus Olofsson", "Mark Kon"], "title": "deFOREST: Fusing Optical and Radar satellite data for Enhanced Sensing of Tree-loss", "comment": null, "summary": "In this paper we develop a deforestation detection pipeline that incorporates\noptical and Synthetic Aperture Radar (SAR) data. A crucial component of the\npipeline is the construction of anomaly maps of the optical data, which is done\nusing the residual space of a discrete Karhunen-Lo\\`{e}ve (KL) expansion.\nAnomalies are quantified using a concentration bound on the distribution of the\nresidual components for the nominal state of the forest. This bound does not\nrequire prior knowledge on the distribution of the data. This is in contrast to\nstatistical parametric methods that assume knowledge of the data distribution,\nan impractical assumption that is especially infeasible for high dimensional\ndata such as ours. Once the optical anomaly maps are computed they are combined\nwith SAR data, and the state of the forest is classified by using a Hidden\nMarkov Model (HMM). We test our approach with Sentinel-1 (SAR) and Sentinel-2\n(Optical) data on a $92.19\\,km \\times 91.80\\,km$ region in the Amazon forest.\nThe results show that both the hybrid optical-radar and optical only methods\nachieve high accuracy that is superior to the recent state-of-the-art hybrid\nmethod. Moreover, the hybrid method is significantly more robust in the case of\nsparse optical data that are common in highly cloudy regions."}
{"id": "2510.14011", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14011", "abs": "https://arxiv.org/abs/2510.14011", "authors": ["Saman Hosseini", "Lee W. Cohnstaedt", "Matin Marjani", "Caterina Scoglio"], "title": "A Data-Parsimonious Model for Long-Term Risk Assessments of West Nile Virus Spillover", "comment": null, "summary": "Many West Nile virus (WNV) forecasting frameworks incorporate entomological\nor avian surveillance data, which may be unavailable in some regions. We\nintroduce a novel data-parsimonious probabilistic model to predict both the\ntiming of outbreak onset and the seasonal severity of WNV spillover. Our\napproach combines a temperature-driven compartmental model of WNV with\nnonparametric kernel density estimation methods to construct a joint\nprobability density function and a Poisson rate surface as function of mosquito\nabundance and normalized cumulative temperature. Calibrated on human incidence\nrecords, the model produces reliable forecasts several months before the\ntransmission season begins, supporting proactive mitigation efforts. We\nevaluated the framework across three counties in California (Orange, Los\nAngeles, and Riverside), two in Texas (Dallas and Harris), and one in Florida\n(Duval), representing completely different ecology and distinct climatic\nregimes, and observed strong agreement across multiple performance metrics."}
{"id": "2510.14145", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14145", "abs": "https://arxiv.org/abs/2510.14145", "authors": ["Mohammed Baragilly", "Hend Gabr"], "title": "High-Dimensional BWDM: A Robust Nonparametric Clustering Validation Index for Large-Scale Data", "comment": null, "summary": "Determining the appropriate number of clusters in unsupervised learning is a\ncentral problem in statistics and data science. Traditional validity indices\nsuch as Calinski-Harabasz, Silhouette, and Davies-Bouldin-depend on\ncentroid-based distances and therefore degrade in high-dimensional or\ncontaminated data. This paper proposes a new robust, nonparametric clustering\nvalidation framework, the High-Dimensional Between-Within Distance Median\n(HD-BWDM), which extends the recently introduced BWDM criterion to\nhigh-dimensional spaces. HD-BWDM integrates random projection and principal\ncomponent analysis to mitigate the curse of dimensionality and applies trimmed\nclustering and medoid-based distances to ensure robustness against outliers. We\nderive theoretical results showing consistency and convergence under\nJohnson-Lindenstrauss embeddings. Extensive simulations demonstrate that\nHD-BWDM remains stable and interpretable under high-dimensional projections and\ncontamination, providing a robust alternative to traditional centroid-based\nvalidation criteria. The proposed method provides a theoretically grounded,\ncomputationally efficient stopping rule for nonparametric clustering in modern\nhigh-dimensional applications."}
{"id": "2510.14723", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14723", "abs": "https://arxiv.org/abs/2510.14723", "authors": ["Cormac MacDermott", "Carl J. Scarrott", "John Ferguson"], "title": "Bayes-ically fair: A Bayesian Ranking of the Olympic Medal Table", "comment": null, "summary": "Evaluating a country's sporting success provides insight into its\ndecision-making and infrastructure for developing athletic talent. The Olympic\nGames serve as a global benchmark, yet conventional medal rankings can be\nunduly influenced by population size. We propose a Bayesian ranking scheme to\nrank the performance of National Olympic Committees by their \"long-run\"\nmedals-to-population ratio. The algorithm aims to mitigate the influence of\nlarge populations and reduce the stochastic fluctuations for smaller nations by\napplying shrinkage. These long-run rankings provide a more stable and\ninterpretable ordering of national sporting performance across games compared\nto existing methods."}
{"id": "2510.14222", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14222", "abs": "https://arxiv.org/abs/2510.14222", "authors": ["Benjamín Castro", "Camilo Ramírez", "Sebastián Espinosa", "Jorge F. Silva", "Marcos E. Orchard", "Heraldo Rozas"], "title": "A novel Information-Driven Strategy for Optimal Regression Assessment", "comment": null, "summary": "In Machine Learning (ML), a regression algorithm aims to minimize a loss\nfunction based on data. An assessment method in this context seeks to quantify\nthe discrepancy between the optimal response for an input-output system and the\nestimate produced by a learned predictive model (the student). Evaluating the\nquality of a learned regressor remains challenging without access to the true\ndata-generating mechanism, as no data-driven assessment method can ensure the\nachievability of global optimality. This work introduces the Information\nTeacher, a novel data-driven framework for evaluating regression algorithms\nwith formal performance guarantees to assess global optimality. Our novel\napproach builds on estimating the Shannon mutual information (MI) between the\ninput variables and the residuals and applies to a broad class of additive\nnoise models. Through numerical experiments, we confirm that the Information\nTeacher is capable of detecting global optimality, which is aligned with the\ncondition of zero estimation error with respect to the -- inaccessible, in\npractice -- true model, working as a surrogate measure of the ground truth\nassessment loss and offering a principled alternative to conventional empirical\nperformance metrics."}
{"id": "2510.13981", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13981", "abs": "https://arxiv.org/abs/2510.13981", "authors": ["David Marcano", "Adrian Dobra"], "title": "Bayesian Inference for Single-factor Graphical Models", "comment": "44 pages, 34 figures", "summary": "We introduce efficient MCMC algorithms for Bayesian inference for\nsingle-factor models with correlated residuals where the residuals'\ndistribution is a Gaussian graphical model. We call this family of models\nsingle-factor graphical models. We extend single-factor graphical models to\ndatasets that also involve binary and ordinal categorical variables and to the\nmodeling of multiple datasets that are spatially or temporally related. Our\nmodels are able to capture multivariate associations through latent factors\nacross time and space, as well as residual conditional dependence structures at\neach spatial location or time point through Gaussian graphical models. We\nillustrate the application of single-factor graphical models in simulated and\nreal-world examples."}
{"id": "2510.14494", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14494", "abs": "https://arxiv.org/abs/2510.14494", "authors": ["Ziad Akram Ali Hammouri", "Yating Zhou", "Rahul Ghosal", "Juan C. Vidal", "Marcos Matabuena"], "title": "ROC Analysis with Covariate Adjustment Using Neural Network Models: Evaluating the Role of Age in the Physical Activity-Mortality Association", "comment": null, "summary": "The receiver operating characteristic (ROC) curve and its summary measure,\nthe Area Under the Curve (AUC), are well-established tools for evaluating the\nefficacy of biomarkers in biomedical studies. Compared to the traditional ROC\ncurve, the covariate-adjusted ROC curve allows for individual evaluation of the\nbiomarker. However, the use of machine learning models has rarely been explored\nin this context, despite their potential to develop more powerful and\nsophisticated approaches for biomarker evaluation. The goal of this paper is to\npropose a framework for neural network-based covariate-adjusted ROC modeling\nthat allows flexible and nonlinear evaluation of the effectiveness of a\nbiomarker to discriminate between two reference populations. The finite-sample\nperformance of our method is investigated through extensive simulation tests\nunder varying dependency structures between biomarkers, covariates, and\nreferenced populations. The methodology is further illustrated in a clinically\ncase study that assesses daily physical activity - measured as total activity\ntime (TAC), a proxy for daily step count-as a biomarker to predict mortality at\nthree, five and eight years. Analyzes stratified by sex and adjusted for age\nand BMI reveal distinct covariate effects on mortality outcomes. These results\nunderscore the importance of covariate-adjusted modeling in biomarker\nevaluation and highlight TAC's potential as a functional capacity biomarker\nbased on specific individual characteristics."}
{"id": "2510.14413", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14413", "abs": "https://arxiv.org/abs/2510.14413", "authors": ["Runlin Zhou", "Letian Li", "Zemin Zheng"], "title": "Personalized federated learning, Row-wise fusion regularization, Multivariate modeling, Sparse estimation", "comment": null, "summary": "We study personalized federated learning for multivariate responses where\nclient models are heterogeneous yet share variable-level structure. Existing\nentry-wise penalties ignore cross-response dependence, while matrix-wise fusion\nover-couples clients. We propose a Sparse Row-wise Fusion (SROF) regularizer\nthat clusters row vectors across clients and induces within-row sparsity, and\nwe develop RowFed, a communication-efficient federated algorithm that embeds\nSROF into a linearized ADMM framework with privacy-preserving partial\nparticipation. Theoretically, we establish an oracle property for\nSROF-achieving correct variable-level group recovery with asymptotic\nnormality-and prove convergence of RowFed to a stationary solution. Under\nrandom client participation, the iterate gap contracts at a rate that improves\nwith participation probability. Empirically, simulations in heterogeneous\nregimes show that RowFed consistently lowers estimation and prediction error\nand strengthens variable-level cluster recovery over NonFed, FedAvg, and a\npersonalized matrix-fusion baseline. A real-data study further corroborates\nthese gains while preserving interpretability. Together, our results position\nrow-wise fusion as an effective and transparent paradigm for large-scale\npersonalized federated multivariate learning, bridging the gap between\nentry-wise and matrix-wise formulations."}
{"id": "2510.14044", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14044", "abs": "https://arxiv.org/abs/2510.14044", "authors": ["Younghoon Kim", "Zachary F. Fisher", "Vladas Pipiras"], "title": "Joint modeling and inference of multiple-subject high-dimensional sparse vector autoregressive models", "comment": null, "summary": "The multiple-subject vector autoregression (multi-VAR) model captures\nheterogeneous network Granger causality across subjects by decomposing\nindividual sparse VAR transition matrices into commonly shared and\nsubject-unique paths. The model has been applied to characterize hidden shared\nand unique paths among subjects and has demonstrated performance compared to\nmethods commonly used in psychology and neuroscience. Despite this innovation,\nthe model suffers from using a weighted median for identifying the common\neffects, leading to statistical inefficiency as the convergence rates of the\ncommon and unique paths are determined by the least sparse subject and the\nsmallest sample size across all subjects. We propose a new identifiability\ncondition for the multi-VAR model based on a communication-efficient data\nintegration framework. We show that this approach achieves convergence rates\ntailored to each subject's sparsity level and sample size. Furthermore, we\ndevelop hypothesis tests to assess the nullity and homogeneity of individual\npaths, using Wald-type test statistics constructed from individual debiased\nestimators. A test for the significance of the common paths can also be derived\nthrough the framework. Simulation studies under various heterogeneity scenarios\nand a real data application demonstrate the performance of the proposed method\ncompared to existing benchmark across standard evaluation metrics."}
{"id": "2510.14502", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14502", "abs": "https://arxiv.org/abs/2510.14502", "authors": ["Eva-Maria Maier", "Alexander Fottner", "Sonja Greven", "Almond Stöcker"], "title": "Additive Density Regression", "comment": null, "summary": "We present a structured additive regression approach to model conditional\ndensities given scalar covariates, where only samples of the conditional\ndistributions are observed. This links our approach to distributional\nregression models for scalar data. The model is formulated in a Bayes Hilbert\nspace -- preserving nonnegativity and integration to one under summation and\nscalar multiplication -- with respect to an arbitrary finite measure. This\nallows to consider, amongst others, continuous, discrete and mixed densities.\nOur theoretical results include asymptotic existence, uniqueness, consistency,\nand asymptotic normality of the penalized maximum likelihood estimator, as well\nas confidence regions and inference for the (effect) densities. For estimation,\nwe propose to maximize the penalized log-likelihood corresponding to an\nappropriate multinomial, or equivalently, Poisson regression model, which we\nshow to approximate the original penalized maximum likelihood problem. We apply\nour framework to a motivating gender economic data set from the German\nSocio-Economic Panel Study (SOEP), analyzing the distribution of the woman's\nshare in a couple's total labor income given covariate effects for year, place\nof residence and age of the youngest child. As the income share is a continuous\nvariable having discrete point masses at zero and one for single-earner\ncouples, the corresponding densities are of mixed type."}
{"id": "2510.14582", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14582", "abs": "https://arxiv.org/abs/2510.14582", "authors": ["Mátyás Schubert", "Tom Claassen", "Sara Magliacane"], "title": "Local Causal Discovery for Statistically Efficient Causal Inference", "comment": null, "summary": "Causal discovery methods can identify valid adjustment sets for causal effect\nestimation for a pair of target variables, even when the underlying causal\ngraph is unknown. Global causal discovery methods focus on learning the whole\ncausal graph and therefore enable the recovery of optimal adjustment sets,\ni.e., sets with the lowest asymptotic variance, but they quickly become\ncomputationally prohibitive as the number of variables grows. Local causal\ndiscovery methods offer a more scalable alternative by focusing on the local\nneighborhood of the target variables, but are restricted to statistically\nsuboptimal adjustment sets. In this work, we propose Local Optimal Adjustments\nDiscovery (LOAD), a sound and complete causal discovery approach that combines\nthe computational efficiency of local methods with the statistical optimality\nof global methods. First, LOAD identifies the causal relation between the\ntargets and tests if the causal effect is identifiable by using only local\ninformation. If it is identifiable, it then finds the optimal adjustment set by\nleveraging local causal discovery to infer the mediators and their parents.\nOtherwise, it returns the locally valid parent adjustment sets based on the\nlearned local structure. In our experiments on synthetic and realistic data\nLOAD outperforms global methods in scalability, while providing more accurate\neffect estimation than local methods."}
{"id": "2510.14142", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14142", "abs": "https://arxiv.org/abs/2510.14142", "authors": ["Yin Tang", "Yanyuan Ma", "Jiwei Zhao"], "title": "Efficient Estimation of the Complier General Causal Effect in Randomized Controlled Trials with One-Sided Noncompliance", "comment": null, "summary": "A randomized controlled trial (RCT) is widely regarded as the gold standard\nfor assessing the causal effect of a treatment or intervention, assuming\nperfect implementation. In practice, however, randomization can be compromised\nfor various reasons, such as one-sided noncompliance. In this paper, we address\nthe issue of one-sided noncompliance and propose a general estimand, the\ncomplier general causal effect (CGCE), to characterize the causal effect among\ncompliers. We further investigate the conditions under which efficient\nestimation of the CGCE can be achieved under minimal assumptions. Comprehensive\nsimulation studies and a real data application are conducted to illustrate the\nproposed methods and to compare them with existing approaches."}
{"id": "2510.14714", "categories": ["stat.ME", "physics.comp-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14714", "abs": "https://arxiv.org/abs/2510.14714", "authors": ["Hristos Tyralis", "Georgia Papacharalampous"], "title": "Loss functions arising from the index of agreement", "comment": "49 pages, 6 figures", "summary": "We examine the theoretical properties of the index of agreement loss function\n$L_W$, the negatively oriented counterpart of Willmott's index of agreement, a\ncommon metric in environmental sciences and engineering. We prove that $L_W$ is\nbounded within [0, 1], translation and scale invariant, and estimates the\nparameter $\\Bbb{E}_{F}[\\underline{y}] \\pm \\Bbb{V}_{F}^{1/2}[\\underline{y}]$\nwhen fitting a distribution. We propose $L_{\\operatorname{NR}_2}$ as a\ntheoretical improvement, which replaces the denominator of $L_W$ with the sum\nof Euclidean distances, better aligning with the underlying geometric\nintuition. This new loss function retains the appealing properties of $L_W$ but\nalso admits closed-form solutions for linear model parameter estimation. We\nshow that as the correlation between predictors and the dependent variable\napproaches 1, parameter estimates from squared error, $L_{\\operatorname{NR}_2}$\nand $L_W$ converge. This behavior is mirrored in hydrologic model calibration\n(a core task in water resources engineering), where performance becomes nearly\nidentical across these loss functions. Finally, we suggest potential\nimprovements for existing $L_p$-norm variants of the index of agreement."}
{"id": "2510.14656", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14656", "abs": "https://arxiv.org/abs/2510.14656", "authors": ["Zhikun Zhang", "Guanyu Pan", "Xiangjun Wang", "Yong Xu", "Guangtao Zhang"], "title": "Parameter Identification for Partial Differential Equation with Jump Discontinuities in Coefficients by Markov Switching Model and Physics-Informed Machine Learning", "comment": null, "summary": "Inverse problems involving partial differential equations (PDEs) with\ndiscontinuous coefficients are fundamental challenges in modeling complex\nspatiotemporal systems with heterogeneous structures and uncertain dynamics.\nTraditional numerical and machine learning approaches often face limitations in\naddressing these problems due to high dimensionality, inherent nonlinearity,\nand discontinuous parameter spaces. In this work, we propose a novel\ncomputational framework that synergistically integrates physics-informed deep\nlearning with Bayesian inference for accurate parameter identification in PDEs\nwith jump discontinuities in coefficients. The core innovation of our framework\nlies in a dual-network architecture employing a gradient-adaptive weighting\nstrategy: a main network approximates PDE solutions while a sub network samples\nits coefficients. To effectively identify mixture structures in parameter\nspaces, we employ Markovian dynamics methods to capture hidden state\ntransitions of complex spatiotemporal systems. The framework has applications\nin reconstruction of solutions and identification of parameter-varying regions.\nComprehensive numerical experiments on various PDEs with jump-varying\ncoefficients demonstrate the framework's exceptional adaptability, accuracy,\nand robustness compared to existing methods. This study provides a\ngeneralizable computational approach of parameter identification for PDEs with\ndiscontinuous parameter structures, particularly in non-stationary or\nheterogeneous systems."}
{"id": "2510.14210", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14210", "abs": "https://arxiv.org/abs/2510.14210", "authors": ["Mingao Yuan"], "title": "Hypothesis testing for the uniformity of random geometric graph", "comment": null, "summary": "Random geometric graphs are widely used in modeling geometry and dependence\nstructure in networks. In a random geometric graph, nodes are independently\ngenerated from some probability distribution $F$ over a metric space, and edges\nlink nodes if their distance is less than some threshold. Most studies assume\nthe distribution $F$ to be uniform. However, recent research shows that some\nreal-world networks may be better modeled by nonuniform distribution $F$.\nMoreover, graphs with nonuniform $F$ have notably different properties from\ngraphs with uniform $F$. A fundamental question is: given a network from a\nrandom geometric graph, is the distribution $F$ uniform or not? In this paper,\nwe approach this question through hypothesis testing. This problem is\nparticularly challenging due to the inherent dependencies among edges in random\ngeometric graphs, a property not present in classic random graphs. We propose\nthe first statistical test. Under the null hypothesis, the test statistic\nconverges in distribution to the standard normal distribution. The asymptotic\ndistribution is derived using the asymptotic theory of degenerate U-statistics\nwith a kernel function dependent on the number of nodes. This technique is\ndifferent from existing methods in network hypothesis testing problems. In\naddition, we present a method for efficiently calculating the test statistic\ndirectly from the adjacency matrix. We also analytically characterize the power\nof the proposed test. The simulation study shows that the proposed uniformity\ntest has high power. Real data applications are also provided."}
{"id": "2510.14711", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14711", "abs": "https://arxiv.org/abs/2510.14711", "authors": ["Pierre Glaser", "David Widmann", "Fredrik Lindsten", "Arthur Gretton"], "title": "Fast and Scalable Score-Based Kernel Calibration Tests", "comment": "26 pages", "summary": "We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD\ntest), a non-parametric, kernel-based test for assessing the calibration of\nprobabilistic models with well-defined scores. In contrast to previous methods,\nour test avoids the need for possibly expensive expectation approximations\nwhile providing control over its type-I error. We achieve these improvements by\nusing a new family of kernels for score-based probabilities that can be\nestimated without probability density samples, and by using a conditional\ngoodness-of-fit criterion for the KCCSD test's U-statistic. We demonstrate the\nproperties of our test on various synthetic settings."}
{"id": "2510.14368", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14368", "abs": "https://arxiv.org/abs/2510.14368", "authors": ["Mei Dong", "Lin Liu", "Dingke Tang", "Geoffrey Liu", "Wei Xu", "Linbo Wang"], "title": "Marginal Causal Effect Estimation with Continuous Instrumental Variables", "comment": null, "summary": "Instrumental variables (IVs) are often continuous, arising in diverse fields\nsuch as economics, epidemiology, and the social sciences. Existing approaches\nfor continuous IVs typically impose strong parametric models or assume\nhomogeneous treatment effects, while fully nonparametric methods may perform\npoorly in moderate- to high-dimensional covariate settings. We propose a new\nframework for identifying the average treatment effect with continuous IVs via\nconditional weighted average derivative effects. Using a conditional Riesz\nrepresenter, our framework unifies continuous and categorical IVs. In this\nframework, the average treatment effect is typically overidentified, leading to\na semiparametric observed-data model with a nontrivial tangent space.\nCharacterizing this tangent space involves a delicate construction of a\nsecond-order parametric submodel, which, to the best of our knowledge, has not\nbeen standard practice in this literature. For estimation, building on an\ninfluence function in the semiparametric model that is also locally efficient\nwithin a submodel, we develop a locally efficient, triply robust, bounded, and\neasy-to-implement estimator. We apply our methods to an observational clinical\nstudy from the Princess Margaret Cancer Centre to examine the so-called obesity\nparadox in oncology, assessing the causal effect of excess body weight on\ntwo-year mortality among patients with non-small cell lung cancer."}
{"id": "2510.14848", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14848", "abs": "https://arxiv.org/abs/2510.14848", "authors": ["Gavin Kerrigan", "Christian A. Naesseth", "Tom Rainforth"], "title": "A Geometric Approach to Optimal Experimental Design", "comment": null, "summary": "We introduce a novel geometric framework for optimal experimental design\n(OED). Traditional OED approaches, such as those based on mutual information,\nrely explicitly on probability densities, leading to restrictive invariance\nproperties. To address these limitations, we propose the mutual transport\ndependence (MTD), a measure of statistical dependence grounded in optimal\ntransport theory which provides a geometric objective for optimizing designs.\nUnlike conventional approaches, the MTD can be tailored to specific downstream\nestimation problems by choosing appropriate geometries on the underlying\nspaces. We demonstrate that our framework produces high-quality designs while\noffering a flexible alternative to standard information-theoretic techniques."}
{"id": "2510.14415", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.14415", "abs": "https://arxiv.org/abs/2510.14415", "authors": ["Tadao Hoshino"], "title": "Evaluating Policy Effects under Network Interference without Network Information: A Transfer Learning Approach", "comment": null, "summary": "This paper develops a sensitivity analysis framework that transfers the\naverage total treatment effect (ATTE) from source data with a fully observed\nnetwork to target data whose network is completely unknown. The ATTE represents\nthe average social impact of a policy that assigns the treatment to every\nindividual in the dataset. We postulate a covariate-shift type assumption that\nboth source and target datasets share the same conditional mean outcome.\nHowever, because the target network is unobserved, this assumption alone is not\nsufficient to pin down the ATTE for the target data. To address this issue, we\nconsider a sensitivity analysis based on the uncertainty of the target\nnetwork's degree distribution, where the extent of uncertainty is measured by\nthe Wasserstein distance from a given reference degree distribution. We then\nconstruct bounds on the target ATTE using a linear programming-based estimator.\nThe limiting distribution of the bound estimator is derived via the functional\ndelta method, and we develop a wild bootstrap approach to approximate the\ndistribution. As an empirical illustration, we revisit the social network\nexperiment on farmers' weather insurance adoption in China by Cai et al.\n(2015)."}
{"id": "2510.14494", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14494", "abs": "https://arxiv.org/abs/2510.14494", "authors": ["Ziad Akram Ali Hammouri", "Yating Zhou", "Rahul Ghosal", "Juan C. Vidal", "Marcos Matabuena"], "title": "ROC Analysis with Covariate Adjustment Using Neural Network Models: Evaluating the Role of Age in the Physical Activity-Mortality Association", "comment": null, "summary": "The receiver operating characteristic (ROC) curve and its summary measure,\nthe Area Under the Curve (AUC), are well-established tools for evaluating the\nefficacy of biomarkers in biomedical studies. Compared to the traditional ROC\ncurve, the covariate-adjusted ROC curve allows for individual evaluation of the\nbiomarker. However, the use of machine learning models has rarely been explored\nin this context, despite their potential to develop more powerful and\nsophisticated approaches for biomarker evaluation. The goal of this paper is to\npropose a framework for neural network-based covariate-adjusted ROC modeling\nthat allows flexible and nonlinear evaluation of the effectiveness of a\nbiomarker to discriminate between two reference populations. The finite-sample\nperformance of our method is investigated through extensive simulation tests\nunder varying dependency structures between biomarkers, covariates, and\nreferenced populations. The methodology is further illustrated in a clinically\ncase study that assesses daily physical activity - measured as total activity\ntime (TAC), a proxy for daily step count-as a biomarker to predict mortality at\nthree, five and eight years. Analyzes stratified by sex and adjusted for age\nand BMI reveal distinct covariate effects on mortality outcomes. These results\nunderscore the importance of covariate-adjusted modeling in biomarker\nevaluation and highlight TAC's potential as a functional capacity biomarker\nbased on specific individual characteristics."}
{"id": "2510.14494", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14494", "abs": "https://arxiv.org/abs/2510.14494", "authors": ["Ziad Akram Ali Hammouri", "Yating Zhou", "Rahul Ghosal", "Juan C. Vidal", "Marcos Matabuena"], "title": "ROC Analysis with Covariate Adjustment Using Neural Network Models: Evaluating the Role of Age in the Physical Activity-Mortality Association", "comment": null, "summary": "The receiver operating characteristic (ROC) curve and its summary measure,\nthe Area Under the Curve (AUC), are well-established tools for evaluating the\nefficacy of biomarkers in biomedical studies. Compared to the traditional ROC\ncurve, the covariate-adjusted ROC curve allows for individual evaluation of the\nbiomarker. However, the use of machine learning models has rarely been explored\nin this context, despite their potential to develop more powerful and\nsophisticated approaches for biomarker evaluation. The goal of this paper is to\npropose a framework for neural network-based covariate-adjusted ROC modeling\nthat allows flexible and nonlinear evaluation of the effectiveness of a\nbiomarker to discriminate between two reference populations. The finite-sample\nperformance of our method is investigated through extensive simulation tests\nunder varying dependency structures between biomarkers, covariates, and\nreferenced populations. The methodology is further illustrated in a clinically\ncase study that assesses daily physical activity - measured as total activity\ntime (TAC), a proxy for daily step count-as a biomarker to predict mortality at\nthree, five and eight years. Analyzes stratified by sex and adjusted for age\nand BMI reveal distinct covariate effects on mortality outcomes. These results\nunderscore the importance of covariate-adjusted modeling in biomarker\nevaluation and highlight TAC's potential as a functional capacity biomarker\nbased on specific individual characteristics."}
{"id": "2510.14694", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14694", "abs": "https://arxiv.org/abs/2510.14694", "authors": ["Razieh Nabi", "Rohit Bhattacharya", "Ilya Shpitser", "James M. Robins"], "title": "Response to Discussions of \"Causal and Counterfactual Views of Missing Data Models\"", "comment": null, "summary": "We are grateful to the discussants, Levis and Kennedy [2025], Luo and Geng\n[2025], Wang and van der Laan [2025], and Yang and Kim [2025], for their\nthoughtful comments on our paper (Nabi et al., 2025). In this rejoinder, we\nsummarize our main contributions and respond to each discussion in turn."}
{"id": "2510.14502", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14502", "abs": "https://arxiv.org/abs/2510.14502", "authors": ["Eva-Maria Maier", "Alexander Fottner", "Sonja Greven", "Almond Stöcker"], "title": "Additive Density Regression", "comment": null, "summary": "We present a structured additive regression approach to model conditional\ndensities given scalar covariates, where only samples of the conditional\ndistributions are observed. This links our approach to distributional\nregression models for scalar data. The model is formulated in a Bayes Hilbert\nspace -- preserving nonnegativity and integration to one under summation and\nscalar multiplication -- with respect to an arbitrary finite measure. This\nallows to consider, amongst others, continuous, discrete and mixed densities.\nOur theoretical results include asymptotic existence, uniqueness, consistency,\nand asymptotic normality of the penalized maximum likelihood estimator, as well\nas confidence regions and inference for the (effect) densities. For estimation,\nwe propose to maximize the penalized log-likelihood corresponding to an\nappropriate multinomial, or equivalently, Poisson regression model, which we\nshow to approximate the original penalized maximum likelihood problem. We apply\nour framework to a motivating gender economic data set from the German\nSocio-Economic Panel Study (SOEP), analyzing the distribution of the woman's\nshare in a couple's total labor income given covariate effects for year, place\nof residence and age of the youngest child. As the income share is a continuous\nvariable having discrete point masses at zero and one for single-earner\ncouples, the corresponding densities are of mixed type."}
{"id": "2510.14890", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14890", "abs": "https://arxiv.org/abs/2510.14890", "authors": ["Andrew Welbaum", "Wanli Qiao"], "title": "EM Approaches to Nonparametric Estimation for Mixture of Linear Regressions", "comment": null, "summary": "In a mixture of linear regression model, the regression coefficients are\ntreated as random vectors that may follow either a continuous or discrete\ndistribution. We propose two Expectation-Maximization (EM) algorithms to\nestimate this prior distribution. The first algorithm solves a kernelized\nversion of the nonparametric maximum likelihood estimation (NPMLE). This method\nnot only recovers continuous prior distributions but also accurately estimates\nthe number of clusters when the prior is discrete. The second algorithm,\ndesigned to approximate the NPMLE, targets prior distributions with a density.\nIt also performs well for discrete priors when combined with a post-processing\nstep. We study the convergence properties of both algorithms and demonstrate\ntheir effectiveness through simulations and applications to real datasets."}
{"id": "2510.14559", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14559", "abs": "https://arxiv.org/abs/2510.14559", "authors": ["En-Yu Lai", "Jih-Chang Yu", "Yen-Tsung Huang"], "title": "Reframing cross-world independence for identifying path-specific effects", "comment": null, "summary": "Understanding causal mechanisms in complex systems requires evaluating\npath-specific effects (PSEs) in multi-mediator models. Identification of PSEs\ntraditionally relies on the demanding cross-world independence assumption. To\nrelax this, VanderWeele et al. (2014) proposed an interventional approach that\nredefines PSEs, while Stensrud et al. (2021) introduced dismissible component\nconditions for identifying separable effects under competing risks. In this\nstudy, we leverage SWIGs to dissect the causal foundations of these three\nsemantics and make two key advances. First, we generalize separable effects\nbeyond competing risks to the setting of multi-mediator models and derive the\nassumptions required for their identification. Second, we unify the three\napproaches by clarifying how they interpret counterfactual outcomes\ndifferently: as mediator-driven effects (classical), randomized contrasts\n(interventional), or component-specific actions (separable). We further\ndemonstrate that violations of cross-world independence originate from\nmediators omitted from the model. By analogy to confounder control, we argue\nthat just as exchangeability is achieved by conditioning on sufficient\nconfounders, cross-world independence can be approximated by including\nsufficient mediators. This reframing turns an abstract assumption into a\ntangible modeling strategy, offering a more practical path forward for applied\nmediation analysis in complex causal systems."}
{"id": "2510.14637", "categories": ["stat.ME", "60G70, 62F15, 62E20"], "pdf": "https://arxiv.org/pdf/2510.14637", "abs": "https://arxiv.org/abs/2510.14637", "authors": ["David L. Carl", "Simone A. Padoan", "Stefano Rizzelli"], "title": "Accurate Bayesian inference for tail risk extrapolation in time series", "comment": null, "summary": "Accurately quantifying tail risks-rare but high-impact events such as\nfinancial crashes or extreme weather-is a central challenge in risk management,\nwith serially dependent data. We develop a Bayesian framework based on the\nGeneralized Pareto (GP) distribution for modeling threshold exceedances,\nproviding posterior distributions for the GP parameters and tail quantiles in\ntime series. Two cases are considered: extrapolation of tail quantiles for the\nstationary marginal distribution under beta-mixing dependence, and dynamic,\npast-conditional tail quantiles in heteroscedastic regression models. The\nproposal yields asymptotically honest credible regions, whose coverage\nprobabilities converge to their nominal levels. We establish the asymptotic\ntheory for the Bayesian procedure, deriving conditions on the prior\ndistributions under which the posterior satisfies key asymptotic properties. To\nachieve this, we first develop a likelihood theory under serial dependence,\nproviding local and global bounds for the empirical log-likelihood process of\nthe misspecified GP model and deriving corresponding asymptotic properties of\nthe Maximum Likelihood Estimator (MLE). Simulations demonstrate that our\nBayesian credible regions outperform naive Bayesian and MLE-based confidence\nregions across several standard time series models, including ARMA, GARCH, and\nMarkovian copula models. Two real-data applications-to U.S. interest rates and\nSwiss electricity demand-highlight the relevance of the proposed methodology."}
{"id": "2510.14681", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14681", "abs": "https://arxiv.org/abs/2510.14681", "authors": ["Alessandro Carminati", "Mario Beraha", "Federico Camerlenghi", "Alessandra Guglielmi"], "title": "Hierarchical shot-noise Cox process mixtures for clustering across groups", "comment": null, "summary": "Clustering observations across partially exchangeable groups of data is a\nroutine task in Bayesian nonparametrics. Previously proposed models allow for\nclustering across groups by sharing atoms in the group-specific mixing\nmeasures. However, exact atom sharing can be overly rigid when groups differ\nsubtly, introducing a trade-off between clustering and density estimates and\nfragmenting across-group clusters, particularly at larger sample sizes. We\nintroduce the hierarchical shot-noise Cox process (HSNCP) mixture model, where\ngroup-specific atoms concentrate around shared centers through a kernel. This\nenables accurate density estimation within groups and flexible borrowing across\ngroups, overcoming the density-clustering trade-off of previous approaches. Our\nconstruction, built on the shot-noise Cox process, remains analytically\ntractable: we derive closed-form prior moments and an inter-group correlation,\nobtain the marginal law and predictive distribution for latent parameters, as\nwell as the posterior of the mixing measures given the latent parameters. We\ndevelop an efficient conditional MCMC algorithm for posterior inference. We\nassess the performance of the HSNCP model through simulations and an\napplication to a large galaxy dataset, demonstrating balanced across-group\nclusters and improved density estimates compared with the hierarchical\nDirichlet process, including under model misspecification."}
{"id": "2510.14694", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14694", "abs": "https://arxiv.org/abs/2510.14694", "authors": ["Razieh Nabi", "Rohit Bhattacharya", "Ilya Shpitser", "James M. Robins"], "title": "Response to Discussions of \"Causal and Counterfactual Views of Missing Data Models\"", "comment": null, "summary": "We are grateful to the discussants, Levis and Kennedy [2025], Luo and Geng\n[2025], Wang and van der Laan [2025], and Yang and Kim [2025], for their\nthoughtful comments on our paper (Nabi et al., 2025). In this rejoinder, we\nsummarize our main contributions and respond to each discussion in turn."}
{"id": "2510.14714", "categories": ["stat.ME", "physics.comp-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.14714", "abs": "https://arxiv.org/abs/2510.14714", "authors": ["Hristos Tyralis", "Georgia Papacharalampous"], "title": "Loss functions arising from the index of agreement", "comment": "49 pages, 6 figures", "summary": "We examine the theoretical properties of the index of agreement loss function\n$L_W$, the negatively oriented counterpart of Willmott's index of agreement, a\ncommon metric in environmental sciences and engineering. We prove that $L_W$ is\nbounded within [0, 1], translation and scale invariant, and estimates the\nparameter $\\Bbb{E}_{F}[\\underline{y}] \\pm \\Bbb{V}_{F}^{1/2}[\\underline{y}]$\nwhen fitting a distribution. We propose $L_{\\operatorname{NR}_2}$ as a\ntheoretical improvement, which replaces the denominator of $L_W$ with the sum\nof Euclidean distances, better aligning with the underlying geometric\nintuition. This new loss function retains the appealing properties of $L_W$ but\nalso admits closed-form solutions for linear model parameter estimation. We\nshow that as the correlation between predictors and the dependent variable\napproaches 1, parameter estimates from squared error, $L_{\\operatorname{NR}_2}$\nand $L_W$ converge. This behavior is mirrored in hydrologic model calibration\n(a core task in water resources engineering), where performance becomes nearly\nidentical across these loss functions. Finally, we suggest potential\nimprovements for existing $L_p$-norm variants of the index of agreement."}
{"id": "2510.14890", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.14890", "abs": "https://arxiv.org/abs/2510.14890", "authors": ["Andrew Welbaum", "Wanli Qiao"], "title": "EM Approaches to Nonparametric Estimation for Mixture of Linear Regressions", "comment": null, "summary": "In a mixture of linear regression model, the regression coefficients are\ntreated as random vectors that may follow either a continuous or discrete\ndistribution. We propose two Expectation-Maximization (EM) algorithms to\nestimate this prior distribution. The first algorithm solves a kernelized\nversion of the nonparametric maximum likelihood estimation (NPMLE). This method\nnot only recovers continuous prior distributions but also accurately estimates\nthe number of clusters when the prior is discrete. The second algorithm,\ndesigned to approximate the NPMLE, targets prior distributions with a density.\nIt also performs well for discrete priors when combined with a post-processing\nstep. We study the convergence properties of both algorithms and demonstrate\ntheir effectiveness through simulations and applications to real datasets."}
{"id": "2510.14950", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14950", "abs": "https://arxiv.org/abs/2510.14950", "authors": ["Mark Dominique Dalipe Muñoz"], "title": "A formative measurement validation methodology for survey questionnaires", "comment": "15 pages, 4 figures, 1 table", "summary": "Model misspecification of formative indicators remains a widely documented\nissue across academic literature, yet scholars lack a clear consensus on\npragmatic, prescriptive approaches to manage this gap. This ambiguity forces\nresearchers to rely on psychometric frameworks primarily intended for\nreflective models, and thus risks misleading findings. This article introduces\na Multi-Step Validation Methodology Framework specifically designed for\nformative constructs in survey-based research. The proposed framework is\ngrounded in an exhaustive literature review and integrates essential pilot\ndiagnostics through descriptive statistics and multicollinearity checks. The\nmethodology provides researchers with the necessary theoretical and structural\nclarity to finally justify and adhere to appropriate validation techniques that\naccurately account for the causal nature of the constructs while ensuring high\npsychometric and statistical integrity."}
