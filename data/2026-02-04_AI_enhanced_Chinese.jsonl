{"id": "2602.00434", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.00434", "abs": "https://arxiv.org/abs/2602.00434", "authors": ["Yulin Shao", "Liangbo Lyu", "Menggang Yu", "Bingkai Wang"], "title": "Benchmarking covariate-adjustment strategies for randomized clinical trials", "comment": null, "summary": "Covariate adjustment is widely recommended to improve statistical efficiency in randomized clinical trials (RCTs), yet empirical evidence comparing available strategies remains limited. This lack of real-world evaluation leaves unresolved practical questions about which adjustment methods to use and which covariates to include. To address this gap, we conduct a large-scale empirical benchmarking using individual-level data from 50 publicly accessible RCTs comprising 29,094 participants and 574 treatment-outcome pairs. We evaluate 18 analytical strategies formed by combining six estimators-including classical regression, inverse probability weighting, and machine-learning methods-with three covariate-selection rules. Across diverse therapeutic areas, covariate adjustment consistently improves precision, yielding median variance reductions of 13.3% relative to unadjusted analyses for continuous outcomes and 4.6% for binary outcomes. However, machine-learning algorithms implemented with default hyperparameter settings do not yield efficiency gains beyond simple linear models. Parsimonious regression approaches, such as analysis of covariance, deliver stable, reproducible performance even in moderate sample sizes. Together, these findings provide the first large-scale empirical evidence that transparent and parsimonious covariate adjustment is sufficient and often preferable for routine RCT analysis. All curated datasets and analysis code are openly released as a reproducible benchmark resource to support future clinical research and methodological development.", "AI": {"tldr": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u968f\u673a\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u7684\u534f\u53d8\u91cf\u8c03\u6574\u7b56\u7565\uff0c\u53d1\u73b0\u7b80\u7ea6\u56de\u5f52\u65b9\u6cd5\uff08\u5982\u534f\u65b9\u5dee\u5206\u6790\uff09\u5728\u4e2d\u7b49\u6837\u672c\u91cf\u4e0b\u8868\u73b0\u7a33\u5b9a\uff0c\u800c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u9ed8\u8ba4\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u5e76\u672a\u63d0\u4f9b\u989d\u5916\u6548\u7387\u589e\u76ca\u3002", "motivation": "\u5c3d\u7ba1\u534f\u53d8\u91cf\u8c03\u6574\u88ab\u5e7f\u6cdb\u63a8\u8350\u7528\u4e8e\u63d0\u9ad8\u968f\u673a\u4e34\u5e8a\u8bd5\u9a8c\u7684\u7edf\u8ba1\u6548\u7387\uff0c\u4f46\u4e0d\u540c\u8c03\u6574\u7b56\u7565\u4e4b\u95f4\u7684\u5b9e\u8bc1\u6bd4\u8f83\u8bc1\u636e\u4ecd\u7136\u6709\u9650\u3002\u8fd9\u79cd\u7f3a\u4e4f\u5b9e\u9645\u8bc4\u4f30\u7684\u60c5\u51b5\u5bfc\u81f4\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5173\u4e8e\u4f7f\u7528\u54ea\u79cd\u8c03\u6574\u65b9\u6cd5\u548c\u5305\u542b\u54ea\u4e9b\u534f\u53d8\u91cf\u7684\u5b9e\u9645\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002", "method": "\u4f7f\u7528\u6765\u81ea50\u4e2a\u516c\u5f00\u53ef\u83b7\u53d6\u7684\u968f\u673a\u4e34\u5e8a\u8bd5\u9a8c\u7684\u4e2a\u4f53\u6c34\u5e73\u6570\u636e\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d629,094\u540d\u53c2\u4e0e\u8005\u548c574\u4e2a\u6cbb\u7597-\u7ed3\u679c\u914d\u5bf9\u3002\u8bc4\u4f30\u4e8618\u79cd\u5206\u6790\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u7531\u516d\u79cd\u4f30\u8ba1\u5668\uff08\u5305\u62ec\u7ecf\u5178\u56de\u5f52\u3001\u9006\u6982\u7387\u52a0\u6743\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff09\u4e0e\u4e09\u79cd\u534f\u53d8\u91cf\u9009\u62e9\u89c4\u5219\u7ec4\u5408\u800c\u6210\u3002", "result": "\u534f\u53d8\u91cf\u8c03\u6574\u5728\u4e0d\u540c\u6cbb\u7597\u9886\u57df\u4e2d\u4e00\u81f4\u63d0\u9ad8\u4e86\u7cbe\u786e\u5ea6\uff0c\u76f8\u5bf9\u4e8e\u672a\u8c03\u6574\u5206\u6790\uff0c\u8fde\u7eed\u7ed3\u679c\u7684\u65b9\u5dee\u4e2d\u4f4d\u6570\u51cf\u5c11\u4e8613.3%\uff0c\u4e8c\u5143\u7ed3\u679c\u51cf\u5c11\u4e864.6%\u3002\u7136\u800c\uff0c\u4f7f\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8bbe\u7f6e\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5e76\u672a\u6bd4\u7b80\u5355\u7ebf\u6027\u6a21\u578b\u5e26\u6765\u989d\u5916\u7684\u6548\u7387\u589e\u76ca\u3002\u7b80\u7ea6\u56de\u5f52\u65b9\u6cd5\uff08\u5982\u534f\u65b9\u5dee\u5206\u6790\uff09\u5373\u4f7f\u5728\u4e2d\u7b49\u6837\u672c\u91cf\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u91cd\u590d\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u8bc1\u636e\uff0c\u8868\u660e\u900f\u660e\u4e14\u7b80\u7ea6\u7684\u534f\u53d8\u91cf\u8c03\u6574\u5bf9\u4e8e\u5e38\u89c4\u968f\u673a\u4e34\u5e8a\u8bd5\u9a8c\u5206\u6790\u662f\u8db3\u591f\u7684\uff0c\u5e76\u4e14\u901a\u5e38\u662f\u66f4\u53ef\u53d6\u7684\u3002\u6240\u6709\u6574\u7406\u7684\u6570\u636e\u96c6\u548c\u5206\u6790\u4ee3\u7801\u90fd\u5df2\u4f5c\u4e3a\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u8d44\u6e90\u516c\u5f00\u53d1\u5e03\uff0c\u4ee5\u652f\u6301\u672a\u6765\u7684\u4e34\u5e8a\u7814\u7a76\u548c\u65b9\u6cd5\u5b66\u53d1\u5c55\u3002"}}
{"id": "2602.00890", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.00890", "abs": "https://arxiv.org/abs/2602.00890", "authors": ["Behzad Ghanbarian", "Victor Oladoja", "Kehinde Bosikun", "Tayeb Jamali", "J\u00fcrgen Kurths"], "title": "Boundary-Induced Biases in Climate Networks of Extreme Precipitation and Temperature", "comment": null, "summary": "To address spatial boundary effects in climate networks, two surrogate-based correction methods, (1) subtraction and (2) division, have been widely applied in the literature. In the subtraction method, an original network measure is adjusted by subtracting the expected value obtained from a surrogate ensemble, whereas in the division method, it is normalized by dividing by this expected value. However, to the best of our knowledge, no prior study has assessed whether these two correction approaches yield statistically different results. In this study, we constructed complex networks of extreme precipitation and temperature events (EPEs and ETEs) across the CONUS for both summer (June-August, JJA) and winter (December-February, DJF) seasons. We computed key network metrics degree centrality (DC), clustering coefficient (CC), mean geographic distance (MGD), and betweenness centrality (BC) and applied both correction methods. Although the corrected spatial patterns generally appeared visually similar, statistical analyses revealed that the network measures derived from the subtraction and division methods were significantly different at the 95 percent confidence level. Across the CONUS, network hubs of EPEs were primarily concentrated in the northwestern United States during summer and shifted toward the east during winter, reflecting seasonal differences in the dominant atmospheric drivers. In contrast, the ETE networks showed strong spatial coherence and pronounced regional teleconnections in both seasons, with higher connectivity and longer synchronization distances in winter, consistent with large-scale circulation patterns such as the Pacific-North American and North Atlantic Oscillation modes. Our results indicated that the network metrics CC and MGD were more sensitive to the correction methods than the DC and BC, particularly in the EPE networks.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u6c14\u5019\u7f51\u7edc\u4e2d\u4e24\u79cd\u8fb9\u754c\u6548\u5e94\u6821\u6b63\u65b9\u6cd5\uff08\u51cf\u6cd5\u548c\u9664\u6cd5\uff09\u7684\u7edf\u8ba1\u5dee\u5f02\uff0c\u53d1\u73b0\u5c3d\u7ba1\u7a7a\u95f4\u6a21\u5f0f\u76f8\u4f3c\uff0c\u4f46\u6821\u6b63\u540e\u7684\u7f51\u7edc\u6307\u6807\u5728\u7edf\u8ba1\u4e0a\u663e\u8457\u4e0d\u540c\uff0c\u5176\u4e2d\u805a\u7c7b\u7cfb\u6570\u548c\u5e73\u5747\u5730\u7406\u8ddd\u79bb\u5bf9\u6821\u6b63\u65b9\u6cd5\u66f4\u654f\u611f\u3002", "motivation": "\u6c14\u5019\u7f51\u7edc\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u51cf\u6cd5\u548c\u9664\u6cd5\u4e24\u79cd\u8fb9\u754c\u6548\u5e94\u6821\u6b63\u65b9\u6cd5\uff0c\u4f46\u6b64\u524d\u6ca1\u6709\u7814\u7a76\u8bc4\u4f30\u8fd9\u4e24\u79cd\u65b9\u6cd5\u662f\u5426\u4f1a\u4ea7\u751f\u7edf\u8ba1\u4e0a\u4e0d\u540c\u7684\u7ed3\u679c\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6bd4\u8f83\u4e24\u79cd\u6821\u6b63\u65b9\u6cd5\u5728\u6781\u7aef\u964d\u6c34\u548c\u6e29\u5ea6\u4e8b\u4ef6\u7f51\u7edc\u4e2d\u7684\u5dee\u5f02\u3002", "method": "\u6784\u5efa\u7f8e\u56fd\u672c\u571f\u6781\u7aef\u964d\u6c34\u548c\u6e29\u5ea6\u4e8b\u4ef6\u7684\u6c14\u5019\u7f51\u7edc\uff0c\u8ba1\u7b97\u5173\u952e\u7f51\u7edc\u6307\u6807\uff08\u5ea6\u4e2d\u5fc3\u6027\u3001\u805a\u7c7b\u7cfb\u6570\u3001\u5e73\u5747\u5730\u7406\u8ddd\u79bb\u3001\u4ecb\u6570\u4e2d\u5fc3\u6027\uff09\uff0c\u5206\u522b\u5e94\u7528\u51cf\u6cd5\u548c\u9664\u6cd5\u4e24\u79cd\u6821\u6b63\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u3002", "result": "\u5c3d\u7ba1\u6821\u6b63\u540e\u7684\u7a7a\u95f4\u6a21\u5f0f\u89c6\u89c9\u4e0a\u76f8\u4f3c\uff0c\u4f46\u7edf\u8ba1\u5206\u6790\u663e\u793a\u51cf\u6cd5\u548c\u9664\u6cd5\u65b9\u6cd5\u5f97\u5230\u7684\u7f51\u7edc\u6307\u6807\u572895%\u7f6e\u4fe1\u6c34\u5e73\u4e0a\u663e\u8457\u4e0d\u540c\u3002\u805a\u7c7b\u7cfb\u6570\u548c\u5e73\u5747\u5730\u7406\u8ddd\u79bb\u6bd4\u5ea6\u4e2d\u5fc3\u6027\u548c\u4ecb\u6570\u4e2d\u5fc3\u6027\u5bf9\u6821\u6b63\u65b9\u6cd5\u66f4\u654f\u611f\uff0c\u7279\u522b\u662f\u5728\u6781\u7aef\u964d\u6c34\u7f51\u7edc\u4e2d\u3002", "conclusion": "\u4e24\u79cd\u8fb9\u754c\u6548\u5e94\u6821\u6b63\u65b9\u6cd5\u5728\u7edf\u8ba1\u4e0a\u4ea7\u751f\u663e\u8457\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u7814\u7a76\u8005\u5728\u9009\u62e9\u6821\u6b63\u65b9\u6cd5\u65f6\u9700\u8981\u8c28\u614e\u8003\u8651\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u805a\u7c7b\u7cfb\u6570\u548c\u5e73\u5747\u5730\u7406\u8ddd\u79bb\u7b49\u654f\u611f\u6307\u6807\u3002\u6781\u7aef\u964d\u6c34\u7f51\u7edc\u4e2d\u5fc3\u968f\u5b63\u8282\u53d8\u5316\uff0c\u800c\u6781\u7aef\u6e29\u5ea6\u7f51\u7edc\u5219\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u9065\u76f8\u5173\u6a21\u5f0f\u3002"}}
{"id": "2602.01099", "categories": ["stat.AP", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.01099", "abs": "https://arxiv.org/abs/2602.01099", "authors": ["Babak Maboudi Afkham", "Ana Carpio"], "title": "Simultaneous Estimation of Seabed and Its Roughness With Longitudinal Waves", "comment": null, "summary": "This paper introduces an infinite-dimensional Bayesian framework for acoustic seabed tomography, leveraging wave scattering to simultaneously estimate the seabed and its roughness. Tomography is considered an ill-posed problem where multiple seabed configurations can result in similar measurement patterns. We propose a novel approach focusing on the statistical isotropy of the seabed. Utilizing fractional differentiability to identify seabed roughness, the paper presents a robust numerical algorithm to estimate the seabed and quantify uncertainties. Extensive numerical experiments validate the effectiveness of this method, offering a promising avenue for large-scale seabed exploration.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9650\u7ef4\u8d1d\u53f6\u65af\u6846\u67b6\u7528\u4e8e\u58f0\u5b66\u6d77\u5e95\u5c42\u6790\u6210\u50cf\uff0c\u5229\u7528\u6ce2\u6563\u5c04\u540c\u65f6\u4f30\u8ba1\u6d77\u5e95\u5730\u5f62\u53ca\u5176\u7c97\u7cd9\u5ea6\uff0c\u901a\u8fc7\u7edf\u8ba1\u5404\u5411\u540c\u6027\u548c\u5206\u6570\u53ef\u5fae\u6027\u8bc6\u522b\u7c97\u7cd9\u5ea6\uff0c\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u6d77\u5e95\u5c42\u6790\u6210\u50cf\u662f\u4e00\u4e2a\u4e0d\u9002\u5b9a\u95ee\u9898\uff0c\u591a\u79cd\u6d77\u5e95\u914d\u7f6e\u53ef\u80fd\u4ea7\u751f\u76f8\u4f3c\u7684\u6d4b\u91cf\u6a21\u5f0f\uff0c\u9700\u8981\u540c\u65f6\u4f30\u8ba1\u6d77\u5e95\u5730\u5f62\u548c\u7c97\u7cd9\u5ea6\u5e76\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u65e0\u9650\u7ef4\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u5229\u7528\u6ce2\u6563\u5c04\u539f\u7406\uff0c\u57fa\u4e8e\u6d77\u5e95\u7684\u7edf\u8ba1\u5404\u5411\u540c\u6027\u5047\u8bbe\uff0c\u4f7f\u7528\u5206\u6570\u53ef\u5fae\u6027\u8bc6\u522b\u7c97\u7cd9\u5ea6\uff0c\u5f00\u53d1\u9c81\u68d2\u6570\u503c\u7b97\u6cd5\u3002", "result": "\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u540c\u65f6\u4f30\u8ba1\u6d77\u5e95\u5730\u5f62\u548c\u7c97\u7cd9\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e3a\u5927\u89c4\u6a21\u6d77\u5e95\u52d8\u63a2\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u6d77\u5e95\u5c42\u6790\u6210\u50cf\u7684\u4e0d\u9002\u5b9a\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u8ba1\u5404\u5411\u540c\u6027\u548c\u5206\u6570\u53ef\u5fae\u6027\u6846\u67b6\u5b9e\u73b0\u4e86\u6d77\u5e95\u5730\u5f62\u548c\u7c97\u7cd9\u5ea6\u7684\u540c\u65f6\u4f30\u8ba1\uff0c\u4e3a\u6d77\u6d0b\u52d8\u63a2\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.01551", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.01551", "abs": "https://arxiv.org/abs/2602.01551", "authors": ["Nohelia Da Silva Sanchez", "Diego Derman", "Damon D. Pham", "Ellyn R. Butler", "Mary Beth Nebel", "Amanda F. Mejia"], "title": "Bayesian brain mapping: population-informed individualized functional topography and connectivity", "comment": null, "summary": "The spatial topography of brain functional organization is increasingly recognized to play an important role in cognition and disease. Accounting for individual differences in functional topography is also crucial for accurately distinguishing spatial and temporal aspects of brain organization. Yet, accurate estimation of individual functional brain networks from functional magnetic resonance imaging (fMRI) without extensive scanning remains challenging, due to low signal-to-noise ratio. Here, we describe Bayesian brain mapping (BBM), a technique for individual functional topography and connectivity leveraging population information. Population-derived priors for both spatial topography and functional connectivity based on existing spatial templates, such as parcellations or continuous network maps, are used to guide subject-level estimation and combat noise. BBM is highly flexible, avoiding strong spatial or temporal constraints and allowing for overlap between networks and heterogeneous patterns of engagement. Unlike multi-subject hierarchical models, BBM is designed for single-subject analysis, making it highly computationally efficient and translatable to clinical settings. Here, we describe the BBM model and illustrate the use of the BayesBrainMap R package to construct population-derived priors, fit the model, and perform inference to identify engagements. A demo is provided in an accompanying Github repo. We also share priors derived from the Human Connectome Project database and provide code to support the construction of priors from different data sources, lowering the barrier to adoption of BBM for studies of individual brain organization.", "AI": {"tldr": "BBM\u662f\u4e00\u79cd\u5229\u7528\u7fa4\u4f53\u4fe1\u606f\u8fdb\u884c\u4e2a\u4f53\u529f\u80fd\u5730\u5f62\u56fe\u548c\u8fde\u63a5\u6027\u5206\u6790\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u901a\u8fc7\u7fa4\u4f53\u5148\u9a8c\u6307\u5bfc\u4e2a\u4f53\u4f30\u8ba1\u6765\u5e94\u5bf9fMRI\u7684\u4f4e\u4fe1\u566a\u6bd4\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u73af\u5883\u3002", "motivation": "\u5927\u8111\u529f\u80fd\u7ec4\u7ec7\u7684\u7a7a\u95f4\u5730\u5f62\u5728\u8ba4\u77e5\u548c\u75be\u75c5\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u4e2a\u4f53\u5dee\u5f02\u663e\u8457\u3002\u4ecefMRI\u51c6\u786e\u4f30\u8ba1\u4e2a\u4f53\u529f\u80fd\u7f51\u7edc\u9762\u4e34\u4f4e\u4fe1\u566a\u6bd4\u6311\u6218\uff0c\u4e14\u9700\u8981\u5927\u91cf\u626b\u63cf\u65f6\u95f4\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u8111\u56fe\uff08BBM\uff09\u6280\u672f\uff0c\u5229\u7528\u57fa\u4e8e\u73b0\u6709\u7a7a\u95f4\u6a21\u677f\uff08\u5982\u5206\u533a\u6216\u8fde\u7eed\u7f51\u7edc\u56fe\uff09\u7684\u7fa4\u4f53\u5148\u9a8c\u6765\u6307\u5bfc\u4e2a\u4f53\u5c42\u9762\u7684\u529f\u80fd\u5730\u5f62\u548c\u8fde\u63a5\u6027\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u5f3a\u65f6\u7a7a\u7ea6\u675f\uff0c\u5141\u8bb8\u7f51\u7edc\u91cd\u53e0\u548c\u5f02\u8d28\u6027\u53c2\u4e0e\u6a21\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86BayesBrainMap R\u5305\uff0c\u63d0\u4f9b\u4ece\u6784\u5efa\u7fa4\u4f53\u5148\u9a8c\u3001\u62df\u5408\u6a21\u578b\u5230\u6267\u884c\u63a8\u65ad\u7684\u5b8c\u6574\u5de5\u5177\u94fe\u3002\u63d0\u4f9b\u4e86\u57fa\u4e8e\u4eba\u7c7b\u8fde\u63a5\u7ec4\u8ba1\u5212\u6570\u636e\u5e93\u7684\u5148\u9a8c\u548c\u4ee3\u7801\uff0c\u964d\u4f4eBBM\u7684\u91c7\u7528\u95e8\u69db\u3002", "conclusion": "BBM\u662f\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u3001\u9002\u7528\u4e8e\u5355\u4e2a\u4f53\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u53ef\u51c6\u786e\u4f30\u8ba1\u4e2a\u4f53\u529f\u80fd\u5730\u5f62\u548c\u8fde\u63a5\u6027\uff0c\u7279\u522b\u9002\u5408\u4e34\u5e8a\u73af\u5883\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u4e2a\u4f53\u5927\u8111\u7ec4\u7ec7\u5dee\u5f02\u3002"}}
{"id": "2602.00194", "categories": ["stat.ME", "cs.AI", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.00194", "abs": "https://arxiv.org/abs/2602.00194", "authors": ["Julie Alberge", "Tristan Haugomat", "Ga\u00ebl Varoquaux", "Judith Ab\u00e9cassis"], "title": "On the calibration of survival models with competing risks", "comment": null, "summary": "Survival analysis deals with modeling the time until an event occurs, and accurate probability estimates are crucial for decision-making, particularly in the competing-risks setting where multiple events are possible. While recent work has addressed calibration in standard survival analysis, the competing-risks setting remains under-explored as it is harder (the calibration applies to both probabilities across classes and time horizon). We show that existing calibration measures are not suited to the competing-risk setting and that recent models do not give well-behaved probabilities. To address this, we introduce a dedicated framework with two novel calibration measures that are minimized for oracle estimators (i.e., both measures are proper). We also introduce some methods to estimate, test, and correct the calibration. Our recalibration methods yield good probabilities while preserving discrimination.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u7ade\u4e89\u98ce\u9669\u751f\u5b58\u5206\u6790\u7684\u65b0\u6821\u51c6\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u7684\u6821\u51c6\u5ea6\u91cf\u6307\u6807\u548c\u76f8\u5e94\u7684\u4f30\u8ba1\u3001\u68c0\u9a8c\u3001\u6821\u6b63\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u5224\u522b\u80fd\u529b\u7684\u540c\u65f6\u6539\u5584\u6982\u7387\u4f30\u8ba1\u8d28\u91cf\u3002", "motivation": "\u7ade\u4e89\u98ce\u9669\u751f\u5b58\u5206\u6790\u4e2d\uff0c\u73b0\u6709\u6821\u51c6\u5ea6\u91cf\u4e0d\u9002\u7528\u4e8e\u8be5\u573a\u666f\uff0c\u4e14\u73b0\u6709\u6a21\u578b\u65e0\u6cd5\u63d0\u4f9b\u884c\u4e3a\u826f\u597d\u7684\u6982\u7387\u4f30\u8ba1\uff0c\u800c\u51c6\u786e\u7684\u6982\u7387\u4f30\u8ba1\u5bf9\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e13\u95e8\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u7684\u6821\u51c6\u5ea6\u91cf\uff08\u5bf9oracle\u4f30\u8ba1\u5668\u6700\u5c0f\u5316\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u4f30\u8ba1\u3001\u68c0\u9a8c\u548c\u6821\u6b63\u6821\u51c6\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u91cd\u65b0\u6821\u51c6\u65b9\u6cd5\u3002", "result": "\u65b0\u6821\u51c6\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u5224\u522b\u80fd\u529b\u7684\u540c\u65f6\u83b7\u5f97\u826f\u597d\u7684\u6982\u7387\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u7ade\u4e89\u98ce\u9669\u8bbe\u7f6e\u4e0b\u7684\u6821\u51c6\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u7ade\u4e89\u98ce\u9669\u751f\u5b58\u5206\u6790\u4e2d\u6821\u51c6\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\u548c\u5de5\u5177\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u6982\u7387\u4f30\u8ba1\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.00171", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00171", "abs": "https://arxiv.org/abs/2602.00171", "authors": ["Mathew Chandy", "Michael Johnson", "Judong Shen", "Devan V. Mehrotra", "Hua Zhou", "Jin Zhou", "Xiaowu Dai"], "title": "Uncertainty-Aware Multimodal Learning via Conformal Shapley Intervals", "comment": null, "summary": "Multimodal learning combines information from multiple data modalities to improve predictive performance. However, modalities often contribute unequally and in a data dependent way, making it unclear which data modalities are genuinely informative and to what extent their contributions can be trusted. Quantifying modality level importance together with uncertainty is therefore central to interpretable and reliable multimodal learning. We introduce conformal Shapley intervals, a framework that combines Shapley values with conformal inference to construct uncertainty-aware importance intervals for each modality. Building on these intervals, we propose a modality selection procedure with a provable optimality guarantee: conditional on the observed features, the selected subset of modalities achieves performance close to that of the optimal subset. We demonstrate the effectiveness of our approach on multiple datasets, showing that it provides meaningful uncertainty quantification and strong predictive performance while relying on only a small number of informative modalities.", "AI": {"tldr": "\u63d0\u51faconformal Shapley intervals\u6846\u67b6\uff0c\u7ed3\u5408Shapley\u503c\u548cconformal inference\u4e3a\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6bcf\u4e2a\u6a21\u6001\u6784\u5efa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u91cd\u8981\u6027\u533a\u95f4\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u5177\u6709\u7406\u8bba\u6700\u4f18\u6027\u4fdd\u8bc1\u7684\u6a21\u6001\u9009\u62e9\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u5404\u6a21\u6001\u8d21\u732e\u4e0d\u5747\u8861\u4e14\u6570\u636e\u4f9d\u8d56\u6027\u5f3a\uff0c\u96be\u4ee5\u786e\u5b9a\u54ea\u4e9b\u6a21\u6001\u771f\u6b63\u5177\u6709\u4fe1\u606f\u91cf\u4ee5\u53ca\u5176\u8d21\u732e\u7684\u53ef\u4fe1\u5ea6\u3002\u91cf\u5316\u6a21\u6001\u7ea7\u522b\u7684\u91cd\u8981\u6027\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684\u591a\u6a21\u6001\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faconformal Shapley intervals\u6846\u67b6\uff0c\u5c06Shapley\u503c\u4e0econformal inference\u7ed3\u5408\uff0c\u4e3a\u6bcf\u4e2a\u6a21\u6001\u6784\u5efa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u91cd\u8981\u6027\u533a\u95f4\u3002\u57fa\u4e8e\u8fd9\u4e9b\u533a\u95f4\uff0c\u8bbe\u8ba1\u6a21\u6001\u9009\u62e9\u7a0b\u5e8f\uff0c\u8be5\u7a0b\u5e8f\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u6027\u4fdd\u8bc1\uff1a\u5728\u7ed9\u5b9a\u89c2\u6d4b\u7279\u5f81\u6761\u4ef6\u4e0b\uff0c\u6240\u9009\u6a21\u6001\u5b50\u96c6\u7684\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u5b50\u96c6\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u4ec5\u4f9d\u8d56\u5c11\u91cf\u4fe1\u606f\u4e30\u5bcc\u7684\u6a21\u6001\u3002", "conclusion": "conformal Shapley intervals\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6a21\u6001\u91cd\u8981\u6027\u8bc4\u4f30\uff0c\u7ed3\u5408\u7406\u8bba\u4fdd\u8bc1\u7684\u6a21\u6001\u9009\u62e9\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u3001\u9ad8\u6548\u7684\u591a\u6a21\u6001\u5b66\u4e60\u3002"}}
{"id": "2602.01931", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.01931", "abs": "https://arxiv.org/abs/2602.01931", "authors": ["Jun-ichi Takeshita", "Kazuhiro Morita", "Tomomichi Suzuki"], "title": "Bootstrap-based estimation and inference for measurement precision under ISO 5725", "comment": null, "summary": "The ISO 5725 series frames interlaboratory precision through repeatability, between-laboratory, and reproducibility variances, yet practical guidance on deploying bootstrap methods within this one-way random-effects setting remains limited. We study resampling strategies tailored to ISO 5725 data and extend a bias-correction idea to obtain simple adjusted point estimators and confidence intervals for the variance components. Using extensive simulations that mirror realistic study sizes and variance ratios, we evaluate accuracy, stability, and coverage, and we contrast the resampling-based procedures with ANOVA-based estimators and common approximate intervals. The results yield a clear division of labor: adjusted within-laboratory resampling provides accurate and stable point estimation in small-to-moderate designs, whereas a two-stage strategy-resampling laboratories and then resampling within each-paired with bias-corrected and accelerated intervals offers the most reliable (near-nominal or conservative) confidence intervals. Performance degrades under extreme designs, such as very small samples or dominant between-laboratory variation, clarifying when additional caution is warranted. A case study from an ISO 5725-4 dataset illustrates how the recommended procedures behave in practice and how they compare with ANOVA and approximate methods. We conclude with concrete guidance for implementing resampling-based precision analysis in interlaboratory studies: use adjusted within-laboratory resampling for point estimation, and adopt the two-stage strategy with bias-corrected and accelerated intervals for interval estimation.", "AI": {"tldr": "\u7814\u7a76ISO 5725\u6807\u51c6\u4e0b\u5b9e\u9a8c\u5ba4\u95f4\u7cbe\u5ea6\u5206\u6790\u7684\u81ea\u52a9\u6cd5\u5e94\u7528\uff0c\u63d0\u51fa\u8c03\u6574\u540e\u7684\u70b9\u4f30\u8ba1\u548c\u7f6e\u4fe1\u533a\u95f4\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u6848\u4f8b\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "ISO 5725\u7cfb\u5217\u6807\u51c6\u867d\u7136\u5b9a\u4e49\u4e86\u5b9e\u9a8c\u5ba4\u95f4\u7cbe\u5ea6\u7684\u91cd\u590d\u6027\u3001\u5b9e\u9a8c\u5ba4\u95f4\u548c\u518d\u73b0\u6027\u65b9\u5dee\uff0c\u4f46\u5728\u5355\u56e0\u7d20\u968f\u673a\u6548\u5e94\u6a21\u578b\u4e2d\u5b9e\u9645\u5e94\u7528\u81ea\u52a9\u6cd5\u7684\u6307\u5bfc\u6709\u9650\u3002\u9700\u8981\u7814\u7a76\u9002\u5408ISO 5725\u6570\u636e\u7684\u91cd\u91c7\u6837\u7b56\u7565\u3002", "method": "1) \u7814\u7a76\u9488\u5bf9ISO 5725\u6570\u636e\u7684\u91cd\u91c7\u6837\u7b56\u7565\uff1b2) \u6269\u5c55\u504f\u5dee\u6821\u6b63\u601d\u60f3\uff0c\u83b7\u5f97\u8c03\u6574\u540e\u7684\u65b9\u5dee\u5206\u91cf\u70b9\u4f30\u8ba1\u548c\u7f6e\u4fe1\u533a\u95f4\uff1b3) \u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8986\u76d6\u7387\uff1b4) \u4e0eANOVA\u4f30\u8ba1\u5668\u548c\u5e38\u7528\u8fd1\u4f3c\u533a\u95f4\u5bf9\u6bd4\uff1b5) \u4f7f\u7528ISO 5725-4\u6570\u636e\u96c6\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "1) \u8c03\u6574\u540e\u7684\u5b9e\u9a8c\u5ba4\u5185\u91cd\u91c7\u6837\u5728\u5c0f\u5230\u4e2d\u7b49\u89c4\u6a21\u8bbe\u8ba1\u4e2d\u63d0\u4f9b\u51c6\u786e\u7a33\u5b9a\u7684\u70b9\u4f30\u8ba1\uff1b2) \u4e24\u9636\u6bb5\u7b56\u7565\uff08\u5148\u91cd\u91c7\u6837\u5b9e\u9a8c\u5ba4\uff0c\u518d\u91cd\u91c7\u6837\u6bcf\u4e2a\u5b9e\u9a8c\u5ba4\u5185\u90e8\uff09\u914d\u5408\u504f\u5dee\u6821\u6b63\u52a0\u901f\u533a\u95f4\u63d0\u4f9b\u6700\u53ef\u9760\u7684\u7f6e\u4fe1\u533a\u95f4\uff1b3) \u5728\u6781\u7aef\u8bbe\u8ba1\uff08\u6837\u672c\u91cf\u6781\u5c0f\u6216\u5b9e\u9a8c\u5ba4\u95f4\u53d8\u5f02\u5360\u4e3b\u5bfc\uff09\u4e0b\u6027\u80fd\u4e0b\u964d\uff1b4) \u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u63a8\u8350\u65b9\u6cd5\u5728\u5b9e\u9645\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u4e3a\u5b9e\u9a8c\u5ba4\u95f4\u7814\u7a76\u4e2d\u7684\u7cbe\u5ea6\u5206\u6790\u63d0\u4f9b\u5177\u4f53\u5b9e\u65bd\u6307\u5bfc\uff1a\u4f7f\u7528\u8c03\u6574\u540e\u7684\u5b9e\u9a8c\u5ba4\u5185\u91cd\u91c7\u6837\u8fdb\u884c\u70b9\u4f30\u8ba1\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\u914d\u5408\u504f\u5dee\u6821\u6b63\u52a0\u901f\u533a\u95f4\u8fdb\u884c\u533a\u95f4\u4f30\u8ba1\u3002"}}
{"id": "2602.01595", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.01595", "abs": "https://arxiv.org/abs/2602.01595", "authors": ["Chunrong Ai", "Wei Huang", "Zheng Zhang"], "title": "Data-Driven Uniform Inference for General Continuous Treatment Models via Minimum-Variance Weighting", "comment": null, "summary": "Ai et al. (2021) studied the estimation of a general dose-response function (GDRF) of a continuous treatment that includes the average dose-response function, the quantile dose-response function, and other expectiles of the dose-response distribution. They specified the GDRF as a parametric function of the treatment status only and proposed a weighted regression with the weighting function estimated using the maximum entropy approach. This paper specifies the GDRF as a nonparametric function of the treatment status, proposes a weighted local linear regression for estimating GDRF, and develops a bootstrap procedure for constructing the uniform confidence bands. We propose stable weights with minimum sample variance while eliminating the sample association between the treatment and the confounding variables. The proposed weights admit a closed-form expression, allowing them to be computed efficiently in the bootstrap sampling. Under certain conditions, we derive the uniform Bahadur representation for the proposed estimator of GDRF and establish the validity of the corresponding uniform confidence bands. A fully data-driven approach to choosing the undersmooth tuning parameters and a data-driven bias-control confidence band are included. A simulation study and an application demonstrate the usefulness of the proposed approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u53c2\u6570\u52a0\u6743\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\u6765\u4f30\u8ba1\u5e7f\u4e49\u5242\u91cf-\u54cd\u5e94\u51fd\u6570\uff0c\u5e76\u5f00\u53d1\u4e86\u6784\u5efa\u5747\u5300\u7f6e\u4fe1\u5e26\u7684bootstrap\u7a0b\u5e8f\uff0c\u6743\u91cd\u5177\u6709\u6700\u5c0f\u6837\u672c\u65b9\u5dee\u4e14\u80fd\u6d88\u9664\u5904\u7406\u4e0e\u6df7\u6742\u53d8\u91cf\u95f4\u7684\u5173\u8054\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u5e7f\u4e49\u5242\u91cf-\u54cd\u5e94\u51fd\u6570\uff08GDRF\uff09\u8bbe\u5b9a\u4e3a\u4ec5\u4f9d\u8d56\u4e8e\u5904\u7406\u72b6\u6001\u7684\u53c2\u6570\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u6700\u5927\u71b5\u65b9\u6cd5\u4f30\u8ba1\u6743\u91cd\u3002\u672c\u6587\u65e8\u5728\u6539\u8fdb\u8fd9\u4e00\u65b9\u6cd5\uff0c\u5c06GDRF\u8bbe\u5b9a\u4e3a\u975e\u53c2\u6570\u51fd\u6570\uff0c\u4ee5\u66f4\u7075\u6d3b\u5730\u6355\u6349\u5242\u91cf-\u54cd\u5e94\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u52a0\u6743\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u4f30\u8ba1GDRF\uff0c\u6743\u91cd\u5177\u6709\u6700\u5c0f\u6837\u672c\u65b9\u5dee\u4e14\u80fd\u6d88\u9664\u5904\u7406\u4e0e\u6df7\u6742\u53d8\u91cf\u95f4\u7684\u5173\u8054\uff0c\u6743\u91cd\u6709\u95ed\u5f0f\u89e3\u4fbf\u4e8ebootstrap\u8ba1\u7b97\u3002\u5f00\u53d1\u4e86bootstrap\u7a0b\u5e8f\u6784\u5efa\u5747\u5300\u7f6e\u4fe1\u5e26\uff0c\u5305\u542b\u6570\u636e\u9a71\u52a8\u7684\u6b20\u5e73\u6ed1\u8c03\u53c2\u65b9\u6cd5\u548c\u504f\u5dee\u63a7\u5236\u7f6e\u4fe1\u5e26\u3002", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u63a8\u5bfc\u4e86GDRF\u4f30\u8ba1\u91cf\u7684\u5747\u5300Bahadur\u8868\u793a\uff0c\u5efa\u7acb\u4e86\u76f8\u5e94\u5747\u5300\u7f6e\u4fe1\u5e26\u7684\u6709\u6548\u6027\u3002\u6a21\u62df\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u975e\u53c2\u6570\u52a0\u6743\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\u80fd\u6709\u6548\u4f30\u8ba1\u5e7f\u4e49\u5242\u91cf-\u54cd\u5e94\u51fd\u6570\uff0c\u6570\u636e\u9a71\u52a8\u7684\u7f6e\u4fe1\u5e26\u6784\u5efa\u65b9\u6cd5\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u4e3a\u5242\u91cf-\u54cd\u5e94\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u53ef\u9760\u7684\u7edf\u8ba1\u5de5\u5177\u3002"}}
{"id": "2602.00291", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.00291", "abs": "https://arxiv.org/abs/2602.00291", "authors": ["Matilda Pitt", "Robert J. B. Goudie"], "title": "A Bayesian Prevalence Incidence Cure model for estimating survival using Electronic Health Records with incomplete baseline diagnoses", "comment": "29 pages, 2 figures", "summary": "Retrospective cohorts can be extracted from Electronic Health Records (EHR) to study prevalence, time until disease or event occurrence and cure proportion in real world scenarios. However, EHR are collected for patient care rather than research, so typically have complexities, such as patients with missing baseline disease status. Prevalence-Incidence (PI) models, which use a two-component mixture model to account for this missing data, have been proposed. However, PI models are biased in settings in which some individuals will never experience the endpoint (they are 'cured'). To address this, we propose a Prevalence Incidence Cure (PIC) model, a 3 component mixture model that combines the PI model framework with a cure model. Our PIC model enables estimation of the prevalence, time-to-incidence, and the cure proportion, and allows for covariates to affect these. We adopt a Bayesian inference approach, and focus on the interpretability of the prior. We show in a simulation study that the PIC model has smaller bias than a PI model for the survival probability; and compare inference under vague, informative and misspecified priors. We illustrate our model using a dataset of 1964 patients undergoing treatment for Diabetic Macular Oedema, demonstrating improved fit under the PIC model.", "AI": {"tldr": "\u63d0\u51faPIC\u6a21\u578b\uff08Prevalence Incidence Cure model\uff09\uff0c\u7d50\u5408PI\u6a21\u578b\u8207\u6cbb\u7652\u6a21\u578b\uff0c\u7528\u65bc\u8655\u7406\u96fb\u5b50\u75c5\u6b77\u4e2d\u7f3a\u5931\u57fa\u7dda\u75be\u75c5\u72c0\u614b\u4e14\u5305\u542b\u6cbb\u7652\u500b\u9ad4\u7684\u60c5\u6cc1\u3002", "motivation": "\u96fb\u5b50\u75c5\u6b77\u6578\u64da\u5b58\u5728\u8907\u96dc\u6027\uff0c\u5982\u60a3\u8005\u57fa\u7dda\u75be\u75c5\u72c0\u614b\u7f3a\u5931\uff0c\u4e14\u90e8\u5206\u60a3\u8005\u53ef\u80fd\u6c38\u9060\u4e0d\u6703\u7d93\u6b77\u7d42\u9ede\u4e8b\u4ef6\uff08\u6cbb\u7652\uff09\u3002\u73fe\u6709\u7684PI\u6a21\u578b\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e09\u6210\u5206\u6df7\u5408\u6a21\u578bPIC\uff0c\u7d50\u5408PI\u6a21\u578b\u6846\u67b6\u8207\u6cbb\u7652\u6a21\u578b\uff0c\u63a1\u7528\u8c9d\u8449\u65af\u63a8\u65b7\u65b9\u6cd5\uff0c\u91cd\u9ede\u95dc\u6ce8\u5148\u9a57\u5206\u5e03\u7684\u53ef\u89e3\u91cb\u6027\u3002", "result": "\u6a21\u64ec\u7814\u7a76\u986f\u793aPIC\u6a21\u578b\u5c0d\u751f\u5b58\u6982\u7387\u7684\u504f\u5dee\u5c0f\u65bcPI\u6a21\u578b\uff1b\u5728\u7cd6\u5c3f\u75c5\u9ec3\u6591\u6c34\u816b\u60a3\u8005\u6578\u64da\u4e2d\uff0cPIC\u6a21\u578b\u986f\u793a\u51fa\u66f4\u597d\u7684\u64ec\u5408\u6548\u679c\u3002", "conclusion": "PIC\u6a21\u578b\u80fd\u5920\u540c\u6642\u4f30\u8a08\u60a3\u75c5\u7387\u3001\u767c\u75c5\u6642\u9593\u548c\u6cbb\u7652\u6bd4\u4f8b\uff0c\u4e26\u5141\u8a31\u5354\u8b8a\u91cf\u5f71\u97ff\u9019\u4e9b\u53c3\u6578\uff0c\u70ba\u8655\u7406\u96fb\u5b50\u75c5\u6b77\u4e2d\u7684\u8907\u96dc\u6578\u64da\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.00172", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00172", "abs": "https://arxiv.org/abs/2602.00172", "authors": ["Guillaume Braun", "Masaaki Imaizumi"], "title": "Neuron Block Dynamics for XOR Classification with Zero-Margin", "comment": "47 pages, 9 figures", "summary": "The ability of neural networks to learn useful features through stochastic gradient descent (SGD) is a cornerstone of their success. Most theoretical analyses focus on regression or on classification tasks with a positive margin, where worst-case gradient bounds suffice. In contrast, we study zero-margin nonlinear classification by analyzing the Gaussian XOR problem, where inputs are Gaussian and the XOR decision boundary determines labels. In this setting, a non-negligible fraction of data lies arbitrarily close to the boundary, breaking standard margin-based arguments. Building on Glasgow's (2024) analysis, we extend the study of training dynamics from discrete to Gaussian inputs and develop a framework for the dynamics of neuron blocks. We show that neurons cluster into four directions and that block-level signals evolve coherently, a phenomenon essential in the Gaussian setting where individual neuron signals vary significantly. Leveraging this block perspective, we analyze generalization without relying on margin assumptions, adopting an average-case view that distinguishes regions of reliable prediction from regions of persistent error. Numerical experiments confirm the predicted two-phase block dynamics and demonstrate their robustness beyond the Gaussian setting.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u96f6\u8fb9\u9645\u975e\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u6790\u9ad8\u65afXOR\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u795e\u7ecf\u5143\u5757\u52a8\u6001\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u5143\u805a\u7c7b\u4e3a\u56db\u4e2a\u65b9\u5411\u7684\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0d\u4f9d\u8d56\u8fb9\u9645\u5047\u8bbe\u7684\u6cdb\u5316\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u5206\u6790\u4e3b\u8981\u5173\u6ce8\u56de\u5f52\u6216\u5177\u6709\u6b63\u8fb9\u9645\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u800c\u96f6\u8fb9\u9645\u975e\u7ebf\u6027\u5206\u7c7b\uff08\u5982\u9ad8\u65afXOR\u95ee\u9898\uff09\u4e2d\uff0c\u6709\u76f8\u5f53\u6bd4\u4f8b\u6570\u636e\u9760\u8fd1\u51b3\u7b56\u8fb9\u754c\uff0c\u7834\u574f\u4e86\u6807\u51c6\u7684\u57fa\u4e8e\u8fb9\u9645\u7684\u8bba\u8bc1\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u57fa\u4e8eGlasgow (2024)\u7684\u5206\u6790\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u7814\u7a76\u4ece\u79bb\u6563\u8f93\u5165\u6269\u5c55\u5230\u9ad8\u65af\u8f93\u5165\uff0c\u5f00\u53d1\u4e86\u795e\u7ecf\u5143\u5757\u52a8\u6001\u6846\u67b6\uff0c\u5206\u6790\u795e\u7ecf\u5143\u5982\u4f55\u805a\u7c7b\u4e3a\u56db\u4e2a\u65b9\u5411\uff0c\u5e76\u91c7\u7528\u5e73\u5747\u60c5\u51b5\u89c6\u89d2\u533a\u5206\u53ef\u9760\u9884\u6d4b\u533a\u57df\u548c\u6301\u7eed\u8bef\u5dee\u533a\u57df\u3002", "result": "\u53d1\u73b0\u795e\u7ecf\u5143\u805a\u7c7b\u4e3a\u56db\u4e2a\u65b9\u5411\uff0c\u5757\u7ea7\u4fe1\u53f7\u6f14\u5316\u5177\u6709\u4e00\u81f4\u6027\uff0c\u8fd9\u5728\u4e2a\u4f53\u795e\u7ecf\u5143\u4fe1\u53f7\u53d8\u5316\u663e\u8457\u7684\u9ad8\u65af\u8bbe\u7f6e\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u4e24\u9636\u6bb5\u5757\u52a8\u6001\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u975e\u9ad8\u65af\u8bbe\u7f6e\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u96f6\u8fb9\u9645\u975e\u7ebf\u6027\u5206\u7c7b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u5143\u5757\u52a8\u6001\u89c6\u89d2\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u9ad8\u65afXOR\u95ee\u9898\u4e2d\u7684\u5b66\u4e60\u673a\u5236\uff0c\u4e3a\u4e0d\u4f9d\u8d56\u8fb9\u9645\u5047\u8bbe\u7684\u6cdb\u5316\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.00512", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2602.00512", "abs": "https://arxiv.org/abs/2602.00512", "authors": ["Xinyi Pei", "Minhyeok Kim", "Vinayak Rao"], "title": "Exact Gibbs sampling for stochastic differential equations with gradient drift and constant diffusion", "comment": "Main document: 18 pages, 4 figures. Supplementary material: 12 pages, 7 figures", "summary": "Stochastic differential equations (SDEs) are an important class of time-series models, used to describe stochastic systems evolving in continuous time. Simulating paths from these processes, particularly after conditioning on noisy observations of the latent path, remains a challenge. Existing methods often introduce bias through time-discretization, require involved rejection sampling or debiasing schemes or are restricted to a narrow family of diffusions. In this work, we propose an exact Markov chain Monte Carlo (MCMC) sampling algorithm that is applicable to a broad subset of all SDEs with unit diffusion coefficient; after suitable transformation, this includes an even larger class of multivariate SDEs and most 1-d SDEs. We develop a Gibbs sampling framework that allows exact MCMC for such diffusions, without any discretization error. We demonstrate how our MCMC methodology requires only fairly straightforward simulation steps. Our framework can be extended to include parameter simulation, and allows tools from the Gaussian process literature to be easily applied. We evaluate our method on synthetic and real datasets, demonstrating superior performance to particle MCMC approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5355\u4f4d\u6269\u6563\u7cfb\u6570SDE\u7684\u7cbe\u786eMCMC\u91c7\u6837\u7b97\u6cd5\uff0c\u65e0\u9700\u79bb\u6563\u5316\u8bef\u5dee\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdbSDE\u7c7b\u522b", "motivation": "\u73b0\u6709SDE\u8def\u5f84\u6a21\u62df\u65b9\u6cd5\u5b58\u5728\u504f\u5dee\u3001\u9700\u8981\u590d\u6742\u62d2\u7edd\u91c7\u6837\u6216\u4ec5\u9650\u4e8e\u7279\u5b9a\u6269\u6563\u7c7b\u578b\uff0c\u9700\u8981\u66f4\u901a\u7528\u4e14\u7cbe\u786e\u7684\u91c7\u6837\u65b9\u6cd5", "method": "\u5f00\u53d1\u4e86Gibbs\u91c7\u6837\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5355\u4f4d\u6269\u6563\u7cfb\u6570SDE\uff0c\u901a\u8fc7\u9002\u5f53\u53d8\u6362\u53ef\u6269\u5c55\u5230\u591a\u5143SDE\u548c\u5927\u591a\u6570\u4e00\u7ef4SDE\uff0c\u65e0\u9700\u79bb\u6563\u5316\u8bef\u5dee", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6027\u80fd\u4f18\u4e8e\u7c92\u5b50MCMC\u65b9\u6cd5\uff0c\u4ec5\u9700\u76f8\u5bf9\u7b80\u5355\u7684\u6a21\u62df\u6b65\u9aa4", "conclusion": "\u63d0\u51fa\u7684\u7cbe\u786eMCMC\u7b97\u6cd5\u4e3a\u5e7f\u6cdbSDE\u7c7b\u522b\u63d0\u4f9b\u4e86\u65e0\u504f\u5dee\u7684\u91c7\u6837\u6846\u67b6\uff0c\u53ef\u6269\u5c55\u5230\u53c2\u6570\u6a21\u62df\u5e76\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b\u5de5\u5177"}}
{"id": "2602.02398", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.02398", "abs": "https://arxiv.org/abs/2602.02398", "authors": ["Hyemin Lee", "Dohee Kim", "Banghee So", "Jae Youn Ahn"], "title": "Counting models with excessive zeros ensuring stochastic monotonicity", "comment": null, "summary": "Standard count models such as the Poisson and Negative Binomial models often fail to capture the large proportion of zero claims commonly observed in insurance data. To address such issue of excessive zeros, zero-inflated and hurdle models introduce additional parameters that explicitly account for excess zeros, thereby improving the joint representation of zero and positive claim outcomes. These models have further been extended with random effects to accommodate longitudinal dependence and unobserved heterogeneity. However, their consistency with fundamental probabilistic principles in insurance, particularly stochastic monotonicity, has not been formally examined. This paper provides a rigorous analysis showing that standard counting random-effect models for excessive zeros may violate this property, leading to inconsistencies in posterior credibility. We then propose new classes of counting random-effect models that both accommodate excessive zeros and ensure stochastic monotonicity, thereby providing fair and theoretically coherent credibility adjustments as claim histories evolve.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u4f20\u7edf\u96f6\u81a8\u80c0\u548c\u969c\u788d\u6a21\u578b\u5728\u4fdd\u9669\u7cbe\u7b97\u4e2d\u53ef\u80fd\u8fdd\u53cd\u968f\u673a\u5355\u8c03\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u968f\u673a\u6548\u5e94\u8ba1\u6570\u6a21\u578b\uff0c\u65e2\u80fd\u5904\u7406\u8fc7\u5ea6\u96f6\u503c\u53c8\u80fd\u4fdd\u8bc1\u968f\u673a\u5355\u8c03\u6027\u3002", "motivation": "\u4fdd\u9669\u6570\u636e\u4e2d\u5e38\u51fa\u73b0\u5927\u91cf\u96f6\u7d22\u8d54\uff0c\u4f20\u7edf\u8ba1\u6570\u6a21\u578b\uff08\u5982\u6cca\u677e\u548c\u8d1f\u4e8c\u9879\u5206\u5e03\uff09\u65e0\u6cd5\u5145\u5206\u5904\u7406\u8fd9\u79cd\u8fc7\u5ea6\u96f6\u503c\u95ee\u9898\u3002\u867d\u7136\u96f6\u81a8\u80c0\u548c\u969c\u788d\u6a21\u578b\u901a\u8fc7\u989d\u5916\u53c2\u6570\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u5230\u968f\u673a\u6548\u5e94\u6a21\u578b\u4ee5\u5904\u7406\u7eb5\u5411\u4f9d\u8d56\u6027\u548c\u672a\u89c2\u6d4b\u5f02\u8d28\u6027\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5728\u4fdd\u9669\u57fa\u672c\u6982\u7387\u539f\u5219\uff08\u7279\u522b\u662f\u968f\u673a\u5355\u8c03\u6027\uff09\u65b9\u9762\u7684\u4e00\u81f4\u6027\u5c1a\u672a\u5f97\u5230\u6b63\u5f0f\u68c0\u9a8c\u3002", "method": "\u9996\u5148\u5bf9\u6807\u51c6\u8ba1\u6570\u968f\u673a\u6548\u5e94\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u5206\u6790\uff0c\u8bc1\u660e\u5b83\u4eec\u53ef\u80fd\u8fdd\u53cd\u968f\u673a\u5355\u8c03\u6027\u3002\u7136\u540e\u63d0\u51fa\u65b0\u7684\u8ba1\u6570\u968f\u673a\u6548\u5e94\u6a21\u578b\u7c7b\u522b\uff0c\u8fd9\u4e9b\u6a21\u578b\u65e2\u80fd\u5bb9\u7eb3\u8fc7\u5ea6\u96f6\u503c\uff0c\u53c8\u80fd\u786e\u4fdd\u968f\u673a\u5355\u8c03\u6027\uff0c\u4ece\u800c\u63d0\u4f9b\u516c\u5e73\u4e14\u7406\u8bba\u4e0a\u4e00\u81f4\u7684\u4fe1\u5ea6\u8c03\u6574\u3002", "result": "\u5206\u6790\u8868\u660e\u4f20\u7edf\u96f6\u81a8\u80c0\u548c\u969c\u788d\u968f\u673a\u6548\u5e94\u6a21\u578b\u53ef\u80fd\u8fdd\u53cd\u968f\u673a\u5355\u8c03\u6027\uff0c\u5bfc\u81f4\u540e\u9a8c\u4fe1\u5ea6\u4e0d\u4e00\u81f4\u3002\u63d0\u51fa\u7684\u65b0\u6a21\u578b\u7c7b\u522b\u6210\u529f\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u786e\u4fdd\u4e86\u968f\u7740\u7d22\u8d54\u5386\u53f2\u6f14\u53d8\uff0c\u4fe1\u5ea6\u8c03\u6574\u7684\u516c\u5e73\u6027\u548c\u7406\u8bba\u4e00\u81f4\u6027\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86\u4fdd\u9669\u7cbe\u7b97\u4e2d\u968f\u673a\u6548\u5e94\u6a21\u578b\u4e0e\u57fa\u672c\u6982\u7387\u539f\u5219\u4e00\u81f4\u6027\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u65b0\u6a21\u578b\u4e3a\u5904\u7406\u4fdd\u9669\u6570\u636e\u4e2d\u7684\u8fc7\u5ea6\u96f6\u503c\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u53ef\u9760\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u4e86\u4fe1\u5ea6\u8c03\u6574\u7684\u516c\u5e73\u6027\u548c\u7406\u8bba\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.01993", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.01993", "abs": "https://arxiv.org/abs/2602.01993", "authors": ["Francesco Gaffi", "Nathaniel Josephs", "Lizhen Lin"], "title": "Exchangeable random permutations with an application to Bayesian graph matching", "comment": "41 pages, 4 figures", "summary": "We introduce a general Bayesian framework for graph matching grounded in a new theory of exchangeable random permutations. Leveraging the cycle representation of permutations and the literature on exchangeable random partitions, we define, characterize, and study the structural and predictive properties of these probabilistic objects. A novel sequential metaphor, the position-aware generalized Chinese restaurant process, provides a constructive foundation for this theory and supports practical algorithmic design. Exchangeable random permutations offer flexible priors for a wide range of inferential problems centered on permutations. As an application, we develop a Bayesian model for graph matching that integrates a correlated stochastic block model with our novel class of priors. The cycle structure of the matching is linked to latent node partitions that explain connectivity patterns, an assumption consistent with the homogeneity requirement underlying the graph matching task itself. Posterior inference is performed through a node-wise blocked Gibbs sampler directly enabled by the proposed sequential construction. To summarize posterior uncertainty, we introduce perSALSO, an adaptation of SALSO to the permutation domain that provides principled point estimation and interpretable posterior summaries. Together, these contributions establish a unified probabilistic framework for modeling, inference, and uncertainty quantification over permutations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u4ea4\u6362\u968f\u673a\u6392\u5217\u7684\u8d1d\u53f6\u65af\u56fe\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u5faa\u73af\u8868\u793a\u548c\u4f4d\u7f6e\u611f\u77e5\u5e7f\u4e49\u4e2d\u9910\u9986\u8fc7\u7a0b\u6784\u5efa\u7406\u8bba\uff0c\u5f00\u53d1\u8282\u70b9\u5206\u5757Gibbs\u91c7\u6837\u5668\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\uff0c\u5e76\u5f15\u5165perSALSO\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u4e3a\u56fe\u5339\u914d\u95ee\u9898\u5efa\u7acb\u7edf\u4e00\u7684\u6982\u7387\u6846\u67b6\uff0c\u5904\u7406\u6392\u5217\u76f8\u5173\u7684\u63a8\u65ad\u95ee\u9898\uff0c\u63d0\u4f9b\u7075\u6d3b\u7684\u6392\u5217\u5148\u9a8c\u5206\u5e03\uff0c\u5e76\u91cf\u5316\u5339\u914d\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u57fa\u4e8e\u53ef\u4ea4\u6362\u968f\u673a\u6392\u5217\u7406\u8bba\uff0c\u5229\u7528\u6392\u5217\u7684\u5faa\u73af\u8868\u793a\u548c\u53ef\u4ea4\u6362\u968f\u673a\u5206\u5272\u6587\u732e\uff0c\u63d0\u51fa\u4f4d\u7f6e\u611f\u77e5\u5e7f\u4e49\u4e2d\u9910\u9986\u8fc7\u7a0b\u4f5c\u4e3a\u6784\u9020\u57fa\u7840\u3002\u5c06\u56fe\u5339\u914d\u5efa\u6a21\u4e3a\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u7ed3\u5408\u76f8\u5173\u968f\u673a\u5757\u6a21\u578b\u548c\u65b0\u578b\u6392\u5217\u5148\u9a8c\uff0c\u901a\u8fc7\u8282\u70b9\u5206\u5757Gibbs\u91c7\u6837\u5668\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u4ea4\u6362\u968f\u673a\u6392\u5217\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u5b9e\u7528\u7684\u8d1d\u53f6\u65af\u56fe\u5339\u914d\u6a21\u578b\u548c\u63a8\u65ad\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e86perSALSO\u65b9\u6cd5\u7528\u4e8e\u6392\u5217\u57df\u7684\u70b9\u4f30\u8ba1\u548c\u540e\u9a8c\u603b\u7ed3\uff0c\u5b9e\u73b0\u4e86\u6392\u5217\u5efa\u6a21\u3001\u63a8\u65ad\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6392\u5217\u76f8\u5173\u7684\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6982\u7387\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u56fe\u5339\u914d\u4efb\u52a1\uff0c\u901a\u8fc7\u7406\u8bba\u521b\u65b0\u548c\u7b97\u6cd5\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684\u5efa\u6a21\u3001\u9ad8\u6548\u63a8\u65ad\u548c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002"}}
{"id": "2602.00836", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.00836", "abs": "https://arxiv.org/abs/2602.00836", "authors": ["Tanique Schaffe-Odeleye", "K\u014dsaku Takanashi", "Vishesh Karwa", "Edoardo M. Airoldi", "Kenichiro McAlinn"], "title": "Dynamic causal inference with time series data", "comment": null, "summary": "We generalize the potential outcome framework to time series with an intervention by defining causal effects on stochastic processes. Interventions in dynamic systems alter not only outcome levels but also evolutionary dynamics -- changing persistence and transition laws. Our framework treats potential outcomes as entire trajectories, enabling causal estimands, identification conditions, and estimators to be formulated directly on path space. The resulting Dynamic Average Treatment Effect (DATE) characterizes how causal effects evolve through time and reduces to the classical average treatment effect under one period of time. For observational data, we derive a dynamic inverse-probability weighting estimator that is unbiased under dynamic ignorability and positivity. When treated units are scarce, we show that conditional mean trajectories underlying the DATE admit a linear state-space representation, yielding a dynamic linear model implementation. Simulations demonstrate that modeling time as intrinsic to the causal mechanism exposes dynamic effects that static methods systematically misestimate. An empirical study of COVID-19 lockdowns illustrates the framework's practical value for estimating and decomposing treatment effects.", "AI": {"tldr": "\u5c06\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u63a8\u5e7f\u5230\u65f6\u5e8f\u5e72\u9884\uff0c\u5b9a\u4e49\u968f\u673a\u8fc7\u7a0b\u4e0a\u7684\u56e0\u679c\u6548\u5e94\uff0c\u63d0\u51fa\u52a8\u6001\u5e73\u5747\u5904\u7406\u6548\u5e94(DATE)\u53ca\u5176\u4f30\u8ba1\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u6216\u622a\u9762\u6570\u636e\uff0c\u4f46\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u5e72\u9884\u4e0d\u4ec5\u6539\u53d8\u7ed3\u679c\u6c34\u5e73\uff0c\u8fd8\u6539\u53d8\u6f14\u5316\u52a8\u6001\uff08\u6301\u4e45\u6027\u548c\u8f6c\u79fb\u89c4\u5f8b\uff09\u3002\u9700\u8981\u5c06\u56e0\u679c\u63a8\u65ad\u6269\u5c55\u5230\u65f6\u95f4\u5e8f\u5217\uff0c\u4ee5\u6355\u6349\u968f\u65f6\u95f4\u6f14\u5316\u7684\u56e0\u679c\u6548\u5e94\u3002", "method": "\u5c06\u6f5c\u5728\u7ed3\u679c\u5b9a\u4e49\u4e3a\u6574\u4e2a\u8f68\u8ff9\uff0c\u5728\u8def\u5f84\u7a7a\u95f4\u4e0a\u76f4\u63a5\u5b9a\u4e49\u56e0\u679c\u4f30\u8ba1\u91cf\u3001\u8bc6\u522b\u6761\u4ef6\u548c\u4f30\u8ba1\u5668\u3002\u63d0\u51fa\u52a8\u6001\u5e73\u5747\u5904\u7406\u6548\u5e94(DATE)\uff0c\u63a8\u5bfc\u52a8\u6001\u9006\u6982\u7387\u52a0\u6743\u4f30\u8ba1\u5668\uff0c\u5728\u53d7\u5904\u7406\u5355\u5143\u7a00\u7f3a\u65f6\u4f7f\u7528\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u5b9e\u73b0\u52a8\u6001\u7ebf\u6027\u6a21\u578b\u3002", "result": "DATE\u80fd\u8868\u5f81\u56e0\u679c\u6548\u5e94\u968f\u65f6\u95f4\u6f14\u5316\uff0c\u5728\u5355\u671f\u65f6\u7b80\u5316\u4e3a\u7ecf\u5178\u5e73\u5747\u5904\u7406\u6548\u5e94\u3002\u52a8\u6001\u9006\u6982\u7387\u52a0\u6743\u4f30\u8ba1\u5668\u5728\u52a8\u6001\u53ef\u5ffd\u7565\u6027\u548c\u6b63\u6027\u6761\u4ef6\u4e0b\u662f\u65e0\u504f\u7684\u3002\u6a21\u62df\u663e\u793a\u5efa\u6a21\u65f6\u95f4\u4f5c\u4e3a\u56e0\u679c\u673a\u5236\u5185\u5728\u90e8\u5206\u80fd\u66b4\u9732\u9759\u6001\u65b9\u6cd5\u7cfb\u7edf\u8bef\u4f30\u7684\u52a8\u6001\u6548\u5e94\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65f6\u95f4\u5e8f\u5217\u5e72\u9884\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u80fd\u4f30\u8ba1\u548c\u5206\u89e3\u968f\u65f6\u95f4\u6f14\u5316\u7684\u5904\u7406\u6548\u5e94\uff0c\u5728COVID-19\u5c01\u9501\u7b49\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00387", "categories": ["stat.ML", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.00387", "abs": "https://arxiv.org/abs/2602.00387", "authors": ["Mame Diarra Toure", "David A. Stephens"], "title": "Singular Bayesian Neural Networks", "comment": "8 pages Main text, 53 pages Appendix, 20 figures", "summary": "Bayesian neural networks promise calibrated uncertainty but require $O(mn)$ parameters for standard mean-field Gaussian posteriors. We argue this cost is often unnecessary, particularly when weight matrices exhibit fast singular value decay. By parameterizing weights as $W = AB^{\\top}$ with $A \\in \\mathbb{R}^{m \\times r}$, $B \\in \\mathbb{R}^{n \\times r}$, we induce a posterior that is singular with respect to the Lebesgue measure, concentrating on the rank-$r$ manifold. This singularity captures structured weight correlations through shared latent factors, geometrically distinct from mean-field's independence assumption. We derive PAC-Bayes generalization bounds whose complexity term scales as $\\sqrt{r(m+n)}$ instead of $\\sqrt{m n}$, and prove loss bounds that decompose the error into optimization and rank-induced bias using the Eckart-Young-Mirsky theorem. We further adapt recent Gaussian complexity bounds for low-rank deterministic networks to Bayesian predictive means. Empirically, across MLPs, LSTMs, and Transformers on standard benchmarks, our method achieves predictive performance competitive with 5-member Deep Ensembles while using up to $15\\times$ fewer parameters. Furthermore, it substantially improves OOD detection and often improves calibration relative to mean-field and perturbation baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f4e\u79e9\u53c2\u6570\u5316\u7684\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u6743\u91cd\u77e9\u9635\u5206\u89e3W=AB^T\u51cf\u5c11\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u80fd\u529b", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u9700\u8981O(mn)\u53c2\u6570\uff0c\u4f46\u8bb8\u591a\u6743\u91cd\u77e9\u9635\u5177\u6709\u5feb\u901f\u5947\u5f02\u503c\u8870\u51cf\u7279\u6027\uff0c\u8fd9\u79cd\u53c2\u6570\u6548\u7387\u4e0d\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u51cf\u5c11\u53c2\u6570\u53c8\u80fd\u4fdd\u6301\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u7684\u65b9\u6cd5", "method": "\u5c06\u6743\u91cd\u53c2\u6570\u5316\u4e3aW=AB^T\u7684\u4f4e\u79e9\u5f62\u5f0f\uff0c\u5176\u4e2dA\u2208\u211d^{m\u00d7r}, B\u2208\u211d^{n\u00d7r}\uff0c\u8bf1\u5bfc\u540e\u9a8c\u96c6\u4e2d\u5728\u79e9r\u6d41\u5f62\u4e0a\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u56e0\u5b50\u6355\u83b7\u7ed3\u6784\u5316\u6743\u91cd\u76f8\u5173\u6027", "result": "\u5728MLP\u3001LSTM\u548cTransformer\u7b49\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u6bd45\u6210\u5458\u6df1\u5ea6\u96c6\u6210\u5c1115\u500d\u7684\u53c2\u6570\uff0c\u8fbe\u5230\u7ade\u4e89\u6027\u9884\u6d4b\u6027\u80fd\u3002\u663e\u8457\u6539\u5584\u4e86OOD\u68c0\u6d4b\uff0c\u901a\u5e38\u6bd4\u5747\u503c\u573a\u548c\u6270\u52a8\u57fa\u7ebf\u6709\u66f4\u597d\u7684\u6821\u51c6", "conclusion": "\u4f4e\u79e9\u53c2\u6570\u5316\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u5229\u7528\u6743\u91cd\u77e9\u9635\u7684\u5947\u5f02\u503c\u8870\u51cf\u7279\u6027\uff0c\u5728\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u80fd\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00878", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2602.00878", "abs": "https://arxiv.org/abs/2602.00878", "authors": ["Beatrice Franzolini", "Francesco Gaffi"], "title": "Complexity bounds for Dirichlet process slice samplers", "comment": null, "summary": "Slice sampling is a standard Monte Carlo technique for Dirichlet process (DP)-based models, widely used in posterior simulation. However, formal assessments of the scalability of posterior slice samplers have remained largely unexplored, primarily because the computational cost of a slice-sampling iteration is random and potentially unbounded. In this work, we obtain high-probability bounds on the computational complexity of DP slice samplers. Our main results show that, uniformly across posterior cluster-growth regimes, the overhead induced by slice variables, relatively to the number of clusters supported by the posterior, is $O_{\\mathbb P}(\\log n)$. As a consequence, even in worst-case configurations, superlinear blow-ups in per-iteration computational cost occur with vanishing probability. Our analysis applies broadly to DP-based models without any likelihood-specific assumptions, still providing complexity guarantees for posterior sampling on arbitrary datasets. These results establish a theoretical foundation for assessing the practical scalability of slice sampling in DP-based models.", "AI": {"tldr": "\u672c\u6587\u5bf9\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\uff08DP\uff09\u6a21\u578b\u4e2d\u7684\u5207\u7247\u91c7\u6837\u7b97\u6cd5\u8fdb\u884c\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5207\u7247\u53d8\u91cf\u7684\u989d\u5916\u5f00\u9500\u76f8\u5bf9\u4e8e\u540e\u9a8c\u7c07\u6570\u91cf\u4e3aO(log n)\uff0c\u5373\u4f7f\u5728\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u6bcf\u6b21\u8fed\u4ee3\u51fa\u73b0\u8d85\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\u7684\u6982\u7387\u4e5f\u8d8b\u4e8e\u96f6\u3002", "motivation": "\u5207\u7247\u91c7\u6837\u662fDP\u6a21\u578b\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6807\u51c6\u8499\u7279\u5361\u6d1b\u6280\u672f\uff0c\u4f46\u5bf9\u5176\u53ef\u6269\u5c55\u6027\u7684\u6b63\u5f0f\u8bc4\u4f30\u4e00\u76f4\u7f3a\u4e4f\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u5207\u7247\u91c7\u6837\u6bcf\u6b21\u8fed\u4ee3\u7684\u8ba1\u7b97\u6210\u672c\u662f\u968f\u673a\u7684\u4e14\u53ef\u80fd\u65e0\u754c\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u83b7\u5f97\u4e86DP\u5207\u7247\u91c7\u6837\u5668\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u9ad8\u6982\u7387\u754c\u9650\uff0c\u5206\u6790\u4e86\u5207\u7247\u53d8\u91cf\u76f8\u5bf9\u4e8e\u540e\u9a8c\u7c07\u6570\u91cf\u7684\u989d\u5916\u5f00\u9500\uff0c\u8bc1\u660e\u4e86\u5747\u5300\u8de8\u8d8a\u540e\u9a8c\u7c07\u589e\u957f\u673a\u5236\uff0c\u8be5\u5f00\u9500\u4e3aO(log n)\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u8868\u660e\uff0c\u5207\u7247\u53d8\u91cf\u7684\u989d\u5916\u5f00\u9500\u76f8\u5bf9\u4e8e\u540e\u9a8c\u652f\u6301\u7684\u7c07\u6570\u91cf\u4e3aO(log n)\uff0c\u5373\u4f7f\u5728\u6700\u574f\u914d\u7f6e\u4e0b\uff0c\u6bcf\u6b21\u8fed\u4ee3\u51fa\u73b0\u8d85\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\u7684\u6982\u7387\u4e5f\u8d8b\u4e8e\u96f6\u3002\u8be5\u5206\u6790\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684DP\u6a21\u578b\uff0c\u65e0\u9700\u7279\u5b9a\u4f3c\u7136\u5047\u8bbe\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u8bc4\u4f30DP\u6a21\u578b\u4e2d\u5207\u7247\u91c7\u6837\u7684\u5b9e\u9645\u53ef\u6269\u5c55\u6027\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5207\u7247\u91c7\u6837\u5728DP\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2602.02216", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.02216", "abs": "https://arxiv.org/abs/2602.02216", "authors": ["Magid Sabbagh", "David A. Stephens"], "title": "Posterior Uncertainty for Targeted Parameters in Bayesian Bootstrap Procedures", "comment": "20 pages", "summary": "We propose a general method to carry out a valid Bayesian analysis of a finite-dimensional `targeted' parameter in the presence of a finite-dimensional nuisance parameter. We apply our methods to causal inference based on estimating equations. While much of the literature in Bayesian causal inference has relied on the conventional 'likelihood times prior' framework, a recently proposed method, the 'Linked Bayesian Bootstrap', deviated from this classical setting to obtain valid Bayesian inference using the Dirichlet process and the Bayesian bootstrap. These methods rely on an adjustment based on the propensity score and explain how to handle the uncertainty concerning it when studying the posterior distribution of a treatment effect. We examine theoretically the asymptotic properties of the posterior distribution obtained and show that our proposed method, a generalized version of the 'Linked Bayesian Bootstrap', enjoys desirable frequentist properties. In addition, we show that the credible intervals have asymptotically the correct coverage properties. We discuss the applications of our method to mis-specified and singly-robust models in causal inference.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u6709\u9650\u7ef4\u76ee\u6807\u53c2\u6570\u5728\u5b58\u5728\u6709\u9650\u7ef4\u5e72\u6270\u53c2\u6570\u65f6\u7684\u6709\u6548\u8d1d\u53f6\u65af\u5206\u6790\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u57fa\u4e8e\u4f30\u8ba1\u65b9\u7a0b\u7684\u56e0\u679c\u63a8\u65ad\uff0c\u662f\"\u94fe\u63a5\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\"\u7684\u63a8\u5e7f\u7248\u672c\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u56e0\u679c\u63a8\u65ad\u4f9d\u8d56\"\u4f3c\u7136\u00d7\u5148\u9a8c\"\u6846\u67b6\uff0c\u4f46\"\u94fe\u63a5\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\"\u504f\u79bb\u8fd9\u4e00\u7ecf\u5178\u8bbe\u7f6e\uff0c\u4f7f\u7528\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\u548c\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\u83b7\u5f97\u6709\u6548\u8d1d\u53f6\u65af\u63a8\u65ad\u3002\u9700\u8981\u5904\u7406\u503e\u5411\u5f97\u5206\u8c03\u6574\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u786e\u4fdd\u540e\u9a8c\u5206\u5e03\u5177\u6709\u826f\u597d\u7684\u9891\u7387\u6027\u8d28\u3002", "method": "\u63d0\u51fa\"\u94fe\u63a5\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\"\u7684\u63a8\u5e7f\u7248\u672c\uff0c\u7528\u4e8e\u5904\u7406\u6709\u9650\u7ef4\u76ee\u6807\u53c2\u6570\u548c\u5e72\u6270\u53c2\u6570\u7684\u8d1d\u53f6\u65af\u5206\u6790\u3002\u65b9\u6cd5\u57fa\u4e8e\u4f30\u8ba1\u65b9\u7a0b\uff0c\u901a\u8fc7\u503e\u5411\u5f97\u5206\u8c03\u6574\u5904\u7406\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\u548c\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\u6846\u67b6\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u7684\u540e\u9a8c\u5206\u5e03\u5177\u6709\u7406\u60f3\u7684\u9891\u7387\u6027\u8d28\uff0c\u7f6e\u4fe1\u533a\u95f4\u5177\u6709\u6e10\u8fd1\u6b63\u786e\u7684\u8986\u76d6\u6027\u8d28\u3002\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u8bef\u8bbe\u6a21\u578b\u548c\u5355\u7a33\u5065\u6a21\u578b\u7684\u56e0\u679c\u63a8\u65ad\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e7f\u4e49\"\u94fe\u63a5\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\"\u4e3a\u5b58\u5728\u5e72\u6270\u53c2\u6570\u65f6\u7684\u76ee\u6807\u53c2\u6570\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8d1d\u53f6\u65af\u5206\u6790\u6846\u67b6\uff0c\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u826f\u597d\u9891\u7387\u6027\u8d28\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2602.00903", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.00903", "abs": "https://arxiv.org/abs/2602.00903", "authors": ["Thomas Muehlenst\u00e4dt", "Marius Bause"], "title": "A Graph-based Framework for Coverage Analysis in Autonomous Driving", "comment": null, "summary": "Coverage analysis is essential for validating the safety of autonomous driving systems, yet existing approaches typically assess coverage factors individually or in limited combinations, struggling to capture the complex interactions inherent in traffic scenes. This paper proposes a graph-based framework for coverage analysis that represents traffic scenes as hierarchical graphs, combining map topology with actor relationships. The framework introduces a two-phase graph construction algorithm that systematically captures spatial relationships between traffic participants, including leading, following, neighboring, and opposing configurations. Two complementary coverage analysis methods are presented. First, a sub-graph isomorphism approach matches traffic scenes against a set of manually defined archetype graphs representing common driving scenarios. Second, a graph embedding approach utilizes Graph Isomorphism Networks with Edge features (GINE) trained via self-supervised contrastive learning to project traffic scenes into a vector space, enabling similarity-based coverage assessment. The framework is validated on both real-world data from the Argoverse 2.0 dataset and synthetic data from the CARLA simulator. The subgraph isomorphism method is used to calculate node coverage percentages using predefined archetypes, while the embedding approach reveals meaningful structure in the latent space suitable for clustering and anomaly detection. The proposed approach offers significant advantages over traditional methods by scaling efficiently to diverse traffic scenarios without requiring scenario-specific handling, and by naturally accommodating varying numbers of actors in a scene.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u8986\u76d6\u5206\u6790\u6846\u67b6\uff0c\u5c06\u4ea4\u901a\u573a\u666f\u8868\u793a\u4e3a\u5206\u5c42\u56fe\uff0c\u7ed3\u5408\u5730\u56fe\u62d3\u6251\u548c\u53c2\u4e0e\u8005\u5173\u7cfb\uff0c\u901a\u8fc7\u5b50\u56fe\u540c\u6784\u548c\u56fe\u5d4c\u5165\u4e24\u79cd\u65b9\u6cd5\u8bc4\u4f30\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u8986\u76d6\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u5355\u72ec\u6216\u6709\u9650\u7ec4\u5408\u8bc4\u4f30\u8986\u76d6\u56e0\u7d20\uff0c\u96be\u4ee5\u6355\u6349\u4ea4\u901a\u573a\u666f\u4e2d\u590d\u6742\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u6846\u67b6\uff0c\u5c06\u4ea4\u901a\u573a\u666f\u8868\u793a\u4e3a\u5206\u5c42\u56fe\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u56fe\u6784\u5efa\u7b97\u6cd5\u7cfb\u7edf\u6355\u6349\u4ea4\u901a\u53c2\u4e0e\u8005\u7a7a\u95f4\u5173\u7cfb\u3002\u63d0\u4f9b\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1\uff09\u5b50\u56fe\u540c\u6784\u5339\u914d\u9884\u5b9a\u4e49\u539f\u578b\u56fe\uff1b2\uff09\u4f7f\u7528\u5e26\u8fb9\u7279\u5f81\u7684\u56fe\u540c\u6784\u7f51\u7edc\uff08GINE\uff09\u901a\u8fc7\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u56fe\u5d4c\u5165\u3002", "result": "\u5728Argoverse 2.0\u771f\u5b9e\u6570\u636e\u548cCARLA\u5408\u6210\u6570\u636e\u4e0a\u9a8c\u8bc1\u3002\u5b50\u56fe\u540c\u6784\u65b9\u6cd5\u80fd\u8ba1\u7b97\u8282\u70b9\u8986\u76d6\u767e\u5206\u6bd4\uff0c\u5d4c\u5165\u65b9\u6cd5\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u663e\u793a\u6709\u610f\u4e49\u7684\u805a\u7c7b\u7ed3\u6784\uff0c\u9002\u5408\u5f02\u5e38\u68c0\u6d4b\u3002\u65b9\u6cd5\u80fd\u9ad8\u6548\u6269\u5c55\u5230\u591a\u6837\u4ea4\u901a\u573a\u666f\uff0c\u65e0\u9700\u573a\u666f\u7279\u5b9a\u5904\u7406\uff0c\u81ea\u7136\u9002\u5e94\u4e0d\u540c\u53c2\u4e0e\u8005\u6570\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u56fe\u7684\u8986\u76d6\u5206\u6790\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u7cfb\u7edf\u6355\u6349\u4ea4\u901a\u573a\u666f\u590d\u6742\u4ea4\u4e92\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u6027\u9a8c\u8bc1\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8986\u76d6\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2602.00399", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00399", "abs": "https://arxiv.org/abs/2602.00399", "authors": ["Armando Alves Neto"], "title": "Reinforcement Learning for Control Systems with Time Delays: A Comprehensive Survey", "comment": "30 pages", "summary": "In the last decade, Reinforcement Learning (RL) has achieved remarkable success in the control and decision-making of complex dynamical systems. However, most RL algorithms rely on the Markov Decision Process assumption, which is violated in practical cyber-physical systems affected by sensing delays, actuation latencies, and communication constraints. Such time delays introduce memory effects that can significantly degrade performance and compromise stability, particularly in networked and multi-agent environments. This paper presents a comprehensive survey of RL methods designed to address time delays in control systems. We first formalize the main classes of delays and analyze their impact on the Markov property. We then systematically categorize existing approaches into five major families: state augmentation and history-based representations, recurrent policies with learned memory, predictor-based and model-aware methods, robust and domain-randomized training strategies, and safe RL frameworks with explicit constraint handling. For each family, we discuss underlying principles, practical advantages, and inherent limitations. A comparative analysis highlights key trade-offs among these approaches and provides practical guidelines for selecting suitable methods under different delay characteristics and safety requirements. Finally, we identify open challenges and promising research directions, including stability certification, large-delay learning, multi-agent communication co-design, and standardized benchmarking. This survey aims to serve as a unified reference for researchers and practitioners developing reliable RL-based controllers in delay-affected cyber-physical systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u5173\u4e8e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5904\u7406\u63a7\u5236\u7cfb\u7edf\u65f6\u5ef6\u95ee\u9898\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u65f6\u5ef6\u5bf9\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u5e76\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u4e94\u5927\u7c7b\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "motivation": "\u5b9e\u9645\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4f20\u611f\u5ef6\u8fdf\u3001\u6267\u884c\u5ef6\u8fdf\u548c\u901a\u4fe1\u7ea6\u675f\u4f1a\u8fdd\u53cd\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5047\u8bbe\uff0c\u8fd9\u4e9b\u65f6\u5ef6\u5f15\u5165\u7684\u8bb0\u5fc6\u6548\u5e94\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\u5e76\u5371\u53ca\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u5316\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u4e3b\u8981\u65f6\u5ef6\u7c7b\u522b\u5e76\u5206\u6790\u5176\u5bf9\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u7136\u540e\u7cfb\u7edf\u5730\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u4e94\u5927\u7c7b\uff1a\u72b6\u6001\u589e\u5f3a\u548c\u5386\u53f2\u8868\u793a\u65b9\u6cd5\u3001\u5177\u6709\u5b66\u4e60\u8bb0\u5fc6\u7684\u5faa\u73af\u7b56\u7565\u3001\u57fa\u4e8e\u9884\u6d4b\u5668\u548c\u6a21\u578b\u611f\u77e5\u7684\u65b9\u6cd5\u3001\u9c81\u68d2\u548c\u57df\u968f\u673a\u5316\u8bad\u7ec3\u7b56\u7565\u3001\u4ee5\u53ca\u5177\u6709\u663e\u5f0f\u7ea6\u675f\u5904\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u5e76\u4e3a\u4e0d\u540c\u65f6\u5ef6\u7279\u6027\u548c\u5b89\u5168\u8981\u6c42\u4e0b\u7684\u65b9\u6cd5\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002\u540c\u65f6\u8bc6\u522b\u4e86\u7a33\u5b9a\u6027\u8ba4\u8bc1\u3001\u5927\u65f6\u5ef6\u5b66\u4e60\u3001\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u534f\u540c\u8bbe\u8ba1\u548c\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u7b49\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u65e8\u5728\u4e3a\u5728\u53d7\u65f6\u5ef6\u5f71\u54cd\u7684\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u5f00\u53d1\u53ef\u9760\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u7684\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u7edf\u4e00\u53c2\u8003\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.01770", "categories": ["stat.CO"], "pdf": "https://arxiv.org/pdf/2602.01770", "abs": "https://arxiv.org/abs/2602.01770", "authors": ["Xuefei Cao", "Shijia Wang", "Yongdao Zhou"], "title": "A multifidelity approximate Bayesian computation with pre-filtering", "comment": null, "summary": "Approximate Bayesian Computation (ABC) methods often require extensive simulations, resulting in high computational costs. This paper focuses on multifidelity simulation models and proposes a pre-filtering hierarchical importance sampling algorithm. Under mild assumptions, we theoretically prove that the proposed algorithm satisfies posterior concentration properties, characterize the error upper bound and the relationship between algorithmic efficiency and pre-filtering criteria. Additionally, we provide a practical strategy to assess the suitability of multifidelity models for the proposed method. Finally, we develop a multifidelity ABC sequential Monte Carlo with adaptive pre-filtering strategy. Numerical experiments are used to demonstrate the effectiveness of the proposed approach. We develop an R package that is available at https://github.com/caofff/MAPS", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4fdd\u771f\u5ea6\u6a21\u62df\u6a21\u578b\u7684\u9884\u8fc7\u6ee4\u5206\u5c42\u91cd\u8981\u6027\u91c7\u6837\u7b97\u6cd5\uff0c\u7528\u4e8e\u52a0\u901f\u8fd1\u4f3c\u8d1d\u53f6\u65af\u8ba1\u7b97\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u9884\u8fc7\u6ee4\u7b56\u7565\u7684\u591a\u4fdd\u771f\u5ea6ABC\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfABC\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\u8ba1\u7b97\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u591a\u4fdd\u771f\u5ea6\u6a21\u62df\u6a21\u578b\u63d0\u4f9b\u4e86\u4e0d\u540c\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u7684\u6a21\u62df\u9009\u9879\uff0c\u4f46\u5982\u4f55\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u6765\u52a0\u901fABC\u8ba1\u7b97\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u8fc7\u6ee4\u5206\u5c42\u91cd\u8981\u6027\u91c7\u6837\u7b97\u6cd5\uff0c\u5229\u7528\u591a\u4fdd\u771f\u5ea6\u6a21\u578b\u8fdb\u884c\u9884\u7b5b\u9009\u3002\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u540e\u9a8c\u96c6\u4e2d\u6027\u8d28\uff0c\u7ed9\u51fa\u4e86\u8bef\u5dee\u4e0a\u754c\u548c\u7b97\u6cd5\u6548\u7387\u4e0e\u9884\u8fc7\u6ee4\u51c6\u5219\u7684\u5173\u7cfb\u3002\u8fd8\u63d0\u4f9b\u4e86\u8bc4\u4f30\u591a\u4fdd\u771f\u5ea6\u6a21\u578b\u9002\u7528\u6027\u7684\u5b9e\u7528\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u9884\u8fc7\u6ee4\u7684\u591a\u4fdd\u771f\u5ea6ABC\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5f00\u53d1\u4e86\u76f8\u5e94\u7684R\u8f6f\u4ef6\u5305\uff08MAPS\uff09\uff0c\u5df2\u5728GitHub\u4e0a\u5f00\u6e90\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u4fdd\u771f\u5ea6\u9884\u8fc7\u6ee4\u65b9\u6cd5\u80fd\u6709\u6548\u52a0\u901fABC\u8ba1\u7b97\uff0c\u5728\u7406\u8bba\u4e0a\u6709\u826f\u597d\u6027\u8d28\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u4e3a\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u8d1d\u53f6\u65af\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01228", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01228", "abs": "https://arxiv.org/abs/2602.01228", "authors": ["Siddhartha Chakraborty", "Asok K. Nanda", "Narayanaswamy Balakrishnan"], "title": "Estimation of Tsallis entropy and its applications to goodness-of-fit tests", "comment": "21 pages, 4 figures", "summary": "In this paper, we consider the problem of estimating Tsallis entropy from a given data set. We propose four different estimators for Tsallis entropy measure based on higher-order sample spacings, and then discuss estimation of Tsallis divergence measure. We compare the performance of the proposed estimators by means of bias and mean squared error and also examine their robustness to outliers. Next, we propose a spacings-based estimator for Tsallis entropy under progressive type-II censoring and study its performance using Monte Carlo simulations. Another estimator for Tsallis entropy is proposed using quantile function and its consistency and asymptotic normality are studied, and its performance is evaluated through Monte Carlo simulations. Goodness-of-fit tests for normal and exponential distributions as applications are developed using Tsallis divergence measure. The performance of the proposed tests are then compared with some known tests using simulations and it is shown that the proposed tests perform very well. Also, an exponentiality test under progressive type-II censoring is proposed, its performance is compared with existing entropy-based tests using simulation. It is observed that the proposed test performs well. Finally, some real data sets are analysed for illustrative purposes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u9ad8\u9636\u6837\u672c\u95f4\u8ddd\u7684Tsallis\u71b5\u4f30\u8ba1\u5668\uff0c\u5305\u62ec\u6e10\u8fdbII\u578b\u622a\u5c3e\u4e0b\u7684\u4f30\u8ba1\u5668\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eTsallis\u6563\u5ea6\u7684\u6b63\u6001\u548c\u6307\u6570\u5206\u5e03\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u3002", "motivation": "\u9700\u8981\u4ece\u6570\u636e\u96c6\u4e2d\u4f30\u8ba1Tsallis\u71b5\uff0c\u5e76\u5f00\u53d1\u76f8\u5173\u7684\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u5f02\u5e38\u503c\u548c\u622a\u5c3e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u57fa\u4e8e\u9ad8\u9636\u6837\u672c\u95f4\u8ddd\u7684Tsallis\u71b5\u4f30\u8ba1\u5668\uff0c\u5305\u62ec\u6e10\u8fdbII\u578b\u622a\u5c3e\u4e0b\u7684\u95f4\u8ddd\u4f30\u8ba1\u5668\u548c\u57fa\u4e8e\u5206\u4f4d\u6570\u51fd\u6570\u7684\u4f30\u8ba1\u5668\uff0c\u5e76\u5229\u7528Tsallis\u6563\u5ea6\u5f00\u53d1\u4e86\u6b63\u6001\u548c\u6307\u6570\u5206\u5e03\u7684\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u3002", "result": "\u901a\u8fc7\u504f\u5dee\u548c\u5747\u65b9\u8bef\u5dee\u6bd4\u8f83\uff0c\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u8868\u73b0\u826f\u597d\u4e14\u5bf9\u5f02\u5e38\u503c\u5177\u6709\u9c81\u68d2\u6027\u3002\u57fa\u4e8eTsallis\u6563\u5ea6\u7684\u68c0\u9a8c\u5728\u6a21\u62df\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u6570\u636e\u5206\u6790\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684Tsallis\u71b5\u4f30\u8ba1\u5668\u548c\u57fa\u4e8eTsallis\u6563\u5ea6\u7684\u68c0\u9a8c\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u7edf\u8ba1\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2602.00413", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00413", "abs": "https://arxiv.org/abs/2602.00413", "authors": ["Yidong Ouyang", "Liyan Xie", "Hongyuan Zha", "Guang Cheng"], "title": "Alignment of Diffusion Model and Flow Matching for Text-to-Image Generation", "comment": null, "summary": "Diffusion models and flow matching have demonstrated remarkable success in text-to-image generation. While many existing alignment methods primarily focus on fine-tuning pre-trained generative models to maximize a given reward function, these approaches require extensive computational resources and may not generalize well across different objectives. In this work, we propose a novel alignment framework by leveraging the underlying nature of the alignment problem -- sampling from reward-weighted distributions -- and show that it applies to both diffusion models (via score guidance) and flow matching models (via velocity guidance). The score function (velocity field) required for the reward-weighted distribution can be decomposed into the pre-trained score (velocity field) plus a conditional expectation of the reward. For the alignment on the diffusion model, we identify a fundamental challenge: the adversarial nature of the guidance term can introduce undesirable artifacts in the generated images. Therefore, we propose a finetuning-free framework that trains a guidance network to estimate the conditional expectation of the reward. We achieve comparable performance to finetuning-based models with one-step generation with at least a 60% reduction in computational cost. For the alignment on flow matching, we propose a training-free framework that improves the generation quality without additional computational cost.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u9f50\u95ee\u9898\u7684\u672c\u8d28\uff08\u4ece\u5956\u52b1\u52a0\u6743\u5206\u5e03\u4e2d\u91c7\u6837\uff09\uff0c\u9002\u7528\u4e8e\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5fae\u8c03\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u4ee5\u6700\u5927\u5316\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u4e14\u96be\u4ee5\u6cdb\u5316\u5230\u4e0d\u540c\u76ee\u6807\u3002\u672c\u6587\u5229\u7528\u5bf9\u9f50\u95ee\u9898\u7684\u672c\u8d28\u2014\u2014\u4ece\u5956\u52b1\u52a0\u6743\u5206\u5e03\u4e2d\u91c7\u6837\u2014\u2014\u6765\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u5bf9\u9f50\u6846\u67b6\u3002", "method": "1. \u5c06\u5956\u52b1\u52a0\u6743\u5206\u5e03\u6240\u9700\u7684\u5206\u6570\u51fd\u6570\uff08\u901f\u5ea6\u573a\uff09\u5206\u89e3\u4e3a\u9884\u8bad\u7ec3\u5206\u6570\uff08\u901f\u5ea6\u573a\uff09\u52a0\u4e0a\u5956\u52b1\u7684\u6761\u4ef6\u671f\u671b\uff1b2. \u5bf9\u4e8e\u6269\u6563\u6a21\u578b\uff0c\u63d0\u51fa\u514d\u5fae\u8c03\u6846\u67b6\uff0c\u8bad\u7ec3\u6307\u5bfc\u7f51\u7edc\u4f30\u8ba1\u5956\u52b1\u7684\u6761\u4ef6\u671f\u671b\uff1b3. \u5bf9\u4e8e\u6d41\u5339\u914d\u6a21\u578b\uff0c\u63d0\u51fa\u514d\u8bad\u7ec3\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u3002", "result": "1. \u5728\u6269\u6563\u6a21\u578b\u4e0a\uff0c\u8fbe\u5230\u4e0e\u57fa\u4e8e\u5fae\u8c03\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u81f3\u5c1160%\uff1b2. \u5728\u6d41\u5339\u914d\u6a21\u578b\u4e0a\uff0c\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u5373\u53ef\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff1b3. \u4e24\u79cd\u6a21\u578b\u90fd\u80fd\u5b9e\u73b0\u4e00\u6b65\u751f\u6210\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5bf9\u9f50\u6846\u67b6\u901a\u8fc7\u5229\u7528\u5956\u52b1\u52a0\u6743\u5206\u5e03\u91c7\u6837\u7684\u672c\u8d28\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2602.00641", "categories": ["stat.ML", "cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.00641", "abs": "https://arxiv.org/abs/2602.00641", "authors": ["Alain Durmus", "Maxence Noble", "Thibaut Pellerin"], "title": "Sampling from multi-modal distributions on Riemannian manifolds with training-free stochastic interpolants", "comment": null, "summary": "In this paper, we propose a general methodology for sampling from un-normalized densities defined on Riemannian manifolds, with a particular focus on multi-modal targets that remain challenging for existing sampling methods. Inspired by the framework of diffusion models developed for generative modeling, we introduce a sampling algorithm based on the simulation of a non-equilibrium deterministic dynamics that transports an easy-to-sample noise distribution toward the target. At the marginal level, the induced density path follows a prescribed stochastic interpolant between the noise and target distributions, specifically constructed to respect the underlying Riemannian geometry. In contrast to related generative modeling approaches that rely on machine learning, our method is entirely training-free. It instead builds on iterative posterior sampling procedures using only standard Monte Carlo techniques, thereby extending recent diffusion-based sampling methodologies beyond the Euclidean setting. We complement our approach with a rigorous theoretical analysis and demonstrate its effectiveness on a range of multi-modal sampling problems, including high-dimensional and heavy-tailed examples.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u9ece\u66fc\u6d41\u5f62\u4e0a\u4ece\u975e\u5f52\u4e00\u5316\u591a\u6a21\u6001\u5bc6\u5ea6\u91c7\u6837\u7684\u8bad\u7ec3\u81ea\u7531\u65b9\u6cd5\uff0c\u57fa\u4e8e\u786e\u5b9a\u6027\u52a8\u529b\u5b66\u5c06\u566a\u58f0\u5206\u5e03\u4f20\u8f93\u5230\u76ee\u6807\u5206\u5e03\uff0c\u65e0\u9700\u673a\u5668\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u91c7\u6837\u65b9\u6cd5\u5728\u5904\u7406\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u591a\u6a21\u6001\u76ee\u6807\u5206\u5e03\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u9ad8\u7ef4\u548c\u91cd\u5c3e\u5206\u5e03\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u80fd\u5904\u7406\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u7684\u91c7\u6837\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u975e\u5e73\u8861\u786e\u5b9a\u6027\u52a8\u529b\u5b66\uff0c\u5c06\u6613\u91c7\u6837\u7684\u566a\u58f0\u5206\u5e03\u4f20\u8f93\u5230\u76ee\u6807\u5206\u5e03\u3002\u5bc6\u5ea6\u8def\u5f84\u9075\u5faa\u566a\u58f0\u4e0e\u76ee\u6807\u5206\u5e03\u4e4b\u95f4\u7684\u968f\u673a\u63d2\u503c\uff0c\u5c0a\u91cd\u9ece\u66fc\u51e0\u4f55\u7ed3\u6784\u3002\u91c7\u7528\u8fed\u4ee3\u540e\u9a8c\u91c7\u6837\u8fc7\u7a0b\uff0c\u4ec5\u4f7f\u7528\u6807\u51c6\u8499\u7279\u5361\u6d1b\u6280\u672f\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u79cd\u591a\u6a21\u6001\u91c7\u6837\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u5305\u62ec\u9ad8\u7ef4\u548c\u91cd\u5c3e\u5206\u5e03\u793a\u4f8b\u3002\u7406\u8bba\u5206\u6790\u4e3a\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e25\u683c\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u8bad\u7ec3\u81ea\u7531\u7684\u9ece\u66fc\u6d41\u5f62\u91c7\u6837\u65b9\u6cd5\uff0c\u5c06\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\u65b9\u6cd5\u6269\u5c55\u5230\u975e\u6b27\u51e0\u91cc\u5f97\u8bbe\u7f6e\uff0c\u4e3a\u5904\u7406\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u7684\u591a\u6a21\u6001\u5206\u5e03\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00844", "categories": ["stat.ML", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.00844", "abs": "https://arxiv.org/abs/2602.00844", "authors": ["Che-Yi Liao", "Zheng Dong", "Gian-Gabriel Garcia", "Kamran Paynabar"], "title": "Multivariate Time Series Data Imputation via Distributionally Robust Regularization", "comment": null, "summary": "Multivariate time series (MTS) imputation is often compromised by mismatch between observed and true data distributions -- a bias exacerbated by non-stationarity and systematic missingness. Standard methods that minimize reconstruction error or encourage distributional alignment risk overfitting these biased observations. We propose the Distributionally Robust Regularized Imputer Objective (DRIO), which jointly minimizes reconstruction error and the divergence between the imputer and a worst-case distribution within a Wasserstein ambiguity set. We derive a tractable dual formulation that reduces infinite-dimensional optimization over measures to adversarial search over sample trajectories, and propose an adversarial learning algorithm compatible with flexible deep learning backbones. Comprehensive experiments on diverse real-world datasets show DRIO consistently improves imputation under both missing-completely-at-random and missing-not-at-random settings, reaching Pareto-optimal trade-offs between reconstruction accuracy and distributional alignment.", "AI": {"tldr": "\u63d0\u51faDRIO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u6b63\u5219\u5316\u89e3\u51b3\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u4e2d\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u968f\u673a\u548c\u975e\u968f\u673a\u7f3a\u5931\u573a\u666f\u4e0b\u5747\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u5e38\u56e0\u89c2\u6d4b\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u5206\u5e03\u4e0d\u5339\u914d\u800c\u53d7\u635f\uff0c\u8fd9\u79cd\u504f\u5dee\u5728\u975e\u5e73\u7a33\u6027\u548c\u7cfb\u7edf\u6027\u7f3a\u5931\u60c5\u51b5\u4e0b\u66f4\u52a0\u4e25\u91cd\u3002\u4f20\u7edf\u65b9\u6cd5\u6700\u5c0f\u5316\u91cd\u6784\u8bef\u5dee\u6216\u9f13\u52b1\u5206\u5e03\u5bf9\u9f50\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u8fd9\u4e9b\u6709\u504f\u89c2\u6d4b\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u9c81\u68d2\u6b63\u5219\u5316\u63d2\u8865\u76ee\u6807(DRIO)\uff0c\u8054\u5408\u6700\u5c0f\u5316\u91cd\u6784\u8bef\u5dee\u548c\u63d2\u8865\u5668\u4e0eWasserstein\u6a21\u7cca\u96c6\u5185\u6700\u574f\u60c5\u51b5\u5206\u5e03\u4e4b\u95f4\u7684\u6563\u5ea6\u3002\u63a8\u5bfc\u51fa\u53ef\u5904\u7406\u7684\u5bf9\u5076\u5f62\u5f0f\uff0c\u5c06\u65e0\u9650\u7ef4\u6d4b\u5ea6\u4f18\u5316\u7b80\u5316\u4e3a\u6837\u672c\u8f68\u8ff9\u7684\u5bf9\u6297\u641c\u7d22\uff0c\u5e76\u63d0\u51fa\u4e0e\u7075\u6d3b\u6df1\u5ea6\u5b66\u4e60\u9aa8\u5e72\u517c\u5bb9\u7684\u5bf9\u6297\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cDRIO\u5728\u5b8c\u5168\u968f\u673a\u7f3a\u5931\u548c\u975e\u968f\u673a\u7f3a\u5931\u8bbe\u7f6e\u4e0b\u5747\u80fd\u6301\u7eed\u6539\u8fdb\u63d2\u8865\u6027\u80fd\uff0c\u8fbe\u5230\u91cd\u6784\u7cbe\u5ea6\u548c\u5206\u5e03\u5bf9\u9f50\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861\u3002", "conclusion": "DRIO\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u6b63\u5219\u5316\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u4e2d\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u591a\u79cd\u7f3a\u5931\u673a\u5236\u4e0b\u90fd\u80fd\u5b9e\u73b0\u66f4\u597d\u7684\u63d2\u8865\u8d28\u91cf\u3002"}}
{"id": "2602.01245", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01245", "abs": "https://arxiv.org/abs/2602.01245", "authors": ["Dotamana Y\u00e9o", "Saralees Nadarajah", "Amadou Sawadogo"], "title": "Explicit Expressions for Multidimensional Value-at-Risk under Archimedean Copulas", "comment": "17 pages, 1 table", "summary": "This paper studies multivariate Value-at-Risk (VaR) for financial portfolios with a focus on modeling dependence structures through Archimedean copulas. Using the generator representation of Archimedean copulas, we derive explicit analytical expressions for the marginal lower-tail multivariate VaR in arbitrary dimensions.\n  Closed-form formulas are obtained for several commonly used copula families, including Clayton, Frank, Gumbel-Hougaard, Joe and Ali--Mikhail--Haq copulas, allowing a direct assessment of the impact of dependence on multivariate risk. These results complement existing approaches, which largely rely on numerical or simulation-based methods, by providing tractable alternatives for theoretical and applied risk analysis.\n  Monte Carlo simulations are conducted to evaluate the finite-sample performance of the proposed VaR estimator and to illustrate the role of different dependence structures. The proposed analytical setting offers transparent tools for multivariate risk measurement and systemic risk assessment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u91d1\u878d\u6295\u8d44\u7ec4\u5408\u7684\u591a\u53d8\u91cf\u98ce\u9669\u4ef7\u503c(VaR)\uff0c\u901a\u8fc7\u963f\u57fa\u7c73\u5fb7\u8fde\u63a5\u51fd\u6570\u5efa\u6a21\u4f9d\u8d56\u7ed3\u6784\uff0c\u63a8\u5bfc\u51fa\u4efb\u610f\u7ef4\u5ea6\u4e0b\u8fb9\u9645\u4e0b\u5c3e\u591a\u53d8\u91cfVaR\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6570\u503c\u6216\u6a21\u62df\u65b9\u6cd5\u8ba1\u7b97\u591a\u53d8\u91cfVaR\uff0c\u7f3a\u4e4f\u89e3\u6790\u89e3\u3002\u8bba\u6587\u65e8\u5728\u4e3a\u7406\u8bba\u7814\u7a76\u548c\u5e94\u7528\u98ce\u9669\u5206\u6790\u63d0\u4f9b\u53ef\u5904\u7406\u7684\u89e3\u6790\u66ff\u4ee3\u65b9\u6848\uff0c\u63d0\u9ad8\u591a\u53d8\u91cf\u98ce\u9669\u6d4b\u91cf\u7684\u900f\u660e\u5ea6\u3002", "method": "\u5229\u7528\u963f\u57fa\u7c73\u5fb7\u8fde\u63a5\u51fd\u6570\u7684\u751f\u6210\u5143\u8868\u793a\uff0c\u63a8\u5bfc\u51fa\u8fb9\u9645\u4e0b\u5c3e\u591a\u53d8\u91cfVaR\u7684\u663e\u5f0f\u89e3\u6790\u8868\u8fbe\u5f0f\u3002\u9488\u5bf9Clayton\u3001Frank\u3001Gumbel-Hougaard\u3001Joe\u548cAli-Mikhail-Haq\u7b49\u5e38\u7528\u8fde\u63a5\u51fd\u6570\u65cf\u83b7\u5f97\u95ed\u5f0f\u516c\u5f0f\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8bc4\u4f30\u6709\u9650\u6837\u672c\u6027\u80fd\u3002", "result": "\u83b7\u5f97\u4e86\u591a\u4e2a\u5e38\u7528\u8fde\u63a5\u51fd\u6570\u65cf\u7684\u95ed\u5f0f\u89e3\u6790\u516c\u5f0f\uff0c\u53ef\u4ee5\u76f4\u63a5\u8bc4\u4f30\u4f9d\u8d56\u7ed3\u6784\u5bf9\u591a\u53d8\u91cf\u98ce\u9669\u7684\u5f71\u54cd\u3002\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u4e86\u6240\u63d0VaR\u4f30\u8ba1\u5668\u7684\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u4f9d\u8d56\u7ed3\u6784\u7684\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u6790\u6846\u67b6\u4e3a\u591a\u53d8\u91cf\u98ce\u9669\u6d4b\u91cf\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u900f\u660e\u5de5\u5177\uff0c\u8865\u5145\u4e86\u73b0\u6709\u7684\u6570\u503c\u65b9\u6cd5\uff0c\u4f7f\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\u66f4\u52a0\u4fbf\u6377\u3002"}}
{"id": "2602.00417", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00417", "abs": "https://arxiv.org/abs/2602.00417", "authors": ["Sahasrajit Sarmasarkar"], "title": "Shuffle and Joint Differential Privacy for Generalized Linear Contextual Bandits", "comment": null, "summary": "We present the first algorithms for generalized linear contextual bandits under shuffle differential privacy and joint differential privacy. While prior work on private contextual bandits has been restricted to linear reward models -- which admit closed-form estimators -- generalized linear models (GLMs) pose fundamental new challenges: no closed-form estimator exists, requiring private convex optimization; privacy must be tracked across multiple evolving design matrices; and optimization error must be explicitly incorporated into regret analysis.\n  We address these challenges under two privacy models and context settings. For stochastic contexts, we design a shuffle-DP algorithm achieving $\\tilde{O}(d^{3/2}\\sqrt{T}/\\sqrt{\\varepsilon})$ regret. For adversarial contexts, we provide a joint-DP algorithm with $\\tilde{O}(d\\sqrt{T}/\\sqrt{\\varepsilon})$ regret -- matching the non-private rate up to a $1/\\sqrt{\\varepsilon}$ factor. Both algorithms remove dependence on the instance-specific parameter $\u03ba$ (which can be exponential in dimension) from the dominant $\\sqrt{T}$ term. Unlike prior work on locally private GLM bandits, our methods require no spectral assumptions on the context distribution beyond $\\ell_2$ boundedness.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u5728\u6d17\u724c\u5dee\u5206\u9690\u79c1\u548c\u8054\u5408\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u5e7f\u4e49\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86GLM\u5e26\u6765\u7684\u65b0\u6311\u6218\uff0c\u5728\u4e0d\u540c\u9690\u79c1\u6a21\u578b\u548c\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u975e\u79c1\u6709\u7b97\u6cd5\u7684\u9057\u61be\u754c\u3002", "motivation": "\u73b0\u6709\u79c1\u6709\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7814\u7a76\u4ec5\u9650\u4e8e\u7ebf\u6027\u5956\u52b1\u6a21\u578b\uff08\u5177\u6709\u95ed\u5f0f\u89e3\uff09\uff0c\u800c\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\uff08GLM\uff09\u5e26\u6765\u65b0\u6311\u6218\uff1a\u65e0\u95ed\u5f0f\u89e3\u9700\u8981\u79c1\u6709\u51f8\u4f18\u5316\u3001\u9690\u79c1\u9700\u8de8\u591a\u4e2a\u6f14\u5316\u8bbe\u8ba1\u77e9\u9635\u8ddf\u8e2a\u3001\u4f18\u5316\u8bef\u5dee\u9700\u660e\u786e\u7eb3\u5165\u9057\u61be\u5206\u6790\u3002", "method": "\u9488\u5bf9\u4e24\u79cd\u9690\u79c1\u6a21\u578b\u548c\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u8bbe\u8ba1\u4e0d\u540c\u7b97\u6cd5\uff1a\u5bf9\u4e8e\u968f\u673a\u4e0a\u4e0b\u6587\uff0c\u8bbe\u8ba1\u6d17\u724c\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\uff1b\u5bf9\u4e8e\u5bf9\u6297\u6027\u4e0a\u4e0b\u6587\uff0c\u63d0\u4f9b\u8054\u5408\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u3002\u4e24\u79cd\u7b97\u6cd5\u90fd\u6d88\u9664\u4e86\u5bf9\u5b9e\u4f8b\u7279\u5b9a\u53c2\u6570\u03ba\u7684\u4f9d\u8d56\uff0c\u4e14\u4e0d\u9700\u8981\u8d85\u51fa\u2113\u2082\u6709\u754c\u6027\u7684\u8c31\u5047\u8bbe\u3002", "result": "\u968f\u673a\u4e0a\u4e0b\u6587\u4e0b\u6d17\u724c\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8fbe\u5230$\\tilde{O}(d^{3/2}\\sqrt{T}/\\sqrt{\\varepsilon})$\u9057\u61be\uff1b\u5bf9\u6297\u6027\u4e0a\u4e0b\u6587\u4e0b\u8054\u5408\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8fbe\u5230$\\tilde{O}(d\\sqrt{T}/\\sqrt{\\varepsilon})$\u9057\u61be\uff0c\u4e0e\u975e\u79c1\u6709\u7387\u76f8\u6bd4\u4ec5\u5dee$1/\\sqrt{\\varepsilon}$\u56e0\u5b50\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u89e3\u51b3\u4e86\u5e7f\u4e49\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u5728\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u7b97\u6cd5\u8bbe\u8ba1\u95ee\u9898\uff0c\u5728\u4e0d\u540c\u9690\u79c1\u6a21\u578b\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9057\u61be\u754c\uff0c\u6d88\u9664\u4e86\u5bf9\u95ee\u9898\u7279\u5b9a\u53c2\u6570\u7684\u4f9d\u8d56\uff0c\u4e3a\u79c1\u6709GLM\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2602.01427", "categories": ["stat.ML", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.01427", "abs": "https://arxiv.org/abs/2602.01427", "authors": ["Haixiang Sun", "Andrew L. Liu"], "title": "Robust Generalization with Adaptive Optimal Transport Priors for Decision-Focused Learning", "comment": null, "summary": "Few-shot learning requires models to generalize under limited supervision while remaining robust to distribution shifts. Existing Sinkhorn Distributionally Robust Optimization (DRO) methods provide theoretical guarantees but rely on a fixed reference distribution, which limits their adaptability. We propose a Prototype-Guided Distributionally Robust Optimization (PG-DRO) framework that learns class-adaptive priors from abundant base data via hierarchical optimal transport and embeds them into the Sinkhorn DRO formulation. This design enables few-shot information to be organically integrated into producing class-specific robust decisions that are both theoretically grounded and efficient, and further aligns the uncertainty set with transferable structural knowledge. Experiments show that PG-DRO achieves stronger robust generalization in few-shot scenarios, outperforming both standard learners and DRO baselines.", "AI": {"tldr": "PG-DRO\uff1a\u4e00\u79cd\u539f\u578b\u5f15\u5bfc\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u6700\u4f18\u4f20\u8f93\u4ece\u4e30\u5bcc\u57fa\u7c7b\u6570\u636e\u4e2d\u5b66\u4e60\u7c7b\u522b\u81ea\u9002\u5e94\u5148\u9a8c\uff0c\u5e76\u5c06\u5176\u5d4c\u5165Sinkhorn DRO\u516c\u5f0f\uff0c\u5728\u5c11\u6837\u672c\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u5f3a\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709Sinkhorn\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u53c2\u8003\u5206\u5e03\uff0c\u9650\u5236\u4e86\u5176\u9002\u5e94\u6027\u3002\u5c11\u6837\u672c\u5b66\u4e60\u9700\u8981\u5728\u6709\u9650\u76d1\u7763\u4e0b\u6cdb\u5316\u5e76\u4fdd\u6301\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u539f\u578b\u5f15\u5bfc\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u5206\u5c42\u6700\u4f18\u4f20\u8f93\u4ece\u4e30\u5bcc\u57fa\u7c7b\u6570\u636e\u5b66\u4e60\u7c7b\u522b\u81ea\u9002\u5e94\u5148\u9a8c\uff1b2\uff09\u5c06\u8fd9\u4e9b\u5148\u9a8c\u5d4c\u5165Sinkhorn DRO\u516c\u5f0f\uff1b3\uff09\u6709\u673a\u6574\u5408\u5c11\u6837\u672c\u4fe1\u606f\u751f\u6210\u7c7b\u522b\u7279\u5b9a\u7684\u9c81\u68d2\u51b3\u7b56\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePG-DRO\u5728\u5c11\u6837\u672c\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u6807\u51c6\u5b66\u4e60\u5668\u548cDRO\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PG-DRO\u6846\u67b6\u901a\u8fc7\u5c06\u53ef\u8fc1\u79fb\u7684\u7ed3\u6784\u77e5\u8bc6\u878d\u5165\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u5b9e\u73b0\u4e86\u7406\u8bba\u4fdd\u8bc1\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u5c11\u6837\u672c\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01366", "categories": ["stat.ME", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.01366", "abs": "https://arxiv.org/abs/2602.01366", "authors": ["Mehmet S\u0131dd\u0131k \u00c7ad\u0131rc\u0131"], "title": "A Fractional M/M/1 Queue Governed by Stretched Non-Local Time Operators", "comment": "13 pages, 3 figures, 1 table", "summary": "We introduce a non-Markovian generalization of the classical M/M/1 queue by incorporating extended nonlocal time dynamics into Kolmogorov forward equations. We obtain the model by replacing the standard time derivative with an extended Caputo-type operator. It preserves the birth-death transition structure of the standard queue while introducing memory effects into the temporal evolution. We derive explicit representations for transient state probabilities in terms of the Kilbas-Saigo function, which naturally emerges as the relaxation kernel associated with the stretched operator, using Laplace transform techniques. We construct a time-varying interpretation and show that the fractional queue can be viewed as a distribution of a classical M/M/1 process evaluated at a non-decreasing random time. It is observed that the fractional queue can be viewed as a distribution of a classical M/M/1 process evaluated at a non-decreasing random time. We prove that under the standard stability condition $\u03c1<1$, the steady-state distribution remains geometric and coincides with the distribution of the classical queue, whilst we prove that the stretched fractional parameters significantly affect the convergence rate in the transient regime. Numerical examples based on Monte Carlo simulations highlight the effect of the parameters $(\u03b1,\u03b3)$ on the distribution of empty states, tail length distributions, and the average tail evolution, and validate the flexibility of the proposed framework in capturing long-memory tail dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u9a6c\u5c14\u53ef\u592bM/M/1\u961f\u5217\u7684\u63a8\u5e7f\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u6269\u5c55\u7684Caputo\u578b\u7b97\u5b50\u6765\u7eb3\u5165\u975e\u5c40\u90e8\u65f6\u95f4\u52a8\u529b\u5b66\uff0c\u4fdd\u7559\u4e86\u7ecf\u5178\u961f\u5217\u7684\u751f\u6b7b\u8f6c\u79fb\u7ed3\u6784\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u8bb0\u5fc6\u6548\u5e94\u3002", "motivation": "\u7ecf\u5178M/M/1\u961f\u5217\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u5047\u8bbe\uff0c\u7f3a\u4e4f\u5bf9\u5177\u6709\u8bb0\u5fc6\u6548\u5e94\u7684\u73b0\u5b9e\u6392\u961f\u7cfb\u7edf\u7684\u5efa\u6a21\u80fd\u529b\u3002\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6355\u6349\u957f\u671f\u8bb0\u5fc6\u5c3e\u52a8\u6001\u7684\u5206\u6570\u9636\u6392\u961f\u6a21\u578b\u3002", "method": "\u5c06\u6807\u51c6\u65f6\u95f4\u5bfc\u6570\u66ff\u6362\u4e3a\u6269\u5c55\u7684Caputo\u578b\u7b97\u5b50\uff0c\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u53d8\u6362\u6280\u672f\u63a8\u5bfc\u77ac\u6001\u72b6\u6001\u6982\u7387\u7684\u663e\u5f0f\u8868\u793a\uff08\u7528Kilbas-Saigo\u51fd\u6570\u8868\u793a\uff09\uff0c\u5e76\u6784\u5efa\u65f6\u95f4\u53d8\u5316\u89e3\u91ca\uff0c\u5c06\u5206\u6570\u9636\u961f\u5217\u89c6\u4e3a\u7ecf\u5178M/M/1\u8fc7\u7a0b\u5728\u975e\u9012\u51cf\u968f\u673a\u65f6\u95f4\u4e0a\u7684\u5206\u5e03\u3002", "result": "\u5728\u7a33\u5b9a\u6027\u6761\u4ef6\u03c1<1\u4e0b\uff0c\u7a33\u6001\u5206\u5e03\u4fdd\u6301\u51e0\u4f55\u5206\u5e03\u5e76\u4e0e\u7ecf\u5178\u961f\u5217\u4e00\u81f4\uff0c\u4f46\u5206\u6570\u9636\u53c2\u6570\u663e\u8457\u5f71\u54cd\u77ac\u6001\u6536\u655b\u901f\u7387\u3002\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\u53c2\u6570(\u03b1,\u03b3)\u5bf9\u7a7a\u72b6\u6001\u5206\u5e03\u3001\u5c3e\u957f\u5206\u5e03\u548c\u5e73\u5747\u5c3e\u6f14\u5316\u7684\u5f71\u54cd\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u6355\u6349\u957f\u671f\u8bb0\u5fc6\u5c3e\u52a8\u6001\u65b9\u9762\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u6570\u9636\u6392\u961f\u6a21\u578b\u6210\u529f\u5730\u5c06\u8bb0\u5fc6\u6548\u5e94\u7eb3\u5165\u7ecf\u5178M/M/1\u961f\u5217\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u7a33\u6001\u7279\u6027\uff0c\u4e3a\u5efa\u6a21\u5177\u6709\u957f\u671f\u8bb0\u5fc6\u7684\u6392\u961f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2602.00427", "categories": ["stat.ML", "cs.LG", "math.MG"], "pdf": "https://arxiv.org/pdf/2602.00427", "abs": "https://arxiv.org/abs/2602.00427", "authors": ["Mouad El Bouchattaoui"], "title": "Topological Residual Asymmetry for Bivariate Causal Direction", "comment": null, "summary": "Inferring causal direction from purely observational bivariate data is fragile: many methods commit to a direction even in ambiguous or near non-identifiable regimes. We propose Topological Residual Asymmetry (TRA), a geometry-based criterion for additive-noise models. TRA compares the shapes of two cross-fitted regressor-residual clouds after rank-based copula standardization: in the correct direction, residuals are approximately independent, producing a two-dimensional bulk, while in the reverse direction -- especially under low noise -- the cloud concentrates near a one-dimensional tube. We quantify this bulk-tube contrast using a 0D persistent-homology functional, computed efficiently from Euclidean MST edge-length profiles. We prove consistency in a triangular-array small-noise regime, extend the method to fixed noise via a binned variant (TRA-s), and introduce TRA-C, a confounding-aware abstention rule calibrated by a Gaussian-copula plug-in bootstrap. Extensive experiments across many challenging synthetic and real-data scenarios demonstrate the method's superiority.", "AI": {"tldr": "\u63d0\u51faTRA\u65b9\u6cd5\uff0c\u57fa\u4e8e\u62d3\u6251\u51e0\u4f55\u5224\u65ad\u56e0\u679c\u65b9\u5411\uff0c\u901a\u8fc7\u6b8b\u5dee\u4e91\u5f62\u72b6\u5bf9\u6bd4\uff08\u4e8c\u7ef4\u5757\u72b6vs\u4e00\u7ef4\u7ba1\u72b6\uff09\uff0c\u4f7f\u7528\u6301\u7eed\u540c\u8c03\u91cf\u5316\u5dee\u5f02\uff0c\u5728\u4f4e\u566a\u58f0\u548c\u56fa\u5b9a\u566a\u58f0\u4e0b\u5747\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u65b9\u5411\u63a8\u65ad\u65b9\u6cd5\u5728\u6a21\u7cca\u6216\u63a5\u8fd1\u4e0d\u53ef\u8bc6\u522b\u7684\u60c5\u51b5\u4e0b\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u51e0\u4f55\u57fa\u7840\u65b9\u6cd5\u3002", "method": "TRA\u65b9\u6cd5\uff1a1) \u79e9\u57facopula\u6807\u51c6\u5316\uff1b2) \u4ea4\u53c9\u62df\u5408\u56de\u5f52\u6b8b\u5dee\u4e91\uff1b3) \u4f7f\u75280\u7ef4\u6301\u7eed\u540c\u8c03\u529f\u80fd\uff08\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97MST\u8fb9\u957f\u5ea6\u5256\u9762\uff09\u91cf\u5316\u6b8b\u5dee\u4e91\u5f62\u72b6\u5dee\u5f02\uff1b4) \u6269\u5c55\u4e3aTRA-s\uff08\u5206\u7bb1\u7248\u672c\uff09\u5904\u7406\u56fa\u5b9a\u566a\u58f0\uff1b5) \u63d0\u51faTRA-C\u6df7\u6dc6\u611f\u77e5\u5f03\u6743\u89c4\u5219\u3002", "result": "\u5728\u4e09\u89d2\u9635\u5217\u5c0f\u566a\u58f0\u673a\u5236\u4e0b\u8bc1\u660e\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u5927\u91cf\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u4f18\u8d8a\u6027\u3002", "conclusion": "TRA\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u7684\u7a33\u5065\u56e0\u679c\u65b9\u5411\u63a8\u65ad\u65b9\u6cd5\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u901a\u8fc7TRA-C\u8bc6\u522b\u6df7\u6dc6\u60c5\u51b5\u3002"}}
{"id": "2602.01573", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01573", "abs": "https://arxiv.org/abs/2602.01573", "authors": ["Kenichiro McAlinn", "K\u014dsaku Takanashi"], "title": "When Is Generalized Bayes Bayesian? A Decision-Theoretic Characterization of Loss-Based Updating", "comment": null, "summary": "Loss-based updating, including generalized Bayes, Gibbs, and quasi-posteriors, replaces likelihoods by a user-chosen loss and produces a posterior-like distribution via exponential tilt. We give a decision-theoretic characterization that separates \\emph{belief posteriors} --  conditional beliefs justified by the foundations of Savage and Anscombe-Aumann under a joint probability mode l-- from \\emph{decision posteriors} -- randomized decision rules justified by preferences over decision rules. We make explicit that a loss-based posterior coincides with ordinary Bayes if and only if the loss is, up to scale and a data-only term, negative log-likelihood. We then show that generalized marginal likelihood is not evidence for decision posteriors, and Bayes factors are not well-defined without additional structure. In the decision posterior regime, non-degenerate posteriors require nonlinear preferences over decision rules. Under sequential coherence and separability, these lead to an entropy-penalized variational representation yielding generalized Bayes as the optimal rule.", "AI": {"tldr": "\u8bba\u6587\u533a\u5206\u4e86\u4fe1\u5ff5\u540e\u9a8c\u548c\u51b3\u7b56\u540e\u9a8c\uff0c\u6307\u51fa\u635f\u5931\u51fd\u6570\u540e\u9a8c\u53ea\u6709\u5728\u635f\u5931\u51fd\u6570\u4e3a\u8d1f\u5bf9\u6570\u4f3c\u7136\u65f6\u624d\u7b49\u540c\u4e8e\u666e\u901a\u8d1d\u53f6\u65af\uff0c\u5e76\u8bc1\u660e\u5728\u51b3\u7b56\u540e\u9a8c\u4f53\u7cfb\u4e2d\u9700\u8981\u975e\u7ebf\u6027\u504f\u597d\u624d\u80fd\u4ea7\u751f\u975e\u9000\u5316\u540e\u9a8c\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u4e3a\u57fa\u4e8e\u635f\u5931\u7684\u66f4\u65b0\u65b9\u6cd5\uff08\u5305\u62ec\u5e7f\u4e49\u8d1d\u53f6\u65af\u3001\u5409\u5e03\u65af\u548c\u62df\u540e\u9a8c\uff09\u63d0\u4f9b\u51b3\u7b56\u7406\u8bba\u57fa\u7840\uff0c\u660e\u786e\u533a\u5206\u4e24\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u6f84\u6e05\u5b83\u4eec\u5728\u7edf\u8ba1\u63a8\u65ad\u4e2d\u7684\u7406\u8bba\u57fa\u7840\u548c\u9002\u7528\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u57fa\u4e8eSavage\u548cAnscombe-Aumann\u7684\u516c\u7406\u4f53\u7cfb\uff0c\u901a\u8fc7\u504f\u597d\u5173\u7cfb\u5206\u6790\u51b3\u7b56\u89c4\u5219\uff0c\u5efa\u7acb\u635f\u5931\u51fd\u6570\u540e\u9a8c\u4e0e\u666e\u901a\u8d1d\u53f6\u65af\u540e\u9a8c\u7684\u7b49\u4ef7\u6761\u4ef6\uff0c\u5e76\u63a2\u8ba8\u975e\u7ebf\u6027\u504f\u597d\u5bf9\u540e\u9a8c\u5206\u5e03\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86\u635f\u5931\u51fd\u6570\u540e\u9a8c\u7b49\u540c\u4e8e\u666e\u901a\u8d1d\u53f6\u65af\u540e\u9a8c\u5f53\u4e14\u4ec5\u5f53\u635f\u5931\u51fd\u6570\uff08\u9664\u5c3a\u5ea6\u56e0\u5b50\u548c\u6570\u636e\u76f8\u5173\u9879\u5916\uff09\u4e3a\u8d1f\u5bf9\u6570\u4f3c\u7136\uff1b\u5728\u51b3\u7b56\u540e\u9a8c\u4f53\u7cfb\u4e2d\uff0c\u975e\u9000\u5316\u540e\u9a8c\u9700\u8981\u975e\u7ebf\u6027\u504f\u597d\uff0c\u4e14\u5e7f\u4e49\u8fb9\u9645\u4f3c\u7136\u4e0d\u80fd\u4f5c\u4e3a\u51b3\u7b56\u540e\u9a8c\u7684\u8bc1\u636e\u3002", "conclusion": "\u635f\u5931\u51fd\u6570\u540e\u9a8c\u53ef\u5206\u4e3a\u4fe1\u5ff5\u540e\u9a8c\u548c\u51b3\u7b56\u540e\u9a8c\u4e24\u7c7b\uff0c\u5b83\u4eec\u6709\u4e0d\u540c\u7684\u7406\u8bba\u57fa\u7840\u548c\u6027\u8d28\u3002\u5728\u51b3\u7b56\u540e\u9a8c\u6846\u67b6\u4e0b\uff0c\u5e7f\u4e49\u8d1d\u53f6\u65af\u53ef\u901a\u8fc7\u71b5\u60e9\u7f5a\u53d8\u5206\u8868\u793a\u4f5c\u4e3a\u6700\u4f18\u51b3\u7b56\u89c4\u5219\uff0c\u4f46\u9700\u8981\u975e\u7ebf\u6027\u504f\u597d\u6765\u4fdd\u8bc1\u540e\u9a8c\u7684\u975e\u9000\u5316\u6027\u3002"}}
{"id": "2602.00474", "categories": ["stat.ML", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.00474", "abs": "https://arxiv.org/abs/2602.00474", "authors": ["Yang Xu", "Vaneet Aggarwal"], "title": "Stabilizing Fixed-Point Iteration for Markov Chain Poisson Equations", "comment": null, "summary": "Poisson equations underpin average-reward reinforcement learning, but beyond ergodicity they can be ill-posed, meaning that solutions are non-unique and standard fixed point iterations can oscillate on reducible or periodic chains. We study finite-state Markov chains with $n$ states and transition matrix $P$. We show that all non-decaying modes are captured by a real peripheral invariant subspace $\\mathcal{K}(P)$, and that the induced operator on the quotient space $\\mathbb{R}^n/\\mathcal{K}(P)$ is strictly contractive, yielding a unique quotient solution. Building on this viewpoint, we develop an end-to-end pipeline that learns the chain structure, estimates an anchor based gauge map, and runs projected stochastic approximation to estimate a gauge-fixed representative together with an associated peripheral residual. We prove $\\widetilde{O}(T^{-1/2})$ convergence up to projection estimation error, enabling stable Poisson equation learning for multichain and periodic regimes with applications to performance evaluation of average-reward reinforcement learning beyond ergodicity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u975e\u904d\u5386\u9a6c\u5c14\u53ef\u592b\u94fe\uff08\u591a\u94fe\u548c\u5468\u671f\u94fe\uff09\u7684\u6cca\u677e\u65b9\u7a0b\u7a33\u5b9a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5546\u7a7a\u95f4\u5206\u6790\u548c\u6295\u5f71\u968f\u673a\u903c\u8fd1\u5b9e\u73b0\u6536\u655b\u3002", "motivation": "\u4f20\u7edf\u5e73\u5747\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6cca\u677e\u65b9\u7a0b\u5728\u904d\u5386\u6027\u5047\u8bbe\u4e0b\u6210\u7acb\uff0c\u4f46\u5728\u975e\u904d\u5386\uff08\u53ef\u7ea6\u6216\u5468\u671f\uff09\u9a6c\u5c14\u53ef\u592b\u94fe\u4e2d\u53ef\u80fd\u75c5\u6001\uff0c\u5bfc\u81f4\u89e3\u4e0d\u552f\u4e00\u4e14\u56fa\u5b9a\u70b9\u8fed\u4ee3\u632f\u8361\u3002\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u66f4\u4e00\u822c\u94fe\u7ed3\u6784\u7684\u7a33\u5b9a\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "1) \u5206\u6790\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u5b9e\u5916\u56f4\u4e0d\u53d8\u5b50\u7a7a\u95f4\uff0c\u8bc1\u660e\u5728\u5546\u7a7a\u95f4\u4e0a\u7684\u8bf1\u5bfc\u7b97\u5b50\u662f\u4e25\u683c\u538b\u7f29\u7684\uff1b2) \u6784\u5efa\u7aef\u5230\u7aef\u6d41\u7a0b\uff1a\u5b66\u4e60\u94fe\u7ed3\u6784\u3001\u4f30\u8ba1\u951a\u5b9a\u89c4\u8303\u6620\u5c04\u3001\u8fd0\u884c\u6295\u5f71\u968f\u673a\u903c\u8fd1\u6765\u4f30\u8ba1\u89c4\u8303\u56fa\u5b9a\u4ee3\u8868\u548c\u5916\u56f4\u6b8b\u5dee\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6295\u5f71\u4f30\u8ba1\u8bef\u5dee\u8303\u56f4\u5185\u8fbe\u5230$\\widetilde{O}(T^{-1/2})$\u6536\u655b\u7387\uff0c\u5b9e\u73b0\u4e86\u591a\u94fe\u548c\u5468\u671f\u673a\u5236\u4e0b\u6cca\u677e\u65b9\u7a0b\u7684\u7a33\u5b9a\u5b66\u4e60\uff0c\u6269\u5c55\u4e86\u5e73\u5747\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u8bc4\u4f30\u8303\u56f4\u3002", "conclusion": "\u901a\u8fc7\u5546\u7a7a\u95f4\u5206\u6790\u548c\u6295\u5f71\u968f\u673a\u903c\u8fd1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u975e\u904d\u5386\u9a6c\u5c14\u53ef\u592b\u94fe\u4e2d\u6cca\u677e\u65b9\u7a0b\u7684\u75c5\u6001\u95ee\u9898\uff0c\u4e3a\u8d85\u8d8a\u904d\u5386\u6027\u7684\u5e73\u5747\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7b97\u6cd5\u3002"}}
{"id": "2602.00629", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00629", "abs": "https://arxiv.org/abs/2602.00629", "authors": ["Natinael Solomon Neggatu", "Jeremie Houssineau", "Giovanni Montana"], "title": "Action-Free Offline-to-Online RL via Discretised State Policies", "comment": "ICLR 2026", "summary": "Most existing offline RL methods presume the availability of action labels within the dataset, but in many practical scenarios, actions may be missing due to privacy, storage, or sensor limitations. We formalise the setting of action-free offline-to-online RL, where agents must learn from datasets consisting solely of $(s,r,s')$ tuples and later leverage this knowledge during online interaction. To address this challenge, we propose learning state policies that recommend desirable next-state transitions rather than actions. Our contributions are twofold. First, we introduce a simple yet novel state discretisation transformation and propose Offline State-Only DecQN (\\algo), a value-based algorithm designed to pre-train state policies from action-free data. \\algo{} integrates the transformation to scale efficiently to high-dimensional problems while avoiding instability and overfitting associated with continuous state prediction. Second, we propose a novel mechanism for guided online learning that leverages these pre-trained state policies to accelerate the learning of online agents. Together, these components establish a scalable and practical framework for leveraging action-free datasets to accelerate online RL. Empirical results across diverse benchmarks demonstrate that our approach improves convergence speed and asymptotic performance, while analyses reveal that discretisation and regularisation are critical to its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u65e0\u52a8\u4f5c\u6807\u7b7e\u7684\u79bb\u7ebf\u6570\u636e\u4e2d\u5b66\u4e60\u72b6\u6001\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u72b6\u6001\u79bb\u6563\u5316\u8f6c\u6362\u548c\u72b6\u6001\u4ef7\u503c\u5b66\u4e60\uff0c\u52a0\u901f\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u79bb\u7ebf\u6570\u636e\u96c6\u5e38\u7f3a\u5931\u52a8\u4f5c\u6807\u7b7e\uff08\u7531\u4e8e\u9690\u79c1\u3001\u5b58\u50a8\u6216\u4f20\u611f\u5668\u9650\u5236\uff09\uff0c\u4f46\u73b0\u6709\u79bb\u7ebfRL\u65b9\u6cd5\u90fd\u5047\u8bbe\u52a8\u4f5c\u6807\u7b7e\u53ef\u7528\u3002\u9700\u8981\u89e3\u51b3\u4ece\u4ec5\u5305\u542b\u72b6\u6001-\u5956\u52b1-\u4e0b\u4e00\u72b6\u6001\u4e09\u5143\u7ec4\u7684\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5e76\u52a0\u901f\u5728\u7ebf\u5b66\u4e60\u7684\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u72b6\u6001\u79bb\u6563\u5316\u8f6c\u6362\uff0c\u5c06\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u79bb\u6563\u5316\u4ee5\u907f\u514d\u4e0d\u7a33\u5b9a\u548c\u8fc7\u62df\u5408\uff1b2. \u63d0\u51faOffline State-Only DecQN\u7b97\u6cd5\uff0c\u4ece\u65e0\u52a8\u4f5c\u6570\u636e\u4e2d\u9884\u8bad\u7ec3\u72b6\u6001\u7b56\u7565\uff08\u63a8\u8350\u671f\u671b\u7684\u4e0b\u4e00\u72b6\u6001\u8f6c\u79fb\u800c\u975e\u52a8\u4f5c\uff09\uff1b3. \u63d0\u51fa\u5f15\u5bfc\u5728\u7ebf\u5b66\u4e60\u673a\u5236\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u72b6\u6001\u7b56\u7565\u52a0\u901f\u5728\u7ebf\u4ee3\u7406\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\u548c\u6e10\u8fd1\u6027\u80fd\u3002\u5206\u6790\u8868\u660e\u72b6\u6001\u79bb\u6563\u5316\u548c\u6b63\u5219\u5316\u5bf9\u65b9\u6cd5\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u65e0\u52a8\u4f5c\u6570\u636e\u96c6\u52a0\u901f\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u573a\u666f\u4e2d\u52a8\u4f5c\u6807\u7b7e\u7f3a\u5931\u7684\u95ee\u9898\u3002"}}
{"id": "2602.01631", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01631", "abs": "https://arxiv.org/abs/2602.01631", "authors": ["Akihiro Sato", "Shonosuke Sugasawa"], "title": "Difference-in-Differences under Local Dependence on Networks", "comment": "34 pages (main) + 8 pages (supplement)", "summary": "Estimating causal effects under interference, where the stable unit treatment value assumption is violated, is critical in fields such as regional and public economics. Much of the existing research on causal inference under interference relies on a pre-specified \"exposure mapping\". This paper focuses on difference-in-difference and proposes a nonparametric identification strategy for direct and indirect average treatment effects under local interference on an observed network. In particular, we proposed a new concept of an indirect effect measuring the total outward influence of the intervension. Based on parallel trends assumption conditional on the neighborhood treatment vector, we develop inverse probability weighted and doubly robust estimators. We establish their asymptotic properties, including consistency under misspecification of nuisance models under some regularity conditions. Simulation studies and an empirical application demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7f51\u7edc\u5e72\u6270\u4e0b\u8bc6\u522b\u76f4\u63a5\u548c\u95f4\u63a5\u5e73\u5747\u5904\u7406\u6548\u5e94\u7684\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u57fa\u4e8e\u53cc\u91cd\u5dee\u5206\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u9006\u6982\u7387\u52a0\u6743\u548c\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\u3002", "motivation": "\u5728\u533a\u57df\u7ecf\u6d4e\u5b66\u548c\u516c\u5171\u7ecf\u6d4e\u5b66\u7b49\u9886\u57df\uff0c\u5b58\u5728\u5e72\u6270\uff08\u5373\u7a33\u5b9a\u5355\u4f4d\u5904\u7406\u503c\u5047\u8bbe\u88ab\u8fdd\u53cd\uff09\u65f6\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u5927\u591a\u4f9d\u8d56\u9884\u8bbe\u7684\"\u66b4\u9732\u6620\u5c04\"\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6761\u4ef6\u90bb\u57df\u5904\u7406\u5411\u91cf\u7684\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u975e\u53c2\u6570\u8bc6\u522b\u7b56\u7565\uff0c\u5f00\u53d1\u4e86\u9006\u6982\u7387\u52a0\u6743\u4f30\u8ba1\u5668\u548c\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u5e76\u5efa\u7acb\u4e86\u5b83\u4eec\u7684\u6e10\u8fd1\u6027\u8d28\u3002", "result": "\u5728\u6a21\u62df\u7814\u7a76\u548c\u5b9e\u8bc1\u5e94\u7528\u4e2d\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u5728\u5e72\u6270\u6a21\u578b\u8bbe\u5b9a\u9519\u8bef\u7684\u60c5\u51b5\u4e0b\uff0c\u4f30\u8ba1\u5668\u5728\u7279\u5b9a\u6b63\u5219\u6761\u4ef6\u4e0b\u4ecd\u80fd\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u7f51\u7edc\u5e72\u6270\u4e0b\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53cc\u91cd\u5dee\u5206\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u76f4\u63a5\u548c\u95f4\u63a5\u5904\u7406\u6548\u5e94\uff0c\u7279\u522b\u662f\u63d0\u51fa\u4e86\u8861\u91cf\u5e72\u9884\u5411\u5916\u603b\u5f71\u54cd\u7684\u95f4\u63a5\u6548\u5e94\u65b0\u6982\u5ff5\u3002"}}
{"id": "2602.01648", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01648", "abs": "https://arxiv.org/abs/2602.01648", "authors": ["Chengxin Yang", "Laine E. Thomas", "Fan Li"], "title": "Demystify Doubly-Robust Estimation: The Role of Overlap", "comment": "Corresponding to Fan Li, Department of Statistical Science, Duke University. Email: fl35@duke.edu", "summary": "The doubly-robust (DR) estimator is popular for evaluating causal effects in observational studies and is often perceived as more desirable than inverse probability weighting (IPW) or outcome modeling alone because it provides extra protection against model misspecification. However, double robustness is an asymptotic property that may not hold in finite samples. We investigate how the finite sample performance of the DR estimator depends on the degree of covariate overlap between comparison groups. Using analytical illustrations and extensive simulations under various scenarios with different degrees of covariate overlap and model specifications, we examine the bias and variance of the DR estimator relative to IPW and outcome modeling estimators. We find that: (i) specification of the outcome model has a stronger influence on the DR estimates than specification of the propensity score model, and this dominance increases as overlap decreases; (ii) with poor overlap, the DR estimator generally amplifies the adverse consequences of extreme weights (large bias and/or variance) regardless of model specifications, and is often inferior to both the IPW and outcome modeling estimators. As a practical guide, we recommend always first checking the degree of overlap in applications. In the case of poor overlap, analysts should consider shifting the target population to a subpopulation with adequate overlap via methods such as trimming or overlap weighting.", "AI": {"tldr": "\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\u5728\u534f\u53d8\u91cf\u91cd\u53e0\u5dee\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u4e0d\u5982IPW\u6216\u7ed3\u679c\u6a21\u578b\u4f30\u8ba1\u5668\uff0c\u5efa\u8bae\u5e94\u7528\u65f6\u5148\u68c0\u67e5\u91cd\u53e0\u7a0b\u5ea6\uff0c\u91cd\u53e0\u5dee\u65f6\u8003\u8651\u8c03\u6574\u76ee\u6807\u4eba\u7fa4\u3002", "motivation": "\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u88ab\u8ba4\u4e3a\u6bd4IPW\u6216\u7ed3\u679c\u6a21\u578b\u66f4\u7a33\u5065\uff0c\u4f46\u8fd9\u662f\u6e10\u8fd1\u6027\u8d28\uff0c\u6709\u9650\u6837\u672c\u4e0b\u8868\u73b0\u53ef\u80fd\u4e0d\u540c\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22DR\u4f30\u8ba1\u5668\u5728\u6709\u9650\u6837\u672c\u4e0b\u7684\u8868\u73b0\u5982\u4f55\u53d7\u534f\u53d8\u91cf\u91cd\u53e0\u7a0b\u5ea6\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u4e0d\u540c\u534f\u53d8\u91cf\u91cd\u53e0\u7a0b\u5ea6\u548c\u6a21\u578b\u8bbe\u5b9a\u573a\u666f\u4e0b\uff0c\u6bd4\u8f83DR\u4f30\u8ba1\u5668\u4e0eIPW\u3001\u7ed3\u679c\u6a21\u578b\u4f30\u8ba1\u5668\u7684\u504f\u5dee\u548c\u65b9\u5dee\u3002", "result": "\u53d1\u73b0\uff1a(1) \u7ed3\u679c\u6a21\u578b\u8bbe\u5b9a\u5bf9DR\u4f30\u8ba1\u7684\u5f71\u54cd\u6bd4\u503e\u5411\u5f97\u5206\u6a21\u578b\u66f4\u5f3a\uff0c\u4e14\u91cd\u53e0\u8d8a\u5dee\u8fd9\u79cd\u4e3b\u5bfc\u4f5c\u7528\u8d8a\u660e\u663e\uff1b(2) \u91cd\u53e0\u5dee\u65f6\uff0cDR\u4f30\u8ba1\u5668\u901a\u5e38\u4f1a\u653e\u5927\u6781\u7aef\u6743\u91cd\u7684\u4e0d\u826f\u540e\u679c\uff08\u5927\u504f\u5dee\u548c/\u6216\u65b9\u5dee\uff09\uff0c\u5f80\u5f80\u4e0d\u5982IPW\u548c\u7ed3\u679c\u6a21\u578b\u4f30\u8ba1\u5668\u3002", "conclusion": "\u5b9e\u9645\u5e94\u7528\u4e2d\u5e94\u9996\u5148\u68c0\u67e5\u534f\u53d8\u91cf\u91cd\u53e0\u7a0b\u5ea6\u3002\u5982\u679c\u91cd\u53e0\u5dee\uff0c\u5efa\u8bae\u901a\u8fc7\u4fee\u526a\u6216\u91cd\u53e0\u52a0\u6743\u7b49\u65b9\u6cd5\u5c06\u76ee\u6807\u4eba\u7fa4\u8c03\u6574\u5230\u6709\u8db3\u591f\u91cd\u53e0\u7684\u5b50\u4eba\u7fa4\u3002"}}
{"id": "2602.00716", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00716", "abs": "https://arxiv.org/abs/2602.00716", "authors": ["Enrico Ventura", "Beatrice Achilli", "Luca Ambrogioni", "Carlo Lucibello"], "title": "Emergence of Distortions in High-Dimensional Guided Diffusion Models", "comment": "ICML 2026 submission, 29 pages, 16 figures", "summary": "Classifier-free guidance (CFG) is the de facto standard for conditional sampling in diffusion models, yet it often leads to a loss of diversity in generated samples. We formalize this phenomenon as generative distortion, defined as the mismatch between the CFG-induced sampling distribution and the true conditional distribution. Considering Gaussian mixtures and their exact scores, and leveraging tools from statistical physics, we characterize the onset of distortion in a high-dimensional regime as a function of the number of classes. Our analysis reveals that distortions emerge through a phase transition in the effective potential governing the guided dynamics. In particular, our dynamical mean-field analysis shows that distortion persists when the number of modes grows exponentially with dimension, but vanishes in the sub-exponential regime. Consistent with prior finite-dimensional results, we further demonstrate that vanilla CFG shifts the mean and shrinks the variance of the conditional distribution. We show that standard CFG schedules are fundamentally incapable of preventing variance shrinkage. Finally, we propose a theoretically motivated guidance schedule featuring a negative-guidance window, which mitigates loss of diversity while preserving class separability.", "AI": {"tldr": "CFG\u5bfc\u81f4\u751f\u6210\u6837\u672c\u591a\u6837\u6027\u635f\u5931\uff0c\u4f5c\u8005\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u751f\u6210\u5931\u771f\uff0c\u5206\u6790\u4e86\u9ad8\u7ef4\u6761\u4ef6\u4e0b\u7684\u5931\u771f\u76f8\u53d8\uff0c\u63d0\u51fa\u8d1f\u5f15\u5bfc\u7a97\u53e3\u65b9\u6cd5\u7f13\u89e3\u591a\u6837\u6027\u635f\u5931", "motivation": "\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\uff08CFG\uff09\u662f\u6269\u6563\u6a21\u578b\u4e2d\u6761\u4ef6\u91c7\u6837\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u5e38\u5e38\u5bfc\u81f4\u751f\u6210\u6837\u672c\u591a\u6837\u6027\u635f\u5931\u3002\u4f5c\u8005\u65e8\u5728\u5f62\u5f0f\u5316\u8fd9\u4e00\u73b0\u8c61\u5e76\u7406\u89e3\u5176\u6839\u672c\u539f\u56e0", "method": "\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u53ca\u5176\u7cbe\u786e\u5206\u6570\uff0c\u501f\u52a9\u7edf\u8ba1\u7269\u7406\u5de5\u5177\u5206\u6790\u9ad8\u7ef4\u6761\u4ef6\u4e0b\u7684\u5931\u771f\u73b0\u8c61\uff1b\u8fdb\u884c\u52a8\u529b\u5b66\u5e73\u5747\u573a\u5206\u6790\uff1b\u63d0\u51fa\u8d1f\u5f15\u5bfc\u7a97\u53e3\u7684\u5f15\u5bfc\u8c03\u5ea6\u65b9\u6cd5", "result": "\u5931\u771f\u901a\u8fc7\u5f15\u5bfc\u52a8\u529b\u5b66\u6709\u6548\u52bf\u7684\u76f8\u53d8\u51fa\u73b0\uff1b\u5f53\u6a21\u5f0f\u6570\u91cf\u968f\u7ef4\u5ea6\u6307\u6570\u589e\u957f\u65f6\u5931\u771f\u6301\u7eed\u5b58\u5728\uff0c\u4f46\u5728\u6b21\u6307\u6570\u589e\u957f\u65f6\u6d88\u5931\uff1b\u6807\u51c6CFG\u65e0\u6cd5\u9632\u6b62\u65b9\u5dee\u6536\u7f29\uff1b\u63d0\u51fa\u7684\u8d1f\u5f15\u5bfc\u7a97\u53e3\u65b9\u6cd5\u80fd\u7f13\u89e3\u591a\u6837\u6027\u635f\u5931", "conclusion": "CFG\u5bfc\u81f4\u7684\u751f\u6210\u5931\u771f\u662f\u4e00\u4e2a\u76f8\u53d8\u73b0\u8c61\uff0c\u6807\u51c6CFG\u8c03\u5ea6\u65e0\u6cd5\u9632\u6b62\u65b9\u5dee\u6536\u7f29\uff0c\u4f46\u901a\u8fc7\u8d1f\u5f15\u5bfc\u7a97\u53e3\u7684\u6539\u8fdb\u8c03\u5ea6\u53ef\u4ee5\u5728\u4fdd\u6301\u7c7b\u522b\u53ef\u5206\u6027\u7684\u540c\u65f6\u7f13\u89e3\u591a\u6837\u6027\u635f\u5931"}}
{"id": "2602.01691", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01691", "abs": "https://arxiv.org/abs/2602.01691", "authors": ["Boyi Hu", "Jiguo Cao"], "title": "Locally sparse estimation for simultaneous functional quantile regression", "comment": null, "summary": "Motivated by the study of how daily temperature affects soybean yield, this article proposes a simultaneous functional quantile regression (FQR) model featuring a locally sparse bivariate slope function indexed by both quantile and time and linked to a functional predictor. The slope function's local sparsity means it holds non-zero values only in certain segments of its domain, remaining zero elsewhere. These zero-slope regions, which vary by quantile, indicate times when the functional predictor has no discernible impact on the response variable. This feature boosts the model's interpretability. Unlike traditional FQR models, which fit one quantile at a time and have several limitations, our proposed method can handle a spectrum of quantiles simultaneously. We tested the new approach through simulation studies, demonstrating its clear advantages over standard techniques. To validate its practical use, we applied the method to soybean yield data, pinpointing the time periods when daily temperature doesn't affect yield. This insight could be crucial for agricultural planning and crop management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5206\u4f4d\u6570\u7684\u51fd\u6570\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5177\u6709\u5c40\u90e8\u7a00\u758f\u7684\u53cc\u53d8\u91cf\u659c\u7387\u51fd\u6570\uff0c\u80fd\u591f\u8bc6\u522b\u529f\u80fd\u9884\u6d4b\u53d8\u91cf\u5bf9\u54cd\u5e94\u53d8\u91cf\u65e0\u5f71\u54cd\u7684\u65f6\u6bb5\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7814\u7a76\u65e5\u6e29\u5ea6\u5bf9\u5927\u8c46\u4ea7\u91cf\u7684\u5f71\u54cd\uff0c\u4f20\u7edf\u51fd\u6570\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u578b\u4e00\u6b21\u53ea\u80fd\u62df\u5408\u4e00\u4e2a\u5206\u4f4d\u6570\u4e14\u5b58\u5728\u591a\u79cd\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5206\u4f4d\u6570\u5e76\u80fd\u8bc6\u522b\u9884\u6d4b\u53d8\u91cf\u65e0\u5f71\u54cd\u65f6\u6bb5\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u540c\u65f6\u51fd\u6570\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u578b\uff0c\u5177\u6709\u5c40\u90e8\u7a00\u758f\u7684\u53cc\u53d8\u91cf\u659c\u7387\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5728\u5206\u4f4d\u6570\u548c\u65f6\u95f4\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u53d8\u5316\uff0c\u4e14\u4ec5\u5728\u7279\u5b9a\u57df\u6bb5\u975e\u96f6\uff0c\u5176\u4f59\u533a\u57df\u4e3a\u96f6\u3002\u8fd9\u4e9b\u96f6\u659c\u7387\u533a\u57df\u968f\u5206\u4f4d\u6570\u53d8\u5316\uff0c\u8868\u793a\u529f\u80fd\u9884\u6d4b\u53d8\u91cf\u5bf9\u54cd\u5e94\u53d8\u91cf\u65e0\u5f71\u54cd\u7684\u65f6\u6bb5\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b0\u65b9\u6cd5\u7684\u660e\u663e\u4f18\u52bf\uff0c\u5e76\u5728\u5927\u8c46\u4ea7\u91cf\u6570\u636e\u5e94\u7528\u4e2d\u6210\u529f\u8bc6\u522b\u51fa\u65e5\u6e29\u5ea6\u5bf9\u4ea7\u91cf\u65e0\u5f71\u54cd\u7684\u65f6\u95f4\u6bb5\uff0c\u4e3a\u519c\u4e1a\u89c4\u5212\u548c\u4f5c\u7269\u7ba1\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u540c\u65f6\u51fd\u6570\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u578b\u80fd\u591f\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5206\u4f4d\u6570\uff0c\u901a\u8fc7\u5c40\u90e8\u7a00\u758f\u7684\u659c\u7387\u51fd\u6570\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u80fd\u8bc6\u522b\u9884\u6d4b\u53d8\u91cf\u65e0\u5f71\u54cd\u7684\u65f6\u6bb5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u90fd\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.00797", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00797", "abs": "https://arxiv.org/abs/2602.00797", "authors": ["Yakun Wang", "Leyang Wang", "Song Liu", "Taiji Suzuki"], "title": "Zero-Flow Encoders", "comment": "Yakun Wang and Leyang Wang contributed equally to this work", "summary": "Flow-based methods have achieved significant success in various generative modeling tasks, capturing nuanced details within complex data distributions. However, few existing works have exploited this unique capability to resolve fine-grained structural details beyond generation tasks. This paper presents a flow-inspired framework for representation learning. First, we demonstrate that a rectified flow trained using independent coupling is zero everywhere at $t=0.5$ if and only if the source and target distributions are identical. We term this property the \\emph{zero-flow criterion}. Second, we show that this criterion can certify conditional independence, thereby extracting \\emph{sufficient information} from the data. Third, we translate this criterion into a tractable, simulation-free loss function that enables learning amortized Markov blankets in graphical models and latent representations in self-supervised learning tasks. Experiments on both simulated and real-world datasets demonstrate the effectiveness of our approach. The code reproducing our experiments can be found at: https://github.com/probabilityFLOW/zfe.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6d41\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u96f6\u6d41\u51c6\u5219\u9a8c\u8bc1\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u5b66\u4e60\u9a6c\u5c14\u53ef\u592b\u6bef\u548c\u6f5c\u5728\u8868\u793a", "motivation": "\u73b0\u6709\u6d41\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u751f\u6210\u4efb\u52a1\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u6355\u6349\u7cbe\u7ec6\u7ed3\u6784\u7ec6\u8282\u7684\u80fd\u529b\u8fdb\u884c\u8868\u793a\u5b66\u4e60\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6d41\u6a21\u578b\u5728\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "1) \u8bc1\u660e\u4f7f\u7528\u72ec\u7acb\u8026\u5408\u8bad\u7ec3\u7684\u6574\u6d41\u6d41\u5728t=0.5\u65f6\u5904\u5904\u4e3a\u96f6\u5f53\u4e14\u4ec5\u5f53\u6e90\u5206\u5e03\u548c\u76ee\u6807\u5206\u5e03\u76f8\u540c\uff08\u96f6\u6d41\u51c6\u5219\uff09\uff1b2) \u5c55\u793a\u8be5\u51c6\u5219\u53ef\u9a8c\u8bc1\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u63d0\u53d6\u6570\u636e\u7684\u5145\u5206\u4fe1\u606f\uff1b3) \u5c06\u8be5\u51c6\u5219\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u3001\u65e0\u9700\u6a21\u62df\u7684\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u5b66\u4e60\u56fe\u6a21\u578b\u4e2d\u7684\u644a\u9500\u9a6c\u5c14\u53ef\u592b\u6bef\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u8868\u793a\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u6210\u529f\u5b66\u4e60\u9a6c\u5c14\u53ef\u592b\u6bef\u548c\u6f5c\u5728\u8868\u793a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u6d41\u51c6\u5219\u5b9e\u73b0\u4e86\u6761\u4ef6\u72ec\u7acb\u6027\u7684\u9a8c\u8bc1\u548c\u5145\u5206\u4fe1\u606f\u7684\u63d0\u53d6\uff0c\u4e3a\u6d41\u6a21\u578b\u5728\u8868\u793a\u5b66\u4e60\u9886\u57df\u7684\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.01825", "categories": ["stat.ME", "cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01825", "abs": "https://arxiv.org/abs/2602.01825", "authors": ["Mingyuan Xu", "Zongqi Xia", "Tianxi Cai", "Doudou Zhou", "Nian Si"], "title": "Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes", "comment": null, "summary": "We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.", "AI": {"tldr": "\u4ece\u5f02\u6784\u591a\u7ad9\u70b9\u79bb\u7ebf\u6570\u636e\u4e2d\u5b66\u4e60\u9c81\u68d2\u987a\u5e8f\u51b3\u7b56\u7b56\u7565\uff0c\u4f7f\u7528\u5177\u6709\u7ec4\u7ebf\u6027\u7ed3\u6784\u7684\u5206\u5e03\u9c81\u68d2MDP\uff0c\u63d0\u51fa\u7279\u5f81\u7ea7\u4e0d\u786e\u5b9a\u6027\u96c6\u548c\u60b2\u89c2\u503c\u8fed\u4ee3\u7b97\u6cd5", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7ecf\u5e38\u4ece\u591a\u4e2a\u7ad9\u70b9\uff08\u5982\u533b\u9662\uff09\u6536\u96c6\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u5177\u6709\u5171\u540c\u7ed3\u6784\u4f46\u5b58\u5728\u5f02\u8d28\u6027\u3002\u9700\u8981\u4ece\u8fd9\u79cd\u79bb\u7ebf\u3001\u591a\u7ad9\u70b9\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u9c81\u68d2\u7684\u987a\u5e8f\u51b3\u7b56\u7b56\u7565\uff0c\u4ee5\u5e94\u5bf9\u8de8\u7ad9\u70b9\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "1. \u4f7f\u7528\u5177\u6709\u7ec4\u7ebf\u6027\u7ed3\u6784\u7684\u5206\u5e03\u9c81\u68d2MDP\uff1a\u6240\u6709\u7ad9\u70b9\u5171\u4eab\u5171\u540c\u7279\u5f81\u6620\u5c04\uff0c\u8f6c\u79fb\u6838\u548c\u671f\u671b\u5956\u52b1\u51fd\u6570\u5728\u8fd9\u4e9b\u5171\u4eab\u7279\u5f81\u4e0a\u662f\u7ebf\u6027\u7684\u30022. \u5f15\u5165\u7279\u5f81\u7ea7\uff08d-\u77e9\u5f62\uff09\u4e0d\u786e\u5b9a\u6027\u96c6\uff0c\u4fdd\u6301\u53ef\u5904\u7406\u7684\u9c81\u68d2Bellman\u9012\u5f52\u30023. \u5f00\u53d1\u57fa\u4e8e\u60b2\u89c2\u503c\u8fed\u4ee3\u7684\u79bb\u7ebf\u7b97\u6cd5\uff1a\u5305\u62ec\u7ad9\u70b9\u7ea7\u5cad\u56de\u5f52\u3001\u7279\u5f81\u7ea7\u6700\u574f\u60c5\u51b5\u805a\u5408\u3001\u57fa\u4e8e\u9006\u8bbe\u8ba1\u77e9\u9635\u5bf9\u89d2\u7ebf\u7684\u6570\u636e\u4f9d\u8d56\u60b2\u89c2\u60e9\u7f5a\u30024. \u63d0\u51fa\u805a\u7c7b\u7ea7\u6269\u5c55\uff0c\u901a\u8fc7\u5148\u9a8c\u7ad9\u70b9\u76f8\u4f3c\u6027\u77e5\u8bc6\u6c60\u5316\u76f8\u4f3c\u7ad9\u70b9\u3002", "result": "\u5728\u9c81\u68d2\u90e8\u5206\u8986\u76d6\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u4e86\u6240\u5f97\u7b56\u7565\u7684\u6b21\u4f18\u6027\u8fb9\u754c\u3002\u7b97\u6cd5\u80fd\u591f\u5904\u7406\u591a\u7ad9\u70b9\u5f02\u6784\u6570\u636e\u6e90\uff0c\u63d0\u4f9b\u9c81\u68d2\u89c4\u5212\u7684\u539f\u5219\u6027\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u591a\u7ad9\u70b9\u5b66\u4e60\u4e2d\u7684\u5f02\u8d28\u6570\u636e\u6e90\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e0d\u4f9d\u8d56\u5f3a\u72b6\u6001-\u52a8\u4f5c\u77e9\u5f62\u5047\u8bbe\u7684\u9c81\u68d2\u89c4\u5212\u539f\u5219\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u7ea7\u4e0d\u786e\u5b9a\u6027\u96c6\u548c\u805a\u7c7b\u6269\u5c55\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2602.00816", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00816", "abs": "https://arxiv.org/abs/2602.00816", "authors": ["Diego Granziol", "Khurshid Juarev"], "title": "Hessian Spectral Analysis at Foundation Model Scale", "comment": null, "summary": "Accurate Hessian spectra of foundation models have remained out of reach, leading most prior work to rely on small models or strong structural approximations. We show that faithful spectral analysis of the true Hessian is tractable at frontier scale. Using shard-local finite-difference Hessian vector products compatible with Fully Sharded Data Parallelism, we perform stochastic Lanczos quadrature on open-source language models with up to 100B parameters, producing the first large-scale spectral density estimates beyond the sub-10B regime. We characterize the numerical behavior of this pipeline, including finite-difference bias, floating-point noise amplification, and their effect on Krylov stability in fp32 and bf16, and derive practical operating regimes that are validated empirically. We further provide end-to-end runtime and memory scaling laws, showing that full-operator spectral probing incurs only a modest constant-factor overhead over first-order training. Crucially, direct access to the Hessian reveals that widely used block-diagonal curvature approximations can fail catastrophically, exhibiting order-one relative error and poor directional alignment even in mid-scale LLMs. Together, our results demonstrate that foundation-model Hessian spectra are both computable and qualitatively misrepresented by prevailing approximations, opening the door to principled curvature-based analysis at scale.", "AI": {"tldr": "\u9996\u6b21\u5728\u767e\u4ebf\u53c2\u6570\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4e86\u771f\u5b9eHessian\u77e9\u9635\u7684\u8c31\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u5757\u5bf9\u89d2\u8fd1\u4f3c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e25\u91cd\u5931\u6548\u95ee\u9898", "motivation": "\u4ee5\u5f80\u7531\u4e8e\u8ba1\u7b97\u56f0\u96be\uff0c\u57fa\u7840\u6a21\u578b\u7684Hessian\u8c31\u5206\u6790\u53ea\u80fd\u5728\u5c0f\u6a21\u578b\u6216\u5f3a\u7ed3\u6784\u8fd1\u4f3c\u4e0b\u8fdb\u884c\uff0c\u7f3a\u4e4f\u5bf9\u524d\u6cbf\u89c4\u6a21\u6a21\u578b\u771f\u5b9eHessian\u8c31\u7684\u51c6\u786e\u7406\u89e3", "method": "\u4f7f\u7528\u4e0e\u5b8c\u5168\u5206\u7247\u6570\u636e\u5e76\u884c\u517c\u5bb9\u7684\u5206\u7247\u5c40\u90e8\u6709\u9650\u5dee\u5206Hessian\u5411\u91cf\u4e58\u79ef\uff0c\u7ed3\u5408\u968f\u673aLanczos\u6c42\u79ef\u6cd5\uff0c\u5728fp32\u548cbf16\u7cbe\u5ea6\u4e0b\u5206\u6790\u6570\u503c\u884c\u4e3a", "result": "\u6210\u529f\u5728100B\u53c2\u6570\u89c4\u6a21\u4e0a\u83b7\u5f97\u9996\u4e2a\u5927\u89c4\u6a21\u8c31\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u53d1\u73b0\u4f20\u7edf\u5757\u5bf9\u89d2\u66f2\u7387\u8fd1\u4f3c\u5b58\u5728\u9636\u4e00\u76f8\u5bf9\u8bef\u5dee\u548c\u65b9\u5411\u5bf9\u9f50\u95ee\u9898\uff0c\u800c\u5168\u7b97\u5b50\u8c31\u63a2\u6d4b\u4ec5\u5e26\u6765\u9002\u5ea6\u5e38\u6570\u56e0\u5b50\u5f00\u9500", "conclusion": "\u57fa\u7840\u6a21\u578b\u7684Hessian\u8c31\u4e0d\u4ec5\u53ef\u8ba1\u7b97\uff0c\u800c\u4e14\u73b0\u6709\u8fd1\u4f3c\u65b9\u6cd5\u4e25\u91cd\u5931\u771f\uff0c\u4e3a\u5927\u89c4\u6a21\u66f2\u7387\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.00822", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00822", "abs": "https://arxiv.org/abs/2602.00822", "authors": ["Diego Granziol"], "title": "Safety-Efficacy Trade Off: Robustness against Data-Poisoning", "comment": null, "summary": "Backdoor and data poisoning attacks can achieve high attack success while evading existing spectral and optimisation based defences. We show that this behaviour is not incidental, but arises from a fundamental geometric mechanism in input space. Using kernel ridge regression as an exact model of wide neural networks, we prove that clustered dirty label poisons induce a rank one spike in the input Hessian whose magnitude scales quadratically with attack efficacy. Crucially, for nonlinear kernels we identify a near clone regime in which poison efficacy remains order one while the induced input curvature vanishes, making the attack provably spectrally undetectable. We further show that input gradient regularisation contracts poison aligned Fisher and Hessian eigenmodes under gradient flow, yielding an explicit and unavoidable safety efficacy trade off by reducing data fitting capacity. For exponential kernels, this defence admits a precise interpretation as an anisotropic high pass filter that increases the effective length scale and suppresses near clone poisons. Extensive experiments on linear models and deep convolutional networks across MNIST and CIFAR 10 and CIFAR 100 validate the theory, demonstrating consistent lags between attack success and spectral visibility, and showing that regularisation and data augmentation jointly suppress poisoning. Our results establish when backdoors are inherently invisible, and provide the first end to end characterisation of poisoning, detectability, and defence through input space curvature.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u540e\u95e8\u653b\u51fb\u548c\u6570\u636e\u6295\u6bd2\u653b\u51fb\u901a\u8fc7\u8f93\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u673a\u5236\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\u5e76\u89c4\u907f\u73b0\u6709\u9632\u5fa1\uff0c\u63ed\u793a\u4e86\u653b\u51fb\u6548\u679c\u4e0e\u8c31\u53ef\u89c1\u6027\u4e4b\u95f4\u7684\u6ede\u540e\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u8f93\u5165\u68af\u5ea6\u6b63\u5219\u5316\u8fdb\u884c\u9632\u5fa1\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8c31\u5206\u6790\u548c\u4f18\u5316\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u540e\u95e8\u548c\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u9700\u8981\u4ece\u7406\u8bba\u4e0a\u7406\u89e3\u653b\u51fb\u4e3a\u4f55\u80fd\u540c\u65f6\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u548c\u9690\u853d\u6027\uff0c\u5e76\u5efa\u7acb\u7cfb\u7edf\u7684\u653b\u51fb-\u68c0\u6d4b-\u9632\u5fa1\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u6838\u5cad\u56de\u5f52\u4f5c\u4e3a\u5bbd\u795e\u7ecf\u7f51\u7edc\u7684\u7cbe\u786e\u6a21\u578b\uff0c\u5206\u6790\u6295\u6bd2\u653b\u51fb\u5728\u8f93\u5165\u7a7a\u95f4\u4e2d\u7684\u51e0\u4f55\u673a\u5236\uff1b\u8bc1\u660e\u805a\u96c6\u7684\u810f\u6807\u7b7e\u6295\u6bd2\u4f1a\u5728\u8f93\u5165Hessian\u4e2d\u4ea7\u751f\u79e9\u4e00\u5c16\u5cf0\uff1b\u8bc6\u522b\u975e\u7ebf\u6027\u6838\u4e2d\u7684\u8fd1\u514b\u9686\u673a\u5236\uff1b\u63d0\u51fa\u8f93\u5165\u68af\u5ea6\u6b63\u5219\u5316\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u6295\u6bd2\u653b\u51fb\u6548\u679c\u4e0e\u8f93\u5165\u66f2\u7387\u4e4b\u95f4\u5b58\u5728\u4e8c\u6b21\u7f29\u653e\u5173\u7cfb\uff1b\u5728\u8fd1\u514b\u9686\u673a\u5236\u4e0b\uff0c\u653b\u51fb\u6548\u679c\u4fdd\u6301\u91cf\u7ea7\u800c\u8f93\u5165\u66f2\u7387\u6d88\u5931\uff0c\u4f7f\u653b\u51fb\u8c31\u4e0d\u53ef\u68c0\u6d4b\uff1b\u8f93\u5165\u68af\u5ea6\u6b63\u5219\u5316\u6536\u7f29\u6bd2\u7269\u5bf9\u9f50\u7684Fisher\u548cHessian\u7279\u5f81\u6a21\uff0c\u4ea7\u751f\u5b89\u5168-\u6548\u80fd\u6743\u8861\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u653b\u51fb\u6210\u529f\u7387\u548c\u8c31\u53ef\u89c1\u6027\u4e4b\u95f4\u7684\u6ede\u540e\u5173\u7cfb\u3002", "conclusion": "\u540e\u95e8\u653b\u51fb\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u56fa\u6709\u7684\u4e0d\u53ef\u89c1\u6027\uff1b\u8f93\u5165\u68af\u5ea6\u6b63\u5219\u5316\u901a\u8fc7\u6536\u7f29\u8f93\u5165\u7a7a\u95f4\u66f2\u7387\u63d0\u4f9b\u9632\u5fa1\uff0c\u4f46\u5b58\u5728\u5b89\u5168-\u6548\u80fd\u6743\u8861\uff1b\u9996\u6b21\u901a\u8fc7\u8f93\u5165\u7a7a\u95f4\u66f2\u7387\u5b8c\u6574\u523b\u753b\u4e86\u6295\u6bd2\u653b\u51fb\u3001\u53ef\u68c0\u6d4b\u6027\u548c\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2602.02172", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02172", "abs": "https://arxiv.org/abs/2602.02172", "authors": ["Jiuchen Zhang", "Ling Zhou", "Peter Song"], "title": "Neural Network Machine Regression (NNMR): A Deep Learning Framework for Uncovering High-order Synergistic Effects", "comment": null, "summary": "We propose a new neural network framework, termed Neural Network Machine Regression (NNMR), which integrates trainable input gating and adaptive depth regularization to jointly perform feature selection and function estimation in an end-to-end manner. By penalizing both gating parameters and redundant layers, NNMR yields sparse and interpretable architectures while capturing complex nonlinear relationships driven by high-order synergistic effects. We further develop a post-selection inference procedure based on split-sample, permutation-based hypothesis testing, enabling valid inference without restrictive parametric assumptions. Compared with existing methods, including Bayesian kernel machine regression and widely used post hoc attribution techniques, NNMR scales efficiently to high-dimensional feature spaces while rigorously controlling type I error. Simulation studies demonstrate its superior selection accuracy and inference reliability. Finally, an empirical application reveals sparse, biologically meaningful food group predictors associated with somatic growth among adolescents living in Mexico City.", "AI": {"tldr": "\u63d0\u51faNNMR\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u8f93\u5165\u95e8\u63a7\u548c\u81ea\u9002\u5e94\u6df1\u5ea6\u6b63\u5219\u5316\u8054\u5408\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u548c\u51fd\u6570\u4f30\u8ba1\uff0c\u652f\u6301\u540e\u9009\u62e9\u63a8\u65ad", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u4e2d\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u7684\u7279\u5f81\u9009\u62e9\u3001\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\u5efa\u6a21\u548c\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad", "method": "NNMR\u6846\u67b6\u6574\u5408\u53ef\u8bad\u7ec3\u8f93\u5165\u95e8\u63a7\uff08\u7279\u5f81\u9009\u62e9\uff09\u548c\u81ea\u9002\u5e94\u6df1\u5ea6\u6b63\u5219\u5316\uff08\u5197\u4f59\u5c42\u60e9\u7f5a\uff09\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u5206\u5272\u6837\u672c\u3001\u7f6e\u6362\u5047\u8bbe\u68c0\u9a8c\u7684\u540e\u9009\u62e9\u63a8\u65ad\u7a0b\u5e8f", "result": "\u76f8\u6bd4\u8d1d\u53f6\u65af\u6838\u673a\u5668\u56de\u5f52\u7b49\u73b0\u6709\u65b9\u6cd5\uff0cNNMR\u5728\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u4e2d\u6269\u5c55\u6548\u7387\u66f4\u9ad8\uff0c\u80fd\u4e25\u683c\u63a7\u5236I\u578b\u9519\u8bef\uff0c\u6a21\u62df\u7814\u7a76\u663e\u793a\u5176\u9009\u62e9\u51c6\u786e\u6027\u548c\u63a8\u65ad\u53ef\u9760\u6027\u66f4\u4f18", "conclusion": "NNMR\u63d0\u4f9b\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u7a00\u758f\u53ef\u89e3\u91ca\u67b6\u6784\uff0c\u80fd\u6355\u6349\u9ad8\u9636\u534f\u540c\u6548\u5e94\u7684\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u5728\u58a8\u897f\u54e5\u57ce\u9752\u5c11\u5e74\u751f\u957f\u7814\u7a76\u4e2d\u53d1\u73b0\u4e86\u5177\u6709\u751f\u7269\u5b66\u610f\u4e49\u7684\u7a00\u758f\u98df\u7269\u7ec4\u9884\u6d4b\u56e0\u5b50"}}
{"id": "2602.00825", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00825", "abs": "https://arxiv.org/abs/2602.00825", "authors": ["Kedar Karhadkar", "Alexander Sietsema", "Deanna Needell", "Guido Montufar"], "title": "Harmful Overfitting in Sobolev Spaces", "comment": null, "summary": "Motivated by recent work on benign overfitting in overparameterized machine learning, we study the generalization behavior of functions in Sobolev spaces $W^{k, p}(\\mathbb{R}^d)$ that perfectly fit a noisy training data set. Under assumptions of label noise and sufficient regularity in the data distribution, we show that approximately norm-minimizing interpolators, which are canonical solutions selected by smoothness bias, exhibit harmful overfitting: even as the training sample size $n \\to \\infty$, the generalization error remains bounded below by a positive constant with high probability. Our results hold for arbitrary values of $p \\in [1, \\infty)$, in contrast to prior results studying the Hilbert space case ($p = 2$) using kernel methods. Our proof uses a geometric argument which identifies harmful neighborhoods of the training data using Sobolev inequalities.", "AI": {"tldr": "\u7814\u7a76Sobolev\u7a7a\u95f4\u4e2d\u8303\u6570\u6700\u5c0f\u5316\u63d2\u503c\u5668\u7684\u6cdb\u5316\u884c\u4e3a\uff0c\u53d1\u73b0\u5728\u6807\u7b7e\u566a\u58f0\u548c\u8db3\u591f\u6b63\u5219\u7684\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u5373\u4f7f\u8bad\u7ec3\u6837\u672c\u91cf\u8d8b\u4e8e\u65e0\u7a77\uff0c\u6cdb\u5316\u8bef\u5dee\u4ecd\u4ee5\u9ad8\u6982\u7387\u4fdd\u6301\u6b63\u4e0b\u754c\uff0c\u8868\u660e\u5b58\u5728\u6709\u5bb3\u8fc7\u62df\u5408\u3002", "motivation": "\u53d7\u8fd1\u671f\u8fc7\u53c2\u6570\u5316\u673a\u5668\u5b66\u4e60\u4e2d\u826f\u6027\u8fc7\u62df\u5408\u7814\u7a76\u7684\u542f\u53d1\uff0c\u63a2\u7d22Sobolev\u7a7a\u95f4\u4e2d\u5b8c\u7f8e\u62df\u5408\u566a\u58f0\u8bad\u7ec3\u6570\u636e\u7684\u51fd\u6570\u7684\u6cdb\u5316\u884c\u4e3a\uff0c\u7279\u522b\u5173\u6ce8\u5e73\u6ed1\u6027\u504f\u7f6e\u9009\u62e9\u7684\u89c4\u8303\u6700\u5c0f\u5316\u63d2\u503c\u5668\u3002", "method": "\u5728\u6807\u7b7e\u566a\u58f0\u548c\u6570\u636e\u5206\u5e03\u8db3\u591f\u6b63\u5219\u7684\u5047\u8bbe\u4e0b\uff0c\u7814\u7a76Sobolev\u7a7a\u95f4W^{k,p}(\u211d^d)\u4e2d\u7684\u51fd\u6570\uff0c\u4f7f\u7528\u51e0\u4f55\u8bba\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7Sobolev\u4e0d\u7b49\u5f0f\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u7684\u6709\u5bb3\u90bb\u57df\u3002", "result": "\u8fd1\u4f3c\u8303\u6570\u6700\u5c0f\u5316\u63d2\u503c\u5668\u8868\u73b0\u51fa\u6709\u5bb3\u8fc7\u62df\u5408\uff1a\u5373\u4f7f\u8bad\u7ec3\u6837\u672c\u91cfn\u2192\u221e\uff0c\u6cdb\u5316\u8bef\u5dee\u4ecd\u4ee5\u9ad8\u6982\u7387\u4fdd\u6301\u6b63\u4e0b\u754c\u3002\u8be5\u7ed3\u679c\u9002\u7528\u4e8e\u4efb\u610fp\u2208[1,\u221e)\uff0c\u6269\u5c55\u4e86\u5148\u524d\u4ec5\u7814\u7a76\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(p=2)\u7684\u60c5\u51b5\u3002", "conclusion": "\u5728Sobolev\u7a7a\u95f4\u4e2d\uff0c\u5e73\u6ed1\u6027\u504f\u7f6e\u9009\u62e9\u7684\u89c4\u8303\u6700\u5c0f\u5316\u63d2\u503c\u5668\u5728\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u65f6\u4f1a\u5bfc\u81f4\u6709\u5bb3\u8fc7\u62df\u5408\uff0c\u5373\u4f7f\u6837\u672c\u91cf\u65e0\u9650\u589e\u5927\u4e5f\u65e0\u6cd5\u907f\u514d\u6cdb\u5316\u8bef\u5dee\u7684\u6b63\u4e0b\u754c\uff0c\u8fd9\u4e00\u73b0\u8c61\u5728\u4efb\u610fp\u503c\u4e0b\u5747\u6210\u7acb\u3002"}}
{"id": "2602.00835", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00835", "abs": "https://arxiv.org/abs/2602.00835", "authors": ["Ahmed Aloui", "Junyi Liao", "Ali Hasan", "Jose Blanchet", "Vahid Tarokh"], "title": "Score-based Metropolis-Hastings for Fractional Langevin Algorithms", "comment": null, "summary": "Sampling from heavy-tailed and multimodal distributions is challenging when neither the target density nor the proposal density can be evaluated, as in $\u03b1$-stable L\u00e9vy-driven fractional Langevin algorithms. While the target distribution can be estimated from data via score-based or energy-based models, the $\u03b1$-stable proposal density and its score are generally unavailable, rendering classical density-based Metropolis--Hastings (MH) corrections impractical. Consequently, existing fractional Langevin methods operate in an unadjusted regime and can exhibit substantial finite-time errors and poor empirical control of tail behavior. We introduce the Metropolis-Adjusted Fractional Langevin Algorithm (MAFLA), an MH-inspired, fully score-based correction mechanism. MAFLA employs designed proxies for fractional proposal score gradients under isotropic symmetric $\u03b1$-stable noise and learns an acceptance function via Score Balance Matching. We empirically illustrate the strong performance of MAFLA on a series of tasks including combinatorial optimization problems where the method significantly improves finite time sampling accuracy over unadjusted fractional Langevin dynamics.", "AI": {"tldr": "MAFLA\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u7684Metropolis-Hastings\u6821\u6b63\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u03b1\u7a33\u5b9aL\u00e9vy\u9a71\u52a8\u7684\u5206\u6570Langevin\u7b97\u6cd5\u5728\u91cd\u5c3e\u591a\u5cf0\u5206\u5e03\u91c7\u6837\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u76ee\u6807\u5206\u5e03\u548c\u63d0\u8bae\u5206\u5e03\u90fd\u65e0\u6cd5\u76f4\u63a5\u8bc4\u4f30\u65f6\uff08\u5982\u03b1\u7a33\u5b9aL\u00e9vy\u9a71\u52a8\u7684\u5206\u6570Langevin\u7b97\u6cd5\uff09\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u5bc6\u5ea6\u7684Metropolis-Hastings\u6821\u6b63\u4e0d\u53ef\u884c\u3002\u73b0\u6709\u7684\u5206\u6570Langevin\u65b9\u6cd5\u5728\u672a\u6821\u6b63\u72b6\u6001\u4e0b\u8fd0\u884c\uff0c\u5b58\u5728\u663e\u8457\u7684\u6709\u9650\u65f6\u95f4\u8bef\u5dee\u548c\u5bf9\u5c3e\u90e8\u884c\u4e3a\u7684\u63a7\u5236\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u63d0\u51faMetropolis-Adjusted Fractional Langevin Algorithm (MAFLA)\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u7684MH\u6821\u6b63\u673a\u5236\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5728\u5404\u9879\u540c\u6027\u5bf9\u79f0\u03b1\u7a33\u5b9a\u566a\u58f0\u4e0b\u8bbe\u8ba1\u5206\u6570\u63d0\u8bae\u68af\u5ea6\u4ee3\u7406\uff1b2) \u901a\u8fc7Score Balance Matching\u5b66\u4e60\u63a5\u53d7\u51fd\u6570\u3002", "result": "MAFLA\u5728\u4e00\u7cfb\u5217\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u76f8\u6bd4\u672a\u6821\u6b63\u7684\u5206\u6570Langevin\u52a8\u529b\u5b66\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6709\u9650\u65f6\u95f4\u91c7\u6837\u7684\u51c6\u786e\u6027\u3002", "conclusion": "MAFLA\u4e3a\u5206\u6570Langevin\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u57fa\u4e8e\u5206\u6570\u7684Metropolis-Hastings\u6821\u6b63\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u91cd\u5c3e\u591a\u5cf0\u5206\u5e03\u91c7\u6837\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u76ee\u6807\u5206\u5e03\u548c\u63d0\u8bae\u5206\u5e03\u90fd\u65e0\u6cd5\u76f4\u63a5\u8bc4\u4f30\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2602.02240", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02240", "abs": "https://arxiv.org/abs/2602.02240", "authors": ["Zihang Wang", "Razieh Nabi", "Benjamin B. Risk"], "title": "Causal Inference for Preprocessed Outcomes with an Application to Functional Connectivity", "comment": "55 pages, 5 figures, 2 tables", "summary": "In biomedical research, repeated measurements within each subject are often processed to remove artifacts and unwanted sources of variation. The resulting data are used to construct derived outcomes that act as proxies for scientific outcomes that are not directly observable. Although intra-subject processing is widely used, its impact on inter-subject statistical inference has not been systematically studied, and a principled framework for causal analysis in this setting is lacking. In this article, we propose a semiparametric framework for causal inference with derived outcomes obtained after intra-subject processing. This framework applies to settings with a modular structure, where intra-subject analyses are conducted independently across subjects and are followed by inter-subject analyses based on parameters from the intra-subject stage. We develop multiply robust estimators of causal parameters under rate conditions on both intra-subject and inter-subject models, which allows the use of flexible machine learning. We specialize the framework to a mediation setting and focus on the natural direct effect. For high dimensional inference, we employ a step-down procedure that controls the exceedance rate of the false discovery proportion. Simulation studies demonstrate the superior performance of the proposed approach. We apply our method to estimate the impact of stimulant medication on brain connectivity in children with autism spectrum disorder.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u534a\u53c2\u6570\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7ecf\u8fc7\u53d7\u8bd5\u8005\u5185\u5904\u7406\u5f97\u5230\u7684\u884d\u751f\u7ed3\u679c\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6a21\u5757\u5316\u7ed3\u6784\u7684\u7814\u7a76\u8bbe\u8ba1\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\uff0c\u53d7\u8bd5\u8005\u5185\u91cd\u590d\u6d4b\u91cf\u6570\u636e\u5e38\u88ab\u5904\u7406\u4ee5\u53bb\u9664\u4f2a\u5f71\u548c\u53d8\u5f02\uff0c\u5f97\u5230\u7684\u884d\u751f\u7ed3\u679c\u4f5c\u4e3a\u4e0d\u53ef\u76f4\u63a5\u89c2\u6d4b\u79d1\u5b66\u7ed3\u679c\u7684\u4ee3\u7406\u3002\u5c3d\u7ba1\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u53d7\u8bd5\u8005\u5185\u5904\u7406\u5bf9\u53d7\u8bd5\u8005\u95f4\u7edf\u8ba1\u63a8\u65ad\u7684\u5f71\u54cd\u5c1a\u672a\u7cfb\u7edf\u7814\u7a76\uff0c\u7f3a\u4e4f\u8be5\u573a\u666f\u4e0b\u7684\u56e0\u679c\u5206\u6790\u539f\u5219\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u534a\u53c2\u6570\u56e0\u679c\u63a8\u65ad\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u6a21\u5757\u5316\u7ed3\u6784\uff08\u53d7\u8bd5\u8005\u5185\u5206\u6790\u72ec\u7acb\u8fdb\u884c\uff0c\u7136\u540e\u57fa\u4e8e\u53d7\u8bd5\u8005\u5185\u53c2\u6570\u8fdb\u884c\u53d7\u8bd5\u8005\u95f4\u5206\u6790\uff09\u3002\u5f00\u53d1\u591a\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u5141\u8bb8\u4f7f\u7528\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002\u4e13\u95e8\u5316\u5230\u4e2d\u4ecb\u5206\u6790\u573a\u666f\uff0c\u805a\u7126\u81ea\u7136\u76f4\u63a5\u6548\u5e94\u3002\u9ad8\u7ef4\u63a8\u65ad\u91c7\u7528\u63a7\u5236\u9519\u8bef\u53d1\u73b0\u6bd4\u4f8b\u8d85\u9650\u7387\u7684\u9010\u6b65\u4e0b\u964d\u7a0b\u5e8f\u3002", "result": "\u6a21\u62df\u7814\u7a76\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\u3002\u5e94\u7528\u4e8e\u4f30\u8ba1\u5174\u594b\u5242\u836f\u7269\u5bf9\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d\u513f\u7ae5\u5927\u8111\u8fde\u63a5\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u7ecf\u8fc7\u53d7\u8bd5\u8005\u5185\u5904\u7406\u5f97\u5230\u7684\u884d\u751f\u7ed3\u679c\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u91cd\u8981\u7814\u7a76\u9886\u57df\u7684\u7a7a\u767d\uff0c\u652f\u6301\u5728\u6a21\u5757\u5316\u7814\u7a76\u8bbe\u8ba1\u4e2d\u5e94\u7528\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u7a33\u5065\u56e0\u679c\u63a8\u65ad\u3002"}}
{"id": "2602.02246", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02246", "abs": "https://arxiv.org/abs/2602.02246", "authors": ["Jiuchen Zhang", "Annie Qu"], "title": "Cumulative Treatment Effect Testing under Continuous Time Reinforcement Learning", "comment": null, "summary": "Understanding the impact of treatment effect over time is a fundamental aspect of many scientific and medical studies. In this paper, we introduce a novel approach under a continuous-time reinforcement learning framework for testing a treatment effect. Specifically, our method provides an effective test on carryover effects of treatment over time utilizing the average treatment effect (ATE). The average treatment effect is defined as difference of value functions over an infinite horizon, which accounts for cumulative treatment effects, both immediate and carryover. The proposed method outperforms existing testing procedures such as discrete time reinforcement learning strategies in multi-resolution observation settings where observation times can be irregular. Another advantage of the proposed method is that it can capture treatment effects of a shorter duration and provide greater accuracy compared to discrete-time approximations, through the use of continuous-time estimation for the value function. We establish the asymptotic normality of the proposed test statistics and apply it to OhioT1DM diabetes data to evaluate the cumulative treatment effects of bolus insulin on patients' glucose levels.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7684\u68c0\u9a8c\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u6cbb\u7597\u968f\u65f6\u95f4\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u6cbb\u7597\u7684\u6ede\u540e\u6548\u5e94\uff0c\u5728\u975e\u89c4\u5219\u89c2\u6d4b\u65f6\u95f4\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u79bb\u6563\u65f6\u95f4\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3\u6cbb\u7597\u6548\u5e94\u968f\u65f6\u95f4\u7684\u5f71\u54cd\u662f\u8bb8\u591a\u79d1\u5b66\u548c\u533b\u5b66\u7814\u7a76\u7684\u57fa\u672c\u65b9\u9762\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u975e\u89c4\u5219\u89c2\u6d4b\u65f6\u95f4\u8bbe\u7f6e\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u68c0\u9a8c\u6cbb\u7597\u7684\u6ede\u540e\u6548\u5e94\u3002", "method": "\u5728\u8fde\u7eed\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e0b\uff0c\u5229\u7528\u5e73\u5747\u6cbb\u7597\u6548\u5e94\uff08ATE\uff09\u68c0\u9a8c\u6cbb\u7597\u7684\u6ede\u540e\u6548\u5e94\u3002ATE\u5b9a\u4e49\u4e3a\u65e0\u9650\u65f6\u95f4\u8303\u56f4\u5185\u4ef7\u503c\u51fd\u6570\u7684\u5dee\u5f02\uff0c\u8003\u8651\u4e86\u7d2f\u79ef\u6cbb\u7597\u6548\u5e94\uff08\u5305\u62ec\u5373\u65f6\u548c\u6ede\u540e\u6548\u5e94\uff09\u3002\u901a\u8fc7\u8fde\u7eed\u65f6\u95f4\u4f30\u8ba1\u4ef7\u503c\u51fd\u6570\uff0c\u80fd\u591f\u6355\u6349\u8f83\u77ed\u6301\u7eed\u65f6\u95f4\u7684\u6cbb\u7597\u6548\u5e94\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u975e\u89c4\u5219\u89c2\u6d4b\u65f6\u95f4\u7684\u591a\u5206\u8fa8\u7387\u89c2\u6d4b\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u79bb\u6563\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002\u5efa\u7acb\u4e86\u68c0\u9a8c\u7edf\u8ba1\u91cf\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5e76\u5728OhioT1DM\u7cd6\u5c3f\u75c5\u6570\u636e\u4e0a\u6210\u529f\u5e94\u7528\uff0c\u8bc4\u4f30\u4e86\u63a8\u6ce8\u80f0\u5c9b\u7d20\u5bf9\u60a3\u8005\u8840\u7cd6\u6c34\u5e73\u7684\u7d2f\u79ef\u6cbb\u7597\u6548\u5e94\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fde\u7eed\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3a\u68c0\u9a8c\u6cbb\u7597\u968f\u65f6\u95f4\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u975e\u89c4\u5219\u89c2\u6d4b\u65f6\u95f4\u8bbe\u7f6e\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6355\u6349\u6cbb\u7597\u6548\u5e94\uff0c\u5305\u62ec\u77ed\u671f\u6548\u5e94\u548c\u6ede\u540e\u6548\u5e94\u3002"}}
{"id": "2602.00989", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00989", "abs": "https://arxiv.org/abs/2602.00989", "authors": ["Tao Wang", "Edgar Dobriban"], "title": "Optimal Decision-Making Based on Prediction Sets", "comment": null, "summary": "Prediction sets can wrap around any ML model to cover unknown test outcomes with a guaranteed probability. Yet, it remains unclear how to use them optimally for downstream decision-making. Here, we propose a decision-theoretic framework that seeks to minimize the expected loss (risk) against a worst-case distribution consistent with the prediction set's coverage guarantee. We first characterize the minimax optimal policy for a fixed prediction set, showing that it balances the worst-case loss inside the set with a penalty for potential losses outside the set. Building on this, we derive the optimal prediction set construction that minimizes the resulting robust risk subject to a coverage constraint. Finally, we introduce Risk-Optimal Conformal Prediction (ROCP), a practical algorithm that targets these risk-minimizing sets while maintaining finite-sample distribution-free marginal coverage. Empirical evaluations on medical diagnosis and safety-critical decision-making tasks demonstrate that ROCP reduces critical mistakes compared to baselines, particularly when out-of-set errors are costly.", "AI": {"tldr": "\u63d0\u51faRisk-Optimal Conformal Prediction (ROCP)\u6846\u67b6\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u6982\u7387\u7684\u524d\u63d0\u4e0b\u6700\u5c0f\u5316\u51b3\u7b56\u98ce\u9669\uff0c\u7279\u522b\u5173\u6ce8\u96c6\u5408\u5916\u9519\u8bef\u7684\u4ee3\u4ef7\u3002", "motivation": "\u9884\u6d4b\u96c6\u5408\u867d\u7136\u80fd\u4e3aML\u6a21\u578b\u63d0\u4f9b\u6982\u7387\u4fdd\u8bc1\u7684\u8986\u76d6\uff0c\u4f46\u5982\u4f55\u5c06\u5176\u6700\u4f18\u5730\u7528\u4e8e\u4e0b\u6e38\u51b3\u7b56\u4ecd\u4e0d\u660e\u786e\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u51b3\u7b56\u98ce\u9669\uff0c\u7279\u522b\u662f\u96c6\u5408\u5916\u9519\u8bef\u7684\u4ee3\u4ef7\u3002", "method": "1) \u5efa\u7acb\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u5728\u9884\u6d4b\u96c6\u5408\u8986\u76d6\u4fdd\u8bc1\u4e0b\u6700\u5c0f\u5316\u6700\u574f\u60c5\u51b5\u5206\u5e03\u7684\u671f\u671b\u635f\u5931\uff1b2) \u63a8\u5bfc\u56fa\u5b9a\u9884\u6d4b\u96c6\u5408\u4e0b\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7b56\u7565\uff1b3) \u8bbe\u8ba1\u6700\u5c0f\u5316\u9c81\u68d2\u98ce\u9669\u7684\u6700\u4f18\u9884\u6d4b\u96c6\u5408\u6784\u9020\uff1b4) \u63d0\u51faROCP\u5b9e\u7528\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u6709\u9650\u6837\u672c\u5206\u5e03\u65e0\u5173\u8fb9\u9645\u8986\u76d6\u7684\u540c\u65f6\u5b9e\u73b0\u98ce\u9669\u6700\u5c0f\u5316\u3002", "result": "\u5728\u533b\u7597\u8bca\u65ad\u548c\u5b89\u5168\u5173\u952e\u51b3\u7b56\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cROCP\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c11\u4e86\u5173\u952e\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u96c6\u5408\u5916\u9519\u8bef\u4ee3\u4ef7\u9ad8\u6602\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "ROCP\u6846\u67b6\u5c06\u9884\u6d4b\u96c6\u5408\u4e0e\u51b3\u7b56\u98ce\u9669\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u6982\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5173\u952e\u9519\u8bef\u7684\u53d1\u751f\u3002"}}
{"id": "2602.02265", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02265", "abs": "https://arxiv.org/abs/2602.02265", "authors": ["Chan Park", "Eric Tchetgen Tchetgen"], "title": "Nonparametric Inference with an Instrumental Variable under a Separable Binary Treatment Choice Model", "comment": null, "summary": "Instrumental variable (IV) methods are widely used to infer treatment effects in the presence of unmeasured confounding. In this paper, we study nonparametric inference with an IV under a separable binary treatment choice model, which posits that the odds of the probability of taking the treatment, conditional on the instrument and the treatment-free potential outcome, factor into separable components for each variable. While nonparametric identification of smooth functionals of the treatment-free potential outcome among the treated, such as the average treatment effect on the treated, has been established under this model, corresponding nonparametric efficient estimation has proven elusive due to variationally dependent nuisance parameters defined in terms of counterfactual quantities. To address this challenge, we introduce a new variationally independent parameterization based on nuisance functions defined directly from the observed data. This parameterization, coupled with a novel fixed-point argument, enables the use of modern machine learning methods for nuisance function estimation. We characterize the semiparametric efficiency bound for any smooth functional of the treatment-free potential outcome among the treated and construct a corresponding semiparametric efficient estimator without imposing any unnecessary restriction on nuisance functions. Furthermore, we describe a straightforward generative model justifying our identifying assumptions and characterize empirically falsifiable implications of the framework to evaluate our assumptions in practical settings. Our approach seamlessly extends to nonlinear treatment effects, population-level effects, and nonignorable missing data settings. We illustrate our methods through simulation studies and an application to the Job Corps study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u975e\u53c2\u6570\u9ad8\u6548\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u53ef\u5206\u79bb\u4e8c\u5143\u5904\u7406\u9009\u62e9\u6a21\u578b\u4e0b\u8fdb\u884c\u5de5\u5177\u53d8\u91cf\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7531\u4e8e\u53cd\u4e8b\u5b9e\u91cf\u5b9a\u4e49\u5bfc\u81f4\u7684\u53d8\u5206\u4f9d\u8d56\u95ee\u9898\u3002", "motivation": "\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\u5728\u5b58\u5728\u672a\u6d4b\u91cf\u6df7\u6742\u56e0\u7d20\u65f6\u88ab\u5e7f\u6cdb\u7528\u4e8e\u63a8\u65ad\u5904\u7406\u6548\u5e94\u3002\u7136\u800c\uff0c\u5728\u53ef\u5206\u79bb\u4e8c\u5143\u5904\u7406\u9009\u62e9\u6a21\u578b\u4e0b\uff0c\u5c3d\u7ba1\u5df2\u7ecf\u5efa\u7acb\u4e86\u5bf9\u5904\u7406\u7ec4\u4e2d\u5904\u7406\u81ea\u7531\u6f5c\u5728\u7ed3\u679c\u7684\u5e73\u6ed1\u6cdb\u51fd\u7684\u975e\u53c2\u6570\u8bc6\u522b\uff0c\u4f46\u7531\u4e8e\u53cd\u4e8b\u5b9e\u91cf\u5b9a\u4e49\u7684\u53d8\u5206\u4f9d\u8d56\u95ee\u9898\uff0c\u76f8\u5e94\u7684\u975e\u53c2\u6570\u9ad8\u6548\u4f30\u8ba1\u4e00\u76f4\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u89c2\u6d4b\u6570\u636e\u76f4\u63a5\u5b9a\u4e49\u7684\u53d8\u5206\u72ec\u7acb\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u4e0d\u52a8\u70b9\u8bba\u8bc1\uff0c\u5229\u7528\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u5e72\u6270\u51fd\u6570\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u8868\u5f81\u5904\u7406\u7ec4\u4e2d\u5904\u7406\u81ea\u7531\u6f5c\u5728\u7ed3\u679c\u7684\u4efb\u4f55\u5e73\u6ed1\u6cdb\u51fd\u7684\u534a\u53c2\u6570\u6548\u7387\u754c\uff0c\u5e76\u6784\u5efa\u76f8\u5e94\u7684\u534a\u53c2\u6570\u9ad8\u6548\u4f30\u8ba1\u5668\u3002", "result": "\u5efa\u7acb\u4e86\u975e\u53c2\u6570\u9ad8\u6548\u4f30\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4e0d\u5f3a\u52a0\u4e0d\u5fc5\u8981\u9650\u5236\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5e72\u6270\u51fd\u6570\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u53ef\u65e0\u7f1d\u6269\u5c55\u5230\u975e\u7ebf\u6027\u5904\u7406\u6548\u5e94\u3001\u603b\u4f53\u6c34\u5e73\u6548\u5e94\u548c\u975e\u53ef\u5ffd\u7565\u7f3a\u5931\u6570\u636e\u8bbe\u7f6e\u3002\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548cJob Corps\u7814\u7a76\u7684\u5e94\u7528\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b0\u53c2\u6570\u5316\u65b9\u6cd5\u548c\u4e0d\u52a8\u70b9\u8bba\u8bc1\u89e3\u51b3\u4e86\u5de5\u5177\u53d8\u91cf\u5206\u6790\u4e2d\u7684\u53d8\u5206\u4f9d\u8d56\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u975e\u53c2\u6570\u9ad8\u6548\u4f30\u8ba1\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7edf\u8ba1\u63a8\u65ad\u6846\u67b6\uff0c\u5e76\u53ef\u901a\u8fc7\u7ecf\u9a8c\u53ef\u8bc1\u4f2a\u7684\u9690\u542b\u6761\u4ef6\u6765\u8bc4\u4f30\u5047\u8bbe\u7684\u5408\u7406\u6027\u3002"}}
{"id": "2602.01400", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01400", "abs": "https://arxiv.org/abs/2602.01400", "authors": ["Kanad Pardeshi", "Samsara Foubert", "Aarti Singh"], "title": "Online Social Welfare Function-based Resource Allocation", "comment": null, "summary": "In many real-world settings, a centralized decision-maker must repeatedly allocate finite resources to a population over multiple time steps. Individuals who receive a resource derive some stochastic utility; to characterize the population-level effects of an allocation, the expected individual utilities are then aggregated using a social welfare function (SWF). We formalize this setting and present a general confidence sequence framework for SWF-based online learning and inference, valid for any monotonic, concave, and Lipschitz-continuous SWF. Our key insight is that monotonicity alone suffices to lift confidence sequences from individual utilities to anytime-valid bounds on optimal welfare. Building on this foundation, we propose SWF-UCB, a SWF-agnostic online learning algorithm that achieves near-optimal $\\tilde{O}(n+\\sqrt{nkT})$ regret (for $k$ resources distributed among $n$ individuals at each of $T$ time steps). We instantiate our framework on three normatively distinct SWF families: Weighted Power Mean, Kolm, and Gini, providing bespoke oracle algorithms for each. Experiments confirm $\\sqrt{T}$ scaling and reveal rich interactions between $k$ and SWF parameters. This framework naturally supports inference applications such as sequential hypothesis testing, optimal stopping, and policy evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u793e\u4f1a\u798f\u5229\u51fd\u6570\uff08SWF\uff09\u7684\u5728\u7ebf\u5b66\u4e60\u548c\u63a8\u65ad\u901a\u7528\u7f6e\u4fe1\u5e8f\u5217\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u5355\u8c03\u3001\u51f9\u4e14Lipschitz\u8fde\u7eed\u7684\u793e\u4f1a\u798f\u5229\u51fd\u6570\uff0c\u5e76\u8bbe\u8ba1\u4e86SWF-UCB\u7b97\u6cd5\u5b9e\u73b0\u8fd1\u4e4e\u6700\u4f18\u7684\u9057\u61be\u754c\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u96c6\u4e2d\u51b3\u7b56\u8005\u9700\u8981\u591a\u6b21\u5c06\u6709\u9650\u8d44\u6e90\u5206\u914d\u7ed9\u4eba\u7fa4\uff0c\u4e2a\u4f53\u83b7\u5f97\u8d44\u6e90\u540e\u4ea7\u751f\u968f\u673a\u6548\u7528\uff0c\u9700\u8981\u901a\u8fc7\u793e\u4f1a\u798f\u5229\u51fd\u6570\u6765\u8bc4\u4f30\u5206\u914d\u6548\u679c\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u9002\u7528\u4e8e\u5404\u79cd\u793e\u4f1a\u798f\u5229\u51fd\u6570\u7684\u7edf\u4e00\u5728\u7ebf\u5b66\u4e60\u548c\u63a8\u65ad\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7f6e\u4fe1\u5e8f\u5217\u6846\u67b6\uff0c\u5173\u952e\u6d1e\u5bdf\u662f\u5355\u8c03\u6027\u8db3\u4ee5\u5c06\u7f6e\u4fe1\u5e8f\u5217\u4ece\u4e2a\u4f53\u6548\u7528\u63d0\u5347\u5230\u6700\u4f18\u798f\u5229\u7684\u4efb\u610f\u65f6\u95f4\u6709\u6548\u8fb9\u754c\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86SWF-UCB\u7b97\u6cd5\uff0c\u5e76\u5728\u4e09\u4e2a\u89c4\u8303\u4e0d\u540c\u7684\u793e\u4f1a\u798f\u5229\u51fd\u6570\u65cf\uff08\u52a0\u6743\u5e42\u5747\u503c\u3001Kolm\u548cGini\uff09\u4e0a\u5b9e\u4f8b\u5316\u6846\u67b6\u3002", "result": "SWF-UCB\u7b97\u6cd5\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684$\\tilde{O}(n+\\sqrt{nkT})$\u9057\u61be\u754c\uff08k\u4e2a\u8d44\u6e90\u5728T\u4e2a\u65f6\u95f4\u6b65\u4e2d\u5206\u914d\u7ed9n\u4e2a\u4e2a\u4f53\uff09\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u4e86$\\sqrt{T}$\u7f29\u653e\uff0c\u5e76\u63ed\u793a\u4e86k\u4e0eSWF\u53c2\u6570\u4e4b\u95f4\u7684\u4e30\u5bcc\u4ea4\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u57fa\u4e8e\u793e\u4f1a\u798f\u5229\u51fd\u6570\u7684\u5728\u7ebf\u5b66\u4e60\u548c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7edf\u4e00\u65b9\u6cd5\uff0c\u652f\u6301\u987a\u5e8f\u5047\u8bbe\u68c0\u9a8c\u3001\u6700\u4f18\u505c\u6b62\u548c\u653f\u7b56\u8bc4\u4f30\u7b49\u63a8\u65ad\u5e94\u7528\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2602.02277", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02277", "abs": "https://arxiv.org/abs/2602.02277", "authors": ["Duncan Lee", "Vinny Davies"], "title": "A spatial random forest algorithm for population-level epidemiological risk assessment", "comment": null, "summary": "Spatial epidemiology identifies the drivers of elevated population-level disease risks, using disease counts, exposures and known confounders at the areal unit level. Poisson regression models are typically used for inference, which incorporate a linear/additive regression component and allow for unmeasured confounding via a set of spatially autocorrelated random effects. This approach requires the confounder interactions and their functional relationships with disease risk to be specified in advance, rather than being learned from the data. Therefore, this paper proposes the SPAR-Forest-ERF algorithm, which is the first fusion of random forests for capturing non-linear and interacting confounder-response effects with Bayesian spatial autocorrelation models that can estimate interpretable exposure response functions (ERF) with full uncertainty quantification. Methodologically, we extend existing methods set in a prediction context by propagating uncertainty between both the ML and statistical models, developing a new stopping criteria designed to ensure the stability of the primary inferential target, and incorporating a range of different ERFs for maximum model flexibility. This methodology is motivated by a new study quantifying the impact of air pollution concentrations on self-rated health in Scotland, using data from the recently released 2022 national census.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SPAR-Forest-ERF\u7b97\u6cd5\uff0c\u9996\u6b21\u5c06\u968f\u673a\u68ee\u6797\uff08\u7528\u4e8e\u6355\u6349\u975e\u7ebf\u6027\u4ea4\u4e92\u6548\u5e94\uff09\u4e0e\u8d1d\u53f6\u65af\u7a7a\u95f4\u81ea\u76f8\u5173\u6a21\u578b\uff08\u7528\u4e8e\u4f30\u8ba1\u53ef\u89e3\u91ca\u7684\u66b4\u9732\u54cd\u5e94\u51fd\u6570\uff09\u76f8\u7ed3\u5408\uff0c\u4ee5\u6539\u8fdb\u7a7a\u95f4\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u4e2d\u7684\u66b4\u9732\u98ce\u9669\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u7a7a\u95f4\u6d41\u884c\u75c5\u5b66\u4f7f\u7528\u6cca\u677e\u56de\u5f52\u6a21\u578b\uff0c\u9700\u8981\u9884\u5148\u6307\u5b9a\u6df7\u6742\u56e0\u7d20\u7684\u4ea4\u4e92\u4f5c\u7528\u548c\u529f\u80fd\u5173\u7cfb\uff0c\u800c\u4e0d\u662f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u3002\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u6355\u6349\u975e\u7ebf\u6027\u6548\u5e94\u548c\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\u7684\u80fd\u529b\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u7a7a\u6c14\u6c61\u67d3\u5bf9\u5065\u5eb7\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faSPAR-Forest-ERF\u7b97\u6cd5\uff0c\u878d\u5408\u968f\u673a\u68ee\u6797\uff08\u6355\u6349\u975e\u7ebf\u6027\u6df7\u6742\u56e0\u7d20-\u54cd\u5e94\u6548\u5e94\uff09\u548c\u8d1d\u53f6\u65af\u7a7a\u95f4\u81ea\u76f8\u5173\u6a21\u578b\uff08\u4f30\u8ba1\u53ef\u89e3\u91ca\u7684\u66b4\u9732\u54cd\u5e94\u51fd\u6570\uff09\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5728ML\u548c\u7edf\u8ba1\u6a21\u578b\u4e4b\u95f4\u4f20\u64ad\u4e0d\u786e\u5b9a\u6027\uff1b2\uff09\u5f00\u53d1\u65b0\u7684\u505c\u6b62\u51c6\u5219\u786e\u4fdd\u63a8\u65ad\u76ee\u6807\u7a33\u5b9a\u6027\uff1b3\uff09\u6574\u5408\u591a\u79cdERF\u4ee5\u6700\u5927\u5316\u6a21\u578b\u7075\u6d3b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u82cf\u683c\u51702022\u5e74\u5168\u56fd\u4eba\u53e3\u666e\u67e5\u6570\u636e\uff0c\u91cf\u5316\u7a7a\u6c14\u6c61\u67d3\u6d53\u5ea6\u5bf9\u81ea\u8bc4\u5065\u5eb7\u7684\u5f71\u54cd\u3002\u7b97\u6cd5\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6df7\u6742\u56e0\u7d20\u7684\u4ea4\u4e92\u4f5c\u7528\u548c\u529f\u80fd\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u66b4\u9732\u54cd\u5e94\u51fd\u6570\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "SPAR-Forest-ERF\u7b97\u6cd5\u662f\u9996\u4e2a\u5c06\u968f\u673a\u68ee\u6797\u4e0e\u8d1d\u53f6\u65af\u7a7a\u95f4\u6a21\u578b\u878d\u5408\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u975e\u7ebf\u6027\u6548\u5e94\u548c\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\uff0c\u4e3a\u7a7a\u95f4\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u89e3\u91ca\u7684\u66b4\u9732\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.01412", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01412", "abs": "https://arxiv.org/abs/2602.01412", "authors": ["Kam\u00e9lia Daudel", "Minh-Ngoc Tran", "Cheng Zhang"], "title": "Importance Weighted Variational Inference without the Reparameterization Trick", "comment": null, "summary": "Importance weighted variational inference (VI) approximates densities known up to a normalizing constant by optimizing bounds that tighten with the number of Monte Carlo samples $N$. Standard optimization relies on reparameterized gradient estimators, which are well-studied theoretically yet restrict both the choice of the data-generating process and the variational approximation. While REINFORCE gradient estimators do not suffer from such restrictions, they lack rigorous theoretical justification. In this paper, we provide the first comprehensive analysis of REINFORCE gradient estimators in importance weighted VI, leveraging this theoretical foundation to diagnose and resolve fundamental deficiencies in current state-of-the-art estimators. Specifically, we introduce and examine a generalized family of variational inference for Monte Carlo objectives (VIMCO) gradient estimators. We prove that state-of-the-art VIMCO gradient estimators exhibit a vanishing signal-to-noise ratio (SNR) as $N$ increases, which prevents effective optimization. To overcome this issue, we propose the novel VIMCO-$\\star$ gradient estimator and show that it averts the SNR collapse of existing VIMCO gradient estimators by achieving a $\\sqrt{N}$ SNR scaling instead. We demonstrate its superior empirical performance compared to current VIMCO implementations in challenging settings where reparameterized gradients are typically unavailable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u91cd\u8981\u6027\u52a0\u6743\u53d8\u5206\u63a8\u65ad\u4e2dREINFORCE\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u7406\u8bba\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86VIMCO-*\u68af\u5ea6\u4f30\u8ba1\u5668\u6765\u89e3\u51b3\u73b0\u6709VIMCO\u4f30\u8ba1\u5668\u968f\u6837\u672c\u6570\u589e\u52a0\u800c\u4fe1\u53f7\u566a\u58f0\u6bd4\u6d88\u5931\u7684\u95ee\u9898\u3002", "motivation": "\u91cd\u8981\u6027\u52a0\u6743\u53d8\u5206\u63a8\u65ad\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6837\u672c\u4f18\u5316\u8fb9\u754c\uff0c\u4f46\u6807\u51c6\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4f30\u8ba1\u5668\u5bf9\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u548c\u53d8\u5206\u8fd1\u4f3c\u6709\u9650\u5236\u3002REINFORCE\u68af\u5ea6\u4f30\u8ba1\u5668\u867d\u7136\u4e0d\u53d7\u8fd9\u4e9b\u9650\u5236\uff0c\u4f46\u7f3a\u4e4f\u4e25\u683c\u7406\u8bba\u5206\u6790\uff0c\u73b0\u6709VIMCO\u68af\u5ea6\u4f30\u8ba1\u5668\u5b58\u5728\u4fe1\u53f7\u566a\u58f0\u6bd4\u968f\u6837\u672c\u6570\u589e\u52a0\u800c\u6d88\u5931\u7684\u95ee\u9898\u3002", "method": "\u5bf9\u91cd\u8981\u6027\u52a0\u6743VI\u4e2d\u7684REINFORCE\u68af\u5ea6\u4f30\u8ba1\u5668\u8fdb\u884c\u9996\u6b21\u5168\u9762\u7406\u8bba\u5206\u6790\uff0c\u5f15\u5165\u5e76\u7814\u7a76\u5e7f\u4e49\u7684VIMCO\u68af\u5ea6\u4f30\u8ba1\u5668\u5bb6\u65cf\u3002\u63d0\u51fa\u65b0\u7684VIMCO-*\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5176\u80fd\u907f\u514d\u73b0\u6709VIMCO\u4f30\u8ba1\u5668\u7684\u4fe1\u53f7\u566a\u58f0\u6bd4\u5d29\u6e83\u95ee\u9898\uff0c\u5b9e\u73b0\u221aN\u7684\u4fe1\u53f7\u566a\u58f0\u6bd4\u7f29\u653e\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u73b0\u6709VIMCO\u68af\u5ea6\u4f30\u8ba1\u5668\u968f\u6837\u672c\u6570N\u589e\u52a0\u4f1a\u51fa\u73b0\u4fe1\u53f7\u566a\u58f0\u6bd4\u6d88\u5931\u7684\u95ee\u9898\uff0c\u800c\u63d0\u51fa\u7684VIMCO-*\u4f30\u8ba1\u5668\u80fd\u907f\u514d\u8fd9\u4e00\u95ee\u9898\uff0c\u5b9e\u73b0\u221aN\u7684\u4fe1\u53f7\u566a\u58f0\u6bd4\u7f29\u653e\u3002\u5728\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4e0d\u53ef\u7528\u7684\u6311\u6218\u6027\u8bbe\u7f6e\u4e2d\uff0cVIMCO-*\u8868\u73b0\u51fa\u6bd4\u73b0\u6709VIMCO\u5b9e\u73b0\u66f4\u4f18\u8d8a\u7684\u5b9e\u8bc1\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cd\u8981\u6027\u52a0\u6743\u53d8\u5206\u63a8\u65ad\u4e2d\u7684REINFORCE\u68af\u5ea6\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u7406\u8bba\u5206\u6790\uff0c\u63ed\u793a\u4e86\u73b0\u6709VIMCO\u4f30\u8ba1\u5668\u7684\u6839\u672c\u7f3a\u9677\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684VIMCO-*\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u91cd\u53c2\u6570\u5316\u68af\u5ea6\u4e0d\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.02319", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02319", "abs": "https://arxiv.org/abs/2602.02319", "authors": ["Behzad Aalipur", "Rachel Kilby"], "title": "Leave-One-Out Neighborhood Smoothing for Graphons: Berry-Esseen Bounds, Confidence Intervals, and Honest Tuning", "comment": null, "summary": "Neighborhood smoothing methods achieve minimax-optimal rates for estimating edge probabilities under graphon models, but their use for statistical inference has remained limited. The main obstacle is that classical neighborhood smoothers select data-driven neighborhoods and average edges using the same adjacency matrix, inducing complex dependencies that invalidate standard concentration and normal approximation arguments.\n  We introduce a leave-one-out modification of neighborhood smoothing for undirected simple graphs. When estimating a single entry P_ij, the neighborhood of node i is constructed from an adjacency matrix in which the jth row and column are set to zero, thereby decoupling neighborhood selection from the edges being averaged. We show that this construction restores conditional independence of the centered summands, enabling the use of classical probabilistic tools for inference.\n  Under piecewise Lipschitz graphon assumptions and logarithmic degree growth, we derive variance-adaptive concentration inequalities based on Bousquet's inequality and establish Berry-Esseen bounds with explicit rates for the normalized estimation error. These results yield both finite-sample and asymptotic confidence intervals for individual edge probabilities. The same leave-one-out structure also supports an honest cross-validation scheme for tuning parameter selection, for which we prove an oracle inequality. The proposed estimator retains the optimal row-wise mean-squared error rates of classical neighborhood smoothing while providing valid entrywise uncertainty quantification.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7559\u4e00\u6cd5\u90bb\u57df\u5e73\u6ed1\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e0\u5411\u7b80\u5355\u56fe\u7684\u8fb9\u6982\u7387\u4f30\u8ba1\u548c\u7edf\u8ba1\u63a8\u65ad\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u6570\u636e\u9a71\u52a8\u90bb\u57df\u9009\u62e9\u5bfc\u81f4\u7684\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u90bb\u57df\u5e73\u6ed1\u65b9\u6cd5\u5728\u56fe\u6a21\u578b\u8fb9\u6982\u7387\u4f30\u8ba1\u4e2d\u80fd\u8fbe\u5230\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7387\uff0c\u4f46\u7531\u4e8e\u4f7f\u7528\u76f8\u540c\u90bb\u63a5\u77e9\u9635\u8fdb\u884c\u90bb\u57df\u9009\u62e9\u548c\u8fb9\u5e73\u5747\uff0c\u5bfc\u81f4\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u5f97\u7edf\u8ba1\u63a8\u65ad\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6062\u590d\u6761\u4ef6\u72ec\u7acb\u6027\u3001\u652f\u6301\u6709\u6548\u63a8\u65ad\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7559\u4e00\u6cd5\u90bb\u57df\u5e73\u6ed1\uff1a\u5728\u4f30\u8ba1\u5355\u4e2a\u6761\u76eeP_ij\u65f6\uff0c\u4ece\u7b2cj\u884c\u548c\u7b2cj\u5217\u7f6e\u96f6\u7684\u90bb\u63a5\u77e9\u9635\u6784\u5efa\u8282\u70b9i\u7684\u90bb\u57df\uff0c\u4ece\u800c\u5c06\u90bb\u57df\u9009\u62e9\u4e0e\u5f85\u5e73\u5747\u8fb9\u89e3\u8026\u3002\u8fd9\u79cd\u6784\u9020\u6062\u590d\u4e86\u4e2d\u5fc3\u5316\u9879\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u3002", "result": "\u5728\u5206\u6bb5Lipschitz\u56fe\u6a21\u578b\u5047\u8bbe\u548c\u5bf9\u6570\u5ea6\u589e\u957f\u6761\u4ef6\u4e0b\uff0c\u57fa\u4e8eBousquet\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u4e86\u65b9\u5dee\u81ea\u9002\u5e94\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u5efa\u7acb\u4e86\u5f52\u4e00\u5316\u4f30\u8ba1\u8bef\u5dee\u7684Berry-Esseen\u754c\u9650\u3002\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e86\u4f20\u7edf\u90bb\u57df\u5e73\u6ed1\u7684\u6700\u4f18\u884c\u5747\u65b9\u8bef\u5dee\u7387\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9010\u70b9\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "\u7559\u4e00\u6cd5\u90bb\u57df\u5e73\u6ed1\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u90bb\u57df\u5e73\u6ed1\u7684\u7edf\u8ba1\u63a8\u65ad\u969c\u788d\uff0c\u6062\u590d\u4e86\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u652f\u6301\u6709\u9650\u6837\u672c\u548c\u6e10\u8fd1\u7f6e\u4fe1\u533a\u95f4\u6784\u5efa\uff0c\u540c\u65f6\u652f\u6301\u8bda\u5b9e\u7684\u4ea4\u53c9\u9a8c\u8bc1\u8c03\u53c2\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u4f30\u8ba1\u7387\u4e0e\u6709\u6548\u63a8\u65ad\u7684\u7edf\u4e00\u3002"}}
{"id": "2602.01466", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01466", "abs": "https://arxiv.org/abs/2602.01466", "authors": ["Tuan Minh Pham", "Thinh Cao", "Viet Nguyen", "Huy Nguyen", "Nhat Ho", "Alessandro Rinaldo"], "title": "Rethinking Multinomial Logistic Mixture of Experts with Sigmoid Gating Function", "comment": "Tuan Minh Pham, Thinh Cao, and Viet Nguyen contributed equally to this work", "summary": "The sigmoid gate in mixture-of-experts (MoE) models has been empirically shown to outperform the softmax gate across several tasks, ranging from approximating feed-forward networks to language modeling. Additionally, recent efforts have demonstrated that the sigmoid gate is provably more sample-efficient than its softmax counterpart under regression settings. Nevertheless, there are three notable concerns that have not been addressed in the literature, namely (i) the benefits of the sigmoid gate have not been established under classification settings; (ii) existing sigmoid-gated MoE models may not converge to their ground-truth; and (iii) the effects of a temperature parameter in the sigmoid gate remain theoretically underexplored. To tackle these open problems, we perform a comprehensive analysis of multinomial logistic MoE equipped with a modified sigmoid gate to ensure model convergence. Our results indicate that the sigmoid gate exhibits a lower sample complexity than the softmax gate for both parameter and expert estimation. Furthermore, we find that incorporating a temperature into the sigmoid gate leads to a sample complexity of exponential order due to an intrinsic interaction between the temperature and gating parameters. To overcome this issue, we propose replacing the vanilla inner product score in the gating function with a Euclidean score that effectively removes that interaction, thereby substantially improving the sample complexity to a polynomial order.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u591a\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u4e2dsigmoid\u95e8\u63a7\u76f8\u5bf9\u4e8esoftmax\u95e8\u63a7\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7684Euclidean\u8bc4\u5206\u65b9\u6cd5\u4ee5\u89e3\u51b3\u6e29\u5ea6\u53c2\u6570\u5e26\u6765\u7684\u6307\u6570\u7ea7\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1sigmoid\u95e8\u63a7\u5728\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4e2d\u5df2\u88ab\u5b9e\u8bc1\u8bc1\u660e\u4f18\u4e8esoftmax\u95e8\u63a7\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5b58\u5728\u4e09\u4e2a\u672a\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\uff1a1\uff09sigmoid\u95e8\u63a7\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u672a\u5f97\u5230\u7406\u8bba\u8bc1\u660e\uff1b2\uff09\u73b0\u6709sigmoid\u95e8\u63a7\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u6536\u655b\u5230\u771f\u5b9e\u53c2\u6570\uff1b3\uff09\u6e29\u5ea6\u53c2\u6570\u5bf9sigmoid\u95e8\u63a7\u7684\u7406\u8bba\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684sigmoid\u95e8\u63a7\u7684\u591a\u9879\u5f0f\u903b\u8f91\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u6bd4\u8f83sigmoid\u548csoftmax\u95e8\u63a7\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002\u4e3a\u89e3\u51b3\u6e29\u5ea6\u53c2\u6570\u5e26\u6765\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7528\u6b27\u51e0\u91cc\u5f97\u8bc4\u5206\u66ff\u4ee3\u4f20\u7edf\u7684\u70b9\u79ef\u8bc4\u5206\uff0c\u6d88\u9664\u6e29\u5ea6\u53c2\u6570\u4e0e\u95e8\u63a7\u53c2\u6570\u4e4b\u95f4\u7684\u5185\u5728\u4ea4\u4e92\u4f5c\u7528\u3002", "result": "sigmoid\u95e8\u63a7\u5728\u53c2\u6570\u4f30\u8ba1\u548c\u4e13\u5bb6\u4f30\u8ba1\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u6bd4softmax\u95e8\u63a7\u66f4\u4f4e\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002\u7136\u800c\uff0c\u5f15\u5165\u6e29\u5ea6\u53c2\u6570\u7684sigmoid\u95e8\u63a7\u4f1a\u5bfc\u81f4\u6307\u6570\u7ea7\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002\u4f7f\u7528\u6b27\u51e0\u91cc\u5f97\u8bc4\u5206\u66ff\u4ee3\u70b9\u79ef\u8bc4\u5206\u540e\uff0c\u6837\u672c\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u591a\u9879\u5f0f\u7ea7\u3002", "conclusion": "sigmoid\u95e8\u63a7\u5728\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4e2d\u786e\u5b9e\u4f18\u4e8esoftmax\u95e8\u63a7\uff0c\u7279\u522b\u662f\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u3002\u901a\u8fc7\u91c7\u7528\u6b27\u51e0\u91cc\u5f97\u8bc4\u5206\u65b9\u6cd5\uff0c\u53ef\u4ee5\u514b\u670d\u6e29\u5ea6\u53c2\u6570\u5e26\u6765\u7684\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f7f\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u9ad8\u6548\u53ef\u884c\u3002"}}
{"id": "2602.01477", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01477", "abs": "https://arxiv.org/abs/2602.01477", "authors": ["Pietro Carlotti", "Nevena Gligi\u0107", "Arya Farahi"], "title": "Density-Informed Pseudo-Counts for Calibrated Evidential Deep Learning", "comment": null, "summary": "Evidential Deep Learning (EDL) is a popular framework for uncertainty-aware classification that models predictive uncertainty via Dirichlet distributions parameterized by neural networks. Despite its popularity, its theoretical foundations and behavior under distributional shift remain poorly understood. In this work, we provide a principled statistical interpretation by proving that EDL training corresponds to amortized variational inference in a hierarchical Bayesian model with a tempered pseudo-likelihood. This perspective reveals a major drawback: standard EDL conflates epistemic and aleatoric uncertainty, leading to systematic overconfidence on out-of-distribution (OOD) inputs. To address this, we introduce Density-Informed Pseudo-count EDL (DIP-EDL), a new parametrization that decouples class prediction from the magnitude of uncertainty by separately estimating the conditional label distribution and the marginal covariate density. This separation preserves evidence in high-density regions while shrinking predictions toward a uniform prior for OOD data. Theoretically, we prove that DIP-EDL achieves asymptotic concentration. Empirically, we show that our method enhances interpretability and improves robustness and uncertainty calibration under distributional shift.", "AI": {"tldr": "EDL\u5b58\u5728\u7406\u8bba\u7f3a\u9677\uff0c\u5c06\u8ba4\u77e5\u548c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u6df7\u4e3a\u4e00\u8c08\uff0c\u5bfc\u81f4OOD\u6570\u636e\u8fc7\u5ea6\u81ea\u4fe1\u3002\u4f5c\u8005\u63d0\u51faDIP-EDL\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u6761\u4ef6\u6807\u7b7e\u5206\u5e03\u548c\u8fb9\u9645\u534f\u53d8\u91cf\u5bc6\u5ea6\u6765\u89e3\u8026\u4e0d\u786e\u5b9a\u6027\uff0c\u6539\u5584\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6821\u51c6\u3002", "motivation": "\u5c3d\u7ba1EDL\u5728\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5206\u7c7b\u4e2d\u5f88\u6d41\u884c\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u548c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u884c\u4e3a\u4ecd\u4e0d\u6e05\u695a\u3002\u4f5c\u8005\u53d1\u73b0\u6807\u51c6EDL\u5c06\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u6df7\u4e3a\u4e00\u8c08\uff0c\u5bfc\u81f4\u5bf9OOD\u8f93\u5165\u7684\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u7f3a\u9677\u3002", "method": "\u63d0\u51faDIP-EDL\uff08\u5bc6\u5ea6\u4fe1\u606f\u4f2a\u8ba1\u6570EDL\uff09\uff0c\u901a\u8fc7\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u4e2d\u7684\u644a\u9500\u53d8\u5206\u63a8\u65ad\u89c6\u89d2\u91cd\u65b0\u89e3\u91caEDL\u3002\u65b0\u65b9\u6cd5\u5206\u79bb\u6761\u4ef6\u6807\u7b7e\u5206\u5e03\u548c\u8fb9\u9645\u534f\u53d8\u91cf\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u5728\u9ad8\u5bc6\u5ea6\u533a\u57df\u4fdd\u7559\u8bc1\u636e\uff0c\u5bf9OOD\u6570\u636e\u5c06\u9884\u6d4b\u6536\u7f29\u5230\u5747\u5300\u5148\u9a8c\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660eDIP-EDL\u5b9e\u73b0\u6e10\u8fd1\u96c6\u4e2d\u6027\u3002\u5b9e\u8bc1\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u6539\u5584\u4e86\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u6027\u80fd\u3002", "conclusion": "DIP-EDL\u89e3\u51b3\u4e86\u6807\u51c6EDL\u7684\u6838\u5fc3\u7f3a\u9677\uff0c\u901a\u8fc7\u89e3\u8026\u7c7b\u522b\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u5927\u5c0f\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.01603", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01603", "abs": "https://arxiv.org/abs/2602.01603", "authors": ["Shokichi Takakura", "Akifumi Wachi", "Rei Higuchi", "Kohei Miyaguchi", "Taiji Suzuki"], "title": "Inference-Aware Meta-Alignment of LLMs via Non-Linear GRPO", "comment": null, "summary": "Aligning large language models (LLMs) to diverse human preferences is fundamentally challenging since criteria can often conflict with each other. Inference-time alignment methods have recently gained popularity as they allow LLMs to be aligned to multiple criteria via different alignment algorithms at inference time. However, inference-time alignment is computationally expensive since it often requires multiple forward passes of the base model. In this work, we propose inference-aware meta-alignment (IAMA), a novel approach that enables LLMs to be aligned to multiple criteria with limited computational budget at inference time. IAMA trains a base model such that it can be effectively aligned to multiple tasks via different inference-time alignment algorithms. To solve the non-linear optimization problems involved in IAMA, we propose non-linear GRPO, which provably converges to the optimal solution in the space of probability measures.", "AI": {"tldr": "\u63d0\u51faIAMA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u4f7f\u57fa\u7840\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e0d\u540c\u7684\u63a8\u7406\u65f6\u5bf9\u9f50\u7b97\u6cd5\u6709\u6548\u5bf9\u9f50\u5230\u591a\u4e2a\u4efb\u52a1\uff0c\u89e3\u51b3\u591a\u6807\u51c6\u5bf9\u9f50\u7684\u6311\u6218\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u5230\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u5177\u6709\u6839\u672c\u6027\u6311\u6218\uff0c\u56e0\u4e3a\u6807\u51c6\u7ecf\u5e38\u76f8\u4e92\u51b2\u7a81\u3002\u63a8\u7406\u65f6\u5bf9\u9f50\u65b9\u6cd5\u867d\u7136\u5141\u8bb8\u901a\u8fc7\u4e0d\u540c\u7b97\u6cd5\u5bf9\u9f50\u591a\u4e2a\u6807\u51c6\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u591a\u6b21\u524d\u5411\u4f20\u64ad\u3002", "method": "\u63d0\u51fa\u63a8\u7406\u611f\u77e5\u5143\u5bf9\u9f50(IAMA)\u65b9\u6cd5\uff0c\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u4f7f\u5176\u80fd\u591f\u901a\u8fc7\u4e0d\u540c\u7684\u63a8\u7406\u65f6\u5bf9\u9f50\u7b97\u6cd5\u6709\u6548\u5bf9\u9f50\u5230\u591a\u4e2a\u4efb\u52a1\u3002\u4e3a\u89e3\u51b3IAMA\u4e2d\u7684\u975e\u7ebf\u6027\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u975e\u7ebf\u6027GRPO\u7b97\u6cd5\uff0c\u5728\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e2d\u53ef\u8bc1\u660e\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002", "result": "IAMA\u4f7fLLMs\u80fd\u591f\u5728\u63a8\u7406\u65f6\u4ee5\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u5bf9\u9f50\u5230\u591a\u4e2a\u6807\u51c6\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u4f18\u5316\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u5176\u5bf9\u5404\u79cd\u63a8\u7406\u65f6\u5bf9\u9f50\u7b97\u6cd5\u90fd\u6709\u6548\u3002", "conclusion": "IAMA\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6807\u51c6\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a8\u7406\u611f\u77e5\u7684\u5143\u5b66\u4e60\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2602.01733", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01733", "abs": "https://arxiv.org/abs/2602.01733", "authors": ["Junxian Liu", "Hao Zeng", "Hongxin Wei"], "title": "ST-BCP: Tightening Coverage Bound for Backward Conformal Prediction via Non-Conformity Score Transformation", "comment": null, "summary": "Conformal Prediction (CP) provides a statistical framework for uncertainty quantification that constructs prediction sets with coverage guarantees. While CP yields uncontrolled prediction set sizes, Backward Conformal Prediction (BCP) inverts this paradigm by enforcing a predefined upper bound on set size and estimating the resulting coverage guarantee. However, the looseness induced by Markov's inequality within the BCP framework causes a significant gap between the estimated coverage bound and the empirical coverage. In this work, we introduce ST-BCP, a novel method that introduces a data-dependent transformation of nonconformity scores to narrow the coverage gap. In particular, we develop a computable transformation and prove that it outperforms the baseline identity transformation. Extensive experiments demonstrate the effectiveness of our method, reducing the average coverage gap from 4.20\\% to 1.12\\% on common benchmarks.", "AI": {"tldr": "ST-BCP\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u53cd\u5411\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u5206\u6570\u53d8\u6362\u7f29\u5c0f\u8986\u76d6\u7387\u5dee\u8ddd\uff0c\u5c06\u5e73\u5747\u8986\u76d6\u7387\u5dee\u8ddd\u4ece4.20%\u964d\u81f31.12%\u3002", "motivation": "\u4f20\u7edf\u53cd\u5411\u5171\u5f62\u9884\u6d4b(BCP)\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u4e0d\u7b49\u5f0f\u5bfc\u81f4\u4f30\u8ba1\u8986\u76d6\u7387\u4e0e\u5b9e\u9645\u8986\u76d6\u7387\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u6539\u8fdb\u65b9\u6cd5\u6765\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51faST-BCP\u65b9\u6cd5\uff0c\u5f15\u5165\u6570\u636e\u4f9d\u8d56\u7684\u975e\u5171\u5f62\u5206\u6570\u53d8\u6362\uff0c\u5f00\u53d1\u53ef\u8ba1\u7b97\u7684\u53d8\u6362\u51fd\u6570\uff0c\u5e76\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u6052\u7b49\u53d8\u6362\u3002", "result": "\u5728\u5e38\u89c1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u5e73\u5747\u8986\u76d6\u7387\u5dee\u8ddd\u4ece4.20%\u663e\u8457\u964d\u4f4e\u81f31.12%\uff0c\u6709\u6548\u7f29\u5c0f\u4e86\u8986\u76d6\u7387\u5dee\u8ddd\u3002", "conclusion": "ST-BCP\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u5206\u6570\u53d8\u6362\u6709\u6548\u6539\u8fdb\u4e86\u53cd\u5411\u5171\u5f62\u9884\u6d4b\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u8986\u76d6\u7387\u5dee\u8ddd\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.01863", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01863", "abs": "https://arxiv.org/abs/2602.01863", "authors": ["Ryotaro Kawata", "Taiji Suzuki"], "title": "Transformers as Measure-Theoretic Associative Memory: A Statistical Perspective and Minimax Optimality", "comment": null, "summary": "Transformers excel through content-addressable retrieval and the ability to exploit contexts of, in principle, unbounded length. We recast associative memory at the level of probability measures, treating a context as a distribution over tokens and viewing attention as an integral operator on measures. Concretely, for mixture contexts $\u03bd= I^{-1} \\sum_{i=1}^I \u03bc^{(i^*)}$ and a query $x_{\\mathrm{q}}(i^*)$, the task decomposes into (i) recall of the relevant component $\u03bc^{(i^*)}$ and (ii) prediction from $(\u03bc_{i^*},x_\\mathrm{q})$. We study learned softmax attention (not a frozen kernel) trained by empirical risk minimization and show that a shallow measure-theoretic Transformer composed with an MLP learns the recall-and-predict map under a spectral assumption on the input densities. We further establish a matching minimax lower bound with the same rate exponent (up to multiplicative constants), proving sharpness of the convergence order. The framework offers a principled recipe for designing and analyzing Transformers that recall from arbitrarily long, distributional contexts with provable generalization guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u6d4b\u5ea6\u7684Transformer\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3atoken\u5206\u5e03\uff0c\u6ce8\u610f\u529b\u89c6\u4e3a\u6d4b\u5ea6\u4e0a\u7684\u79ef\u5206\u7b97\u5b50\uff0c\u8bc1\u660e\u4e86\u6d45\u5c42Transformer\u5728\u8c31\u5047\u8bbe\u4e0b\u80fd\u591f\u5b66\u4e60\"\u56de\u5fc6-\u9884\u6d4b\"\u6620\u5c04\uff0c\u5e76\u5efa\u7acb\u4e86\u5339\u914d\u7684\u6781\u5c0f\u6781\u5927\u4e0b\u754c\u3002", "motivation": "Transformer\u901a\u8fc7\u5185\u5bb9\u5bfb\u5740\u68c0\u7d22\u548c\u5229\u7528\u7406\u8bba\u4e0a\u65e0\u9650\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u8868\u73b0\u51fa\u8272\u3002\u672c\u6587\u65e8\u5728\u4ece\u6982\u7387\u6d4b\u5ea6\u7684\u89d2\u5ea6\u91cd\u65b0\u6784\u5efa\u5173\u8054\u8bb0\u5fc6\uff0c\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3atoken\u5206\u5e03\uff0c\u6ce8\u610f\u529b\u89c6\u4e3a\u6d4b\u5ea6\u4e0a\u7684\u79ef\u5206\u7b97\u5b50\uff0c\u4e3a\u8bbe\u8ba1\u548c\u5206\u6790\u80fd\u591f\u4ece\u4efb\u610f\u957f\u5206\u5e03\u4e0a\u4e0b\u6587\u4e2d\u56de\u5fc6\u7684Transformer\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5c06\u4e0a\u4e0b\u6587\u91cd\u65b0\u8868\u8ff0\u4e3a\u6df7\u5408\u5206\u5e03\u03bd = I\u207b\u00b9\u2211\u03bc\u207d\u2071*\u207e\uff0c\u67e5\u8be2\u4e3ax_q(i*)\u3002\u4efb\u52a1\u5206\u89e3\u4e3a\uff1a(1)\u56de\u5fc6\u76f8\u5173\u5206\u91cf\u03bc\u207d\u2071*\u207e\uff0c(2)\u4ece(\u03bc\u207d\u2071*\u207e, x_q)\u8fdb\u884c\u9884\u6d4b\u3002\u7814\u7a76\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u8bad\u7ec3\u7684softmax\u6ce8\u610f\u529b\uff08\u975e\u51bb\u7ed3\u6838\uff09\uff0c\u8bc1\u660e\u5728\u8f93\u5165\u5bc6\u5ea6\u7684\u8c31\u5047\u8bbe\u4e0b\uff0c\u6d45\u5c42\u6d4b\u5ea6\u8bbaTransformer\u4e0eMLP\u7ec4\u5408\u80fd\u591f\u5b66\u4e60\u56de\u5fc6-\u9884\u6d4b\u6620\u5c04\u3002", "result": "\u8bc1\u660e\u4e86\u6d45\u5c42\u6d4b\u5ea6\u8bbaTransformer\u80fd\u591f\u5b66\u4e60\u56de\u5fc6-\u9884\u6d4b\u6620\u5c04\uff0c\u5e76\u5efa\u7acb\u4e86\u5339\u914d\u7684\u6781\u5c0f\u6781\u5927\u4e0b\u754c\uff08\u6536\u655b\u9636\u76f8\u540c\uff0c\u4ec5\u5dee\u4e58\u6cd5\u5e38\u6570\uff09\uff0c\u8bc1\u660e\u4e86\u6536\u655b\u9636\u7684\u5c16\u9510\u6027\u3002\u8be5\u6846\u67b6\u4e3a\u8bbe\u8ba1\u548c\u5206\u6790\u80fd\u591f\u4ece\u4efb\u610f\u957f\u5206\u5e03\u4e0a\u4e0b\u6587\u4e2d\u56de\u5fc6\u7684Transformer\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bbe\u8ba1\u548c\u5206\u6790\u80fd\u591f\u4ece\u4efb\u610f\u957f\u5206\u5e03\u4e0a\u4e0b\u6587\u4e2d\u56de\u5fc6\u7684Transformer\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6cdb\u5316\u4fdd\u8bc1\u3002\u901a\u8fc7\u5c06Transformer\u91cd\u65b0\u8868\u8ff0\u4e3a\u6d4b\u5ea6\u4e0a\u7684\u79ef\u5206\u7b97\u5b50\uff0c\u4e3a\u7406\u89e3\u5176\u5904\u7406\u5206\u5e03\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.01912", "categories": ["stat.ML", "cs.AI", "cs.LG", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.01912", "abs": "https://arxiv.org/abs/2602.01912", "authors": ["Du-Yi Wang", "Guo Liang", "Kun Zhang", "Qianwen Zhu"], "title": "Reliable Real-Time Value at Risk Estimation via Quantile Regression Forest with Conformal Calibration", "comment": null, "summary": "Rapidly evolving market conditions call for real-time risk monitoring, but its online estimation remains challenging. In this paper, we study the online estimation of one of the most widely used risk measures, Value at Risk (VaR). Its accurate and reliable estimation is essential for timely risk control and informed decision-making. We propose to use the quantile regression forest in the offline-simulation-online-estimation (OSOA) framework. Specifically, the quantile regression forest is trained offline to learn the relationship between the online VaR and risk factors, and real-time VaR estimates are then produced online by incorporating observed risk factors. To further ensure reliability, we develop a conformalized estimator that calibrates the online VaR estimates. To the best of our knowledge, we are the first to leverage conformal calibration to estimate real-time VaR reliably based on the OSOA formulation. Theoretical analysis establishes the consistency and coverage validity of the proposed estimators. Numerical experiments confirm the proposed method and demonstrate its effectiveness in practice.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u79bb\u7ebf\u6a21\u62df\u5728\u7ebf\u4f30\u8ba1\u6846\u67b6\u7684\u5206\u4f4d\u6570\u56de\u5f52\u68ee\u6797\u65b9\u6cd5\uff0c\u7ed3\u5408\u4fdd\u5f62\u6821\u51c6\u5b9e\u73b0\u5b9e\u65f6\u98ce\u9669\u4ef7\u503c\u53ef\u9760\u4f30\u8ba1", "motivation": "\u5e02\u573a\u6761\u4ef6\u5feb\u901f\u53d8\u5316\u9700\u8981\u5b9e\u65f6\u98ce\u9669\u76d1\u63a7\uff0c\u4f46\u98ce\u9669\u4ef7\u503c\u7684\u5728\u7ebf\u4f30\u8ba1\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u51c6\u786e\u53ef\u9760\u7684\u5b9e\u65f6\u98ce\u9669\u4ef7\u503c\u4f30\u8ba1\u6765\u8fdb\u884c\u53ca\u65f6\u98ce\u9669\u63a7\u5236\u548c\u660e\u667a\u51b3\u7b56", "method": "\u91c7\u7528\u79bb\u7ebf\u6a21\u62df\u5728\u7ebf\u4f30\u8ba1\u6846\u67b6\uff0c\u4f7f\u7528\u5206\u4f4d\u6570\u56de\u5f52\u68ee\u6797\u79bb\u7ebf\u5b66\u4e60\u5728\u7ebf\u98ce\u9669\u4ef7\u503c\u4e0e\u98ce\u9669\u56e0\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7136\u540e\u5728\u7ebf\u7ed3\u5408\u89c2\u6d4b\u5230\u7684\u98ce\u9669\u56e0\u7d20\u751f\u6210\u5b9e\u65f6\u98ce\u9669\u4ef7\u503c\u4f30\u8ba1\uff0c\u5e76\u5f00\u53d1\u4fdd\u5f62\u5316\u4f30\u8ba1\u5668\u6765\u6821\u51c6\u5728\u7ebf\u98ce\u9669\u4ef7\u503c\u4f30\u8ba1\u4ee5\u786e\u4fdd\u53ef\u9760\u6027", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u6240\u63d0\u4f30\u8ba1\u5668\u7684\u4e00\u81f4\u6027\u548c\u8986\u76d6\u6709\u6548\u6027\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u52bf", "conclusion": "\u9996\u6b21\u57fa\u4e8e\u79bb\u7ebf\u6a21\u62df\u5728\u7ebf\u4f30\u8ba1\u6846\u67b6\u5229\u7528\u4fdd\u5f62\u6821\u51c6\u5b9e\u73b0\u53ef\u9760\u5b9e\u65f6\u98ce\u9669\u4ef7\u503c\u4f30\u8ba1\uff0c\u4e3a\u5b9e\u65f6\u98ce\u9669\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01928", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01928", "abs": "https://arxiv.org/abs/2602.01928", "authors": ["Simon Roburin", "Rafa\u00ebl Pinot", "Erwan Scornet"], "title": "Privacy Amplification by Missing Data", "comment": null, "summary": "Privacy preservation is a fundamental requirement in many high-stakes domains such as medicine and finance, where sensitive personal data must be analyzed without compromising individual confidentiality. At the same time, these applications often involve datasets with missing values due to non-response, data corruption, or deliberate anonymization. Missing data is traditionally viewed as a limitation because it reduces the information available to analysts and can degrade model performance. In this work, we take an alternative perspective and study missing data from a privacy preservation standpoint. Intuitively, when features are missing, less information is revealed about individuals, suggesting that missingness could inherently enhance privacy. We formalize this intuition by analyzing missing data as a privacy amplification mechanism within the framework of differential privacy. We show, for the first time, that incomplete data can yield privacy amplification for differentially private algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7f3a\u5931\u6570\u636e\u53ef\u4f5c\u4e3a\u9690\u79c1\u589e\u5f3a\u673a\u5236\uff0c\u9996\u6b21\u8bc1\u660e\u4e0d\u5b8c\u6574\u6570\u636e\u80fd\u4e3a\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u63d0\u4f9b\u9690\u79c1\u653e\u5927\u6548\u679c", "motivation": "\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9ad8\u654f\u611f\u9886\u57df\uff0c\u9690\u79c1\u4fdd\u62a4\u662f\u57fa\u672c\u8981\u6c42\uff0c\u4f46\u8fd9\u4e9b\u9886\u57df\u7684\u6570\u636e\u5e38\u5b58\u5728\u7f3a\u5931\u503c\u3002\u4f20\u7edf\u4e0a\u7f3a\u5931\u6570\u636e\u88ab\u89c6\u4e3a\u9650\u5236\uff0c\u4f46\u672c\u6587\u4ece\u9690\u79c1\u4fdd\u62a4\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u7f3a\u5931\u6570\u636e\uff0c\u8ba4\u4e3a\u7f3a\u5931\u6027\u53ef\u80fd\u5929\u7136\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4", "method": "\u5728\u5dee\u5206\u9690\u79c1\u6846\u67b6\u4e0b\uff0c\u5c06\u7f3a\u5931\u6570\u636e\u5f62\u5f0f\u5316\u4e3a\u9690\u79c1\u653e\u5927\u673a\u5236\u8fdb\u884c\u5206\u6790\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e0d\u5b8c\u6574\u6570\u636e\u5982\u4f55\u4e3a\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u589e\u5f3a", "result": "\u9996\u6b21\u8bc1\u660e\u4e0d\u5b8c\u6574\u6570\u636e\u80fd\u4ea7\u751f\u9690\u79c1\u653e\u5927\u6548\u679c\uff0c\u5373\u7f3a\u5931\u6570\u636e\u53ef\u4ee5\u589e\u5f3a\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b", "conclusion": "\u7f3a\u5931\u6570\u636e\u4e0d\u5e94\u4ec5\u88ab\u89c6\u4e3a\u9650\u5236\uff0c\u800c\u5e94\u88ab\u91cd\u65b0\u8bc4\u4f30\u4e3a\u6709\u4ef7\u503c\u7684\u9690\u79c1\u589e\u5f3a\u673a\u5236\uff0c\u4e3a\u9ad8\u654f\u611f\u9886\u57df\u7684\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u89c6\u89d2"}}
{"id": "2602.01988", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01988", "abs": "https://arxiv.org/abs/2602.01988", "authors": ["James Boran Yu", "RuiKang OuYang", "Julien Horwood", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "title": "Stochastic Interpolants in Hilbert Spaces", "comment": "8 pages, 1 figure, 2 tables", "summary": "Although diffusion models have successfully extended to function-valued data, stochastic interpolants -- which offer a flexible way to bridge arbitrary distributions -- remain limited to finite-dimensional settings. This work bridges this gap by establishing a rigorous framework for stochastic interpolants in infinite-dimensional Hilbert spaces. We provide comprehensive theoretical foundations, including proofs of well-posedness and explicit error bounds. We demonstrate the effectiveness of the proposed framework for conditional generation, focusing particularly on complex PDE-based benchmarks. By enabling generative bridges between arbitrary functional distributions, our approach achieves state-of-the-art results, offering a powerful, general-purpose tool for scientific discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u6784\u5efa\u968f\u673a\u63d2\u503c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u539f\u672c\u5c40\u9650\u4e8e\u6709\u9650\u7ef4\u7684\u968f\u673a\u63d2\u503c\u65b9\u6cd5\u6269\u5c55\u5230\u51fd\u6570\u503c\u6570\u636e\uff0c\u4e3a\u4efb\u610f\u51fd\u6570\u5206\u5e03\u4e4b\u95f4\u7684\u751f\u6210\u6865\u63a5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5df2\u6210\u529f\u6269\u5c55\u5230\u51fd\u6570\u503c\u6570\u636e\uff0c\u4f46\u968f\u673a\u63d2\u503c\u65b9\u6cd5\uff08\u63d0\u4f9b\u8fde\u63a5\u4efb\u610f\u5206\u5e03\u7684\u7075\u6d3b\u65b9\u5f0f\uff09\u4ecd\u5c40\u9650\u4e8e\u6709\u9650\u7ef4\u8bbe\u7f6e\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u968f\u673a\u63d2\u503c\u5efa\u7acb\u4e25\u683c\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u968f\u673a\u63d2\u503c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u8bc1\u660e\u9002\u5b9a\u6027\u548c\u63d0\u4f9b\u663e\u5f0f\u8bef\u5dee\u754c\u3002\u5c06\u6846\u67b6\u5e94\u7528\u4e8e\u6761\u4ef6\u751f\u6210\uff0c\u7279\u522b\u5173\u6ce8\u590d\u6742\u7684\u57fa\u4e8ePDE\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u4efb\u610f\u51fd\u6570\u5206\u5e03\u4e4b\u95f4\u7684\u751f\u6210\u6865\u63a5\uff0c\u5728\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684PDE\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u65e0\u9650\u7ef4\u7a7a\u95f4\u4e2d\u7684\u968f\u673a\u63d2\u503c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u5176\u6210\u4e3a\u79d1\u5b66\u53d1\u73b0\u7684\u5f3a\u5927\u901a\u7528\u5de5\u5177\uff0c\u6210\u529f\u5c06\u968f\u673a\u63d2\u503c\u65b9\u6cd5\u4ece\u6709\u9650\u7ef4\u6269\u5c55\u5230\u51fd\u6570\u503c\u6570\u636e\u9886\u57df\u3002"}}
{"id": "2602.02113", "categories": ["stat.ML", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.02113", "abs": "https://arxiv.org/abs/2602.02113", "authors": ["Minglei Yang", "Sicheng He"], "title": "Training-free score-based diffusion for parameter-dependent stochastic dynamical systems", "comment": null, "summary": "Simulating parameter-dependent stochastic differential equations (SDEs) presents significant computational challenges, as separate high-fidelity simulations are typically required for each parameter value of interest. Despite the success of machine learning methods in learning SDE dynamics, existing approaches either require expensive neural network training for score function estimation or lack the ability to handle continuous parameter dependence. We present a training-free conditional diffusion model framework for learning stochastic flow maps of parameter-dependent SDEs, where both drift and diffusion coefficients depend on physical parameters. The key technical innovation is a joint kernel-weighted Monte Carlo estimator that approximates the conditional score function using trajectory data sampled at discrete parameter values, enabling interpolation across both state space and the continuous parameter domain. Once trained, the resulting generative model produces sample trajectories for any parameter value within the training range without retraining, significantly accelerating parameter studies, uncertainty quantification, and real-time filtering applications. The performance of the proposed approach is demonstrated via three numerical examples of increasing complexity, showing accurate approximation of conditional distributions across varying parameter values.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u53c2\u6570\u4f9d\u8d56SDE\u7684\u968f\u673a\u6d41\u6620\u5c04\uff0c\u901a\u8fc7\u8054\u5408\u6838\u52a0\u6743\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u8fd1\u4f3c\u6761\u4ef6\u5f97\u5206\u51fd\u6570\uff0c\u5b9e\u73b0\u53c2\u6570\u57df\u5185\u63d2\u503c\u3002", "motivation": "\u6a21\u62df\u53c2\u6570\u4f9d\u8d56\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5bf9\u6bcf\u4e2a\u53c2\u6570\u503c\u5355\u72ec\u8fdb\u884c\u9ad8\u4fdd\u771f\u6a21\u62df\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6765\u4f30\u8ba1\u5f97\u5206\u51fd\u6570\uff0c\u8981\u4e48\u65e0\u6cd5\u5904\u7406\u8fde\u7eed\u53c2\u6570\u4f9d\u8d56\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u514d\u8d39\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u4f7f\u7528\u8054\u5408\u6838\u52a0\u6743\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u8fd1\u4f3c\u6761\u4ef6\u5f97\u5206\u51fd\u6570\u3002\u8be5\u4f30\u8ba1\u5668\u5229\u7528\u79bb\u6563\u53c2\u6570\u503c\u91c7\u6837\u7684\u8f68\u8ff9\u6570\u636e\uff0c\u5b9e\u73b0\u72b6\u6001\u7a7a\u95f4\u548c\u8fde\u7eed\u53c2\u6570\u57df\u7684\u53cc\u91cd\u63d2\u503c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u6570\u503c\u793a\u4f8b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u51c6\u786e\u8fd1\u4f3c\u4e0d\u540c\u53c2\u6570\u503c\u4e0b\u7684\u6761\u4ef6\u5206\u5e03\u3002\u8bad\u7ec3\u540e\u7684\u751f\u6210\u6a21\u578b\u53ef\u5728\u8bad\u7ec3\u8303\u56f4\u5185\u4e3a\u4efb\u610f\u53c2\u6570\u503c\u751f\u6210\u6837\u672c\u8f68\u8ff9\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u52a0\u901f\u4e86\u53c2\u6570\u7814\u7a76\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5b9e\u65f6\u6ee4\u6ce2\u5e94\u7528\uff0c\u4e3a\u89e3\u51b3\u53c2\u6570\u4f9d\u8d56SDE\u7684\u6a21\u62df\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2602.02153", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02153", "abs": "https://arxiv.org/abs/2602.02153", "authors": ["Onat Ure", "Samet Demir", "Zafer Dogan"], "title": "Learning Beyond the Gaussian Data: Learning Dynamics of Neural Networks on an Expressive and Cumulant-Controllable Data Model", "comment": "ICASSP 2026, 5 pages, 2 figures", "summary": "We study the effect of high-order statistics of data on the learning dynamics of neural networks (NNs) by using a moment-controllable non-Gaussian data model. Considering the expressivity of two-layer neural networks, we first construct the data model as a generative two-layer NN where the activation function is expanded by using Hermite polynomials. This allows us to achieve interpretable control over high-order cumulants such as skewness and kurtosis through the Hermite coefficients while keeping the data model realistic. Using samples generated from the data model, we perform controlled online learning experiments with a two-layer NN. Our results reveal a moment-wise progression in training: networks first capture low-order statistics such as mean and covariance, and progressively learn high-order cumulants. Finally, we pretrain the generative model on the Fashion-MNIST dataset and leverage the generated samples for further experiments. The results of these additional experiments confirm our conclusions and show the utility of the data model in a real-world scenario. Overall, our proposed approach bridges simplified data assumptions and practical data complexity, which offers a principled framework for investigating distributional effects in machine learning and signal processing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u53ef\u63a7\u5236\u9ad8\u9636\u7edf\u8ba1\u91cf\u7684\u975e\u9ad8\u65af\u6570\u636e\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4ece\u4f4e\u9636\u7edf\u8ba1\u91cf\u5230\u9ad8\u9636\u7edf\u8ba1\u91cf\u7684\u6e10\u8fdb\u5b66\u4e60\u89c4\u5f8b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u6570\u636e\u7684\u9ad8\u9636\u7edf\u8ba1\u91cf\uff08\u5982\u504f\u5ea6\u548c\u5cf0\u5ea6\uff09\u5982\u4f55\u5f71\u54cd\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u52a8\u6001\u3002\u5f53\u524d\u7814\u7a76\u591a\u57fa\u4e8e\u7b80\u5316\u7684\u9ad8\u65af\u6570\u636e\u5047\u8bbe\uff0c\u800c\u5b9e\u9645\u6570\u636e\u5177\u6709\u590d\u6742\u7684\u975e\u9ad8\u65af\u7279\u6027\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u6570\u636e\u6a21\u578b\u6765\u63a2\u7a76\u5206\u5e03\u7279\u6027\u5bf9\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u6784\u5efa\u57fa\u4e8e\u751f\u6210\u5f0f\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u63a7\u975e\u9ad8\u65af\u6570\u636e\u6a21\u578b\uff0c\u4f7f\u7528Hermite\u591a\u9879\u5f0f\u5c55\u5f00\u6fc0\u6d3b\u51fd\u6570\u4ee5\u63a7\u5236\u9ad8\u9636\u7d2f\u79ef\u91cf\uff1b2\uff09\u7528\u8be5\u6570\u636e\u6a21\u578b\u751f\u6210\u6837\u672c\u8fdb\u884c\u53d7\u63a7\u5728\u7ebf\u5b66\u4e60\u5b9e\u9a8c\uff1b3\uff09\u5728Fashion-MNIST\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u9a8c\u8bc1\u7ed3\u8bba\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\"\u77e9\u7ea7\u6e10\u8fdb\"\u73b0\u8c61\uff1a\u7f51\u7edc\u9996\u5148\u5b66\u4e60\u4f4e\u9636\u7edf\u8ba1\u91cf\uff08\u5747\u503c\u548c\u534f\u65b9\u5dee\uff09\uff0c\u7136\u540e\u9010\u6b65\u5b66\u4e60\u9ad8\u9636\u7d2f\u79ef\u91cf\u3002\u5728Fashion-MNIST\u4e0a\u7684\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u8fd9\u4e00\u7ed3\u8bba\uff0c\u5e76\u5c55\u793a\u4e86\u6570\u636e\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7b80\u5316\u6570\u636e\u5047\u8bbe\u548c\u5b9e\u9645\u6570\u636e\u590d\u6742\u6027\u4e4b\u95f4\u5efa\u7acb\u4e86\u6865\u6881\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u548c\u4fe1\u53f7\u5904\u7406\u4e2d\u7814\u7a76\u5206\u5e03\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7edf\u8ba1\u89c4\u5f8b\u3002"}}
{"id": "2602.02190", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02190", "abs": "https://arxiv.org/abs/2602.02190", "authors": ["Gachon Erell", "J\u00e9r\u00e9mie Bigot", "Elsa Cazelles"], "title": "PCA of probability measures: Sparse and Dense sampling regimes", "comment": null, "summary": "A common approach to perform PCA on probability measures is to embed them into a Hilbert space where standard functional PCA techniques apply. While convergence rates for estimating the embedding of a single measure from $m$ samples are well understood, the literature has not addressed the setting involving multiple measures. In this paper, we study PCA in a double asymptotic regime where $n$ probability measures are observed, each through $m$ samples. We derive convergence rates of the form $n^{-1/2} + m^{-\u03b1}$ for the empirical covariance operator and the PCA excess risk, where $\u03b1>0$ depends on the chosen embedding. This characterizes the relationship between the number $n$ of measures and the number $m$ of samples per measure, revealing a sparse (small $m$) to dense (large $m$) transition in the convergence behavior. Moreover, we prove that the dense-regime rate is minimax optimal for the empirical covariance error. Our numerical experiments validate these theoretical rates and demonstrate that appropriate subsampling preserves PCA accuracy while reducing computational cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6982\u7387\u6d4b\u5ea6PCA\u7684\u53cc\u91cd\u6e10\u8fd1\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u534f\u65b9\u5dee\u7b97\u5b50\u548cPCA\u8d85\u989d\u98ce\u9669\u7684\u6536\u655b\u901f\u7387\uff0c\u63ed\u793a\u4e86\u4ece\u7a00\u758f\u5230\u5bc6\u96c6\u7684\u8fc7\u6e21\u884c\u4e3a\uff0c\u5e76\u8bc1\u660e\u4e86\u5bc6\u96c6\u533a\u57df\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u4ecem\u4e2a\u6837\u672c\u4f30\u8ba1\u5355\u4e2a\u6d4b\u5ea6\u5d4c\u5165\u7684\u6536\u655b\u901f\u7387\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6d89\u53ca\u591a\u4e2a\u6d4b\u5ea6\u7684PCA\u6536\u655b\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u5f53\u89c2\u6d4b\u5230n\u4e2a\u6982\u7387\u6d4b\u5ea6\u4e14\u6bcf\u4e2a\u6d4b\u5ea6\u6709m\u4e2a\u6837\u672c\u65f6\u7684PCA\u6536\u655b\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u6e10\u8fd1\u6846\u67b6\uff0c\u5c06\u6982\u7387\u6d4b\u5ea6\u5d4c\u5165\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u7136\u540e\u5e94\u7528\u6807\u51c6\u51fd\u6570PCA\u6280\u672f\u3002\u7406\u8bba\u5206\u6790\u63a8\u5bfc\u4e86\u7ecf\u9a8c\u534f\u65b9\u5dee\u7b97\u5b50\u548cPCA\u8d85\u989d\u98ce\u9669\u7684\u6536\u655b\u901f\u7387\uff0c\u5f62\u5f0f\u4e3an^{-1/2} + m^{-\u03b1}\uff0c\u5176\u4e2d\u03b1\u53d6\u51b3\u4e8e\u5d4c\u5165\u9009\u62e9\u3002\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u63a2\u7d22\u5b50\u91c7\u6837\u7b56\u7565\u3002", "result": "\u5efa\u7acb\u4e86\u6536\u655b\u901f\u7387n^{-1/2} + m^{-\u03b1}\uff0c\u63ed\u793a\u4e86\u4ece\u7a00\u758f\uff08\u5c0fm\uff09\u5230\u5bc6\u96c6\uff08\u5927m\uff09\u7684\u8fc7\u6e21\u884c\u4e3a\u3002\u8bc1\u660e\u4e86\u5bc6\u96c6\u533a\u57df\u7684\u7ecf\u9a8c\u534f\u65b9\u5dee\u8bef\u5dee\u662f\u6700\u5c0f\u6700\u5927\u6700\u4f18\u7684\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u901f\u7387\uff0c\u5e76\u663e\u793a\u9002\u5f53\u5b50\u91c7\u6837\u80fd\u5728\u4fdd\u6301PCA\u7cbe\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u591a\u6d4b\u5ea6PCA\u7684\u53cc\u91cd\u6e10\u8fd1\u6536\u655b\u884c\u4e3a\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u6307\u5bfc\u3002\u7814\u7a76\u63ed\u793a\u4e86\u6837\u672c\u6570\u91cf\u4e0e\u6d4b\u5ea6\u6570\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u8d44\u6e90\u5206\u914d\u548c\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2602.02358", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02358", "abs": "https://arxiv.org/abs/2602.02358", "authors": ["Yikun Zhang", "Steven Wilkins-Reeves", "Wesley Lee", "Aude Hofleitner"], "title": "Transfer Learning Through Conditional Quantile Matching", "comment": "24 pages (8 pages for the main paper), 3 figures, 3 tables", "summary": "We introduce a transfer learning framework for regression that leverages heterogeneous source domains to improve predictive performance in a data-scarce target domain. Our approach learns a conditional generative model separately for each source domain and calibrates the generated responses to the target domain via conditional quantile matching. This distributional alignment step corrects general discrepancies between source and target domains without imposing restrictive assumptions such as covariate or label shift. The resulting framework provides a principled and flexible approach to high-quality data augmentation for downstream learning tasks in the target domain. From a theoretical perspective, we show that an empirical risk minimizer (ERM) trained on the augmented dataset achieves a tighter excess risk bound than the target-only ERM under mild conditions. In particular, we establish new convergence rates for the quantile matching estimator that governs the transfer bias-variance tradeoff. From a practical perspective, extensive simulations and real data applications demonstrate that the proposed method consistently improves prediction accuracy over target-only learning and competing transfer learning methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u56de\u5f52\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u8d28\u6e90\u57df\u6539\u5584\u6570\u636e\u7a00\u7f3a\u76ee\u6807\u57df\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u4f7f\u7528\u6761\u4ef6\u751f\u6210\u6a21\u578b\u548c\u5206\u4f4d\u6570\u5339\u914d\u8fdb\u884c\u5206\u5e03\u5bf9\u9f50", "motivation": "\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u76ee\u6807\u57df\u7684\u9884\u6d4b\u95ee\u9898\uff0c\u5229\u7528\u5f02\u8d28\u6e90\u57df\u7684\u77e5\u8bc6\u63d0\u5347\u6027\u80fd\uff0c\u907f\u514d\u4f20\u7edf\u8fc1\u79fb\u5b66\u4e60\u4e2d\u4e25\u683c\u7684\u5206\u5e03\u5047\u8bbe\u9650\u5236", "method": "\u4e3a\u6bcf\u4e2a\u6e90\u57df\u5b66\u4e60\u72ec\u7acb\u7684\u6761\u4ef6\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u6761\u4ef6\u5206\u4f4d\u6570\u5339\u914d\u5c06\u751f\u6210\u7684\u54cd\u5e94\u6821\u51c6\u5230\u76ee\u6807\u57df\uff0c\u5b9e\u73b0\u5206\u5e03\u5bf9\u9f50\u800c\u4e0d\u9700\u8981\u534f\u53d8\u91cf\u6216\u6807\u7b7e\u504f\u79fb\u7b49\u9650\u5236\u6027\u5047\u8bbe", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u5728\u589e\u5f3a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684ERM\u6bd4\u4ec5\u4f7f\u7528\u76ee\u6807\u6570\u636e\u7684ERM\u5177\u6709\u66f4\u7d27\u7684\u8fc7\u5269\u98ce\u9669\u754c\uff1b\u5b9e\u8df5\u9a8c\u8bc1\uff1a\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5e94\u7528\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u4ec5\u76ee\u6807\u57df\u5b66\u4e60\u548c\u7ade\u4e89\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0b\u6e38\u5b66\u4e60\u4efb\u52a1\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u7075\u6d3b\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027"}}
{"id": "2602.02406", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02406", "abs": "https://arxiv.org/abs/2602.02406", "authors": ["Tung Quoc Le", "Anh Tuan Nguyen", "Viet Anh Nguyen"], "title": "Provably Data-driven Multiple Hyper-parameter Tuning with Structured Loss Function", "comment": null, "summary": "Data-driven algorithm design automates hyperparameter tuning, but its statistical foundations remain limited because model performance can depend on hyperparameters in implicit and highly non-smooth ways. Existing guarantees focus on the simple case of a one-dimensional (scalar) hyperparameter. This leaves the practically important, multi-dimensional hyperparameter tuning setting unresolved. We address this open question by establishing the first general framework for establishing generalization guarantees for tuning multi-dimensional hyperparameters in data-driven settings. Our approach strengthens the generalization guarantee framework for semi-algebraic function classes by exploiting tools from real algebraic geometry, yielding sharper, more broadly applicable guarantees. We then extend the analysis to hyperparameter tuning using the validation loss under minimal assumptions, and derive improved bounds when additional structure is available. Finally, we demonstrate the scope of the framework with new learnability results, including data-driven weighted group lasso and weighted fused lasso.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u591a\u7ef4\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u6cdb\u5316\u4fdd\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u5b9e\u4ee3\u6570\u51e0\u4f55\u5de5\u5177\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u652f\u6491", "motivation": "\u5f53\u524d\u6570\u636e\u9a71\u52a8\u7684\u7b97\u6cd5\u8bbe\u8ba1\u7f3a\u4e4f\u7edf\u8ba1\u7406\u8bba\u57fa\u7840\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u591a\u7ef4\u8d85\u53c2\u6570\u8c03\u4f18\u95ee\u9898\uff0c\u73b0\u6709\u7406\u8bba\u53ea\u89e3\u51b3\u4e86\u6807\u91cf\u8d85\u53c2\u6570\u7684\u60c5\u51b5\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u8d85\u53c2\u6570\u5f80\u5f80\u662f\u591a\u7ef4\u7684\u4e14\u6027\u80fd\u4f9d\u8d56\u5173\u7cfb\u590d\u6742", "method": "\u901a\u8fc7\u52a0\u5f3a\u534a\u4ee3\u6570\u51fd\u6570\u7c7b\u7684\u6cdb\u5316\u4fdd\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u5b9e\u4ee3\u6570\u51e0\u4f55\u5de5\u5177\uff0c\u5efa\u7acb\u591a\u7ef4\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u6cdb\u5316\u7406\u8bba\uff0c\u5e76\u5728\u9a8c\u8bc1\u635f\u5931\u6700\u5c0f\u5316\u5047\u8bbe\u4e0b\u6269\u5c55\u5206\u6790\uff0c\u63a8\u5bfc\u51fa\u6539\u8fdb\u7684\u8fb9\u754c", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u591a\u7ef4\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u6cdb\u5316\u4fdd\u8bc1\u6846\u67b6\uff0c\u83b7\u5f97\u4e86\u66f4\u5c16\u9510\u3001\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u4fdd\u8bc1\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u5728\u52a0\u6743\u7ec4lasso\u548c\u52a0\u6743\u878d\u5408lasso\u7b49\u65b0\u53ef\u5b66\u4e60\u6027\u7ed3\u679c\u4e2d\u7684\u5e94\u7528", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u6570\u636e\u9a71\u52a8\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u591a\u7ef4\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7edf\u8ba1\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u7b97\u6cd5\u6848\u4f8b\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5e7f\u6cdb\u9002\u7528\u6027"}}
{"id": "2602.02431", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02431", "abs": "https://arxiv.org/abs/2602.02431", "authors": ["Filip Kova\u010devi\u0107", "Hong Chang Ji", "Denny Wu", "Mahdi Soltanolkotabi", "Marco Mondelli"], "title": "Full-Batch Gradient Descent Outperforms One-Pass SGD: Sample Complexity Separation in Single-Index Learning", "comment": null, "summary": "It is folklore that reusing training data more than once can improve the statistical efficiency of gradient-based learning. However, beyond linear regression, the theoretical advantage of full-batch gradient descent (GD, which always reuses all the data) over one-pass stochastic gradient descent (online SGD, which uses each data point only once) remains unclear. In this work, we consider learning a $d$-dimensional single-index model with a quadratic activation, for which it is known that one-pass SGD requires $n\\gtrsim d\\log d$ samples to achieve weak recovery. We first show that this $\\log d$ factor in the sample complexity persists for full-batch spherical GD on the correlation loss; however, by simply truncating the activation, full-batch GD exhibits a favorable optimization landscape at $n \\simeq d$ samples, thereby outperforming one-pass SGD (with the same activation) in statistical efficiency. We complement this result with a trajectory analysis of full-batch GD on the squared loss from small initialization, showing that $n \\gtrsim d$ samples and $T \\gtrsim\\log d$ gradient steps suffice to achieve strong (exact) recovery.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5168\u6279\u6b21\u68af\u5ea6\u4e0b\u964d(GD)\u4e0e\u5355\u6b21\u968f\u673a\u68af\u5ea6\u4e0b\u964d(online SGD)\u5728\u7edf\u8ba1\u6548\u7387\u4e0a\u7684\u7406\u8bba\u5dee\u5f02\uff0c\u53d1\u73b0\u5728\u5b66\u4e60\u4e8c\u6b21\u6fc0\u6d3b\u7684\u5355\u7d22\u5f15\u6a21\u578b\u65f6\uff0c\u901a\u8fc7\u622a\u65ad\u6fc0\u6d3b\u51fd\u6570\uff0c\u5168\u6279\u6b21GD\u53ef\u4ee5\u5728n\u2248d\u6837\u672c\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u4f18\u5316\u666f\u89c2\uff0c\u4ece\u800c\u8d85\u8d8a\u5355\u6b21SGD\u3002", "motivation": "\u867d\u7136\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u91cd\u590d\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u63d0\u9ad8\u68af\u5ea6\u5b66\u4e60\u7684\u7edf\u8ba1\u6548\u7387\uff0c\u4f46\u9664\u4e86\u7ebf\u6027\u56de\u5f52\u4e4b\u5916\uff0c\u5168\u6279\u6b21\u68af\u5ea6\u4e0b\u964d(GD)\u76f8\u5bf9\u4e8e\u5355\u6b21\u968f\u673a\u68af\u5ea6\u4e0b\u964d(online SGD)\u7684\u7406\u8bba\u4f18\u52bf\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u66f4\u590d\u6742\u7684\u6a21\u578b\uff08\u5982\u5355\u7d22\u5f15\u6a21\u578b\uff09\u4e2d\uff0c\u6570\u636e\u91cd\u7528\u662f\u5426\u80fd\u5e26\u6765\u7edf\u8ba1\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002", "method": "\u7814\u7a76d\u7ef4\u4e8c\u6b21\u6fc0\u6d3b\u7684\u5355\u7d22\u5f15\u6a21\u578b\u5b66\u4e60\u95ee\u9898\u3002\u9996\u5148\u5206\u6790\u5168\u6279\u6b21\u7403\u5f62GD\u5728\u76f8\u5173\u6027\u635f\u5931\u4e0a\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u53d1\u73b0\u5176\u4e0e\u5355\u6b21SGD\u4e00\u6837\u9700\u8981n\u2273d log d\u6837\u672c\u3002\u7136\u540e\u901a\u8fc7\u622a\u65ad\u6fc0\u6d3b\u51fd\u6570\uff0c\u5206\u6790\u5168\u6279\u6b21GD\u5728\u5e73\u65b9\u635f\u5931\u4e0a\u7684\u4f18\u5316\u666f\u89c2\u3002\u6700\u540e\u5bf9\u4ece\u5c0f\u521d\u59cb\u5316\u5f00\u59cb\u7684\u5168\u6279\u6b21GD\u8f68\u8ff9\u8fdb\u884c\u5206\u6790\u3002", "result": "1. \u5168\u6279\u6b21\u7403\u5f62GD\u5728\u76f8\u5173\u6027\u635f\u5931\u4e0a\u9700\u8981n\u2273d log d\u6837\u672c\u624d\u80fd\u5b9e\u73b0\u5f31\u6062\u590d\uff0c\u4e0e\u5355\u6b21SGD\u76f8\u540c\uff1b2. \u901a\u8fc7\u622a\u65ad\u6fc0\u6d3b\u51fd\u6570\uff0c\u5168\u6279\u6b21GD\u5728n\u2248d\u6837\u672c\u4e0b\u5c55\u73b0\u51fa\u6709\u5229\u7684\u4f18\u5316\u666f\u89c2\uff0c\u7edf\u8ba1\u6548\u7387\u4f18\u4e8e\u5355\u6b21SGD\uff1b3. \u4ece\u5c0f\u521d\u59cb\u5316\u5f00\u59cb\u7684\u5168\u6279\u6b21GD\u5728\u5e73\u65b9\u635f\u5931\u4e0a\uff0cn\u2273d\u6837\u672c\u548cT\u2273log d\u68af\u5ea6\u6b65\u6570\u8db3\u4ee5\u5b9e\u73b0\u5f3a\u6062\u590d\u3002", "conclusion": "\u6570\u636e\u91cd\u7528\u786e\u5b9e\u80fd\u63d0\u9ad8\u7edf\u8ba1\u6548\u7387\uff0c\u4f46\u9700\u8981\u9002\u5f53\u7684\u6fc0\u6d3b\u51fd\u6570\u8bbe\u8ba1\uff08\u5982\u622a\u65ad\uff09\u3002\u5bf9\u4e8e\u4e8c\u6b21\u6fc0\u6d3b\u7684\u5355\u7d22\u5f15\u6a21\u578b\uff0c\u5168\u6279\u6b21GD\u901a\u8fc7\u622a\u65ad\u6fc0\u6d3b\u53ef\u4ee5\u5728n\u2248d\u6837\u672c\u4e0b\u8d85\u8d8a\u5355\u6b21SGD\uff0c\u800c\u5355\u6b21SGD\u9700\u8981n\u2273d log d\u6837\u672c\u3002\u8fd9\u4e3a\u7406\u89e3\u6570\u636e\u91cd\u7528\u5728\u4e0d\u540c\u5b66\u4e60\u7b97\u6cd5\u4e2d\u7684\u4f18\u52bf\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
